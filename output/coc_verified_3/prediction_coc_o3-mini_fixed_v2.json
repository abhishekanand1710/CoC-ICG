[
    {
        "instance_id": "astropy__astropy-12907",
        "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..126e77b3eb 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -211,7 +211,8 @@ def _coord_matrix(model, pos, noutp):\n \n         for i in range(model.n_inputs):\n             mat[i, i] = 1\n-        if pos == 'right':\n+            mat = np.roll(mat, (noutp - model.n_outputs), axis=0)\n+\n             mat = np.roll(mat, (noutp - model.n_outputs))\n     return mat\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13033",
        "model_patch": "diff --git a/astropy/timeseries/core.py b/astropy/timeseries/core.py\nindex c279f35f87..27e3f16138 100644\n--- a/astropy/timeseries/core.py\n+++ b/astropy/timeseries/core.py\n@@ -68,17 +68,17 @@ class BaseTimeSeries(QTable):\n \n             plural = 's' if len(required_columns) > 1 else ''\n \n-            if not self._required_columns_relax and len(self.colnames) == 0:\n+if not self._required_columns_relax and len(self.colnames) == 0:\n+    raise ValueError(\"{} object is invalid - expected '{}' as the first column{} but time series has no columns\"\n+                     .format(self.__class__.__name__, required_columns[0], plural))\n+elif len(self.colnames) < len(required_columns):\n+    missing = required_columns[len(self.colnames):]\n+    raise ValueError(\"{} object is invalid - missing required column(s): {}\"\n+                     .format(self.__class__.__name__, missing))\n+elif self.colnames[:len(required_columns)] != required_columns:\n+    raise ValueError(\"{} object is invalid - expected first columns '{}' but found '{}'\"\n+                     .format(self.__class__.__name__, required_columns, self.colnames[:len(required_columns)]))\n \n-                raise ValueError(\"{} object is invalid - expected '{}' \"\n-                                 \"as the first column{} but time series has no columns\"\n-                                 .format(self.__class__.__name__, required_columns[0], plural))\n-\n-            elif self.colnames[:len(required_columns)] != required_columns:\n-\n-                raise ValueError(\"{} object is invalid - expected '{}' \"\n-                                 \"as the first column{} but found '{}'\"\n-                                 .format(self.__class__.__name__, required_columns[0], plural, self.colnames[0]))\n \n             if (self._required_columns_relax\n                     and self._required_columns == self.colnames[:len(self._required_columns)]):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13236",
        "model_patch": "diff --git a/astropy/table/column.py b/astropy/table/column.py\nindex 43e04d1975..0570eddc06 100644\n--- a/astropy/table/column.py\n+++ b/astropy/table/column.py\n@@ -247,14 +247,18 @@ def _convert_sequence_data_to_array(data, dtype=None):\n     context = {'ma_masked': np.ma.masked, 'data': data}\n     has_masked = eval(any_statement, context)\n \n-    # If there are any masks then explicitly change each one to a fill value and\n-    # set a mask boolean array. If not has_masked then we're done.\n-    if has_masked:\n-        mask = np.zeros(np_data.shape, dtype=bool)\n-        data_filled = np.array(data, dtype=object)\n-\n-        # Make type-appropriate fill value based on initial conversion.\n-        if np_data.dtype.kind == 'U':\n+        # Structured ndarray gets viewed as a mixin unless already a valid\n+        # mixin class.\n+        # NOTE: Auto-conversion of structured ndarray is deprecated.\n+        # Please wrap your structured array in a Column explicitly.\n+        # In a future release (v5.2) the array will be added directly as a Column.\n+        if (not isinstance(data, Column) and not data_is_mixin\n+                and isinstance(data, np.ndarray) and len(data.dtype) > 1):\n+            import warnings\n+            warnings.warn(\"Passing a structured ndarray to a Table is deprecated; please wrap it in a Column. In a future release (v5.2) the array will be added directly as a Column.\", FutureWarning)\n+            data = data.view(NdarrayMixin)\n+            data_is_mixin = True\n+\n             fill = ''\n         elif np_data.dtype.kind == 'S':\n             fill = b''\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13398",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13453",
        "model_patch": "diff --git a/astropy/io/ascii/html.py b/astropy/io/ascii/html.py\nindex 266cf229cc..26de641718 100644\n--- a/astropy/io/ascii/html.py\n+++ b/astropy/io/ascii/html.py\n@@ -346,6 +346,175 @@ class HTML(core.BaseReader):\n         # Check that table has only 1-d or 2-d columns. Above that fails.\n         self._check_multidim_table(table)\n \n+# Apply any user-specified formats to table columns (as in other writers)\n+\n+\n+self.cols = cols\n+\n+\n+if hasattr(self, 'formats') and self.formats:\n+\n+\n+    self._set_col_formats()\n+\n+\n         cols = list(table.columns.values())\n \n         self.data.header.cols = cols\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13579",
        "model_patch": "diff --git a/astropy/wcs/wcsapi/wrappers/sliced_wcs.py b/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\nindex d7605b078c..85fde03146 100644\n--- a/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\n+++ b/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\n@@ -244,14 +244,18 @@ class SlicedLowLevelWCS(BaseWCSWrapper):\n \n     def world_to_pixel_values(self, *world_arrays):\n         world_arrays = tuple(map(np.asanyarray, world_arrays))\n-        world_arrays_new = []\n-        iworld_curr = -1\n-        for iworld in range(self._wcs.world_n_dim):\n-            if iworld in self._world_keep:\n-                iworld_curr += 1\n-                world_arrays_new.append(world_arrays[iworld_curr])\n-            else:\n-                world_arrays_new.append(1.)\n+    world_arrays_new = []\n+    iworld_curr = -1\n+    # Compute reference world coordinates for dropped axes using the underlying WCS.\n+    # This ensures we use the proper CRVAL-like value instead of the hardcoded 1.0.\n+    ref_world = self._wcs.pixel_to_world_values(*([0] * len(self._pixel_keep)))\n+    for iworld in range(self._wcs.world_n_dim):\n+        if iworld in self._world_keep:\n+            iworld_curr += 1\n+            world_arrays_new.append(world_arrays[iworld_curr])\n+        else:\n+            world_arrays_new.append(ref_world[iworld])\n+\n \n         world_arrays_new = np.broadcast_arrays(*world_arrays_new)\n         pixel_arrays = list(self._wcs.world_to_pixel_values(*world_arrays_new))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13977",
        "model_patch": "diff --git a/astropy/units/quantity.py b/astropy/units/quantity.py\nindex b98abfafb0..bae1bfdccc 100644\n--- a/astropy/units/quantity.py\n+++ b/astropy/units/quantity.py\n@@ -665,9 +665,14 @@ class Quantity(np.ndarray):\n \n         # Same for inputs, but here also convert if necessary.\n         arrays = []\n+        arrays = []\n         for input_, converter in zip(inputs, converters):\n             input_ = getattr(input_, \"value\", input_)\n-            arrays.append(converter(input_) if converter else input_)\n+            try:\n+                converted = converter(input_) if converter else input_\n+            except ValueError:\n+                return NotImplemented\n+            arrays.append(converted)\n \n         # Call our superclass's __array_ufunc__\n         result = super().__array_ufunc__(function, method, *arrays, **kwargs)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14096",
        "model_patch": "diff --git a/astropy/coordinates/sky_coordinate.py b/astropy/coordinates/sky_coordinate.py\nindex ab475f7d0d..48259e75e2 100644\n--- a/astropy/coordinates/sky_coordinate.py\n+++ b/astropy/coordinates/sky_coordinate.py\n@@ -866,38 +866,42 @@ class SkyCoord(ShapedLikeNDArray):\n             isinstance(self.frame.name, list) and string in self.frame.name\n         )\n \n-    def __getattr__(self, attr):\n-        \"\"\"\n-        Overrides getattr to return coordinates that this can be transformed\n-        to, based on the alias attr in the primary transform graph.\n-        \"\"\"\n-        if \"_sky_coord_frame\" in self.__dict__:\n-            if self._is_name(attr):\n-                return self  # Should this be a deepcopy of self?\n-\n-            # Anything in the set of all possible frame_attr_names is handled\n-            # here. If the attr is relevant for the current frame then delegate\n-            # to self.frame otherwise get it from self._<attr>.\n-            if attr in frame_transform_graph.frame_attributes:\n-                if attr in self.frame.frame_attributes:\n-                    return getattr(self.frame, attr)\n-                else:\n-                    return getattr(self, \"_\" + attr, None)\n-\n-            # Some attributes might not fall in the above category but still\n-            # are available through self._sky_coord_frame.\n-            if not attr.startswith(\"_\") and hasattr(self._sky_coord_frame, attr):\n-                return getattr(self._sky_coord_frame, attr)\n-\n-            # Try to interpret as a new frame for transforming.\n-            frame_cls = frame_transform_graph.lookup_name(attr)\n-            if frame_cls is not None and self.frame.is_transformable_to(frame_cls):\n-                return self.transform_to(attr)\n-\n-        # Fail\n-        raise AttributeError(\n-            f\"'{self.__class__.__name__}' object has no attribute '{attr}'\"\n-        )\n+def __getattr__(self, attr):\n+    # If the attribute is defined on the class (e.g. as a property),\n+    # then try to fetch it normally. This is important because if a property\n+    # (like \"prop\") is defined but its getter fails internally (because it\n+    # references a missing attribute such as \"random_attr\"), we want the error\n+    # to reflect the actual missing attribute and not switch to the fallback.\n+    if attr in type(self).__dict__:\n+        return object.__getattribute__(self, attr)\n+\n+    if \"_sky_coord_frame\" in self.__dict__:\n+        if self._is_name(attr):\n+            return self  # Should this be a deepcopy of self?\n+\n+        # Anything in the set of all possible frame_attr_names is handled\n+        # here. If the attr is relevant for the current frame then delegate\n+        # to self.frame otherwise get it from self._<attr>.\n+        if attr in frame_transform_graph.frame_attributes:\n+            if attr in self.frame.frame_attributes:\n+                return getattr(self.frame, attr)\n+            else:\n+                return getattr(self, \"_\" + attr, None)\n+\n+        # Some attributes might not fall in the above category but still\n+        # are available through self._sky_coord_frame.\n+        if not attr.startswith(\"_\") and hasattr(self._sky_coord_frame, attr):\n+            return getattr(self._sky_coord_frame, attr)\n+\n+        # Try to interpret as a new frame for transforming.\n+        frame_cls = frame_transform_graph.lookup_name(attr)\n+        if frame_cls is not None and self.frame.is_transformable_to(frame_cls):\n+            return self.transform_to(attr)\n+\n+    # Fail if nothing is found\n+    raise AttributeError(\n+        f\"'{self.__class__.__name__}' object has no attribute '{attr}'\"\n+    )\n \n     def __setattr__(self, attr, val):\n         # This is to make anything available through __getattr__ immutable\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14182",
        "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..414f06bf65 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -57,8 +57,8 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n-        super().__init__(delimiter_pad=None, bookend=False)\n+    def __init__(self, header_rows=None, **kwargs):\n+        super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows, **kwargs)\n \n     def write(self, lines):\n         lines = super().write(lines)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14309",
        "model_patch": "diff --git a/astropy/io/fits/connect.py b/astropy/io/fits/connect.py\nindex 4b6150f4ac..7eaa8f8886 100644\n--- a/astropy/io/fits/connect.py\n+++ b/astropy/io/fits/connect.py\n@@ -69,9 +69,12 @@ def is_fits(origin, filepath, fileobj, *args, **kwargs):\n             (\".fits\", \".fits.gz\", \".fit\", \".fit.gz\", \".fts\", \".fts.gz\")\n         ):\n             return True\n+    if not args:\n+        return False\n     return isinstance(args[0], (HDUList, TableHDU, BinTableHDU, GroupsHDU))\n \n \n+\n def _decode_mixins(tbl):\n     \"\"\"Decode a Table ``tbl`` that has astropy Columns + appropriate meta-data into\n     the corresponding table with mixin columns (as appropriate).\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14365",
        "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..4c56bd8e26 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -68,7 +68,8 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n+\n     line = line.strip()\n     if not line:\n         return \"comment\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14369",
        "model_patch": "diff --git a/astropy/units/format/cds.py b/astropy/units/format/cds.py\nindex 307e987ed6..f0c0958eae 100644\n--- a/astropy/units/format/cds.py\n+++ b/astropy/units/format/cds.py\n@@ -179,15 +179,223 @@ class CDS(Base):\n             else:\n                 p[0] = p[1]\n \n-        def p_division_of_units(p):\n-            \"\"\"\n-            division_of_units : DIVISION unit_expression\n-                              | unit_expression DIVISION combined_units\n-            \"\"\"\n-            if len(p) == 3:\n-                p[0] = p[2] ** -1\n-            else:\n-                p[0] = p[1] / p[3]\n+def p_division_of_units(p):\n+    \"\"\"\n+    division_of_units : unit_expression division_list\n+    \"\"\"\n+    # Fold divisions left-to-right so that:\n+    # J/m/s/kpc2  ->  ((J / m) / s) / kpc2\n+    result = p[1]\n+    for u in p[2]:\n+        result = result / u\n+    p[0] = result\n+\n+def p_division_list(p):\n+\n+\n+    \"\"\"\n+\n+\n+    division_list : DIVISION unit_expression division_list\n+\n+\n+                  | \n+\n+\n+    \"\"\"\n+\n+\n+    if len(p) == 4:\n+\n+\n+        p[0] = [p[2]] + p[3]\n+\n+\n+    else:\n+\n+\n+        p[0] = []\n+\n+\n \n         def p_unit_expression(p):\n             \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14508",
        "model_patch": "diff --git a/astropy/io/fits/card.py b/astropy/io/fits/card.py\nindex 118bfced89..d790b37f6a 100644\n--- a/astropy/io/fits/card.py\n+++ b/astropy/io/fits/card.py\n@@ -1298,36 +1298,36 @@ def _format_value(value):\n \n \n def _format_float(value):\n-    \"\"\"Format a floating number to make sure it gets the decimal point.\"\"\"\n-    value_str = f\"{value:.16G}\"\n-    if \".\" not in value_str and \"E\" not in value_str:\n-        value_str += \".0\"\n-    elif \"E\" in value_str:\n-        # On some Windows builds of Python (and possibly other platforms?) the\n-        # exponent is zero-padded out to, it seems, three digits.  Normalize\n-        # the format to pad only to two digits.\n-        significand, exponent = value_str.split(\"E\")\n-        if exponent[0] in (\"+\", \"-\"):\n-            sign = exponent[0]\n-            exponent = exponent[1:]\n-        else:\n-            sign = \"\"\n-        value_str = f\"{significand}E{sign}{int(exponent):02d}\"\n+    candidate = str(value)\n+    if \".\" not in candidate and \"E\" not in candidate and \"e\" not in candidate:\n+        candidate += \".0\"\n \n-    # Limit the value string to at most 20 characters.\n-    str_len = len(value_str)\n+    if len(candidate) <= 20:\n+        value_str = candidate\n+    else:\n+        value_str = f\"{value:.16G}\"\n+        if \".\" not in value_str and \"E\" not in value_str:\n+            value_str += \".0\"\n+        elif \"E\" in value_str:\n+            significand, exponent = value_str.split(\"E\")\n+            if exponent[0] in (\"+\", \"-\"):\n+                sign = exponent[0]\n+                exponent = exponent[1:]\n+            else:\n+                sign = \"\"\n+            value_str = f\"{significand}E{sign}{int(exponent):02d}\"\n \n-    if str_len > 20:\n+    if len(value_str) > 20:\n+        str_len = len(value_str)\n         idx = value_str.find(\"E\")\n-\n         if idx < 0:\n             value_str = value_str[:20]\n         else:\n             value_str = value_str[: 20 - (str_len - idx)] + value_str[idx:]\n-\n     return value_str\n \n \n+\n def _pad(input):\n     \"\"\"Pad blank space to the input string to be multiple of 80.\"\"\"\n     _len = len(input)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14539",
        "model_patch": "diff --git a/astropy/io/fits/diff.py b/astropy/io/fits/diff.py\nindex 100cdf1b8c..189aff5813 100644\n--- a/astropy/io/fits/diff.py\n+++ b/astropy/io/fits/diff.py\n@@ -1449,7 +1449,7 @@ class TableDataDiff(_BaseDiff):\n                 arrb.dtype, np.floating\n             ):\n                 diffs = where_not_allclose(arra, arrb, rtol=self.rtol, atol=self.atol)\n-            elif \"P\" in col.format:\n+            elif col.format and col.format[0] in (\"P\", \"Q\"):\n                 diffs = (\n                     [\n                         idx\n@@ -1462,6 +1462,7 @@ class TableDataDiff(_BaseDiff):\n             else:\n                 diffs = np.where(arra != arrb)\n \n+\n             self.diff_total += len(set(diffs[0]))\n \n             if self.numdiffs >= 0:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14598",
        "model_patch": "diff --git a/astropy/io/fits/card.py b/astropy/io/fits/card.py\nindex 1b3285ddce..e1439e19b3 100644\n--- a/astropy/io/fits/card.py\n+++ b/astropy/io/fits/card.py\n@@ -767,12 +767,13 @@ class Card(_Verify):\n \n         if m.group(\"bool\") is not None:\n             value = m.group(\"bool\") == \"T\"\n-        elif m.group(\"strg\") is not None:\n-            value = re.sub(\"''\", \"'\", m.group(\"strg\"))\n-        elif m.group(\"numr\") is not None:\n-            #  Check for numbers with leading 0s.\n-            numr = self._number_NFSC_RE.match(m.group(\"numr\"))\n-            digt = translate(numr.group(\"digt\"), FIX_FP_TABLE2, \" \")\n+elif m.group(\"strg\") is not None:\n+    # If exactly two single quotes, treat as a null string.\n+    if m.group(\"strg\") == \"''\":\n+        value = \"\"\n+    else:\n+        value = re.sub(\"''\", \"'\", m.group(\"strg\"))\n+\n             if numr.group(\"sign\") is None:\n                 sign = \"\"\n             else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14995",
        "model_patch": "diff --git a/astropy/nddata/mixins/ndarithmetic.py b/astropy/nddata/mixins/ndarithmetic.py\nindex 4153dfccb2..f8b1d014b9 100644\n--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -512,19 +512,28 @@ class NDArithmeticMixin:\n             If neither had a mask ``None`` is returned. Otherwise\n             ``handle_mask`` must create (and copy) the returned mask.\n         \"\"\"\n-        # If only one mask is present we need not bother about any type checks\n-        if (\n-            self.mask is None and operand is not None and operand.mask is None\n-        ) or handle_mask is None:\n+        # If no callable is provided for handling the mask, simply return None.\n+        if handle_mask is None:\n             return None\n-        elif self.mask is None and operand is not None:\n-            # Make a copy so there is no reference in the result.\n-            return deepcopy(operand.mask)\n-        elif operand is None:\n+\n+        # Check if self.mask is missing.\n+        if self.mask is None:\n+            if operand is not None and operand.mask is not None:\n+                return deepcopy(operand.mask)\n+            else:\n+                return None\n+\n+        # If operand is missing entirely, return a copy of self.mask.\n+        if operand is None:\n             return deepcopy(self.mask)\n-        else:\n-            # Now lets calculate the resulting mask (operation enforces copy)\n-            return handle_mask(self.mask, operand.mask, **kwds)\n+\n+        # If operand exists but its mask is missing, propagate self.mask.\n+        if operand.mask is None:\n+            return deepcopy(self.mask)\n+\n+        # Otherwise, both masks are present; apply the handle_mask callable.\n+        return handle_mask(self.mask, operand.mask, **kwds)\n+\n \n     def _arithmetic_wcs(self, operation, operand, compare_wcs, **kwds):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-7166",
        "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d18..b8bf306126 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -520,24 +520,39 @@ class InheritDocstrings(type):\n         u'Wiggle the thingamajig'\n     \"\"\"\n \n-    def __init__(cls, name, bases, dct):\n-        def is_public_member(key):\n-            return (\n-                (key.startswith('__') and key.endswith('__')\n-                 and len(key) > 4) or\n-                not key.startswith('_'))\n-\n-        for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n-                is_public_member(key) and\n-                val.__doc__ is None):\n-                for base in cls.__mro__[1:]:\n-                    super_method = getattr(base, key, None)\n-                    if super_method is not None:\n-                        val.__doc__ = super_method.__doc__\n-                        break\n-\n-        super().__init__(name, bases, dct)\n+def __init__(cls, name, bases, dct):\n+    def is_public_member(key):\n+        return (\n+            (key.startswith('__') and key.endswith('__') and len(key) > 4) or\n+            not key.startswith('_'))\n+    \n+    for key, val in dct.items():\n+        # Process both normal functions and properties.\n+        if ((inspect.isfunction(val) or isinstance(val, property))\n+            and is_public_member(key)):\n+            if isinstance(val, property):\n+                # For property objects, check if the getter lacks a docstring.\n+                if val.fget.__doc__ is None:\n+                    for base in cls.__mro__[1:]:\n+                        super_prop = getattr(base, key, None)\n+                        if (isinstance(super_prop, property) and\n+                            super_prop.fget.__doc__):\n+                            inherited_doc = super_prop.fget.__doc__\n+                            # Create a new property with the inherited docstring.\n+                            new_prop = property(val.fget, val.fset, val.fdel, inherited_doc)\n+                            dct[key] = new_prop\n+                            break\n+            else:\n+                # For normal functions, behave as before.\n+                if val.__doc__ is None:\n+                    for base in cls.__mro__[1:]:\n+                        super_method = getattr(base, key, None)\n+                        if super_method is not None and super_method.__doc__:\n+                            val.__doc__ = super_method.__doc__\n+                            break\n+                         \n+    super().__init__(name, bases, dct)\n+\n \n \n class OrderedDescriptor(metaclass=abc.ABCMeta):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-7336",
        "model_patch": "diff --git a/astropy/units/decorators.py b/astropy/units/decorators.py\nindex 8bece5a850..002ee81879 100644\n--- a/astropy/units/decorators.py\n+++ b/astropy/units/decorators.py\n@@ -217,14 +217,16 @@ class QuantityInput:\n                 _validate_arg_value(param.name, wrapped_function.__name__,\n                                     arg, valid_targets, self.equivalencies)\n \n-            # Call the original function with any equivalencies in force.\n             with add_enabled_equivalencies(self.equivalencies):\n                 return_ = wrapped_function(*func_args, **func_kwargs)\n+            if return_ is None:\n+                return None\n             if wrapped_signature.return_annotation is not inspect.Signature.empty:\n                 return return_.to(wrapped_signature.return_annotation)\n             else:\n                 return return_\n \n+\n         return wrapper\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-7606",
        "model_patch": "diff --git a/astropy/units/core.py b/astropy/units/core.py\nindex e9bd986d33..57013e6cee 100644\n--- a/astropy/units/core.py\n+++ b/astropy/units/core.py\n@@ -1696,11 +1696,12 @@ class UnrecognizedUnit(IrreducibleUnit):\n \n     def __str__(self):\n         return self.name\n+        # Return False immediately if other is None, since None cannot represent a valid unit.\n+        if other is None:\n+            return False\n+        other = Unit(other, parse_strict='silent')\n+        return isinstance(other, UnrecognizedUnit) and self.name == other.name\n \n-    def to_string(self, format=None):\n-        return self.name\n-\n-    def _unrecognized_operator(self, *args, **kwargs):\n         raise ValueError(\n             \"The unit {0!r} is unrecognized, so all arithmetic operations \"\n             \"with it are invalid.\".format(self.name))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-7671",
        "model_patch": "diff --git a/astropy/utils/introspection.py b/astropy/utils/introspection.py\nindex 3e784f9fc3..a641e8b001 100644\n--- a/astropy/utils/introspection.py\n+++ b/astropy/utils/introspection.py\n@@ -7,6 +7,60 @@ import inspect\n import types\n import importlib\n from distutils.version import LooseVersion\n+from packaging.version import parse as parse_version\n+\n+\n \n \n __all__ = ['resolve_name', 'minversion', 'find_current_module',\n@@ -140,9 +194,10 @@ def minversion(module, version, inclusive=True, version_path='__version__'):\n         have_version = resolve_name(module.__name__, version_path)\n \n     if inclusive:\n-        return LooseVersion(have_version) >= LooseVersion(version)\n+        return parse_version(have_version) >= parse_version(version)\n     else:\n-        return LooseVersion(have_version) > LooseVersion(version)\n+        return parse_version(have_version) > parse_version(version)\n+\n \n \n def find_current_module(depth=1, finddiff=False):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-8707",
        "model_patch": "diff --git a/astropy/io/fits/card.py b/astropy/io/fits/card.py\nindex 8c1ac5d738..5bc68f2487 100644\n--- a/astropy/io/fits/card.py\n+++ b/astropy/io/fits/card.py\n@@ -13,6 +13,84 @@ from astropy.utils.exceptions import AstropyUserWarning\n \n \n __all__ = ['Card', 'Undefined']\n+        if isinstance(card, bytes):\n+\n+\n+            card = card.decode('ascii')\n+\n+\n \n \n FIX_FP_TABLE = str.maketrans('de', 'DE')\ndiff --git a/astropy/io/fits/header.py b/astropy/io/fits/header.py\nindex ad07e6d52d..29254cff1b 100644\n--- a/astropy/io/fits/header.py\n+++ b/astropy/io/fits/header.py\n@@ -347,6 +347,76 @@ class Header:\n         header\n             A new `Header` instance.\n         \"\"\"\n+    if isinstance(data, bytes):\n+\n+\n+        data = data.decode('ascii')\n+\n+\n \n         cards = []\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-8872",
        "model_patch": "diff --git a/astropy/units/quantity.py b/astropy/units/quantity.py\nindex ded609cbe9..3ae9a4f871 100644\n--- a/astropy/units/quantity.py\n+++ b/astropy/units/quantity.py\n@@ -376,12 +376,15 @@ class Quantity(np.ndarray, metaclass=InheritDocstrings):\n             raise TypeError(\"The value must be a valid Python or \"\n                             \"Numpy numeric type.\")\n \n-        # by default, cast any integer, boolean, etc., to float\n-        if dtype is None and (not (np.can_cast(np.float32, value.dtype)\n-                                   or value.dtype.fields)\n+        # by default, cast any integer, boolean, or non-floating types to float.\n+        # If the value is already a floating-point type (e.g. np.float16),\n+        # we preserve its dtype.\n+        if dtype is None and (not np.issubdtype(value.dtype, np.floating)\n+                              or value.dtype.fields\n                               or value.dtype.kind == 'O'):\n             value = value.astype(float)\n \n+\n         value = value.view(cls)\n         value._set_unit(value_unit)\n         if unit is value_unit:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10097",
        "model_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex 92394a7eae..e116d4c478 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -92,13 +92,14 @@ class URLValidator(RegexValidator):\n     )\n     host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'\n \n-    regex = _lazy_re_compile(\n-        r'^(?:[a-z0-9\\.\\-\\+]*)://'  # scheme is validated separately\n-        r'(?:\\S+(?::\\S*)?@)?'  # user:pass authentication\n-        r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n-        r'(?::\\d{2,5})?'  # port\n-        r'(?:[/?#][^\\s]*)?'  # resource path\n-        r'\\Z', re.IGNORECASE)\n+regex = _lazy_re_compile(\n+    r'^(?:[a-z0-9\\.\\-\\+]*)://'  # scheme is validated separately\n+    r'(?:[^\\s:@/]+(?::[^\\s:@/]+)?@)?'  # user:pass authentication, disallowing unencoded \":\", \"@\" and \"/\"\n+    r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n+    r'(?::\\d{2,5})?'  # port\n+    r'(?:[/?#][^\\s]*)?'  # resource path\n+    r'\\Z', re.IGNORECASE)\n+\n     message = _('Enter a valid URL.')\n     schemes = ['http', 'https', 'ftp', 'ftps']\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10554",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 1544beb613..06198ed1c9 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1497,14 +1497,16 @@ class Prefetch:\n                 _result_cache=[],\n                 _prefetch_done=True,\n             )\n-        return obj_dict\n+def union(self, *other_qs, all=False):\n+    obj = self._chain()\n+    # Clear any ordering that was applied to one or more unioned\n+    # subqueries so that the final SELECT clause has a matching list\n+    # of columns. Without this, extra ordering fields such as \"order\"\n+    # can leak into the ORDER BY clause and cause errors.\n+    obj.query.clear_ordering(force_empty=True)\n+    # ... rest of existing union logic (unchanged) ...\n+    return obj\n \n-    def add_prefix(self, prefix):\n-        self.prefetch_through = prefix + LOOKUP_SEP + self.prefetch_through\n-        self.prefetch_to = prefix + LOOKUP_SEP + self.prefetch_to\n-\n-    def get_current_prefetch_to(self, level):\n-        return LOOKUP_SEP.join(self.prefetch_to.split(LOOKUP_SEP)[:level + 1])\n \n     def get_current_to_attr(self, level):\n         parts = self.prefetch_to.split(LOOKUP_SEP)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10880",
        "model_patch": "diff --git a/django/db/models/aggregates.py b/django/db/models/aggregates.py\nindex ac0b62d0bf..76a2a12c16 100644\n--- a/django/db/models/aggregates.py\n+++ b/django/db/models/aggregates.py\n@@ -68,7 +68,8 @@ class Aggregate(Func):\n         return []\n \n     def as_sql(self, compiler, connection, **extra_context):\n-        extra_context['distinct'] = 'DISTINCT' if self.distinct else ''\n+        extra_context['distinct'] = 'DISTINCT ' if self.distinct else ''\n+\n         if self.filter:\n             if connection.features.supports_aggregate_filter_clause:\n                 filter_sql, filter_params = self.filter.as_sql(compiler, connection)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10914",
        "model_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\nindex acee9887d2..8c46ea67c9 100644\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -304,7 +304,8 @@ FILE_UPLOAD_TEMP_DIR = None\n \n # The numeric mode to set newly-uploaded files to. The value should be a mode\n # you'd pass directly to os.chmod; see https://docs.python.org/library/os.html#files-and-directories.\n-FILE_UPLOAD_PERMISSIONS = None\n+FILE_UPLOAD_PERMISSIONS = 0o644\n+\n \n # The numeric mode to assign to newly-created directories, when uploading files.\n # The value should be a mode as you'd pass to os.chmod;\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10973",
        "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..a38844738f 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -34,38 +34,19 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n+        env = os.environ.copy()\n+        if passwd:\n+            env['PGPASSWORD'] = passwd\n+\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n-            if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            subprocess.run(args, env=env, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n+\n \n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10999",
        "model_patch": "diff --git a/django/utils/dateparse.py b/django/utils/dateparse.py\nindex 8d08b7d1d3..2a1ca6dbd5 100644\n--- a/django/utils/dateparse.py\n+++ b/django/utils/dateparse.py\n@@ -29,13 +29,14 @@ datetime_re = re.compile(\n standard_duration_re = re.compile(\n     r'^'\n     r'(?:(?P<days>-?\\d+) (days?, )?)?'\n-    r'((?:(?P<hours>-?\\d+):)(?=\\d+:\\d+))?'\n+    r'((?:(?P<hours>-?\\d+):)(?=-?\\d+:-?\\d+))?'\n     r'(?:(?P<minutes>-?\\d+):)?'\n     r'(?P<seconds>-?\\d+)'\n     r'(?:\\.(?P<microseconds>\\d{1,6})\\d{0,6})?'\n     r'$'\n )\n \n+\n # Support the sections of ISO 8601 date representation that are accepted by\n # timedelta\n iso8601_duration_re = re.compile(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11066",
        "model_patch": "diff --git a/django/contrib/contenttypes/management/__init__.py b/django/contrib/contenttypes/management/__init__.py\nindex 2b5f688136..979335f813 100644\n--- a/django/contrib/contenttypes/management/__init__.py\n+++ b/django/contrib/contenttypes/management/__init__.py\n@@ -24,7 +24,8 @@ class RenameContentType(migrations.RunPython):\n             content_type.model = new_model\n             try:\n                 with transaction.atomic(using=db):\n-                    content_type.save(update_fields={'model'})\n+        content_type.save(using=db, update_fields={'model'})\n+\n             except IntegrityError:\n                 # Gracefully fallback if a stale content type causes a\n                 # conflict as remove_stale_contenttypes will take care of\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11087",
        "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 3a462f1c4c..a9eb8cf46c 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -232,9 +232,13 @@ class Collector:\n         \"\"\"\n         Get a QuerySet of objects related to `objs` via the relation `related`.\n         \"\"\"\n-        return related.related_model._base_manager.using(self.using).filter(\n-            **{\"%s__in\" % related.field.name: objs}\n-        )\n+    qs = related.related_model._base_manager.using(self.using).filter(\n+        **{\"%s__in\" % related.field.name: objs}\n+    )\n+    # Only fetch the primary key field to avoid unwanted decoding of non-essential fields.\n+    pk_name = related.related_model._meta.pk.attname\n+    return qs.only(pk_name)\n+\n \n     def instances_with_model(self):\n         for model, instances in self.data.items():\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11095",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 5e7b23f9a0..2c3eec457a 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -553,6 +553,277 @@ class ModelAdmin(BaseModelAdmin):\n     paginator = Paginator\n     preserve_filters = True\n     inlines = []\n+    def get_inlines(self, request, obj=None):\n+\n+\n+        \"\"\"\n+\n+\n+        Hook to return the inline classes to be used in the admin.\n+\n+\n+        Subclasses can override this method to return a different list based on the request or obj.\n+\n+\n+        \"\"\"\n+\n+\n+        return self.inlines\n+\n+\n \n     # Custom templates (designed to be over-ridden in subclasses)\n     add_form_template = None\n@@ -582,7 +853,8 @@ class ModelAdmin(BaseModelAdmin):\n \n     def get_inline_instances(self, request, obj=None):\n         inline_instances = []\n-        for inline_class in self.inlines:\n+        for inline_class in self.get_inlines(request, obj):\n+\n             inline = inline_class(self.model, self.admin_site)\n             if request:\n                 if not (inline.has_view_or_change_permission(request, obj) or\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11099",
        "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..3d271bfe51 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,8 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n+\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +18,8 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+    regex = r'\\A[\\w.@+-]+\\Z'\n+\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11119",
        "model_patch": "diff --git a/django/template/engine.py b/django/template/engine.py\nindex dfaa67ba12..1488df94a2 100644\n--- a/django/template/engine.py\n+++ b/django/template/engine.py\n@@ -160,7 +160,8 @@ class Engine:\n         if isinstance(context, Context):\n             return t.render(context)\n         else:\n-            return t.render(Context(context))\n+            return t.render(Context(context, autoescape=self.autoescape))\n+\n \n     def select_template(self, template_name_list):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11133",
        "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..bd2e5d6593 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -229,14 +229,15 @@ class HttpResponseBase:\n         # Handle string types -- we can't rely on force_bytes here because:\n         # - Python attempts str conversion first\n         # - when self._charset != 'utf-8' it re-encodes the content\n-        if isinstance(value, bytes):\n-            return bytes(value)\n-        if isinstance(value, str):\n-            return bytes(value.encode(self.charset))\n-        # Handle non-string types.\n-        return str(value).encode(self.charset)\n-\n-    # These methods partially implement the file-like object interface.\n+if isinstance(value, bytes):\n+    return bytes(value)\n+if isinstance(value, str):\n+    return bytes(value.encode(self.charset))\n+if isinstance(value, memoryview):  # New check for memoryview objects\n+    return bytes(value)\n+# Handle non-string types.\n+return str(value).encode(self.charset)\n+\n     # See https://docs.python.org/library/io.html#io.IOBase\n \n     # The WSGI server must call this method upon completion of the request.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11138",
        "model_patch": "diff --git a/django/db/backends/mysql/operations.py b/django/db/backends/mysql/operations.py\nindex 50f85e0621..425a4b8e66 100644\n--- a/django/db/backends/mysql/operations.py\n+++ b/django/db/backends/mysql/operations.py\n@@ -68,10 +68,14 @@ class DatabaseOperations(BaseDatabaseOperations):\n         else:\n             return \"DATE(%s)\" % (field_name)\n \n-    def _convert_field_to_tz(self, field_name, tzname):\n-        if settings.USE_TZ:\n-            field_name = \"CONVERT_TZ(%s, 'UTC', '%s')\" % (field_name, tzname)\n-        return field_name\n+def _convert_field_to_tz(self, field_name, tzname):\n+    if settings.USE_TZ:\n+        db_tz = getattr(self.connection, 'timezone', 'UTC')\n+        if db_tz == tzname:\n+            return field_name\n+        field_name = \"CONVERT_TZ(%s, '%s', '%s')\" % (field_name, db_tz, tzname)\n+    return field_name\n+\n \n     def datetime_cast_date_sql(self, field_name, tzname):\n         field_name = self._convert_field_to_tz(field_name, tzname)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11141",
        "model_patch": "diff --git a/django/db/migrations/loader.py b/django/db/migrations/loader.py\nindex 8c308621d2..ea58d0d3ed 100644\n--- a/django/db/migrations/loader.py\n+++ b/django/db/migrations/loader.py\n@@ -86,9 +86,6 @@ class MigrationLoader:\n             else:\n                 # Empty directories are namespaces.\n                 # getattr() needed on PY36 and older (replace w/attribute access).\n-                if getattr(module, '__file__', None) is None:\n-                    self.unmigrated_apps.add(app_config.label)\n-                    continue\n                 # Module is not a package (e.g. migrations.py).\n                 if not hasattr(module, '__path__'):\n                     self.unmigrated_apps.add(app_config.label)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11149",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 880a2cc17b..c63ebc875d 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -2118,24 +2118,13 @@ class InlineModelAdmin(BaseModelAdmin):\n             # to have the view permission for the related model in order to\n             # be able to do anything with the intermediate model.\n             return self.has_view_permission(request, obj)\n-        return super().has_add_permission(request)\n+    def has_add_permission(self, request, obj):\n+        return super().has_add_permission(request, obj)\n \n     def has_change_permission(self, request, obj=None):\n-        if self.opts.auto_created:\n-            # We're checking the rights to an auto-created intermediate model,\n-            # which doesn't have its own individual permissions. The user needs\n-            # to have the view permission for the related model in order to\n-            # be able to do anything with the intermediate model.\n-            return self.has_view_permission(request, obj)\n-        return super().has_change_permission(request)\n+        return super().has_change_permission(request, obj)\n \n     def has_delete_permission(self, request, obj=None):\n-        if self.opts.auto_created:\n-            # We're checking the rights to an auto-created intermediate model,\n-            # which doesn't have its own individual permissions. The user needs\n-            # to have the view permission for the related model in order to\n-            # be able to do anything with the intermediate model.\n-            return self.has_view_permission(request, obj)\n         return super().has_delete_permission(request, obj)\n \n     def has_view_permission(self, request, obj=None):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11163",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex d157c291ef..11459848fa 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -83,7 +83,8 @@ def model_to_dict(instance, fields=None, exclude=None):\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n         if not getattr(f, 'editable', False):\n             continue\n-        if fields and f.name not in fields:\n+        if fields is not None and f.name not in fields:\n+\n             continue\n         if exclude and f.name in exclude:\n             continue\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11179",
        "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..1dd1979fd5 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -272,12 +272,14 @@ class Collector:\n         deleted_counter = Counter()\n \n         # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n-            if self.can_fast_delete(instance):\n-                with transaction.mark_for_rollback_on_error():\n-                    count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n-                return count, {model._meta.label: count}\n+if len(self.data) == 1 and len(instances) == 1:\n+    instance = list(instances)[0]\n+    if self.can_fast_delete(instance):\n+        with transaction.mark_for_rollback_on_error():\n+            count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+        # Clear the primary key field after fast deletion\n+        setattr(instance, model._meta.pk.attname, None)\n+        return count, {model._meta.label: count}\n \n         with transaction.atomic(using=self.using, savepoint=False):\n             # send pre_delete signals\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11206",
        "model_patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\nindex 88b35fc435..838b66bee3 100644\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -30,7 +30,13 @@ def format(number, decimal_sep, decimal_pos=None, grouping=0, thousand_sep='',\n         # Format values with more than 200 digits (an arbitrary cutoff) using\n         # scientific notation to avoid high memory usage in {:f}'.format().\n         _, digits, exponent = number.as_tuple()\n-        if abs(exponent) + len(digits) > 200:\n+    if abs(exponent) + len(digits) > 200:\n+        # If a fixed number of decimal positions is requested and the\n+        # absolute value is too small to be represented in that format,\n+        # then we force a fixed-point representation as zero.\n+        if decimal_pos is not None and abs(number) < Decimal('1e-' + str(decimal_pos)):\n+            str_number = '{:f}'.format(Decimal(0))\n+        else:\n             number = '{:e}'.format(number)\n             coefficient, exponent = number.split('e')\n             # Format the coefficient.\n@@ -39,8 +45,9 @@ def format(number, decimal_sep, decimal_pos=None, grouping=0, thousand_sep='',\n                 thousand_sep, force_grouping, use_l10n,\n             )\n             return '{}e{}'.format(coefficient, exponent)\n-        else:\n-            str_number = '{:f}'.format(number)\n+    else:\n+        str_number = '{:f}'.format(number)\n+\n     else:\n         str_number = str(number)\n     if str_number[0] == '-':\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11211",
        "model_patch": "diff --git a/django/contrib/contenttypes/fields.py b/django/contrib/contenttypes/fields.py\nindex ed98ecb48c..70791a0f0e 100644\n--- a/django/contrib/contenttypes/fields.py\n+++ b/django/contrib/contenttypes/fields.py\n@@ -567,7 +567,8 @@ def create_generic_related_manager(superclass, rel):\n \n             query = {\n                 '%s__pk' % self.content_type_field_name: self.content_type.id,\n-                '%s__in' % self.object_id_field_name: {obj.pk for obj in instances}\n+'%s__in' % self.object_id_field_name: {str(obj.pk) for obj in instances}\n+\n             }\n \n             # We (possibly) need to convert object IDs to the type of the\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11239",
        "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex cf4df76882..6dedff3c72 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -30,6 +30,348 @@ class DatabaseClient(BaseDatabaseClient):\n         subprocess_env = os.environ.copy()\n         if passwd:\n             subprocess_env['PGPASSWORD'] = str(passwd)\n+        if conn_params.get('sslcert'):\n+\n+\n+            subprocess_env['PGSSLCERT'] = str(conn_params['sslcert'])\n+\n+\n+        if conn_params.get('sslkey'):\n+\n+\n+            subprocess_env['PGSSLKEY'] = str(conn_params['sslkey'])\n+\n+\n+        if conn_params.get('sslrootcert'):\n+\n+\n+            subprocess_env['PGSSLROOTCERT'] = str(conn_params['sslrootcert'])\n+\n+\n         try:\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11265",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex d69c24419b..dd612c1aa0 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1665,7 +1665,9 @@ class Query(BaseExpression):\n         if isinstance(filter_rhs, F):\n             filter_expr = (filter_lhs, OuterRef(filter_rhs.name))\n         # Generate the inner query.\n-        query = Query(self.model)\n+query = Query(self.model)\n+query._filtered_relations = self._filtered_relations.copy()\n+\n         query.add_filter(filter_expr)\n         query.clear_ordering(True)\n         # Try to have as simple as possible subquery -> trim leading joins from\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11276",
        "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex 9c519978f5..703b010ebd 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -3,6 +3,19 @@\n import json\n import re\n from html.parser import HTMLParser\n+import html\n+\n+\n from urllib.parse import (\n     parse_qsl, quote, unquote, urlencode, urlsplit, urlunsplit,\n )\n@@ -43,7 +56,8 @@ def escape(text):\n     This may result in double-escaping. If this is a concern, use\n     conditional_escape() instead.\n     \"\"\"\n-    return mark_safe(str(text).translate(_html_escapes))\n+    return mark_safe(html.escape(str(text), quote=True))\n+\n \n \n _js_escapes = {\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11292",
        "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex 0c3a981290..6e43eae4df 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -286,7 +286,11 @@ class BaseCommand:\n             '--force-color', action='store_true',\n             help='Force colorization of the command output.',\n         )\n+        parser.add_argument(\n+            '--skip-checks', action='store_true', help='Skip system checks'\n+        )\n         self.add_arguments(parser)\n+\n         return parser\n \n     def add_arguments(self, parser):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11299",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex b99f03cd88..37e851bf5d 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1321,8 +1321,13 @@ class Query(BaseExpression):\n             self.where.add(clause, AND)\n         self.demote_joins(existing_inner)\n \n-    def build_where(self, q_object):\n-        return self._add_q(q_object, used_aliases=set(), allow_joins=False, simple_col=True)[0]\n+def build_where(self, q_object):\n+    # For check constraints we want joins to be allowed so that joins (if any)\n+    # will be trimmed out and all column references rendered as unqualified\n+    # by SimpleCol. (This fixes a bug when a compound Q object mixes join-required\n+    # lookups with direct ones.)\n+    return self._add_q(q_object, used_aliases=set(), allow_joins=True, simple_col=True)[0]\n+\n \n     def _add_q(self, q_object, used_aliases, branch_negated=False,\n                current_negated=False, allow_joins=True, split_subq=True,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11333",
        "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 247e3680c0..b1f03d78a5 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -63,11 +63,130 @@ class ResolverMatch:\n         )\n \n \n-@functools.lru_cache(maxsize=None)\n def get_resolver(urlconf=None):\n     if urlconf is None:\n         urlconf = settings.ROOT_URLCONF\n-    return URLResolver(RegexPattern(r'^/'), urlconf)\n+    return _get_resolver(urlconf)\n+\n+@functools.lru_cache(maxsize=None)\n+\n+\n+def _get_resolver(urlconf):\n+\n+\n+    return URLResolver(RegexPattern(r'^/'), urlconf)\n+\n+\n \n \n @functools.lru_cache(maxsize=None)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11400",
        "model_patch": "diff --git a/django/contrib/admin/filters.py b/django/contrib/admin/filters.py\nindex d65e01d5e2..c7e4a06940 100644\n--- a/django/contrib/admin/filters.py\n+++ b/django/contrib/admin/filters.py\n@@ -193,12 +193,15 @@ class RelatedFieldListFilter(FieldListFilter):\n     def expected_parameters(self):\n         return [self.lookup_kwarg, self.lookup_kwarg_isnull]\n \n-    def field_choices(self, field, request, model_admin):\n-        ordering = ()\n-        related_admin = model_admin.admin_site._registry.get(field.remote_field.model)\n-        if related_admin is not None:\n-            ordering = related_admin.get_ordering(request)\n-        return field.get_choices(include_blank=False, ordering=ordering)\n+def field_choices(self, field, request, model_admin):\n+    ordering = ()\n+    related_admin = model_admin.admin_site._registry.get(field.remote_field.model)\n+    if related_admin is not None:\n+        ordering = related_admin.get_ordering(request)\n+    # Fall back to the related model\u2019s Meta.ordering if no ordering is defined\n+    if not ordering:\n+        ordering = field.remote_field.model._meta.ordering\n+    return field.get_choices(include_blank=False, ordering=ordering)\n \n     def choices(self, changelist):\n         yield {\n@@ -417,6 +420,13 @@ FieldListFilter.register(lambda f: True, AllValuesFieldListFilter)\n \n \n class RelatedOnlyFieldListFilter(RelatedFieldListFilter):\n-    def field_choices(self, field, request, model_admin):\n-        pk_qs = model_admin.get_queryset(request).distinct().values_list('%s__pk' % self.field_path, flat=True)\n-        return field.get_choices(include_blank=False, limit_choices_to={'pk__in': pk_qs})\n+def field_choices(self, field, request, model_admin):\n+    pk_qs = model_admin.get_queryset(request).distinct().values_list('%s__pk' % self.field_path, flat=True)\n+    ordering = ()\n+    related_admin = model_admin.admin_site._registry.get(field.remote_field.model)\n+    if related_admin is not None:\n+        ordering = related_admin.get_ordering(request)\n+    # If ordering is not provided by ModelAdmin, fall back to Meta.ordering.\n+    if not ordering:\n+        ordering = field.remote_field.model._meta.ordering\n+    return field.get_choices(include_blank=False, ordering=ordering, limit_choices_to={'pk__in': pk_qs})\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11433",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5edbbd376f..51780c24fc 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -46,11 +46,11 @@ def construct_instance(form, instance, fields=None, exclude=None):\n             continue\n         if exclude and f.name in exclude:\n             continue\n-        # Leave defaults for fields that aren't in POST data, except for\n-        # checkbox inputs because they don't appear in POST data if not checked.\n-        if (f.has_default() and\n-                form[f.name].field.widget.value_omitted_from_data(form.data, form.files, form.add_prefix(f.name))):\n-            continue\n+        # Allow cleaned_data to override default values even when the raw data\n+        # is omitted. Since f.name is present in cleaned_data (checked above),\n+        # we do not want to skip updating the field even if the widget considers\n+        # the value omitted.\n+\n         # Defer saving file-type fields until after the other fields, so a\n         # callable upload_to can use the values from other fields.\n         if isinstance(f, models.FileField):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11451",
        "model_patch": "diff --git a/django/contrib/auth/backends.py b/django/contrib/auth/backends.py\nindex f4b1722757..7124baab6d 100644\n--- a/django/contrib/auth/backends.py\n+++ b/django/contrib/auth/backends.py\n@@ -39,6 +39,81 @@ class ModelBackend(BaseBackend):\n     def authenticate(self, request, username=None, password=None, **kwargs):\n         if username is None:\n             username = kwargs.get(UserModel.USERNAME_FIELD)\n+        if username is None or password is None:\n+\n+\n+            return None\n+\n+\n         try:\n             user = UserModel._default_manager.get_by_natural_key(username)\n         except UserModel.DoesNotExist:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11477",
        "model_patch": "diff --git a/django/urls/base.py b/django/urls/base.py\nindex 0e1c3d909c..8849485f62 100644\n--- a/django/urls/base.py\n+++ b/django/urls/base.py\n@@ -172,9 +172,12 @@ def translate_url(url, lang_code):\n         to_be_reversed = \"%s:%s\" % (match.namespace, match.url_name) if match.namespace else match.url_name\n         with override(lang_code):\n             try:\n-                url = reverse(to_be_reversed, args=match.args, kwargs=match.kwargs)\n+                # Filter out any optional kwargs with a value of None to prevent malformed URL segments.\n+                clean_kwargs = {k: v for k, v in match.kwargs.items() if v is not None}\n+                url = reverse(to_be_reversed, args=match.args, kwargs=clean_kwargs)\n             except NoReverseMatch:\n                 pass\n             else:\n                 url = urlunsplit((parsed.scheme, parsed.netloc, url, parsed.query, parsed.fragment))\n+\n     return url\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11490",
        "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex a44adfc760..55814af8a0 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -425,12 +425,13 @@ class SQLCompiler:\n                 # If the columns list is limited, then all combined queries\n                 # must have the same columns list. Set the selects defined on\n                 # the query on all combined queries, if not already set.\n-                if not compiler.query.values_select and self.query.values_select:\n+                if self.query.values_select:\n                     compiler.query.set_values((\n                         *self.query.extra_select,\n                         *self.query.values_select,\n                         *self.query.annotation_select,\n                     ))\n+\n                 part_sql, part_args = compiler.as_sql()\n                 if compiler.query.combinator:\n                     # Wrap in a subquery if wrapping in parentheses isn't\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11532",
        "model_patch": "diff --git a/django/core/mail/message.py b/django/core/mail/message.py\nindex e393b4cf5c..08b409ad06 100644\n--- a/django/core/mail/message.py\n+++ b/django/core/mail/message.py\n@@ -256,8 +256,10 @@ class EmailMessage:\n             # will get picked up by formatdate().\n             msg['Date'] = formatdate(localtime=settings.EMAIL_USE_LOCALTIME)\n         if 'message-id' not in header_names:\n-            # Use cached DNS_NAME for performance\n-            msg['Message-ID'] = make_msgid(domain=DNS_NAME)\n+            # Use cached DNS_NAME for performance and punycode conversion\n+            domain = DNS_NAME.get_fqdn().encode('idna').decode('ascii')\n+            msg['Message-ID'] = make_msgid(domain=domain)\n+\n         for name, value in self.extra_headers.items():\n             if name.lower() != 'from':  # From is already handled\n                 msg[name] = value\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11551",
        "model_patch": "diff --git a/django/contrib/admin/checks.py b/django/contrib/admin/checks.py\nindex f82c20c2f1..f753c45e8d 100644\n--- a/django/contrib/admin/checks.py\n+++ b/django/contrib/admin/checks.py\n@@ -718,35 +718,33 @@ class ModelAdminChecks(BaseModelAdminChecks):\n     def _check_list_display_item(self, obj, item, label):\n         if callable(item):\n             return []\n-        elif hasattr(obj, item):\n-            return []\n-        elif hasattr(obj.model, item):\n+        try:\n+            field = obj.model._meta.get_field(item)\n+        except FieldDoesNotExist:\n             try:\n-                field = obj.model._meta.get_field(item)\n-            except FieldDoesNotExist:\n-                return []\n-            else:\n-                if isinstance(field, models.ManyToManyField):\n-                    return [\n-                        checks.Error(\n-                            \"The value of '%s' must not be a ManyToManyField.\" % label,\n-                            obj=obj.__class__,\n-                            id='admin.E109',\n-                        )\n-                    ]\n-                return []\n-        else:\n+                # Fallback: try getting the attribute (handles descriptors that work only on an instance)\n+                field = getattr(obj.model, item)\n+            except AttributeError:\n+                return [\n+                    checks.Error(\n+                        \"The value of '%s' refers to '%s', which is not a callable, \"\n+                        \"an attribute of '%s', or an attribute or method on '%s.%s'.\" % (\n+                            label, item, obj.__class__.__name__,\n+                            obj.model._meta.app_label, obj.model._meta.object_name,\n+                        ),\n+                        obj=obj.__class__,\n+                        id='admin.E108',\n+                    )\n+                ]\n+        if isinstance(field, models.ManyToManyField):\n             return [\n                 checks.Error(\n-                    \"The value of '%s' refers to '%s', which is not a callable, \"\n-                    \"an attribute of '%s', or an attribute or method on '%s.%s'.\" % (\n-                        label, item, obj.__class__.__name__,\n-                        obj.model._meta.app_label, obj.model._meta.object_name,\n-                    ),\n+                    \"The value of '%s' must not be a ManyToManyField.\" % label,\n                     obj=obj.__class__,\n-                    id='admin.E108',\n+                    id='admin.E109',\n                 )\n             ]\n+        return []\n \n     def _check_list_display_links(self, obj):\n         \"\"\" Check that list_display_links is a unique subset of list_display.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11555",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex e15e64cde4..2a411af88d 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -2217,12 +2217,19 @@ def get_order_dir(field, default='ASC'):\n     The 'default' param is used to indicate which way no prefix (or a '+'\n     prefix) should sort. The '-' prefix always sorts the opposite way.\n     \"\"\"\n+    # If ordering is provided as an OrderBy expression rather than a string,\n+    # extract the underlying expression and determine the ordering direction.\n+    from django.db.models.expressions import OrderBy\n+    if isinstance(field, OrderBy):\n+        return (field.expression, 'DESC' if field.descending else 'ASC')\n+\n     dirn = ORDER_DIR[default]\n-    if field[0] == '-':\n+    if isinstance(field, str) and field and field[0] == '-':\n         return field[1:], dirn[1]\n     return field, dirn[0]\n \n \n+\n def add_to_dict(data, key, value):\n     \"\"\"\n     Add \"value\" to the set of values for \"key\", whether or not \"key\" already\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11603",
        "model_patch": "diff --git a/django/db/models/aggregates.py b/django/db/models/aggregates.py\nindex da4ff928aa..dbe19f8626 100644\n--- a/django/db/models/aggregates.py\n+++ b/django/db/models/aggregates.py\n@@ -99,6 +99,33 @@ class Aggregate(Func):\n class Avg(FixDurationInputMixin, NumericOutputFieldMixin, Aggregate):\n     function = 'AVG'\n     name = 'Avg'\n+    allow_distinct = True\n+\n+\n \n \n class Count(Aggregate):\n@@ -142,6 +169,33 @@ class StdDev(NumericOutputFieldMixin, Aggregate):\n class Sum(FixDurationInputMixin, Aggregate):\n     function = 'SUM'\n     name = 'Sum'\n+    allow_distinct = True\n+\n+\n \n \n class Variance(NumericOutputFieldMixin, Aggregate):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11728",
        "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 1ce4594501..4f50bda836 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -172,7 +172,6 @@ def replace_named_groups(pattern):\n             if unmatched_open_brackets == 0:\n                 group_pattern_and_name.append((pattern[start:end + idx], group_name))\n                 break\n-\n             # Check for unescaped `(` and `)`. They mark the start and end of a\n             # nested group.\n             if val == '(' and prev_char != '\\\\':\n@@ -180,6 +179,12 @@ def replace_named_groups(pattern):\n             elif val == ')' and prev_char != '\\\\':\n                 unmatched_open_brackets -= 1\n             prev_char = val\n+        else:\n+            # If no more characters are left in pattern[end:] (or the loop\n+            # finishes without balancing the brackets) then append the captured\n+            # group pattern from start to the end of the string.\n+            if unmatched_open_brackets != 0:\n+                group_pattern_and_name.append((pattern[start:], group_name))\n \n     # Replace the string for named capture groups with their group names.\n     for group_pattern, group_name in group_pattern_and_name:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11734",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 35f3c5e1ea..534fde44e1 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1697,6 +1697,128 @@ class Query(BaseExpression):\n             WHERE NOT (pk IN (SELECT parent_id FROM thetable\n                               WHERE name = 'foo' AND parent_id IS NOT NULL))\n \n+        # Force the inner query to be treated as a subquery to resolve OuterRef properly.\n+\n+\n+        query.subquery = True\n+\n+\n         It might be worth it to consider using WHERE NOT EXISTS as that has\n         saner null handling, and is easier for the backend's optimizer to\n         handle.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11740",
        "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 0dc1c77c53..14c96d3e9e 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -963,6 +963,10 @@ class MigrationAutodetector:\n                             preserve_default = False\n                     else:\n                         field = new_field\n+                    dependencies = []\n+                    # If the new field is a ForeignKey, add dependency on the target model\u2019s migration.\n+                    if new_field.remote_field:\n+                        dependencies.extend(self._get_dependencies_for_foreign_key(new_field))\n                     self.add_operation(\n                         app_label,\n                         operations.AlterField(\n@@ -970,9 +974,10 @@ class MigrationAutodetector:\n                             name=field_name,\n                             field=field,\n                             preserve_default=preserve_default,\n-                        )\n+                        ),\n+                        dependencies=dependencies\n                     )\n-                else:\n+\n                     # We cannot alter between m2m and concrete fields\n                     self._generate_removed_field(app_label, model_name, field_name)\n                     self._generate_added_field(app_label, model_name, field_name)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11749",
        "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 5f2e64761e..50662d685d 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -120,18 +120,21 @@ def call_command(command_name, *args, **options):\n     arg_options = {opt_mapping.get(key, key): value for key, value in options.items()}\n     parse_args = [str(a) for a in args]\n \n-    def get_actions(parser):\n-        # Parser actions and actions from sub-parser choices.\n-        for opt in parser._actions:\n-            if isinstance(opt, _SubParsersAction):\n-                for sub_opt in opt.choices.values():\n-                    yield from get_actions(sub_opt)\n-            else:\n-                yield opt\n+    def is_option_required(opt):\n+        # Check if the option is explicitly marked as required.\n+        if opt.required:\n+            return True\n+        # Check if the option belongs to a mutually exclusive group that is required.\n+        for group in getattr(parser, '_mutually_exclusive_groups', []):\n+            if opt in group._group and getattr(group, 'required', False):\n+                return True\n+        return False\n+\n+    parse_args += [\n+        '{}={}'.format(min(opt.option_strings), arg_options[opt.dest])\n+        for opt in parser._actions if is_option_required(opt) and opt.dest in options\n+    ]\n \n-    parser_actions = list(get_actions(parser))\n-    # Any required arguments which are passed in via **options must be passed\n-    # to parse_args().\n     parse_args += [\n         '{}={}'.format(min(opt.option_strings), arg_options[opt.dest])\n         for opt in parser_actions if opt.required and opt.dest in options\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11790",
        "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex a0cfed0995..788ba49348 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -192,6 +192,94 @@ class AuthenticationForm(forms.Form):\n         # Set the max length and label for the \"username\" field.\n         self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n         self.fields['username'].max_length = self.username_field.max_length or 254\n+self.fields['username'].widget.attrs['maxlength'] = self.fields['username'].max_length\n+\n+\n         if self.fields['username'].label is None:\n             self.fields['username'].label = capfirst(self.username_field.verbose_name)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11815",
        "model_patch": "diff --git a/django/db/migrations/serializer.py b/django/db/migrations/serializer.py\nindex 27b5cbd379..4c1aeb6a60 100644\n--- a/django/db/migrations/serializer.py\n+++ b/django/db/migrations/serializer.py\n@@ -120,9 +120,10 @@ class EnumSerializer(BaseSerializer):\n     def serialize(self):\n         enum_class = self.value.__class__\n         module = enum_class.__module__\n-        v_string, v_imports = serializer_factory(self.value.value).serialize()\n-        imports = {'import %s' % module, *v_imports}\n-        return \"%s.%s(%s)\" % (module, enum_class.__name__, v_string), imports\n+        # Instead of using the enum's translated value (which may be localized),\n+        # use its invariant name for migration serialization.\n+        imports = {'import %s' % module}\n+        return \"%s.%s[%r]\" % (module, enum_class.__name__, self.value.name), imports\n \n \n class FloatSerializer(BaseSimpleSerializer):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11820",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11848",
        "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..e6fc48b6d5 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -174,12 +174,19 @@ def parse_http_date(date):\n     else:\n         raise ValueError(\"%r is not in a valid HTTP date format\" % date)\n     try:\n-        year = int(m.group('year'))\n-        if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n+year = int(m.group('year'))\n+if year < 100:\n+    # RFC7231 requires that for a two-digit year the timestamp that appears to be\n+    # more than 50 years in the future should be interpreted as the most recent\n+    # past occurrence. Here we add 2000 and, if that result is more than 50 years\n+    # ahead of the current UTC year, subtract 100 years.\n+    now_year = datetime.datetime.utcnow().year\n+    candidate = year + 2000\n+    if candidate > now_year + 50:\n+        year = candidate - 100\n+    else:\n+        year = candidate\n+\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11880",
        "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 03cd8af8d7..cd737f39ef 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -195,12 +195,14 @@ class Field:\n         \"\"\"\n         return BoundField(form, self, field_name)\n \n-    def __deepcopy__(self, memo):\n-        result = copy.copy(self)\n-        memo[id(self)] = result\n-        result.widget = copy.deepcopy(self.widget, memo)\n-        result.validators = self.validators[:]\n-        return result\n+def __deepcopy__(self, memo):\n+    result = copy.copy(self)\n+    memo[id(self)] = result\n+    result.widget = copy.deepcopy(self.widget, memo)\n+    result.validators = self.validators[:]\n+    result.error_messages = copy.deepcopy(self.error_messages, memo)\n+    return result\n+\n \n \n class CharField(Field):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11885",
        "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex ae82d26340..75d2978d84 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -309,10 +309,23 @@ class Collector:\n                         sender=model, instance=obj, using=self.using\n                     )\n \n-            # fast deletes\n+            # fast deletes: group querysets by model (table) and combine their conditions using OR\n+            from django.db.models.sql.where import WhereNode\n+            grouped_fast_deletes = {}\n             for qs in self.fast_deletes:\n-                count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+                key = qs.model\n+                grouped_fast_deletes.setdefault(key, []).append(qs)\n+            for model, qs_list in grouped_fast_deletes.items():\n+                if len(qs_list) == 1:\n+                    count = qs_list[0]._raw_delete(using=self.using)\n+                else:\n+                    combined_where = WhereNode(qs_list[0].query.where.connector, qs_list[0].query.where.negated)\n+                    for qs in qs_list:\n+                        for child in qs.query.where.children:\n+                            combined_where.add(child, connector=\"OR\")\n+                    qs_list[0].query.where = combined_where\n+                    count = qs_list[0]._raw_delete(using=self.using)\n+                deleted_counter[model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11951",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 794e0faae7..3fd401eef5 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1209,7 +1209,9 @@ class QuerySet:\n         if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:\n             raise NotSupportedError('This database backend does not support ignoring conflicts.')\n         ops = connections[self.db].ops\n-        batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1))\n+max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)\n+batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n+\n         inserted_rows = []\n         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert\n         for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11964",
        "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex bbe362a6ab..a6595b602c 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -32,9 +32,10 @@ class ChoicesMeta(enum.EnumMeta):\n         # label in the choices.\n         cls.label = property(lambda self: cls._value2label_map_.get(self.value))\n         return enum.unique(cls)\n+class TextChoices(str, Choices):\n+    def __str__(self):\n+        return self.value\n \n-    def __contains__(cls, member):\n-        if not isinstance(member, enum.Enum):\n             # Allow non-enums to match against member values.\n             return member in {x.value for x in cls}\n         return super().__contains__(member)\n@@ -65,7 +66,9 @@ class Choices(enum.Enum, metaclass=ChoicesMeta):\n \n class IntegerChoices(int, Choices):\n     \"\"\"Class for creating enumerated integer choices.\"\"\"\n-    pass\n+    def __str__(self):\n+        return str(self.value)\n+\n \n \n class TextChoices(str, Choices):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11999",
        "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex ee45bb941e..7f9009da0f 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -97,13 +97,14 @@ class Field(RegisterLookupMixin):\n     auto_creation_counter = -1\n     default_validators = []  # Default set of validators\n     default_error_messages = {\n-        'invalid_choice': _('Value %(value)r is not a valid choice.'),\n-        'null': _('This field cannot be null.'),\n-        'blank': _('This field cannot be blank.'),\n-        'unique': _('%(model_name)s with this %(field_label)s '\n-                    'already exists.'),\n-        # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n-        # Eg: \"Title must be unique for pub_date year\"\n+        if self.choices:\n+            display_method = \"get_%s_display\" % self.name\n+            # Only add the auto\u2010generated display method if the user has not overridden it.\n+            if display_method not in cls.__dict__:\n+                def get_field_display(instance):\n+                    return instance._get_FIELD_display(self)\n+                cls.add_to_class(display_method, get_field_display)\n+\n         'unique_for_date': _(\"%(field_label)s must be unique for \"\n                              \"%(date_field_label)s %(lookup_type)s.\"),\n     }\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12039",
        "model_patch": "diff --git a/django/db/backends/ddl_references.py b/django/db/backends/ddl_references.py\nindex 44e49806f8..61e13dc277 100644\n--- a/django/db/backends/ddl_references.py\n+++ b/django/db/backends/ddl_references.py\n@@ -81,14 +81,15 @@ class Columns(TableColumns):\n         self.col_suffixes = col_suffixes\n         super().__init__(table, columns)\n \n-    def __str__(self):\n-        def col_str(column, idx):\n-            try:\n-                return self.quote_name(column) + self.col_suffixes[idx]\n-            except IndexError:\n-                return self.quote_name(column)\n+def __str__(self):\n+    def col_str(column, idx):\n+        try:\n+            suffix = self.col_suffixes[idx]\n+        except IndexError:\n+            suffix = \"\"\n+        return self.quote_name(column) + (\" \" + suffix if suffix else \"\")\n+    return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \n-        return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \n \n class IndexName(TableColumns):\n@@ -108,16 +109,18 @@ class IndexColumns(Columns):\n         self.opclasses = opclasses\n         super().__init__(table, columns, quote_name, col_suffixes)\n \n-    def __str__(self):\n-        def col_str(column, idx):\n-            # Index.__init__() guarantees that self.opclasses is the same\n-            # length as self.columns.\n-            col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n-            try:\n-                col = '{} {}'.format(col, self.col_suffixes[idx])\n-            except IndexError:\n-                pass\n-            return col\n+def __str__(self):\n+    def col_str(column, idx):\n+        # Index.__init__() guarantees that self.opclasses is the same length as self.columns.\n+        col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n+        try:\n+            suffix = self.col_suffixes[idx]\n+        except IndexError:\n+            suffix = \"\"\n+        if suffix:\n+            col = '{} {}'.format(col, suffix)\n+        return col\n+    return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \n         return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12050",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..41fa4e019a 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1069,7 +1069,11 @@ class Query(BaseExpression):\n                         ))\n                     else:\n                         resolved_values.append(sub_value.resolve_expression(\n-                            self, reuse=can_reuse, allow_joins=allow_joins,\n+            if isinstance(value, list):\n+                value = list(resolved_values)\n+            else:\n+                value = tuple(resolved_values)\n+\n                         ))\n                 else:\n                     resolved_values.append(sub_value)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12125",
        "model_patch": "diff --git a/django/utils/deconstruct.py b/django/utils/deconstruct.py\nindex aa952f6b73..f4515be438 100644\n--- a/django/utils/deconstruct.py\n+++ b/django/utils/deconstruct.py\n@@ -26,8 +26,9 @@ def deconstructible(*args, path=None):\n             if path:\n                 module_name, _, name = path.rpartition('.')\n             else:\n-                module_name = obj.__module__\n-                name = obj.__class__.__name__\n+    module_name = obj.__module__\n+    name = getattr(obj.__class__, '__qualname__', obj.__class__.__name__)\n+\n             # Make sure it's actually there and not an inner class\n             module = import_module(module_name)\n             if not hasattr(module, name):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12143",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 137e6faa0f..a100f1c499 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1631,7 +1631,7 @@ class ModelAdmin(BaseModelAdmin):\n \n     def _get_edited_object_pks(self, request, prefix):\n         \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n-        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(prefix, self.model._meta.pk.name))\n+        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(re.escape(prefix), self.model._meta.pk.name))\n         return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n \n     def _get_list_editable_queryset(self, request, prefix):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12155",
        "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 4c0e7e2a56..02993b2c2c 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -34,7 +34,8 @@ def trim_docstring(docstring):\n         return ''\n     # Convert tabs to spaces and split into lines\n     lines = docstring.expandtabs().splitlines()\n-    indent = min(len(line) - len(line.lstrip()) for line in lines if line.lstrip())\n+    indent = min(len(line) - len(line.lstrip()) for line in lines[1:] if line.lstrip())\n+\n     trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]]\n     return \"\\n\".join(trimmed).strip()\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12193",
        "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 6fe220bea7..3c71f057e4 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -830,11 +830,10 @@ class MultiWidget(Widget):\n                 widget_value = value[i]\n             except IndexError:\n                 widget_value = None\n-            if id_:\n-                widget_attrs = final_attrs.copy()\n-                widget_attrs['id'] = '%s_%s' % (id_, i)\n-            else:\n-                widget_attrs = final_attrs\n+widget_attrs = final_attrs.copy()\n+if id_:\n+    widget_attrs['id'] = '%s_%s' % (id_, i)\n+\n             subwidgets.append(widget.get_context(widget_name, widget_value, widget_attrs)['widget'])\n         context['widget']['subwidgets'] = subwidgets\n         return context\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12209",
        "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex e3b14a41a0..d8269e21fb 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -403,17 +403,26 @@ class ModelState:\n \n class Model(metaclass=ModelBase):\n \n-    def __init__(self, *args, **kwargs):\n-        # Alias some things as locals to avoid repeat global lookups\n-        cls = self.__class__\n-        opts = self._meta\n-        _setattr = setattr\n-        _DEFERRED = DEFERRED\n-\n-        pre_init.send(sender=cls, args=args, kwargs=kwargs)\n+def __init__(self, *args, **kwargs):\n+    # Alias some things as locals to avoid repeat global lookups\n+    cls = self.__class__\n+    opts = self._meta\n+    _setattr = setattr\n+    _DEFERRED = DEFERRED\n+\n+    # Determine if an explicit primary key was provided.\n+    # We check both the 'pk' alias and the actual primary key field name.\n+    pk_field_name = opts.pk.attname\n+    explicit_pk = ('pk' in kwargs) or (pk_field_name in kwargs) or (args and len(args) >= 1)\n+\n+    pre_init.send(sender=cls, args=args, kwargs=kwargs)\n+\n+    # Set up the storage for instance state\n+    self._state = ModelState()\n+    # If an explicit primary key was provided, mark the instance as not adding.\n+    if explicit_pk:\n+        self._state.adding = False\n \n-        # Set up the storage for instance state\n-        self._state = ModelState()\n \n         # There is a rather weird disparity here; if kwargs, it's set, then args\n         # overrides it. It should be one or the other; don't duplicate the work\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12262",
        "model_patch": "diff --git a/django/template/library.py b/django/template/library.py\nindex 20bc86dac8..1858fb1796 100644\n--- a/django/template/library.py\n+++ b/django/template/library.py\n@@ -261,7 +261,8 @@ def parse_bits(parser, bits, params, varargs, varkw, defaults,\n         if kwarg:\n             # The kwarg was successfully extracted\n             param, value = kwarg.popitem()\n-            if param not in params and param not in unhandled_kwargs and varkw is None:\n+                if param not in params and param not in kwonly and varkw is None:\n+\n                 # An unexpected keyword argument was supplied\n                 raise TemplateSyntaxError(\n                     \"'%s' received unexpected keyword argument '%s'\" %\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12273",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12276",
        "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 338d54d72f..9339923388 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -385,7 +385,9 @@ class FileInput(Input):\n         return files.get(name)\n \n     def value_omitted_from_data(self, data, files, name):\n-        return name not in files\n+    def use_required_attribute(self, initial):\n+        return not self.is_hidden and not initial\n+\n \n \n FILE_INPUT_CONTRADICTION = object()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12304",
        "model_patch": "diff --git a/django/db/models/enums.py b/django/db/models/enums.py\nindex f48143ddaf..05fac8b883 100644\n--- a/django/db/models/enums.py\n+++ b/django/db/models/enums.py\n@@ -60,6 +60,43 @@ class ChoicesMeta(enum.EnumMeta):\n \n class Choices(enum.Enum, metaclass=ChoicesMeta):\n     \"\"\"Class for creating enumerated choices.\"\"\"\n+    do_not_call_in_templates = True\n+\n+\n \n     def __str__(self):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12308",
        "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..8dfb167567 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -396,10 +396,13 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value, field.decimal_places)\n     elif isinstance(field, (models.IntegerField, models.FloatField)):\n         return formats.number_format(value)\n-    elif isinstance(field, models.FileField) and value:\n-        return format_html('<a href=\"{}\">{}</a>', value.url, value)\n-    else:\n-        return display_for_value(value, empty_value_display)\n+elif isinstance(field, models.FileField) and value:\n+    return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+elif isinstance(field, models.JSONField):\n+    return field.prepare_value(value)\n+else:\n+    return display_for_value(value, empty_value_display)\n+\n \n \n def display_for_value(value, empty_value_display, boolean=False):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12325",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12406",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..593220086e 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -13,8 +13,9 @@ from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, SelectMultiple,\n+    HiddenInput, MultipleHiddenInput, SelectMultiple, RadioSelect,\n )\n+\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n \n@@ -1189,6 +1190,111 @@ class ModelChoiceField(ChoiceField):\n             self.empty_label = None\n         else:\n             self.empty_label = empty_label\n+        if widget is not None and isinstance(widget, RadioSelect):\n+\n+\n+            self.empty_label = None\n+\n+\n \n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12419",
        "model_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\nindex 09c9b95d26..5dd7afaf99 100644\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -637,6 +637,7 @@ SECURE_HSTS_INCLUDE_SUBDOMAINS = False\n SECURE_HSTS_PRELOAD = False\n SECURE_HSTS_SECONDS = 0\n SECURE_REDIRECT_EXEMPT = []\n-SECURE_REFERRER_POLICY = None\n+SECURE_REFERRER_POLICY = \"same-origin\"\n+\n SECURE_SSL_HOST = None\n SECURE_SSL_REDIRECT = False\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12663",
        "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex caa03665ea..fc4c75447d 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -957,12 +957,14 @@ class BooleanField(Field):\n             code='invalid',\n             params={'value': value},\n         )\n-\n     def get_prep_value(self, value):\n-        value = super().get_prep_value(value)\n-        if value is None:\n-            return None\n-        return self.to_python(value)\n+        from django.utils.functional import SimpleLazyObject, empty\n+        if isinstance(value, SimpleLazyObject):\n+            # Force evaluation of the lazy object to retrieve the underlying value.\n+            if value._wrapped is empty:\n+                value._setup()\n+            value = value._wrapped\n+        return int(value)\n \n     def formfield(self, **kwargs):\n         if self.choices is not None:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12708",
        "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..b7ca7a47b9 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -392,8 +392,9 @@ class BaseDatabaseSchemaEditor:\n         olds = {tuple(fields) for fields in old_index_together}\n         news = {tuple(fields) for fields in new_index_together}\n         # Deleted indexes\n-        for fields in olds.difference(news):\n-            self._delete_composed_index(model, fields, {'index': True}, self.sql_delete_index)\n+for fields in olds.difference(news):\n+    self._delete_composed_index(model, fields, {'index': True, 'unique': False}, self.sql_delete_index)\n+\n         # Created indexes\n         for field_names in news.difference(olds):\n             fields = [model._meta.get_field(field) for field in field_names]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12713",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 69a5fbf389..771c40be5a 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -249,16 +249,18 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n             return None\n         db = kwargs.get('using')\n \n-        autocomplete_fields = self.get_autocomplete_fields(request)\n-        if db_field.name in autocomplete_fields:\n-            kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in self.raw_id_fields:\n-            kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n-            kwargs['widget'] = widgets.FilteredSelectMultiple(\n-                db_field.verbose_name,\n-                db_field.name in self.filter_vertical\n-            )\n+autocomplete_fields = self.get_autocomplete_fields(request)\n+if 'widget' not in kwargs:\n+    if db_field.name in autocomplete_fields:\n+        kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n+    elif db_field.name in self.raw_id_fields:\n+        kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n+    elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n+        kwargs['widget'] = widgets.FilteredSelectMultiple(\n+            db_field.verbose_name,\n+            db_field.name in self.filter_vertical\n+        )\n+\n \n         if 'queryset' not in kwargs:\n             queryset = self.get_field_queryset(db, db_field, request)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12741",
        "model_patch": "diff --git a/django/db/backends/base/operations.py b/django/db/backends/base/operations.py\nindex 70ac07ae09..87aa72dad8 100644\n--- a/django/db/backends/base/operations.py\n+++ b/django/db/backends/base/operations.py\n@@ -400,9 +400,11 @@ class BaseDatabaseOperations:\n         \"\"\"\n         raise NotImplementedError('subclasses of BaseDatabaseOperations must provide a sql_flush() method')\n \n-    def execute_sql_flush(self, using, sql_list):\n+    def execute_sql_flush(self, sql_list):\n+\n         \"\"\"Execute a list of SQL statements to flush the database.\"\"\"\n-        with transaction.atomic(using=using, savepoint=self.connection.features.can_rollback_ddl):\n+        with transaction.atomic(using=self.connection.alias, savepoint=self.connection.features.can_rollback_ddl):\n+\n             with self.connection.cursor() as cursor:\n                 for sql in sql_list:\n                     cursor.execute(sql)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12754",
        "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 30616c0172..f7ebab6a20 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -887,21 +887,21 @@ class MigrationAutodetector:\n         for app_label, model_name, field_name in sorted(self.old_field_keys - self.new_field_keys):\n             self._generate_removed_field(app_label, model_name, field_name)\n \n-    def _generate_removed_field(self, app_label, model_name, field_name):\n-        self.add_operation(\n-            app_label,\n-            operations.RemoveField(\n-                model_name=model_name,\n-                name=field_name,\n-            ),\n-            # We might need to depend on the removal of an\n-            # order_with_respect_to or index/unique_together operation;\n-            # this is safely ignored if there isn't one\n-            dependencies=[\n-                (app_label, model_name, field_name, \"order_wrt_unset\"),\n-                (app_label, model_name, field_name, \"foo_together_change\"),\n-            ],\n-        )\n+def _generate_removed_field(self, app_label, model_name, field_name):\n+    self.add_operation(\n+        app_label,\n+        operations.RemoveField(\n+            model_name=model_name,\n+            name=field_name,\n+        ),\n+        # Ensure that the removal of the field is processed before any\n+        # CreateModel that would cause a clash on the field.\n+        dependencies=[\n+            (app_label, model_name, field_name, False),\n+            (app_label, model_name, field_name, False),\n+        ],\n+    )\n+\n \n     def generate_altered_fields(self):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12774",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..94514c834e 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -682,6 +682,53 @@ class QuerySet:\n         for obj in (self.reverse() if self.ordered else self.order_by('-pk'))[:1]:\n             return obj\n \n+from django.db.models import UniqueConstraint\n+\n+\n     def in_bulk(self, id_list=None, *, field_name='pk'):\n         \"\"\"\n         Return a dictionary mapping each of the given IDs to the object with\n@@ -689,8 +736,19 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot use 'limit' or 'offset' with in_bulk\"\n-        if field_name != 'pk' and not self.model._meta.get_field(field_name).unique:\n-            raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+    if field_name != 'pk':\n+        field = self.model._meta.get_field(field_name)\n+        if not field.unique:\n+            unique_via_constraint = any(\n+                isinstance(constraint, UniqueConstraint) and\n+                len(constraint.fields) == 1 and\n+                constraint.fields[0] == field_name and\n+                constraint.condition is None\n+                for constraint in self.model._meta.constraints\n+            )\n+            if not unique_via_constraint:\n+                raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+\n         if id_list is not None:\n             if not id_list:\n                 return {}\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12858",
        "model_patch": "diff --git a/django/db/models/options.py b/django/db/models/options.py\nindex 0e28b6812a..f1f8436453 100644\n--- a/django/db/models/options.py\n+++ b/django/db/models/options.py\n@@ -1,4 +1,55 @@\n import bisect\n+from django.db.models.constants import LOOKUP_SEP\n+\n+\n import copy\n import inspect\n from collections import defaultdict\n@@ -551,30 +602,38 @@ class Options:\n                 pass\n         return res\n \n-    def get_field(self, field_name):\n-        \"\"\"\n-        Return a field instance given the name of a forward or reverse field.\n-        \"\"\"\n-        try:\n-            # In order to avoid premature loading of the relation tree\n-            # (expensive) we prefer checking if the field is a forward field.\n-            return self._forward_fields_map[field_name]\n-        except KeyError:\n-            # If the app registry is not ready, reverse fields are\n-            # unavailable, therefore we throw a FieldDoesNotExist exception.\n-            if not self.apps.models_ready:\n-                raise FieldDoesNotExist(\n-                    \"%s has no field named '%s'. The app cache isn't ready yet, \"\n-                    \"so if this is an auto-created related field, it won't \"\n-                    \"be available yet.\" % (self.object_name, field_name)\n-                )\n-\n-        try:\n-            # Retrieve field instance by name from cached or just-computed\n-            # field map.\n-            return self.fields_map[field_name]\n-        except KeyError:\n-            raise FieldDoesNotExist(\"%s has no field named '%s'\" % (self.object_name, field_name))\n+def get_field(self, field_name):\n+    \"\"\"\n+    Return a field instance given the name of a forward or reverse field.\n+    If the lookup ends with a recognized transform (e.g. '__isnull'),\n+    strip it off before attempting resolution.\n+    \"\"\"\n+    # If the field lookup uses the lookup separator, check whether the last\n+    # segment is a known transform (currently handling only \"isnull\").\n+    if LOOKUP_SEP in field_name:\n+        parts = field_name.split(LOOKUP_SEP)\n+        valid_transforms = {\"isnull\"}\n+        if parts[-1] in valid_transforms:\n+            field_name = LOOKUP_SEP.join(parts[:-1])\n+    try:\n+        # In order to avoid premature loading of the relation tree\n+        # (expensive) we prefer checking if the field is a forward field.\n+        return self._forward_fields_map[field_name]\n+    except KeyError:\n+        # If the app registry is not ready, reverse fields are\n+        # unavailable, therefore we throw a FieldDoesNotExist exception.\n+        if not self.apps.models_ready:\n+            raise FieldDoesNotExist(\n+                \"%s has no field named '%s'. The app cache isn't ready yet, \"\n+                \"so if this is an auto-created related field, it won't \"\n+                \"be available yet.\" % (self.object_name, field_name)\n+            )\n+    try:\n+        # Retrieve field instance by name from cached or just-computed\n+        # field map.\n+        return self.fields_map[field_name]\n+    except KeyError:\n+        raise FieldDoesNotExist(\"%s has no field named '%s'\" % (self.object_name, field_name))\n \n     def get_base_chain(self, model):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12965",
        "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 29e33c075f..4dabdd3b41 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1407,7 +1407,10 @@ class SQLInsertCompiler(SQLCompiler):\n class SQLDeleteCompiler(SQLCompiler):\n     @cached_property\n     def single_alias(self):\n-        return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1\n+        # If there is exactly one alias in the query, use simple \"DELETE FROM table\"\n+        # rather than deleting via a subquery. This fixes the regression where\n+        # DELETE queries generate inefficient subqueries.\n+        return len(self.query.alias_map) == 1\n \n     def _as_sql(self, query):\n         result = [\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13012",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex c1a76584f0..8ff4dadfb9 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -862,6 +862,109 @@ class ExpressionWrapper(Expression):\n \n     def get_source_expressions(self):\n         return [self.expression]\n+    def get_group_by_cols(self, alias=None):\n+\n+\n+        return self.expression.get_group_by_cols(alias)\n+\n+\n \n     def as_sql(self, compiler, connection):\n         return self.expression.as_sql(compiler, connection)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13023",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13028",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..3b6c7b468c 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1124,6 +1124,101 @@ class Query(BaseExpression):\n \n     def check_filterable(self, expression):\n         \"\"\"Raise an error if expression cannot be used in a WHERE clause.\"\"\"\n+    from django.db.models import Model\n+\n+\n+    if isinstance(expression, Model):\n+\n+\n+        return\n+\n+\n         if not getattr(expression, 'filterable', True):\n             raise NotSupportedError(\n                 expression.__class__.__name__ + ' is disallowed in the filter '\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13033",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex d65141b834..971080d00b 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1680,15 +1680,21 @@ class Query(BaseExpression):\n             else:\n                 return annotation\n         else:\n-            field_list = name.split(LOOKUP_SEP)\n-            join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)\n-            targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)\n-            if not allow_joins and len(join_list) > 1:\n-                raise FieldError('Joined field references are not permitted in this query')\n-            if len(targets) > 1:\n-                raise FieldError(\"Referencing multicolumn fields with F() objects \"\n-                                 \"isn't supported\")\n-            # Verify that the last lookup in name is a field or a transform:\n+    else:\n+        field_list = name.split(LOOKUP_SEP)\n+        # NEW: If the lookup is explicit on the FK\u2019s id field (e.g. \"record__root_id\")\n+        # and the FK field\u2019s attname matches that suffix, then we convert the\n+        # lookup into a two\u2010step relationship lookup (e.g. \"record__root__id\").\n+        if len(field_list) == 2:\n+            try:\n+                fk_field = self.get_meta().get_field(field_list[0])\n+                if fk_field.is_relation and fk_field.attname == field_list[1]:\n+                    # Replace lookup [\"record\", \"root_id\"] with [\"record\", \"id\"]\n+                    field_list = [field_list[0], fk_field.related_model._meta.pk.name]\n+            except FieldDoesNotExist:\n+                pass\n+        join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)\n+\n             # transform_function() raises FieldError if not.\n             join_info.transform_function(targets[0], final_alias)\n             if reuse is not None:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13089",
        "model_patch": "diff --git a/django/core/cache/backends/db.py b/django/core/cache/backends/db.py\nindex 33c79c5a14..d302928505 100644\n--- a/django/core/cache/backends/db.py\n+++ b/django/core/cache/backends/db.py\n@@ -267,9 +267,11 @@ class DatabaseCache(BaseDatabaseCache):\n                 cursor.execute(\n                     connection.ops.cache_key_culling_sql() % table,\n                     [cull_num])\n-                cursor.execute(\"DELETE FROM %s \"\n-                               \"WHERE cache_key < %%s\" % table,\n-                               [cursor.fetchone()[0]])\n+                row = cursor.fetchone()\n+                if row is not None:\n+                    threshold = row[0]\n+                    cursor.execute(\"DELETE FROM %s WHERE cache_key < %%s\" % table, [threshold])\n+\n \n     def clear(self):\n         db = router.db_for_write(self.cache_model_class)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13109",
        "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex d517d7269b..7238144140 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -914,9 +914,10 @@ class ForeignKey(ForeignObject):\n             return\n \n         using = router.db_for_read(self.remote_field.model, instance=model_instance)\n-        qs = self.remote_field.model._default_manager.using(using).filter(\n-            **{self.remote_field.field_name: value}\n-        )\n+qs = self.remote_field.model._base_manager.using(using).filter(\n+    **{self.remote_field.field_name: value}\n+)\n+\n         qs = qs.complex_filter(self.get_limit_choices_to())\n         if not qs.exists():\n             raise exceptions.ValidationError(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13112",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13121",
        "model_patch": "diff --git a/django/db/backends/mysql/operations.py b/django/db/backends/mysql/operations.py\nindex af8cfd86b5..ac30b65c87 100644\n--- a/django/db/backends/mysql/operations.py\n+++ b/django/db/backends/mysql/operations.py\n@@ -276,10 +276,12 @@ class DatabaseOperations(BaseDatabaseOperations):\n         return \"VALUES \" + values_sql\n \n     def combine_expression(self, connector, sub_expressions):\n+        # If the expression is combining DurationField values, use our duration-specific override.\n+        if (hasattr(sub_expressions[0], 'output_field') and\n+                sub_expressions[0].output_field.get_internal_type() == 'DurationField'):\n+            return self.combine_duration_expression(connector, sub_expressions)\n         if connector == '^':\n             return 'POW(%s)' % ','.join(sub_expressions)\n-        # Convert the result to a signed integer since MySQL's binary operators\n-        # return an unsigned integer.\n         elif connector in ('&', '|', '<<', '#'):\n             connector = '^' if connector == '#' else connector\n             return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions)\n@@ -288,6 +290,493 @@ class DatabaseOperations(BaseDatabaseOperations):\n             return 'FLOOR(%(lhs)s / POW(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs}\n         return super().combine_expression(connector, sub_expressions)\n \n+    def combine_duration_expression(self, connector, sub_expressions):\n+\n+\n+        if connector not in ['+', '-']:\n+\n+\n+            raise DatabaseError('Invalid connector for timedelta: %s.' % connector)\n+\n+\n+        if len(sub_expressions) != 2:\n+\n+\n+            raise ValueError('Duration arithmetic requires exactly two operands.')\n+\n+\n+        # Directly perform arithmetic on the microsecond numeric representation.\n+\n+\n+        return \"(%s %s %s)\" % (sub_expressions[0], connector, sub_expressions[1])\n+\n+\n+\n     def get_db_converters(self, expression):\n         converters = super().get_db_converters(expression)\n         internal_type = expression.output_field.get_internal_type()\ndiff --git a/django/db/backends/sqlite3/operations.py b/django/db/backends/sqlite3/operations.py\nindex 9510b5edd9..4d8e7b3b65 100644\n--- a/django/db/backends/sqlite3/operations.py\n+++ b/django/db/backends/sqlite3/operations.py\n@@ -336,13 +336,13 @@ class DatabaseOperations(BaseDatabaseOperations):\n             return 'BITXOR(%s)' % ','.join(sub_expressions)\n         return super().combine_expression(connector, sub_expressions)\n \n-    def combine_duration_expression(self, connector, sub_expressions):\n-        if connector not in ['+', '-']:\n-            raise DatabaseError('Invalid connector for timedelta: %s.' % connector)\n-        fn_params = [\"'%s'\" % connector] + sub_expressions\n-        if len(fn_params) > 3:\n-            raise ValueError('Too many params for timedelta operations.')\n-        return \"django_format_dtdelta(%s)\" % ', '.join(fn_params)\n+def combine_duration_expression(self, connector, sub_expressions):\n+    if connector not in ['+', '-']:\n+        raise DatabaseError('Invalid connector for timedelta: %s.' % connector)\n+    if len(sub_expressions) != 2:\n+        raise ValueError('Duration arithmetic requires exactly two operands.')\n+    # Directly perform arithmetic on the microsecond numeric representation.\n+    return \"(%s %s %s)\" % (sub_expressions[0], connector, sub_expressions[1])\n \n     def integer_field_range(self, internal_type):\n         # SQLite doesn't enforce any integer constraints\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13128",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex d913658291..7ad31acdbd 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -512,8 +512,9 @@ class DurationExpression(CombinedExpression):\n class TemporalSubtraction(CombinedExpression):\n     output_field = fields.DurationField()\n \n-    def __init__(self, lhs, rhs):\n-        super().__init__(lhs, self.SUB, rhs)\n+\tdef __init__(self, lhs, rhs):\n+\t\tsuper().__init__(lhs, self.SUB, rhs, output_field=self.output_field)\n+\n \n     def as_sql(self, compiler, connection):\n         connection.ops.check_expression_support(self)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13158",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 07d6ffd4ca..6b6d6b400d 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -916,11 +916,15 @@ class QuerySet:\n             'datetimefield', flat=True\n         ).distinct().filter(plain_field__isnull=False).order_by(('-' if order == 'DESC' else '') + 'datetimefield')\n \n-    def none(self):\n-        \"\"\"Return an empty QuerySet.\"\"\"\n-        clone = self._chain()\n-        clone.query.set_empty()\n-        return clone\n+def none(self):\n+    \"\"\"Return an empty QuerySet.\"\"\"\n+    clone = self._chain()\n+    # Clear union/combinator state from previous union() calls.\n+    clone.query.combinator = None\n+    clone.query.combined_queries = ()\n+    clone.query.set_empty()\n+    return clone\n+\n \n     ##################################################################\n     # PUBLIC METHODS THAT ALTER ATTRIBUTES AND RETURN A NEW QUERYSET #\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13195",
        "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex e00bcacefb..60eba70d0b 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -215,8 +215,14 @@ class HttpResponseBase:\n         # with __Host- or __Secure- and the cookie doesn't use the secure flag.\n         secure = key.startswith(('__Secure-', '__Host-'))\n         self.set_cookie(\n-            key, max_age=0, path=path, domain=domain, secure=secure,\n+            key,\n+            max_age=0,\n+            path=path,\n             expires='Thu, 01 Jan 1970 00:00:00 GMT',\n+            domain=domain if domain is not None else settings.SESSION_COOKIE_DOMAIN,\n+            secure=(settings.SESSION_COOKIE_SECURE or secure),\n+            httponly=settings.SESSION_COOKIE_HTTPONLY,\n+            samesite=settings.SESSION_COOKIE_SAMESITE,\n         )\n \n     # Common methods used by subclasses\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13212",
        "model_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex 84b4f31ec7..2f69f3bfa1 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -48,7 +48,8 @@ class RegexValidator:\n         regex_matches = self.regex.search(str(value))\n         invalid_input = regex_matches if self.inverse_match else not regex_matches\n         if invalid_input:\n-            raise ValidationError(self.message, code=self.code)\n+            raise ValidationError(self.message, code=self.code, params={'value': value})\n+\n \n     def __eq__(self, other):\n         return (\n@@ -208,12 +209,14 @@ class EmailValidator:\n \n     def __call__(self, value):\n         if not value or '@' not in value:\n-            raise ValidationError(self.message, code=self.code)\n+                raise ValidationError(self.message, code=self.code, params={'value': value})\n+\n \n         user_part, domain_part = value.rsplit('@', 1)\n \n         if not self.user_regex.match(user_part):\n-            raise ValidationError(self.message, code=self.code)\n+            raise ValidationError(self.message, code=self.code, params={'value': value})\n+\n \n         if (domain_part not in self.domain_allowlist and\n                 not self.validate_domain_part(domain_part)):\n@@ -225,7 +228,8 @@ class EmailValidator:\n             else:\n                 if self.validate_domain_part(domain_part):\n                     return\n-            raise ValidationError(self.message, code=self.code)\n+            raise ValidationError(self.message, code=self.code, params={'value': value})\n+\n \n     def validate_domain_part(self, domain_part):\n         if self.domain_regex.match(domain_part):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13279",
        "model_patch": "diff --git a/django/core/signing.py b/django/core/signing.py\nindex c6713c3033..0e8ac2ab00 100644\n--- a/django/core/signing.py\n+++ b/django/core/signing.py\n@@ -121,9 +121,14 @@ def dumps(obj, key=None, salt='django.core.signing', serializer=JSONSerializer,\n     base64d = b64_encode(data).decode()\n     if is_compressed:\n         base64d = '.' + base64d\n+# Use legacy non-timestamped signer for DEFAULT_HASHING_ALGORITHM \"sha1\"\n+if settings.DEFAULT_HASHING_ALGORITHM == \"sha1\":\n+    return Signer(key, salt=salt).sign(base64d)\n+else:\n     return TimestampSigner(key, salt=salt).sign(base64d)\n \n \n+\n def loads(s, key=None, salt='django.core.signing', serializer=JSONSerializer, max_age=None):\n     \"\"\"\n     Reverse of dumps(), raise BadSignature if signature fails.\n@@ -132,7 +137,12 @@ def loads(s, key=None, salt='django.core.signing', serializer=JSONSerializer, ma\n     \"\"\"\n     # TimestampSigner.unsign() returns str but base64 and zlib compression\n     # operate on bytes.\n+# For legacy session data signed without a timestamp, use Signer\n+if settings.DEFAULT_HASHING_ALGORITHM == \"sha1\":\n+    base64d = Signer(key, salt=salt).unsign(s).encode()\n+else:\n     base64d = TimestampSigner(key, salt=salt).unsign(s, max_age=max_age).encode()\n+\n     decompress = base64d[:1] == b'.'\n     if decompress:\n         # It's compressed; uncompress it first\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13297",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13315",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5d115458a1..2c8307b6f5 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -100,7 +100,8 @@ def apply_limit_choices_to_to_formfield(formfield):\n     if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n+            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to).distinct()\n+\n \n \n def fields_for_model(model, fields=None, exclude=None, widgets=None,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13343",
        "model_patch": "diff --git a/django/db/models/fields/files.py b/django/db/models/fields/files.py\nindex e10a5bb6d9..5be40d772f 100644\n--- a/django/db/models/fields/files.py\n+++ b/django/db/models/fields/files.py\n@@ -17,9 +17,11 @@ class FieldFile(File):\n         super().__init__(None, name)\n         self.instance = instance\n         self.field = field\n-        self.storage = field.storage\n+        # Evaluate callable storage now at runtime so that file operations work.\n+        self.storage = field.storage() if callable(field.storage) else field.storage\n         self._committed = True\n \n+\n     def __eq__(self, other):\n         # Older code may be expecting FileField values to be simple strings.\n         # By overriding the == operator, it can remain backwards compatibility.\n@@ -228,15 +230,15 @@ class FileField(Field):\n         self._primary_key_set_explicitly = 'primary_key' in kwargs\n \n         self.storage = storage or default_storage\n-        if callable(self.storage):\n-            self.storage = self.storage()\n-            if not isinstance(self.storage, Storage):\n-                raise TypeError(\n-                    \"%s.storage must be a subclass/instance of %s.%s\"\n-                    % (self.__class__.__qualname__, Storage.__module__, Storage.__qualname__)\n-                )\n+        # Do not evaluate callable storage here \u2013 preserve the callable for deconstruction.\n+        if not callable(self.storage) and not isinstance(self.storage, Storage):\n+            raise TypeError(\n+                \"%s.storage must be a subclass/instance of %s.%s\"\n+                % (self.__class__.__qualname__, Storage.__module__, Storage.__qualname__)\n+            )\n         self.upload_to = upload_to\n \n+\n         kwargs.setdefault('max_length', 100)\n         super().__init__(verbose_name, name, **kwargs)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13344",
        "model_patch": "diff --git a/django/utils/deprecation.py b/django/utils/deprecation.py\nindex b2c681b33c..625f43fe6f 100644\n--- a/django/utils/deprecation.py\n+++ b/django/utils/deprecation.py\n@@ -115,10 +115,19 @@ class MiddlewareMixin:\n         if hasattr(self, 'process_request'):\n             response = self.process_request(request)\n         response = response or self.get_response(request)\n+        import inspect\n+        if inspect.isawaitable(response):\n+            from asgiref.sync import async_to_sync\n+\n+            async def await_response():\n+                return await response\n+\n+            response = async_to_sync(await_response)()\n         if hasattr(self, 'process_response'):\n             response = self.process_response(request, response)\n         return response\n \n+\n     async def __acall__(self, request):\n         \"\"\"\n         Async version of __call__ that is swapped in when an async request\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13346",
        "model_patch": "diff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py\nindex fafc1beee8..fec64af7d0 100644\n--- a/django/db/models/fields/json.py\n+++ b/django/db/models/fields/json.py\n@@ -489,6 +489,405 @@ KeyTransform.register_lookup(KeyTransformEndsWith)\n KeyTransform.register_lookup(KeyTransformIEndsWith)\n KeyTransform.register_lookup(KeyTransformRegex)\n KeyTransform.register_lookup(KeyTransformIRegex)\n+# Register a lookup for the \"in\" operator on KeyTransform.\n+\n+\n+class KeyTransformIn(lookups.In):\n+\n+\n+    lookup_name = 'in'\n+\n+\n+\n+\n+    # This lookup relies on the default behavior of the built-in In lookup.\n+\n+\n+    # Since the left-hand side (the key transform) already correctly produces\n+\n+\n+    # the JSON extraction SQL, we can simply use the inherited behavior.\n+\n+\n+\n+\n+KeyTransform.register_lookup(KeyTransformIn)\n+\n+\n \n KeyTransform.register_lookup(KeyTransformLt)\n KeyTransform.register_lookup(KeyTransformLte)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13363",
        "model_patch": "diff --git a/django/db/models/functions/datetime.py b/django/db/models/functions/datetime.py\nindex b6594b043b..f06c87b3ca 100644\n--- a/django/db/models/functions/datetime.py\n+++ b/django/db/models/functions/datetime.py\n@@ -289,12 +289,13 @@ class TruncDate(TruncBase):\n     lookup_name = 'date'\n     output_field = DateField()\n \n-    def as_sql(self, compiler, connection):\n-        # Cast to date rather than truncate to date.\n-        lhs, lhs_params = compiler.compile(self.lhs)\n-        tzname = timezone.get_current_timezone_name() if settings.USE_TZ else None\n-        sql = connection.ops.datetime_cast_date_sql(lhs, tzname)\n-        return sql, lhs_params\n+def as_sql(self, compiler, connection):\n+    # Cast to date rather than truncate to date.\n+    lhs, lhs_params = compiler.compile(self.lhs)\n+    tzname = self.get_tzname()  # Use the tzinfo provided if available.\n+    sql = connection.ops.datetime_cast_date_sql(lhs, tzname)\n+    return sql, lhs_params\n+\n \n \n class TruncTime(TruncBase):\n@@ -302,12 +303,13 @@ class TruncTime(TruncBase):\n     lookup_name = 'time'\n     output_field = TimeField()\n \n-    def as_sql(self, compiler, connection):\n-        # Cast to time rather than truncate to time.\n-        lhs, lhs_params = compiler.compile(self.lhs)\n-        tzname = timezone.get_current_timezone_name() if settings.USE_TZ else None\n-        sql = connection.ops.datetime_cast_time_sql(lhs, tzname)\n-        return sql, lhs_params\n+def as_sql(self, compiler, connection):\n+    # Cast to time rather than truncate to time.\n+    lhs, lhs_params = compiler.compile(self.lhs)\n+    tzname = self.get_tzname()  # Use the tzinfo provided if available.\n+    sql = connection.ops.datetime_cast_time_sql(lhs, tzname)\n+    return sql, lhs_params\n+\n \n \n class TruncHour(TruncBase):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13401",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13406",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex b48d0df9c0..d4c237768d 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -37,14 +37,15 @@ REPR_OUTPUT_SIZE = 20\n class BaseIterable:\n     def __init__(self, queryset, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):\n         self.queryset = queryset\n-        self.chunked_fetch = chunked_fetch\n-        self.chunk_size = chunk_size\n+@property\n+def _iterable_class(self):\n+    from django.db.models.query import ModelIterable, ValuesIterable\n+    # If the underlying query returns dict results (i.e. it was built via values()),\n+    # then use the ValuesIterable. Otherwise, use the default ModelIterable.\n+    if self.query.is_values_query:\n+        return ValuesIterable\n+    return ModelIterable\n \n-\n-class ModelIterable(BaseIterable):\n-    \"\"\"Iterable that yields a model instance for each row.\"\"\"\n-\n-    def __iter__(self):\n         queryset = self.queryset\n         db = queryset.db\n         compiler = queryset.query.get_compiler(using=db)\ndiff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..8f26c46fa9 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -236,6 +236,303 @@ class Query(BaseExpression):\n             return getattr(select, 'target', None) or select.field\n         elif len(self.annotation_select) == 1:\n             return next(iter(self.annotation_select.values())).output_field\n+    @property\n+\n+\n+    def is_values_query(self):\n+\n+\n+        \"\"\"\n+\n+\n+        Return True if this Query was originally built using values()/values_list()\n+\n+\n+        so that the SQL results should be returned as a dictionary rather than a model instance.\n+\n+\n+        \"\"\"\n+\n+\n+        return bool(self.values_select)\n+\n+\n \n     @property\n     def has_select_fields(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13410",
        "model_patch": "diff --git a/django/core/files/locks.py b/django/core/files/locks.py\nindex c46b00b905..b3dd86771b 100644\n--- a/django/core/files/locks.py\n+++ b/django/core/files/locks.py\n@@ -106,10 +106,18 @@ else:\n             # File is unlocked\n             return True\n     else:\n-        def lock(f, flags):\n-            ret = fcntl.flock(_fd(f), flags)\n-            return ret == 0\n+def lock(f, flags):\n+    try:\n+        fcntl.flock(_fd(f), flags)\n+        return True\n+    except OSError:\n+        return False\n+\n+\n+def unlock(f):\n+    try:\n+        fcntl.flock(_fd(f), fcntl.LOCK_UN)\n+        return True\n+    except OSError:\n+        return False\n \n-        def unlock(f):\n-            ret = fcntl.flock(_fd(f), fcntl.LOCK_UN)\n-            return ret == 0\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13417",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 85cd8311a7..d4022810a3 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1224,8 +1224,9 @@ class QuerySet:\n             return True\n         if self.query.extra_order_by or self.query.order_by:\n             return True\n-        elif self.query.default_ordering and self.query.get_meta().ordering:\n-            return True\n+elif self.query.default_ordering and self.query.get_meta().ordering and not self.query.group_by:\n+    return True\n+\n         else:\n             return False\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13449",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 90d90119d0..7176c19fc2 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -21,13 +21,27 @@ class SQLiteNumericMixin:\n     numeric to be properly filtered.\n     \"\"\"\n     def as_sqlite(self, compiler, connection, **extra_context):\n-        sql, params = self.as_sql(compiler, connection, **extra_context)\n-        try:\n-            if self.output_field.get_internal_type() == 'DecimalField':\n+    sql, params = self.as_sql(compiler, connection, **extra_context)\n+    try:\n+        if self.output_field.get_internal_type() == 'DecimalField':\n+            # If the SQL already includes an OVER clause (from a Window function),\n+            # move the CAST so it wraps the entire expression including OVER.\n+            if ' OVER ' in sql.upper():\n+                # Look for an already-applied CAST followed by the OVER clause.\n+                import re\n+                m = re.match(r'^CAST\\((.+?)\\s+AS\\s+NUMERIC\\)(\\s+OVER\\s+\\(.*\\))$', sql, re.IGNORECASE)\n+                if m:\n+                    inner_sql, over_clause = m.groups()\n+                    sql = 'CAST(%s%s AS NUMERIC)' % (inner_sql, over_clause)\n+                else:\n+                    # Otherwise, wrap the whole SQL\n+                    sql = 'CAST(%s AS NUMERIC)' % sql\n+            else:\n                 sql = 'CAST(%s AS NUMERIC)' % sql\n-        except FieldError:\n-            pass\n-        return sql, params\n+    except FieldError:\n+        pass\n+    return sql, params\n+\n \n \n class Combinable:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13512",
        "model_patch": "diff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py\nindex a249f4cdbf..20e4962f3c 100644\n--- a/django/db/models/fields/json.py\n+++ b/django/db/models/fields/json.py\n@@ -81,7 +81,8 @@ class JSONField(CheckFieldDefaultMixin, Field):\n     def get_prep_value(self, value):\n         if value is None:\n             return value\n-        return json.dumps(value, cls=self.encoder)\n+        return json.dumps(value, cls=self.encoder, ensure_ascii=False)\n+\n \n     def get_transform(self, name):\n         transform = super().get_transform(name)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13513",
        "model_patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex 7a89f7bd15..afa73161f5 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -395,11 +395,12 @@ class ExceptionReporter:\n         return lower_bound, pre_context, context_line, post_context\n \n     def get_traceback_frames(self):\n-        def explicit_or_implicit_cause(exc_value):\n-            explicit = getattr(exc_value, '__cause__', None)\n-            suppress_context = getattr(exc_value, '__suppress_context__', None)\n-            implicit = getattr(exc_value, '__context__', None)\n-            return explicit or (None if suppress_context else implicit)\n+    def explicit_or_implicit_cause(exc_value):\n+        explicit = getattr(exc_value, '__cause__', None)\n+        suppress_context = getattr(exc_value, '__suppress_context__', None)\n+        implicit = getattr(exc_value, '__context__', None)\n+        return explicit or (None if suppress_context else implicit)\n+\n \n         # Get the exception and all its causes\n         exceptions = []\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13516",
        "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex e6cbf8c64f..7e9f49b4d4 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -149,6 +149,55 @@ class OutputWrapper(TextIOBase):\n             msg += ending\n         style_func = style_func or self.style_func\n         self._out.write(style_func(msg))\n+    def flush(self):\n+\n+\n+        self._out.flush()\n+\n+\n \n \n class BaseCommand:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13551",
        "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..01223bb35c 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -91,10 +91,12 @@ class PasswordResetTokenGenerator:\n         Running this data through salted_hmac() prevents password cracking\n         attempts using the reset token, provided the secret isn't compromised.\n         \"\"\"\n-        # Truncate microseconds so that tokens are consistent even if the\n-        # database doesn't support microseconds.\n-        login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+# Truncate microseconds so that tokens are consistent even if the\n+# database doesn't support microseconds.\n+login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n+email = getattr(user, 'email', '')\n+return str(user.pk) + user.password + email + str(login_timestamp) + str(timestamp)\n+\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13568",
        "model_patch": "diff --git a/django/contrib/auth/checks.py b/django/contrib/auth/checks.py\nindex 65fc266f7e..dc8aba44d0 100644\n--- a/django/contrib/auth/checks.py\n+++ b/django/contrib/auth/checks.py\n@@ -1,5 +1,52 @@\n from itertools import chain\n from types import MethodType\n+from django.db.models import UniqueConstraint\n+\n+\n \n from django.apps import apps\n from django.conf import settings\n@@ -51,30 +98,37 @@ def check_user_model(app_configs=None, **kwargs):\n             )\n         )\n \n-    # Check that the username field is unique\n-    if not cls._meta.get_field(cls.USERNAME_FIELD).unique:\n-        if (settings.AUTHENTICATION_BACKENDS ==\n-                ['django.contrib.auth.backends.ModelBackend']):\n-            errors.append(\n-                checks.Error(\n-                    \"'%s.%s' must be unique because it is named as the 'USERNAME_FIELD'.\" % (\n-                        cls._meta.object_name, cls.USERNAME_FIELD\n-                    ),\n-                    obj=cls,\n-                    id='auth.E003',\n-                )\n+# Check that the username field is unique either by its \"unique\" attribute\n+# or via a UniqueConstraint in the model's Meta.constraints.\n+username_field = cls._meta.get_field(cls.USERNAME_FIELD)\n+has_unique_constraint = any(\n+    isinstance(constraint, UniqueConstraint) and\n+    constraint.fields == [cls.USERNAME_FIELD]\n+    for constraint in cls._meta.constraints\n+)\n+if not (username_field.unique or has_unique_constraint):\n+    if settings.AUTHENTICATION_BACKENDS == ['django.contrib.auth.backends.ModelBackend']:\n+        errors.append(\n+            checks.Error(\n+                \"'%s.%s' must be unique because it is named as the 'USERNAME_FIELD'.\" % (\n+                    cls._meta.object_name, cls.USERNAME_FIELD\n+                ),\n+                obj=cls,\n+                id='auth.E003',\n             )\n-        else:\n-            errors.append(\n-                checks.Warning(\n-                    \"'%s.%s' is named as the 'USERNAME_FIELD', but it is not unique.\" % (\n-                        cls._meta.object_name, cls.USERNAME_FIELD\n-                    ),\n-                    hint='Ensure that your authentication backend(s) can handle non-unique usernames.',\n-                    obj=cls,\n-                    id='auth.W004',\n-                )\n+        )\n+    else:\n+        errors.append(\n+            checks.Warning(\n+                \"'%s.%s' is named as the 'USERNAME_FIELD', but it is not unique.\" % (\n+                    cls._meta.object_name, cls.USERNAME_FIELD\n+                ),\n+                hint='Ensure that your authentication backend(s) can handle non-unique usernames.',\n+                obj=cls,\n+                id='auth.W004',\n             )\n+        )\n+\n \n     if isinstance(cls().is_anonymous, MethodType):\n         errors.append(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13569",
        "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 04e430a42e..d1fb132847 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -125,11 +125,65 @@ class SQLCompiler:\n             cols = expr.get_group_by_cols()\n             for col in cols:\n                 expressions.append(col)\n-        for expr, (sql, params, is_ref) in order_by:\n-            # Skip References to the select clause, as all expressions in the\n-            # select clause are already part of the group by.\n-            if not is_ref:\n-                expressions.extend(expr.get_group_by_cols())\n+from django.db.models.functions.math import Random\n+\n+\n+for expr, (sql, params, is_ref) in order_by:\n+    # Skip order_by expressions that are referenced or are Random,\n+    # as RANDOM() should not contribute to the GROUP BY clause.\n+    if is_ref or isinstance(expr, Random):\n+        continue\n+    expressions.extend(expr.get_group_by_cols())\n+\n         having_group_by = self.having.get_group_by_cols() if self.having else ()\n         for expr in having_group_by:\n             expressions.append(expr)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13590",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..49c21c8631 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1077,10 +1077,11 @@ class Query(BaseExpression):\n         elif isinstance(value, (list, tuple)):\n             # The items of the iterable may be expressions and therefore need\n             # to be resolved independently.\n-            return type(value)(\n+            return type(value)(*(\n                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n                 for sub_value in value\n-            )\n+            ))\n+\n         return value\n \n     def solve_lookup_type(self, lookup):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13658",
        "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex 463e4e8665..81a90a2be3 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -277,14 +277,17 @@ class BaseCommand:\n         Create and return the ``ArgumentParser`` which will be used to\n         parse the arguments to this command.\n         \"\"\"\n-        parser = CommandParser(\n-            prog='%s %s' % (os.path.basename(prog_name), subcommand),\n-            description=self.help or None,\n-            formatter_class=DjangoHelpFormatter,\n-            missing_args_message=getattr(self, 'missing_args_message', None),\n-            called_from_command_line=getattr(self, '_called_from_command_line', None),\n-            **kwargs\n-        )\n+# Use the already\u2013computed program name (set in ManagementUtility) if available\n+corrected_prog = getattr(self, 'prog_name', prog_name)\n+parser = CommandParser(\n+    prog='%s %s' % (corrected_prog, subcommand),\n+    description=self.help or None,\n+    formatter_class=DjangoHelpFormatter,\n+    missing_args_message=getattr(self, 'missing_args_message', None),\n+    called_from_command_line=getattr(self, '_called_from_command_line', None),\n+    **kwargs\n+)\n+\n         parser.add_argument('--version', action='version', version=self.get_version())\n         parser.add_argument(\n             '-v', '--verbosity', default=1,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13670",
        "model_patch": "diff --git a/django/utils/dateformat.py b/django/utils/dateformat.py\nindex afd36d79e0..bb17a1ed2a 100644\n--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -324,9 +324,10 @@ class DateFormat(TimeFormat):\n         \"ISO-8601 week number of year, weeks starting on Monday\"\n         return self.data.isocalendar()[1]\n \n-    def y(self):\n-        \"Year, 2 digits; e.g. '99'\"\n-        return str(self.data.year)[2:]\n+def y(self):\n+    \"Year, 2 digits; e.g. '99'\"\n+    return '%02d' % (self.data.year % 100)\n+\n \n     def Y(self):\n         \"Year, 4 digits; e.g. '1999'\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13741",
        "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b9eb33329f..0606e29d0f 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -56,6 +56,43 @@ class ReadOnlyPasswordHashField(forms.Field):\n \n     def __init__(self, *args, **kwargs):\n         kwargs.setdefault(\"required\", False)\n+kwargs.setdefault(\"disabled\", True)\n+\n+\n         super().__init__(*args, **kwargs)\n \n     def bound_data(self, data, initial):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13786",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex dddf7c679c..b8ef8d1356 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -137,13 +137,15 @@ class CreateModel(ModelOperation):\n                 ),\n             ]\n         elif isinstance(operation, AlterModelOptions) and self.name_lower == operation.name_lower:\n-            return [\n-                CreateModel(\n-                    self.name,\n-                    fields=self.fields,\n-                    options={**self.options, **operation.options},\n-                    bases=self.bases,\n-                    managers=self.managers,\n+    def reduce(self, operation):\n+        if isinstance(operation, AlterModelOptions) and operation.name == self.name:\n+            # Instead of merging the existing options with operation.options,\n+            # override self.options with the provided ones to ensure that model\n+            # options not explicitly provided are unset (mimicking\n+            # AlterModelOptions.state_forwards behavior)\n+            self.options = dict(operation.options)\n+            return self\n+\n                 ),\n             ]\n         elif isinstance(operation, AlterTogetherOptionOperation) and self.name_lower == operation.name_lower:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13794",
        "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 1c844580c6..c8f68c4494 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -678,11 +678,12 @@ def add(value, arg):\n         return int(value) + int(arg)\n     except (ValueError, TypeError):\n         try:\n-            return value + arg\n+            return str(value) + str(arg)\n         except Exception:\n             return ''\n \n \n+\n @register.filter(is_safe=False)\n def get_digit(value, arg):\n     \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13807",
        "model_patch": "diff --git a/django/db/backends/sqlite3/base.py b/django/db/backends/sqlite3/base.py\nindex 2eeaf98c0d..dbb34f53fa 100644\n--- a/django/db/backends/sqlite3/base.py\n+++ b/django/db/backends/sqlite3/base.py\n@@ -327,13 +327,15 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n                     violations = cursor.execute('PRAGMA foreign_key_check').fetchall()\n                 else:\n                     violations = chain.from_iterable(\n-                        cursor.execute('PRAGMA foreign_key_check(%s)' % table_name).fetchall()\n+cursor.execute('PRAGMA foreign_key_check(\"%s\")' % table_name).fetchall()\n+\n                         for table_name in table_names\n                     )\n                 # See https://www.sqlite.org/pragma.html#pragma_foreign_key_check\n                 for table_name, rowid, referenced_table_name, foreign_key_index in violations:\n                     foreign_key = cursor.execute(\n-                        'PRAGMA foreign_key_list(%s)' % table_name\n+'PRAGMA foreign_key_list(\"%s\")' % table_name\n+\n                     ).fetchall()[foreign_key_index]\n                     column_name, referenced_column_name = foreign_key[3:5]\n                     primary_key_column_name = self.introspection.get_primary_key_column(cursor, table_name)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13809",
        "model_patch": "diff --git a/django/core/management/commands/runserver.py b/django/core/management/commands/runserver.py\nindex d9fb088350..aef86bf421 100644\n--- a/django/core/management/commands/runserver.py\n+++ b/django/core/management/commands/runserver.py\n@@ -114,11 +114,15 @@ class Command(BaseCommand):\n         shutdown_message = options.get('shutdown_message', '')\n         quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C'\n \n-        self.stdout.write(\"Performing system checks...\\n\\n\")\n-        self.check(display_num_errors=True)\n-        # Need to check migrations here, so can't use the\n-        # requires_migrations_check attribute.\n-        self.check_migrations()\n+if not options.get('skip_checks'):\n+    self.stdout.write(\"Performing system checks...\\n\\n\")\n+    self.check(display_num_errors=True)\n+    # Need to check migrations here, so can't use the\n+    # requires_migrations_check attribute.\n+    self.check_migrations()\n+else:\n+    self.stdout.write(\"Skipping system checks.\\n\\n\")\n+\n         now = datetime.now().strftime('%B %d, %Y - %X')\n         self.stdout.write(now)\n         self.stdout.write((\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13810",
        "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..8cccf38a5a 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -49,20 +49,27 @@ class BaseHandler:\n                 middleware_is_async = False\n             else:\n                 middleware_is_async = middleware_can_async\n-            try:\n-                # Adapt handler, if needed.\n-                handler = self.adapt_method_mode(\n-                    middleware_is_async, handler, handler_is_async,\n-                    debug=settings.DEBUG, name='middleware %s' % middleware_path,\n-                )\n-                mw_instance = middleware(handler)\n-            except MiddlewareNotUsed as exc:\n-                if settings.DEBUG:\n-                    if str(exc):\n-                        logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n-                    else:\n-                        logger.debug('MiddlewareNotUsed: %r', middleware_path)\n-                continue\n+# Save the current handler before adaptation.\n+original_handler = handler\n+try:\n+    # Adapt handler, if needed.\n+    adapted_handler = self.adapt_method_mode(\n+        middleware_is_async, handler, handler_is_async,\n+        debug=settings.DEBUG, name='middleware %s' % middleware_path,\n+    )\n+    mw_instance = middleware(adapted_handler)\n+    # On success, update the handler to the adapted version.\n+    handler = adapted_handler\n+except MiddlewareNotUsed as exc:\n+    if settings.DEBUG:\n+        if str(exc):\n+            logger.debug('MiddlewareNotUsed(%r): %s', middleware_path, exc)\n+        else:\n+            logger.debug('MiddlewareNotUsed: %r', middleware_path)\n+    # Revert back to unadapted handler.\n+    handler = original_handler\n+    continue\n+\n \n             if mw_instance is None:\n                 raise ImproperlyConfigured(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13820",
        "model_patch": "diff --git a/django/db/migrations/loader.py b/django/db/migrations/loader.py\nindex 95a5062ec9..243e7da909 100644\n--- a/django/db/migrations/loader.py\n+++ b/django/db/migrations/loader.py\n@@ -90,9 +90,10 @@ class MigrationLoader:\n             else:\n                 # Empty directories are namespaces.\n                 # getattr() needed on PY36 and older (replace w/attribute access).\n-                if getattr(module, '__file__', None) is None:\n+                if getattr(module, '__file__', None) is None and not (hasattr(module, '__path__') and isinstance(module.__path__, list)):\n                     self.unmigrated_apps.add(app_config.label)\n                     continue\n+\n                 # Module is not a package (e.g. migrations.py).\n                 if not hasattr(module, '__path__'):\n                     self.unmigrated_apps.add(app_config.label)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13821",
        "model_patch": "diff --git a/django/db/backends/sqlite3/base.py b/django/db/backends/sqlite3/base.py\nindex ab4ea70492..c587f9f97e 100644\n--- a/django/db/backends/sqlite3/base.py\n+++ b/django/db/backends/sqlite3/base.py\n@@ -64,8 +64,9 @@ def list_aggregate(function):\n \n \n def check_sqlite_version():\n-    if Database.sqlite_version_info < (3, 8, 3):\n-        raise ImproperlyConfigured('SQLite 3.8.3 or later is required (found %s).' % Database.sqlite_version)\n+    if Database.sqlite_version_info < (3, 9, 0):\n+        raise ImproperlyConfigured('SQLite 3.9.0 or later is required (found %s).' % Database.sqlite_version)\n+\n \n \n check_sqlite_version()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13837",
        "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex b8efb9f881..3ac6326054 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -216,15 +216,29 @@ def get_child_arguments():\n     executable is reported to not have the .exe extension which can cause bugs\n     on reloading.\n     \"\"\"\n-    import django.__main__\n-    django_main_path = Path(django.__main__.__file__)\n+import __main__\n+try:\n+    # Use __main__.__spec__ to check if Python was launched with -m.\n+    main_spec = __main__.__spec__\n+except AttributeError:\n+    main_spec = None\n+\n+# Retain legacy django main path for fallback.\n+import django.__main__\n+django_main_path = Path(django.__main__.__file__)\n+\n     py_script = Path(sys.argv[0])\n \n     args = [sys.executable] + ['-W%s' % o for o in sys.warnoptions]\n-    if py_script == django_main_path:\n-        # The server was started with `python -m django runserver`.\n-        args += ['-m', 'django']\n-        args += sys.argv[1:]\n+if main_spec is not None and main_spec.parent != \"\":\n+    # Launched via -m with an arbitrary package\n+    args += ['-m', main_spec.parent]\n+    args += sys.argv[1:]\n+elif py_script == django_main_path:\n+    # Legacy case: launched with `python -m django runserver`.\n+    args += ['-m', 'django']\n+    args += sys.argv[1:]\n+\n     elif not py_script.exists():\n         # sys.argv[0] may not exist for several reasons on Windows.\n         # It may exist with a .exe extension or have a -script.py suffix.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13925",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13933",
        "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex daa65d61eb..f77a416748 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -54,10 +54,10 @@ class Field:\n         'required': _('This field is required.'),\n     }\n     empty_values = list(validators.EMPTY_VALUES)\n+    default_error_messages = {\n+        'invalid_choice': _('Select a valid choice. %(value)s is not one of the available choices.'),\n+    }\n \n-    def __init__(self, *, required=True, widget=None, label=None, initial=None,\n-                 help_text='', error_messages=None, show_hidden_initial=False,\n-                 validators=(), localize=False, disabled=False, label_suffix=None):\n         # required -- Boolean that specifies whether the field is required.\n         #             True by default.\n         # widget -- A Widget class, or instance of a Widget class, that should\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13964",
        "model_patch": "diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex 872a4c98dc..88784e8ad0 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -193,6 +193,611 @@ class ForwardManyToOneDescriptor:\n                     remote_field.set_cached_value(rel_obj, instance)\n             self.field.set_cached_value(instance, rel_obj)\n \n+        # --- NEW: update parent's foreign key value from the cached related object ---\n+\n+\n+        if rel_obj is not None:\n+\n+\n+            # In most cases there is exactly one related field pair (local, remote)\n+\n+\n+            local_field, remote_field = self.field.related_fields[0]\n+\n+\n+            current_fk = instance.__dict__.get(self.field.attname)\n+\n+\n+            updated_fk = getattr(rel_obj, remote_field.attname)\n+\n+\n+            if current_fk != updated_fk:\n+\n+\n+                instance.__dict__[self.field.attname] = updated_fk\n+\n+\n+        # -------------------------------------------------------------------------\n+\n+\n         if rel_obj is None and not self.field.null:\n             raise self.RelatedObjectDoesNotExist(\n                 \"%s has no %s.\" % (self.field.model.__name__, self.field.name)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14007",
        "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex f02199d97c..bcbb737201 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1400,25 +1400,43 @@ class SQLInsertCompiler(SQLCompiler):\n                 for p, vals in zip(placeholder_rows, param_rows)\n             ]\n \n-    def execute_sql(self, returning_fields=None):\n-        assert not (\n-            returning_fields and len(self.query.objs) != 1 and\n-            not self.connection.features.can_return_rows_from_bulk_insert\n-        )\n-        self.returning_fields = returning_fields\n-        with self.connection.cursor() as cursor:\n-            for sql, params in self.as_sql():\n-                cursor.execute(sql, params)\n-            if not self.returning_fields:\n-                return []\n-            if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:\n-                return self.connection.ops.fetch_returned_insert_rows(cursor)\n-            if self.connection.features.can_return_columns_from_insert:\n-                assert len(self.query.objs) == 1\n-                return [self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)]\n-            return [(self.connection.ops.last_insert_id(\n-                cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column\n-            ),)]\n+def execute_sql(self, returning_fields=None):\n+    assert not (\n+        returning_fields and len(self.query.objs) != 1 and\n+        not self.connection.features.can_return_rows_from_bulk_insert\n+    )\n+    self.returning_fields = returning_fields\n+    with self.connection.cursor() as cursor:\n+        for sql, params in self.as_sql():\n+            cursor.execute(sql, params)\n+        if not self.returning_fields:\n+            return []\n+\n+        # Fetch the converters for the returning field expressions so that\n+        # from_db_value is applied to the raw database return value.\n+        converters = self.get_converters(self.returning_fields)\n+\n+        if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:\n+            raw_rows = self.connection.ops.fetch_returned_insert_rows(cursor)\n+            if converters:\n+                raw_rows = list(self.apply_converters(raw_rows, converters))\n+            return raw_rows\n+\n+        if self.connection.features.can_return_columns_from_insert:\n+            assert len(self.query.objs) == 1\n+            raw_row = self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)\n+            if converters:\n+                # apply_converters expects an iterable of rows; process [raw_row]\n+                raw_row = list(self.apply_converters([raw_row], converters))[0]\n+            return [raw_row]\n+\n+        # Fallback using last_insert_id.\n+        raw_id = (self.connection.ops.last_insert_id(\n+            cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column\n+        ),)\n+        if converters:\n+            raw_id = list(self.apply_converters([raw_id], converters))[0]\n+        return [raw_id]\n \n \n class SQLDeleteCompiler(SQLCompiler):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14011",
        "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..f8f392b1b6 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -80,6 +80,531 @@ class WSGIServer(simple_server.WSGIServer):\n class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n     \"\"\"A threaded version of the WSGIServer\"\"\"\n     daemon_threads = True\n+    def process_request_thread(self, request, client_address):\n+\n+\n+        \"\"\"\n+\n+\n+        Process a request in a separate thread and ensure that database connections\n+\n+\n+        are closed after finishing the request.\n+\n+\n+        \"\"\"\n+\n+\n+        try:\n+\n+\n+            self.finish_request(request, client_address)\n+\n+\n+        except Exception:\n+\n+\n+            self.handle_error(request, client_address)\n+\n+\n+        finally:\n+\n+\n+            self.shutdown_request(request)\n+\n+\n+            from django.db import connections\n+\n+\n+            connections.close_all()\n+\n+\n \n \n class ServerHandler(simple_server.ServerHandler):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14017",
        "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..37663994c8 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -40,8 +40,11 @@ class Q(tree.Node):\n         super().__init__(children=[*args, *sorted(kwargs.items())], connector=_connector, negated=_negated)\n \n     def _combine(self, other, conn):\n-        if not isinstance(other, Q):\n-            raise TypeError(other)\n+if not isinstance(other, Q):\n+    if hasattr(other, '__rand__'):\n+        return other.__rand__(self)\n+    raise TypeError(other)\n+\n \n         # If the other Q() is empty, ignore it and just use `self`.\n         if not other:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14034",
        "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 65d6a9ec82..e82c6df5b1 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -1023,10 +1023,23 @@ class MultiValueField(Field):\n             value = self.widget.decompress(value)\n         if not value or isinstance(value, (list, tuple)):\n             if not value or not [v for v in value if v not in self.empty_values]:\n-                if self.required:\n-                    raise ValidationError(self.error_messages['required'], code='required')\n+                # Instead of immediately returning compress([]) when all values are empty,\n+                # check each sub-field. Even if the overall field is not required, we should\n+                # raise an error if any individual sub-field is required but missing.\n+                errors = []\n+                for i, field in enumerate(self.fields):\n+                    try:\n+                        field_value = value[i]\n+                    except IndexError:\n+                        field_value = None\n+                    if field.required and field_value in self.empty_values:\n+                        # Use the field's 'incomplete' error message if defined\n+                        errors.append(field.error_messages.get('incomplete', self.error_messages['incomplete']))\n+                if errors:\n+                    raise ValidationError(errors)\n                 else:\n                     return self.compress([])\n+\n         else:\n             raise ValidationError(self.error_messages['invalid'], code='invalid')\n         for i, field in enumerate(self.fields):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14053",
        "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..3624ab0179 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -235,9 +235,11 @@ class HashedFilesMixin:\n \n         for i in range(self.max_post_process_passes):\n             substitutions = False\n-            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                yield name, hashed_name, processed\n-                substitutions = substitutions or subst\n+for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+    if subst:\n+        yield name, hashed_name, processed\n+    substitutions = substitutions or subst\n+\n \n             if not substitutions:\n                 break\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14089",
        "model_patch": "diff --git a/django/utils/datastructures.py b/django/utils/datastructures.py\nindex 871b016715..90872592ce 100644\n--- a/django/utils/datastructures.py\n+++ b/django/utils/datastructures.py\n@@ -23,6 +23,77 @@ class OrderedSet:\n             pass\n \n     def __iter__(self):\n+    def __reversed__(self):\n+\n+\n+        return reversed(list(self.dict))\n+\n+\n         return iter(self.dict)\n \n     def __contains__(self, item):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14122",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 6c728d17bf..597d75e6b2 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -2028,14 +2028,20 @@ class Query(BaseExpression):\n                     })\n                     seen_models.add(model)\n \n-        group_by = list(self.select)\n-        if self.annotation_select:\n-            for alias, annotation in self.annotation_select.items():\n-                if not allow_aliases or alias in column_names:\n-                    alias = None\n-                group_by_cols = annotation.get_group_by_cols(alias=alias)\n-                group_by.extend(group_by_cols)\n-        self.group_by = tuple(group_by)\n+group_by = list(self.select)\n+# If ordering has been cleared (i.e. self.default_ordering is False), remove Meta.ordering fields from GROUP BY.\n+if not self.default_ordering:\n+    meta = self.get_meta()\n+    ordering_field_names = {f.attname for f in meta.concrete_fields for ord_field in meta.ordering if f.name == ord_field.lstrip('-')}\n+    group_by = [col for col in group_by if not (hasattr(col, 'target') and col.target and col.target.attname in ordering_field_names)]\n+if self.annotation_select:\n+    for alias, annotation in self.annotation_select.items():\n+        if not allow_aliases or alias in column_names:\n+            alias = None\n+        group_by_cols = annotation.get_group_by_cols(alias=alias)\n+        group_by.extend(group_by_cols)\n+self.group_by = tuple(group_by)\n+\n \n     def add_select_related(self, fields):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14140",
        "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex ae0f886107..ba051217ab 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -87,11 +87,12 @@ class Q(tree.Node):\n         args, kwargs = (), {}\n         if len(self.children) == 1 and not isinstance(self.children[0], Q):\n             child = self.children[0]\n-            kwargs = {child[0]: child[1]}\n-        else:\n-            args = tuple(self.children)\n-            if self.connector != self.default:\n-                kwargs = {'_connector': self.connector}\n+            # Only treat child as key/value if it is a 2-item tuple/list.\n+            if isinstance(child, (list, tuple)) and len(child) == 2:\n+                kwargs = {child[0]: child[1]}\n+            else:\n+                args = (child,)\n+\n         if self.negated:\n             kwargs['_negated'] = True\n         return path, args, kwargs\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14155",
        "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..c8f5de8ef6 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -30,30 +30,40 @@ from .utils import get_callable\n \n \n class ResolverMatch:\n-    def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n-        self.func = func\n-        self.args = args\n-        self.kwargs = kwargs\n-        self.url_name = url_name\n-        self.route = route\n-        self.tried = tried\n-\n-        # If a URLRegexResolver doesn't have a namespace or app_name, it passes\n-        # in an empty value.\n-        self.app_names = [x for x in app_names if x] if app_names else []\n-        self.app_name = ':'.join(self.app_names)\n-        self.namespaces = [x for x in namespaces if x] if namespaces else []\n-        self.namespace = ':'.join(self.namespaces)\n-\n-        if not hasattr(func, '__name__'):\n-            # A class-based view\n-            self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n-        else:\n-            # A function-based view\n-            self._func_path = func.__module__ + '.' + func.__name__\n-\n-        view_path = url_name or self._func_path\n-        self.view_name = ':'.join(self.namespaces + [view_path])\n+def __init__(self, func, args, kwargs, url_name=None, app_names=None, namespaces=None, route=None, tried=None):\n+    import functools\n+    # Unwrap the partial function if provided to get the underlying view.\n+    if isinstance(func, functools.partial):\n+        partial_obj = func\n+        func = partial_obj.func\n+        # Prepend preset positional arguments.\n+        args = partial_obj.args + args\n+        # Merge preset keyword arguments with the provided kwargs.\n+        new_kwargs = {}\n+        if partial_obj.keywords:\n+            new_kwargs.update(partial_obj.keywords)\n+        new_kwargs.update(kwargs)\n+        kwargs = new_kwargs\n+\n+    self.func = func\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+    # If a URLRegexResolver doesn't have a namespace or app_name, it passes in an empty value.\n+    self.app_names = [x for x in app_names if x] if app_names else []\n+    self.app_name = ':'.join(self.app_names)\n+    self.namespaces = [x for x in namespaces if x] if namespaces else []\n+    self.namespace = ':'.join(self.namespaces)\n+\n+    if hasattr(func, '__name__'):\n+        # A function-based view\n+        self._func_path = func.__module__ + '.' + func.__name__\n+    else:\n+        # A class-based view\n+        self._func_path = func.__class__.__module__ + '.' + func.__class__.__name__\n+\n+    view_path = url_name or self._func_path\n+    self.view_name = ':'.join(self.namespaces + [view_path])\n \n     def __getitem__(self, index):\n         return (self.func, self.args, self.kwargs)[index]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14170",
        "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex 916478d075..24cc6733a7 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -547,8 +547,12 @@ class YearLookup(Lookup):\n         return bounds\n \n     def as_sql(self, compiler, connection):\n-        # Avoid the extract operation if the rhs is a direct value to allow\n-        # indexes to be used.\n+        # When filtering with the iso_year lookup, we must use the full\n+        # ExtractIsoYear implementation, not the optimization which produces a BETWEEN clause.\n+        if getattr(self.lhs, 'lookup_name', None) == 'iso_year':\n+            return super().as_sql(compiler, connection)\n+\n+        # Avoid the extract operation if the rhs is a direct value to allow indexes to be used.\n         if self.rhs_is_direct_value():\n             # Skip the extract part by directly using the originating field,\n             # that is self.lhs.lhs.\n@@ -560,6 +564,7 @@ class YearLookup(Lookup):\n             return '%s %s' % (lhs_sql, rhs_sql), params\n         return super().as_sql(compiler, connection)\n \n+\n     def get_direct_rhs_sql(self, connection, rhs):\n         return connection.operators[self.lookup_name] % rhs\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14238",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14311",
        "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex b6af5f5491..d3d3496447 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -223,9 +223,14 @@ def get_child_arguments():\n     # __spec__ is set when the server was started with the `-m` option,\n     # see https://docs.python.org/3/reference/import.html#main-spec\n     # __spec__ may not exist, e.g. when running in a Conda env.\n-    if getattr(__main__, '__spec__', None) is not None and __main__.__spec__.parent:\n-        args += ['-m', __main__.__spec__.parent]\n+    if getattr(__main__, '__spec__', None) is not None:\n+        if getattr(__main__.__spec__, 'submodule_search_locations', None):\n+            module_name = __main__.__spec__.parent\n+        else:\n+            module_name = __main__.__spec__.name\n+        args += ['-m', module_name]\n         args += sys.argv[1:]\n+\n     elif not py_script.exists():\n         # sys.argv[0] may not exist for several reasons on Windows.\n         # It may exist with a .exe extension or have a -script.py suffix.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14315",
        "model_patch": "diff --git a/django/db/backends/base/client.py b/django/db/backends/base/client.py\nindex 339f1e863c..f268462986 100644\n--- a/django/db/backends/base/client.py\n+++ b/django/db/backends/base/client.py\n@@ -23,4 +23,27 @@ class BaseDatabaseClient:\n         args, env = self.settings_to_cmd_args_env(self.connection.settings_dict, parameters)\n         if env:\n             env = {**os.environ, **env}\n+else:\n+\n+\n+    env = None\n+\n+\n         subprocess.run(args, env=env, check=True)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14349",
        "model_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex a385819510..5368bfd9b1 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -101,6 +101,215 @@ class URLValidator(RegexValidator):\n     def __call__(self, value):\n         if not isinstance(value, str):\n             raise ValidationError(self.message, code=self.code, params={'value': value})\n+        # Explicit check for forbidden whitespace characters\n+\n+\n+        if any(c in value for c in ('\\n', '\\r', '\\t')):\n+\n+\n+            raise ValidationError(self.message, code=self.code, params={'value': value})\n+\n+\n         # Check if the scheme is valid.\n         scheme = value.split('://')[0].lower()\n         if scheme not in self.schemes:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14351",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 6629a1fd51..10449ec57a 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -7,15 +7,28 @@ databases). The abstraction barrier only works one way: this module has to know\n all about the internals of models in order to get the information it needs.\n \"\"\"\n import copy\n-import difflib\n-import functools\n-import sys\n-from collections import Counter, namedtuple\n-from collections.abc import Iterator, Mapping\n-from itertools import chain, count, product\n-from string import ascii_uppercase\n-\n-from django.core.exceptions import FieldDoesNotExist, FieldError\n+    for field in opts.concrete_fields:\n+        model = field.model._meta.concrete_model\n+        # A proxy model will have a different model and concrete_model.\n+        # We assign None if the field belongs to this model.\n+        if model == opts.model:\n+            model = None\n+        if from_parent and model is not None and issubclass(\n+                from_parent._meta.concrete_model, model._meta.concrete_model):\n+            # Avoid loading data for already loaded parents.\n+            # This happens when select_related() resolution proceeds from parent to child.\n+            continue\n+        if field.model in only_load and field.attname not in only_load[field.model]:\n+            continue\n+        alias = self.query.join_parent_model(opts, model, start_alias, seen_models)\n+        column = field.get_col(alias)\n+        result.append(column)\n+    # If this query is being used as a subquery \u2013 such as for an __in lookup \u2013\n+    # return only the primary key column to avoid \"subquery must return only one column\" error.\n+    if self.query.subquery and len(result) > 1:\n+        result = [result[0]]\n+    return result\n+\n from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections\n from django.db.models.aggregates import Count\n from django.db.models.constants import LOOKUP_SEP\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14373",
        "model_patch": "diff --git a/django/utils/dateformat.py b/django/utils/dateformat.py\nindex 38e89c47bb..3ac0bebb04 100644\n--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -312,9 +312,10 @@ class DateFormat(TimeFormat):\n         \"\"\"Year, 2 digits with leading zeros; e.g. '99'.\"\"\"\n         return '%02d' % (self.data.year % 100)\n \n-    def Y(self):\n-        \"Year, 4 digits; e.g. '1999'\"\n-        return self.data.year\n+def Y(self):\n+    \"Year, 4 digits; e.g. '1999'\"\n+    return '%04d' % self.data.year\n+\n \n     def z(self):\n         \"\"\"Day of the year, i.e. 1 to 366.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14376",
        "model_patch": "diff --git a/django/db/backends/mysql/base.py b/django/db/backends/mysql/base.py\nindex 2c62182d31..fea33c5872 100644\n--- a/django/db/backends/mysql/base.py\n+++ b/django/db/backends/mysql/base.py\n@@ -200,9 +200,11 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n         if settings_dict['USER']:\n             kwargs['user'] = settings_dict['USER']\n         if settings_dict['NAME']:\n-            kwargs['db'] = settings_dict['NAME']\n+            kwargs['database'] = settings_dict['NAME']\n+\n         if settings_dict['PASSWORD']:\n-            kwargs['passwd'] = settings_dict['PASSWORD']\n+            kwargs['password'] = settings_dict['PASSWORD']\n+\n         if settings_dict['HOST'].startswith('/'):\n             kwargs['unix_socket'] = settings_dict['HOST']\n         elif settings_dict['HOST']:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14404",
        "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 59a4a0364d..325cabf711 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -420,7 +420,9 @@ class AdminSite:\n     def catch_all_view(self, request, url):\n         if settings.APPEND_SLASH and not url.endswith('/'):\n             urlconf = getattr(request, 'urlconf', None)\n-            path = '%s/' % request.path_info\n+# Use request.path instead of request.path_info to include FORCE_SCRIPT_NAME.\n+path = '%s/' % request.path\n+\n             try:\n                 match = resolve(path, urlconf)\n             except Resolver404:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14434",
        "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex ad2f5a7da1..3dfc462681 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -1251,7 +1251,8 @@ class BaseDatabaseSchemaEditor:\n         else:\n             sql = self.sql_create_unique\n         if columns:\n-            columns = self._index_columns(table, columns, col_suffixes=(), opclasses=opclasses)\n+\t            columns = self._index_columns(model._meta.db_table, columns, col_suffixes=(), opclasses=opclasses)\n+\n         else:\n             columns = Expressions(model._meta.db_table, expressions, compiler, self.quote_value)\n         return Statement(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14493",
        "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex f957a667b2..52158ea3f6 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -261,17 +261,20 @@ class HashedFilesMixin:\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n-        for i in range(self.max_post_process_passes):\n-            substitutions = False\n-            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                # Overwrite since hashed_name may be newer.\n-                processed_adjustable_paths[name] = (name, hashed_name, processed)\n-                substitutions = substitutions or subst\n+global_substitutions = False\n+for i in range(self.max_post_process_passes):\n+    substitutions = False\n+    for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+        # Overwrite since hashed_name may be newer.\n+        processed_adjustable_paths[name] = (name, hashed_name, processed)\n+        substitutions = substitutions or subst\n+    global_substitutions = global_substitutions or substitutions\n+    if not substitutions:\n+        break\n+\n \n-            if not substitutions:\n-                break\n+if global_substitutions:\n \n-        if substitutions:\n             yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n \n         # Store the processed paths\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14500",
        "model_patch": "diff --git a/django/db/migrations/executor.py b/django/db/migrations/executor.py\nindex 57042a8690..dc47e54d44 100644\n--- a/django/db/migrations/executor.py\n+++ b/django/db/migrations/executor.py\n@@ -250,12 +250,10 @@ class MigrationExecutor:\n         if not fake:\n             with self.connection.schema_editor(atomic=migration.atomic) as schema_editor:\n                 state = migration.unapply(state, schema_editor)\n-        # For replacement migrations, record individual statuses\n-        if migration.replaces:\n-            for app_label, name in migration.replaces:\n-                self.recorder.record_unapplied(app_label, name)\n-        else:\n-            self.recorder.record_unapplied(migration.app_label, migration.name)\n+        # For all migrations (including squashed/replacement migrations),\n+        # record the unapplication using the migration\u2019s own key.\n+        self.recorder.record_unapplied(migration.app_label, migration.name)\n+\n         # Report progress\n         if self.progress_callback:\n             self.progress_callback(\"unapply_success\", migration, fake)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14534",
        "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 2ff8b0ee26..bd22483bda 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -275,9 +275,10 @@ class BoundWidget:\n             return self.data['template_name']\n         return self.parent_widget.template_name\n \n-    @property\n-    def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+@property\n+def id_for_label(self):\n+    return self.data['attrs']['id']\n+\n \n     @property\n     def choice_label(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14539",
        "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex 3bc02b8dd3..450defcd59 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -284,7 +284,8 @@ def urlize(text, trim_url_limit=None, nofollow=False, autoescape=False):\n             stripped = middle_unescaped.rstrip(TRAILING_PUNCTUATION_CHARS)\n             if middle_unescaped != stripped:\n                 trail = middle[len(stripped):] + trail\n-                middle = middle[:len(stripped) - len(middle_unescaped)]\n+                middle = middle[:len(stripped)]\n+\n                 trimmed_something = True\n         return lead, middle, trail\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14559",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 387deca527..e1c5f6bd82 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -540,8 +540,9 @@ class QuerySet:\n             raise ValueError('bulk_update() can only be used with concrete fields.')\n         if any(f.primary_key for f in fields):\n             raise ValueError('bulk_update() cannot be used with primary key fields.')\n-        if not objs:\n-            return\n+if not objs:\n+    return 0\n+\n         # PK is used twice in the resulting update query, once in the filter\n         # and once in the WHEN. Each field will also have one CAST.\n         max_batch_size = connections[self.db].ops.bulk_batch_size(['pk', 'pk'] + fields, objs)\n@@ -563,10 +564,12 @@ class QuerySet:\n                     case_statement = Cast(case_statement, output_field=field)\n                 update_kwargs[field.attname] = case_statement\n             updates.append(([obj.pk for obj in batch_objs], update_kwargs))\n-        with transaction.atomic(using=self.db, savepoint=False):\n-            for pks, update_kwargs in updates:\n-                self.filter(pk__in=pks).update(**update_kwargs)\n-    bulk_update.alters_data = True\n+total = 0\n+with transaction.atomic(using=self.db, savepoint=False):\n+    for pks, update_kwargs in updates:\n+        total += self.filter(pk__in=pks).update(**update_kwargs)\n+bulk_update.alters_data = True\n+return total\n \n     def get_or_create(self, defaults=None, **kwargs):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14580",
        "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..0e03bf024d 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -162,13 +162,17 @@ class MigrationWriter:\n                 imports.remove(line)\n                 self.needs_manual_porting = True\n \n-        # django.db.migrations is always used, but models import may not be.\n-        # If models import exists, merge it with migrations import.\n-        if \"from django.db import models\" in imports:\n-            imports.discard(\"from django.db import models\")\n-            imports.add(\"from django.db import migrations, models\")\n-        else:\n-            imports.add(\"from django.db import migrations\")\n+# django.db.migrations is always used. However, if any operation serializes\n+# a reference to models.Model (for example in a bases tuple), we need to\n+# include an explicit models import.\n+if \"models.Model\" in items[\"operations\"]:\n+    imports.add(\"from django.db import migrations, models\")\n+elif \"from django.db import models\" in imports:\n+    imports.discard(\"from django.db import models\")\n+    imports.add(\"from django.db import migrations, models\")\n+else:\n+    imports.add(\"from django.db import migrations\")\n+\n \n         # Sort imports by the package / module to be imported (the part after\n         # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14608",
        "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex a89c35599f..db9eb79093 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -334,6 +334,63 @@ class BaseFormSet:\n         \"\"\"\n         self._errors = []\n         self._non_form_errors = self.error_class()\n+        self._non_form_errors.error_class += \" nonform\"\n+\n+\n         empty_forms_count = 0\n \n         if not self.is_bound:  # Stop further processing.\n@@ -382,6 +439,63 @@ class BaseFormSet:\n         except ValidationError as e:\n             self._non_form_errors = self.error_class(e.error_list)\n \n+        self._non_form_errors.error_class += \" nonform\"\n+\n+\n     def clean(self):\n         \"\"\"\n         Hook for doing any extra formset-wide cleaning after Form.clean() has\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14631",
        "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 88adadb37d..5c7e996e38 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -117,13 +117,13 @@ class BoundField:\n     def data(self):\n         \"\"\"\n         Return the data for this BoundField, or None if it wasn't given.\n+    def _did_change(self):\n         \"\"\"\n-        return self.form._field_data_value(self.field, self.html_name)\n-\n-    def value(self):\n+        Return True if data for this field has changed from its initial value.\n+        This delegates change detection to the field's own has_changed() method.\n         \"\"\"\n-        Return the value for this BoundField, using the initial value if\n-        the form is not bound or the data otherwise.\n+        return self.field.has_changed(self.initial, self.data)\n+\n         \"\"\"\n         data = self.initial\n         if self.form.is_bound:\ndiff --git a/django/forms/forms.py b/django/forms/forms.py\nindex d14037bfe9..bbfcb24c48 100644\n--- a/django/forms/forms.py\n+++ b/django/forms/forms.py\n@@ -388,16 +388,12 @@ class BaseForm:\n \n     def _clean_fields(self):\n         for name, field in self.fields.items():\n-            if field.disabled:\n-                value = self.get_initial_for_field(field, name)\n-            else:\n-                value = self._field_data_value(field, self.add_prefix(name))\n+            bf = self[name]\n             try:\n                 if isinstance(field, FileField):\n-                    initial = self.get_initial_for_field(field, name)\n-                    value = field.clean(value, initial)\n+                    value = field.clean(bf.data, bf.initial)\n                 else:\n-                    value = field.clean(value)\n+                    value = field.clean(bf.data)\n                 self.cleaned_data[name] = value\n                 if hasattr(self, 'clean_%s' % name):\n                     value = getattr(self, 'clean_%s' % name)()\n@@ -405,6 +401,7 @@ class BaseForm:\n             except ValidationError as e:\n                 self.add_error(name, e)\n \n+\n     def _clean_form(self):\n         try:\n             cleaned_data = self.clean()\n@@ -435,28 +432,14 @@ class BaseForm:\n         return bool(self.changed_data)\n \n     @cached_property\n+    @property\n     def changed_data(self):\n-        data = []\n-        for name, field in self.fields.items():\n-            data_value = self._field_data_value(field, self.add_prefix(name))\n-            if not field.show_hidden_initial:\n-                # Use the BoundField's initial as this is the value passed to\n-                # the widget.\n-                initial_value = self[name].initial\n-            else:\n-                initial_prefixed_name = self.add_initial_prefix(name)\n-                hidden_widget = field.hidden_widget()\n-                try:\n-                    initial_value = field.to_python(\n-                        self._widget_data_value(hidden_widget, initial_prefixed_name)\n-                    )\n-                except ValidationError:\n-                    # Always assume data has changed if validation fails.\n-                    data.append(name)\n-                    continue\n-            if field.has_changed(initial_value, data_value):\n-                data.append(name)\n-        return data\n+        return [name for name, bf in self._bound_items() if bf._did_change()]\n+\n+    def _bound_items(self):\n+        for name in self.fields:\n+            yield name, self[name]\n+\n \n     @property\n     def media(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14672",
        "model_patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\nindex ccc2223a5f..d81a5d5e8e 100644\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -306,13 +306,14 @@ class ManyToManyRel(ForeignObjectRel):\n         self.symmetrical = symmetrical\n         self.db_constraint = db_constraint\n \n-    @property\n-    def identity(self):\n-        return super().identity + (\n-            self.through,\n-            self.through_fields,\n-            self.db_constraint,\n-        )\n+@property\n+def identity(self):\n+    return super().identity + (\n+        self.through,\n+        make_hashable(self.through_fields),\n+        self.db_constraint,\n+    )\n+\n \n     def get_related_field(self):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14725",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 7effb202e3..ba726c3468 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -811,22 +811,23 @@ class BaseModelFormSet(BaseFormSet):\n                     self.saved_forms.append(form)\n         return saved_instances\n \n-    def save_new_objects(self, commit=True):\n-        self.new_objects = []\n-        for form in self.extra_forms:\n-            if not form.has_changed():\n-                continue\n-            # If someone has marked an add form for deletion, don't save the\n-            # object.\n-            if self.can_delete and self._should_delete_form(form):\n-                continue\n-            self.new_objects.append(self.save_new(form, commit=commit))\n-            if not commit:\n-                self.saved_forms.append(form)\n-        return self.new_objects\n+def save_new_objects(self, commit=True):\n+    # If extra forms are disallowed (extra==0), ignore any extra form data.\n+    if self.extra == 0:\n+        return []\n+\n+    self.new_objects = []\n+    for form in self.extra_forms:\n+        if not form.has_changed():\n+            continue\n+        # If someone has marked an add form for deletion, don't save the object.\n+        if self.can_delete and self._should_delete_form(form):\n+            continue\n+        self.new_objects.append(self.save_new(form, commit=commit))\n+        if not commit:\n+            self.saved_forms.append(form)\n+    return self.new_objects\n \n-    def add_fields(self, form, index):\n-        \"\"\"Add a hidden field for the object's primary key.\"\"\"\n         from django.db.models import AutoField, ForeignKey, OneToOneField\n         self._pk_field = pk = self.model._meta.pk\n         # If a pk isn't editable, then it won't be on the form, so we need to\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14752",
        "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..0102c8dcf8 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -26,12 +26,317 @@ class AutocompleteJsonView(BaseListView):\n         context = self.get_context_data()\n         return JsonResponse({\n             'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n+                self.serialize_result(obj, to_field_name)\n                 for obj in context['object_list']\n             ],\n             'pagination': {'more': context['page_obj'].has_next()},\n         })\n \n+    def serialize_result(self, obj, to_field_name):\n+\n+\n+        \"\"\"\n+\n+\n+        Return a dictionary representation for an autocomplete result.\n+\n+\n+        By default, includes 'id' and 'text'; override to add custom fields.\n+\n+\n+        \"\"\"\n+\n+\n+        return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n+\n+\n+\n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n         return self.model_admin.get_paginator(self.request, *args, **kwargs)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14765",
        "model_patch": "diff --git a/django/db/migrations/state.py b/django/db/migrations/state.py\nindex 088f5c41f0..8b5c5456e4 100644\n--- a/django/db/migrations/state.py\n+++ b/django/db/migrations/state.py\n@@ -91,10 +91,12 @@ class ProjectState:\n     def __init__(self, models=None, real_apps=None):\n         self.models = models or {}\n         # Apps to include from main registry, usually unmigrated ones\n-        if real_apps:\n-            self.real_apps = real_apps if isinstance(real_apps, set) else set(real_apps)\n-        else:\n-            self.real_apps = set()\n+if real_apps:\n+    assert isinstance(real_apps, set), \"real_apps must be a set\"\n+    self.real_apps = real_apps\n+else:\n+    self.real_apps = set()\n+\n         self.is_delayed = False\n         # {remote_model_key: {model_key: [(field_name, field)]}}\n         self.relations = None\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14771",
        "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex cc65c043ab..37eae6ce55 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -220,6 +220,225 @@ def get_child_arguments():\n     py_script = Path(sys.argv[0])\n \n     args = [sys.executable] + ['-W%s' % o for o in sys.warnoptions]\n+# Propagate CPython-specific -X options to the child process.\n+\n+\n+for opt, val in sys._xoptions.items():\n+\n+\n+    if val is True or val == 1:\n+\n+\n+        args.append(f'-X{opt}')\n+\n+\n+    else:\n+\n+\n+        args.append(f'-X{opt}={val}')\n+\n+\n     # __spec__ is set when the server was started with the `-m` option,\n     # see https://docs.python.org/3/reference/import.html#main-spec\n     # __spec__ may not exist, e.g. when running in a Conda env.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14787",
        "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..4006e13876 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -32,15 +32,18 @@ def _multi_decorate(decorators, method):\n     else:\n         decorators = [decorators]\n \n-    def _wrapper(self, *args, **kwargs):\n-        # bound_method has the signature that 'decorator' expects i.e. no\n-        # 'self' argument, but it's a closure over self so it can call\n-        # 'func'. Also, wrap method.__get__() in a function because new\n-        # attributes can't be set on bound method objects, only on functions.\n-        bound_method = partial(method.__get__(self, type(self)))\n-        for dec in decorators:\n-            bound_method = dec(bound_method)\n-        return bound_method(*args, **kwargs)\n+def _wrapper(self, *args, **kwargs):\n+    # Instead of using a partial (which loses function attributes), \n+    # define a closure that properly binds the method and then update \n+    # its wrapper so that metadata such as __name__ and __module__ are preserved.\n+    def bound_method_wrapper(*a, **kw):\n+        return method.__get__(self, type(self))(*a, **kw)\n+    update_wrapper(bound_method_wrapper, method)\n+    bound_method = bound_method_wrapper\n+    for dec in decorators:\n+        bound_method = dec(bound_method)\n+    return bound_method(*args, **kwargs)\n+\n \n     # Copy any attributes that a decorator adds to the function it decorates.\n     for dec in decorators:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14792",
        "model_patch": "diff --git a/django/db/backends/postgresql/operations.py b/django/db/backends/postgresql/operations.py\nindex 8d19872bea..5e673c4415 100644\n--- a/django/db/backends/postgresql/operations.py\n+++ b/django/db/backends/postgresql/operations.py\n@@ -44,12 +44,16 @@ class DatabaseOperations(BaseDatabaseOperations):\n         return \"DATE_TRUNC('%s', %s)\" % (lookup_type, field_name)\n \n     def _prepare_tzname_delta(self, tzname):\n-        if '+' in tzname:\n-            return tzname.replace('+', '-')\n-        elif '-' in tzname:\n-            return tzname.replace('-', '+')\n+        # Only invert sign if tzname is a simple offset (e.g. \"+10\" or \"-10\").\n+        import re\n+        if re.fullmatch(r'^[+-]\\d+$', tzname):\n+            if tzname.startswith('+'):\n+                return '-' + tzname[1:]\n+            else:\n+                return '+' + tzname[1:]\n         return tzname\n \n+\n     def _convert_field_to_tz(self, field_name, tzname):\n         if tzname and settings.USE_TZ:\n             field_name = \"%s AT TIME ZONE '%s'\" % (field_name, self._prepare_tzname_delta(tzname))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14855",
        "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..582d66808c 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -209,11 +209,13 @@ class AdminReadonlyField:\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(url_name, args=[quote(remote_obj.pk)],\n+                          current_app=self.model_admin.admin_site.name)\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n \n+\n     def contents(self):\n         from django.contrib.admin.templatetags.admin_list import _boolean_icon\n         field, obj, model_admin = self.field['field'], self.form.instance, self.model_admin\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14915",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5dcf923c12..53da51b5d1 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1170,6 +1170,64 @@ class ModelChoiceIteratorValue:\n         if isinstance(other, ModelChoiceIteratorValue):\n             other = other.value\n         return self.value == other\n+    def __hash__(self):\n+\n+\n+        return hash(self.value)\n+\n+\n \n \n class ModelChoiceIterator:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14999",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..b6f3b61e0a 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -320,13 +320,14 @@ class RenameModel(ModelOperation):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n-            # Move the main table\n-            schema_editor.alter_db_table(\n-                new_model,\n-                old_model._meta.db_table,\n-                new_model._meta.db_table,\n-            )\n-            # Alter the fields pointing to us\n+            # Only alter the table if the underlying database table name changed.\n+            if old_model._meta.db_table != new_model._meta.db_table:\n+                schema_editor.alter_db_table(\n+                    new_model,\n+                    old_model._meta.db_table,\n+                    new_model._meta.db_table,\n+                )\n+\n             for related_object in old_model._meta.related_objects:\n                 if related_object.related_model == old_model:\n                     model = new_model\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15022",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 66f3396a6b..689c5fbb3e 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1028,21 +1028,34 @@ class ModelAdmin(BaseModelAdmin):\n \n         may_have_duplicates = False\n         search_fields = self.get_search_fields(request)\n-        if search_fields and search_term:\n-            orm_lookups = [construct_search(str(search_field))\n-                           for search_field in search_fields]\n-            for bit in smart_split(search_term):\n-                if bit.startswith(('\"', \"'\")) and bit[0] == bit[-1]:\n-                    bit = unescape_string_literal(bit)\n-                or_queries = models.Q(\n-                    *((orm_lookup, bit) for orm_lookup in orm_lookups),\n-                    _connector=models.Q.OR,\n-                )\n-                queryset = queryset.filter(or_queries)\n-            may_have_duplicates |= any(\n-                lookup_spawns_duplicates(self.opts, search_spec)\n-                for search_spec in orm_lookups\n-            )\n+if search_fields and search_term:\n+    orm_lookups = [construct_search(str(search_field))\n+                   for search_field in search_fields]\n+    search_bits = smart_split(search_term)\n+    combined_q = None\n+    for bit in search_bits:\n+        if bit.startswith(('\"', \"'\")) and bit[0] == bit[-1]:\n+            bit = unescape_string_literal(bit)\n+        # Create an OR query for this bit across all lookup fields.\n+        bit_q = None\n+        for lookup in orm_lookups:\n+            q = models.Q(**{lookup: bit})\n+            if bit_q is None:\n+                bit_q = q\n+            else:\n+                bit_q |= q\n+        # Combine each bit's query using AND so every search word must match.\n+        if combined_q is None:\n+            combined_q = bit_q\n+        else:\n+            combined_q &= bit_q\n+    if combined_q is not None:\n+        queryset = queryset.filter(combined_q)\n+    may_have_duplicates |= any(\n+        lookup_spawns_duplicates(self.opts, search_spec)\n+        for search_spec in orm_lookups\n+    )\n+\n         return queryset, may_have_duplicates\n \n     def get_preserved_filters(self, request):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15037",
        "model_patch": "diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\nindex f9b4bfb477..8c25c8dab5 100644\n--- a/django/core/management/commands/inspectdb.py\n+++ b/django/core/management/commands/inspectdb.py\n@@ -115,19 +115,29 @@ class Command(BaseCommand):\n                     elif column_name in unique_columns:\n                         extra_params['unique'] = True\n \n-                    if is_relation:\n-                        if extra_params.pop('unique', False) or extra_params.get('primary_key'):\n-                            rel_type = 'OneToOneField'\n-                        else:\n-                            rel_type = 'ForeignKey'\n-                        rel_to = (\n-                            \"self\" if relations[column_name][1] == table_name\n-                            else table2model(relations[column_name][1])\n-                        )\n-                        if rel_to in known_models:\n-                            field_type = '%s(%s' % (rel_type, rel_to)\n-                        else:\n-                            field_type = \"%s('%s'\" % (rel_type, rel_to)\n+if is_relation:\n+    is_unique = extra_params.pop('unique', False)\n+    if is_unique or extra_params.get('primary_key'):\n+        rel_type = 'OneToOneField'\n+    else:\n+        rel_type = 'ForeignKey'\n+\n+    rel_to_table = relations[column_name][1]\n+    rel_to = (\n+        \"self\" if rel_to_table == table_name\n+        else table2model(rel_to_table)\n+    )\n+    if rel_to in known_models:\n+        field_type = '%s(%s' % (rel_type, rel_to)\n+    else:\n+        field_type = \"%s('%s'\" % (rel_type, rel_to)\n+\n+    if rel_type == 'ForeignKey':\n+        ref_column = relations[column_name][0]\n+        ref_pk = connection.introspection.get_primary_key_column(cursor, rel_to_table)\n+        if ref_column != ref_pk:\n+            extra_params['to_field'] = ref_column\n+\n                     else:\n                         # Calling `get_field_type` to get the field type string and any\n                         # additional parameters and notes.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15098",
        "model_patch": "diff --git a/django/utils/translation/trans_real.py b/django/utils/translation/trans_real.py\nindex 7dcc77b46c..9b27ccaf37 100644\n--- a/django/utils/translation/trans_real.py\n+++ b/django/utils/translation/trans_real.py\n@@ -461,6 +461,1167 @@ def get_languages():\n \n \n @functools.lru_cache(maxsize=1000)\n+def canonicalize_language_code(lang_code):\n+\n+\n+    \"\"\"\n+\n+\n+    Normalize a language code following RFC 5646:\n+\n+\n+      - The language subtag is lower-case.\n+\n+\n+      - The script subtag (if present) is title-case.\n+\n+\n+      - The region subtag (if present) is upper-case.\n+\n+\n+\n+\n+    Example:\n+\n+\n+      \"en-latn-us\" becomes \"en-Latn-US\"\n+\n+\n+    \"\"\"\n+\n+\n+    if not lang_code:\n+\n+\n+        return lang_code\n+\n+\n+    parts = lang_code.split('-')\n+\n+\n+    if not parts:\n+\n+\n+        return lang_code\n+\n+\n+    language = parts[0].lower()\n+\n+\n+    script = \"\"\n+\n+\n+    region = \"\"\n+\n+\n+    others = []\n+\n+\n+    if len(parts) >= 2:\n+\n+\n+        # Check if the second part is a script (exactly 4 letters)\n+\n+\n+        if len(parts[1]) == 4:\n+\n+\n+            script = parts[1].title()\n+\n+\n+            if len(parts) >= 3:\n+\n+\n+                region = parts[2].upper()\n+\n+\n+                others = parts[3:]\n+\n+\n+            else:\n+\n+\n+                others = []\n+\n+\n+        else:\n+\n+\n+            region = parts[1].upper()\n+\n+\n+            others = parts[2:]\n+\n+\n+    normalized = [language]\n+\n+\n+    if script:\n+\n+\n+        normalized.append(script)\n+\n+\n+    if region:\n+\n+\n+        normalized.append(region)\n+\n+\n+    if others:\n+\n+\n+        normalized.extend(others)\n+\n+\n+    return \"-\".join(normalized)\n+\n+\n def get_supported_language_variant(lang_code, strict=False):\n     \"\"\"\n     Return the language code that's listed in supported languages, possibly\n@@ -474,30 +1635,37 @@ def get_supported_language_variant(lang_code, strict=False):\n     <https://www.djangoproject.com/weblog/2007/oct/26/security-fix/>.\n     \"\"\"\n     if lang_code:\n-        # If 'zh-hant-tw' is not supported, try special fallback or subsequent\n-        # language codes i.e. 'zh-hant' and 'zh'.\n-        possible_lang_codes = [lang_code]\n+        # Normalize the incoming language code per RFC 5646.\n+        norm_lang_code = canonicalize_language_code(lang_code)\n+\n+        # Build a mapping from normalized supported language codes to the original codes.\n+        supported = get_languages()\n+        norm_supported = {canonicalize_language_code(code): code for code in supported}\n+\n+        # Build candidate list from the normalized language code.\n+        possible_lang_codes = [norm_lang_code]\n         try:\n-            possible_lang_codes.extend(LANG_INFO[lang_code]['fallback'])\n+            possible_lang_codes.extend(LANG_INFO[norm_lang_code]['fallback'])\n         except KeyError:\n             pass\n         i = None\n-        while (i := lang_code.rfind('-', 0, i)) > -1:\n-            possible_lang_codes.append(lang_code[:i])\n+        while (i := norm_lang_code.rfind('-', 0, i)) > -1:\n+            possible_lang_codes.append(norm_lang_code[:i])\n         generic_lang_code = possible_lang_codes[-1]\n-        supported_lang_codes = get_languages()\n \n-        for code in possible_lang_codes:\n-            if code in supported_lang_codes and check_for_language(code):\n-                return code\n+        for candidate in possible_lang_codes:\n+            if candidate in norm_supported and check_for_language(norm_supported[candidate]):\n+                return norm_supported[candidate]\n         if not strict:\n-            # if fr-fr is not supported, try fr-ca.\n-            for supported_code in supported_lang_codes:\n-                if supported_code.startswith(generic_lang_code + '-'):\n-                    return supported_code\n+            # Fallback: if the generic variant is not found, try any supported code that\n+            # starts with the generic language code.\n+            for norm_supported_code, original_code in norm_supported.items():\n+                if norm_supported_code.startswith(generic_lang_code + '-') and check_for_language(original_code):\n+                    return original_code\n     raise LookupError(lang_code)\n \n \n+\n def get_language_from_path(path, strict=False):\n     \"\"\"\n     Return the language code if there's a valid language code found in `path`.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15103",
        "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex da1b5675ec..64ec4c45be 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -61,7 +61,8 @@ _json_script_escapes = {\n }\n \n \n-def json_script(value, element_id):\n+def json_script(value, element_id=None):\n+\n     \"\"\"\n     Escape all the HTML/XML special characters with their unicode escapes, so\n     value is safe to be output anywhere except for inside a tag attribute. Wrap\n@@ -69,10 +70,17 @@ def json_script(value, element_id):\n     \"\"\"\n     from django.core.serializers.json import DjangoJSONEncoder\n     json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n-    return format_html(\n-        '<script id=\"{}\" type=\"application/json\">{}</script>',\n-        element_id, mark_safe(json_str)\n-    )\n+    if element_id:\n+        return format_html(\n+            '<script id=\"{}\" type=\"application/json\">{}</script>',\n+            element_id, mark_safe(json_str)\n+        )\n+    else:\n+        return format_html(\n+            '<script type=\"application/json\">{}</script>',\n+            mark_safe(json_str)\n+        )\n+\n \n \n def conditional_escape(text):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15104",
        "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 97977d72ef..83e1c1342c 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -96,7 +96,8 @@ class MigrationAutodetector:\n         for name, field in sorted(fields.items()):\n             deconstruction = self.deep_deconstruct(field)\n             if field.remote_field and field.remote_field.model:\n-                del deconstruction[2]['to']\n+                deconstruction[2].pop('to', None)\n+\n             fields_def.append(deconstruction)\n         return fields_def\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15127",
        "model_patch": "diff --git a/django/contrib/messages/storage/base.py b/django/contrib/messages/storage/base.py\nindex 01422066a6..ac74320f53 100644\n--- a/django/contrib/messages/storage/base.py\n+++ b/django/contrib/messages/storage/base.py\n@@ -1,7 +1,8 @@\n from django.conf import settings\n from django.contrib.messages import constants, utils\n \n-LEVEL_TAGS = utils.get_level_tags()\n+# LEVEL_TAGS = utils.get_level_tags()\n+\n \n \n class Message:\n@@ -36,9 +37,11 @@ class Message:\n     def tags(self):\n         return ' '.join(tag for tag in [self.extra_tags, self.level_tag] if tag)\n \n-    @property\n-    def level_tag(self):\n-        return LEVEL_TAGS.get(self.level, '')\n+@property\n+def level_tag(self):\n+    # Dynamically retrieve current MESSAGE_TAGS to honor override_settings changes\n+    return utils.get_level_tags().get(self.level, '')\n+\n \n \n class BaseStorage:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15128",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex aaf35ee37c..5e1197049e 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -604,7 +604,8 @@ class Query(BaseExpression):\n             # If the left side of the join was already relabeled, use the\n             # updated alias.\n             join = join.relabeled_clone(change_map)\n-            new_alias = self.join(join, reuse=reuse)\n+                new_alias = self.join(join, reuse=reuse, alias_avoid=set(change_map.keys()))\n+\n             if join.join_type == INNER:\n                 rhs_votes.add(new_alias)\n             # We can't reuse the same join again in the query. If we have two\n@@ -948,7 +949,7 @@ class Query(BaseExpression):\n         \"\"\"\n         return len([1 for count in self.alias_refcount.values() if count])\n \n-    def join(self, join, reuse=None):\n+    def join(self, join, reuse=None, alias_avoid=None):\n         \"\"\"\n         Return an alias for the 'join', either reusing an existing alias for\n         that join or creating a new one. 'join' is either a base_table_class or\n@@ -961,6 +962,8 @@ class Query(BaseExpression):\n         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new\n         joins are created as LOUTER if the join is nullable.\n         \"\"\"\n+        if alias_avoid is None:\n+            alias_avoid = set()\n         reuse_aliases = [\n             a for a, j in self.alias_map.items()\n             if (reuse is None or a in reuse) and j.equals(join)\n@@ -976,7 +979,15 @@ class Query(BaseExpression):\n             return reuse_alias\n \n         # No reuse is possible, so we need a new alias.\n-        alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)\n+        candidate, created = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)\n+        if candidate in alias_avoid:\n+            counter = len(self.alias_map) + 1\n+            new_candidate = '%s%d' % (self.alias_prefix, counter)\n+            while new_candidate in alias_avoid or new_candidate in self.alias_map:\n+                counter += 1\n+                new_candidate = '%s%d' % (self.alias_prefix, counter)\n+            candidate = new_candidate\n+        alias = candidate\n         if join.join_type:\n             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:\n                 join_type = LOUTER\n@@ -987,6 +998,7 @@ class Query(BaseExpression):\n         self.alias_map[alias] = join\n         return alias\n \n+\n     def join_parent_model(self, opts, model, alias, seen):\n         \"\"\"\n         Make sure the given 'model' is joined in the query. If 'model' isn't\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15161",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 8642e1f151..6ce2be7e83 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -651,8 +651,9 @@ class OuterRef(F):\n         return self\n \n \n+@deconstructible(path='django.db.models.Func')\n class Func(SQLiteNumericMixin, Expression):\n-    \"\"\"An SQL function call.\"\"\"\n+\n     function = None\n     template = '%(function)s(%(expressions)s)'\n     arg_joiner = ', '\n@@ -731,8 +732,9 @@ class Func(SQLiteNumericMixin, Expression):\n         return copy\n \n \n+@deconstructible(path='django.db.models.Value')\n class Value(SQLiteNumericMixin, Expression):\n-    \"\"\"Represent a wrapped value as a node within an expression.\"\"\"\n+\n     # Provide a default value for `for_save` in order to allow unresolved\n     # instances to be compiled until a decision is taken in #25425.\n     for_save = False\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15252",
        "model_patch": "diff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..911b68e23a 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -56,40 +56,47 @@ class MigrationRecorder:\n             tables = self.connection.introspection.table_names(cursor)\n         return self.Migration._meta.db_table in tables\n \n-    def ensure_schema(self):\n-        \"\"\"Ensure the table exists and has the correct schema.\"\"\"\n-        # If the table's there, that's fine - we've never changed its schema\n-        # in the codebase.\n-        if self.has_table():\n-            return\n-        # Make the table\n-        try:\n-            with self.connection.schema_editor() as editor:\n-                editor.create_model(self.Migration)\n-        except DatabaseError as exc:\n-            raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n-\n-    def applied_migrations(self):\n-        \"\"\"\n-        Return a dict mapping (app_name, migration_name) to Migration instances\n-        for all applied migrations.\n-        \"\"\"\n-        if self.has_table():\n-            return {(migration.app, migration.name): migration for migration in self.migration_qs}\n-        else:\n-            # If the django_migrations table doesn't exist, then no migrations\n-            # are applied.\n-            return {}\n-\n-    def record_applied(self, app, name):\n-        \"\"\"Record that a migration was applied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.create(app=app, name=name)\n-\n-    def record_unapplied(self, app, name):\n-        \"\"\"Record that a migration was unapplied.\"\"\"\n-        self.ensure_schema()\n-        self.migration_qs.filter(app=app, name=name).delete()\n+def ensure_schema(self):\n+    \"\"\"Ensure the table exists and has the correct schema if migrations are allowed.\"\"\"\n+    from django.db import router\n+    # Check whether migration is allowed on this connection\n+    if not router.allow_migrate(self.connection.alias, self.Migration):\n+        return\n+    # If the table already exists, no-op.\n+    if self.has_table():\n+        return\n+    # Create the table otherwise.\n+    try:\n+        with self.connection.schema_editor() as editor:\n+            editor.create_model(self.Migration)\n+    except DatabaseError as exc:\n+        raise MigrationSchemaMissing(\"Unable to create the django_migrations table (%s)\" % exc)\n+\n+def applied_migrations(self):\n+    from django.db import router\n+    # Return no migrations if migrations are not allowed on this connection.\n+    if not router.allow_migrate(self.connection.alias, self.Migration):\n+        return {}\n+    if self.has_table():\n+        return {(migration.app, migration.name): migration for migration in self.migration_qs}\n+    else:\n+        return {}\n+\n+def record_applied(self, app, name):\n+    from django.db import router\n+    # Do not record migrations if not allowed on this connection.\n+    if not router.allow_migrate(self.connection.alias, self.Migration):\n+        return\n+    self.ensure_schema()\n+    self.migration_qs.create(app=app, name=name)\n+\n+def record_unapplied(self, app, name):\n+    from django.db import router\n+    # Do not record unapplied migrations if not allowed on this connection.\n+    if not router.allow_migrate(self.connection.alias, self.Migration):\n+        return\n+    self.ensure_schema()\n+    self.migration_qs.filter(app=app, name=name).delete()\n \n     def flush(self):\n         \"\"\"Delete all migration records. Useful for testing migrations.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15268",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex c120f5d32d..2159796855 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -479,17 +479,32 @@ class AlterTogetherOptionOperation(ModelOptionOperation):\n     @cached_property\n     def option_value(self):\n         return getattr(self, self.option_name)\n+def reduce(self, operation, app_label):\n+    if isinstance(operation, self.__class__) and self.name_lower == operation.name_lower:\n+        # If the current op is a removal (empty set) and the subsequent op provides\n+        # a non\u2011empty value, then the removal is redundant: use the subsequent op.\n+        if not self.option_value and operation.option_value:\n+            return [operation]\n+        # If the current op has a non\u2011empty value but the subsequent op \u201cremoves\u201d the constraints,\n+        # then keep the current state.\n+        elif self.option_value and not operation.option_value:\n+            return [self]\n+        # Otherwise (both non\u2011empty or both empty), let the later op win.\n+        else:\n+            return [operation]\n+    return super().reduce(operation, app_label)\n+\n+def deconstruct(self):\n+    kwargs = {\n+        'name': self.name,\n+        self.option_name: self.option_value,\n+    }\n+    return (\n+        self.__class__.__qualname__,\n+        [],\n+        kwargs\n+    )\n \n-    def deconstruct(self):\n-        kwargs = {\n-            'name': self.name,\n-            self.option_name: self.option_value,\n-        }\n-        return (\n-            self.__class__.__qualname__,\n-            [],\n-            kwargs\n-        )\n \n     def state_forwards(self, app_label, state):\n         state.alter_model_options(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15277",
        "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex f30b523346..75c778930b 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -64,8 +64,10 @@ def _load_field(app_label, model_name, field_name):\n #                \"name\", except in the case of ForeignKeys, where \"_id\" is\n #                appended.\n #   * db_column: The db_column specified in the model (or None).\n-#   * column:    The database column for this field. This is the same as\n-#                \"attname\", except if db_column is specified.\n+        if self.max_length is not None:\n+\n+            self.validators.append(validators.MaxLengthValidator(self.max_length))\n+\n #\n # Code that introspects values, or does other dynamic things, should use\n # attname. For example, this gets the primary key value of object \"obj\":\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15278",
        "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex 6752a8e3c0..f274e4020a 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -327,11 +327,12 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         # Fields with default values cannot by handled by ALTER TABLE ADD\n         # COLUMN statement because DROP DEFAULT is not supported in\n         # ALTER TABLE.\n-        if not field.null or self.effective_default(field) is not None:\n+        if not field.null or self.effective_default(field) is not None or getattr(field, 'unique', False):\n             self._remake_table(model, create_field=field)\n         else:\n             super().add_field(model, field)\n \n+\n     def remove_field(self, model, field):\n         \"\"\"\n         Remove a field from a model. Usually involves deleting a column,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15280",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..c407fa2f85 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1947,8 +1947,11 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n             else:\n                 # No to_attr has been given for this prefetch operation and the\n                 # cache_name does not point to a descriptor. Store the value of\n-                # the field in the object's field cache.\n+                # the field in the object's field cache and update the instance's\n+                # __dict__ so that the loaded field is not considered deferred.\n                 obj._state.fields_cache[cache_name] = val\n+                setattr(obj, cache_name, val)\n+\n         else:\n             if as_attr:\n                 setattr(obj, to_attr, vals)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15315",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15368",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex f8d848e926..a5c045d0b6 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -670,8 +670,12 @@ class QuerySet:\n                 when_statements = []\n                 for obj in batch_objs:\n                     attr = getattr(obj, field.attname)\n-                    if not isinstance(attr, Expression):\n-                        attr = Value(attr, output_field=field)\n+# If the attribute is a plain F() expression, it will have\n+# a resolve_expression method but still needs to be wrapped so that\n+# the final SQL uses a column reference rather than its string representation.\n+if isinstance(attr, F) or not hasattr(attr, 'resolve_expression'):\n+    attr = Value(attr, output_field=field)\n+\n                     when_statements.append(When(pk=obj.pk, then=attr))\n                 case_statement = Case(*when_statements, output_field=field)\n                 if requires_casting:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15375",
        "model_patch": "diff --git a/django/db/models/aggregates.py b/django/db/models/aggregates.py\nindex 8c4eae7906..97a7f58bb3 100644\n--- a/django/db/models/aggregates.py\n+++ b/django/db/models/aggregates.py\n@@ -65,7 +65,10 @@ class Aggregate(Func):\n         if hasattr(default, 'resolve_expression'):\n             default = default.resolve_expression(query, allow_joins, reuse, summarize)\n         c.default = None  # Reset the default argument before wrapping.\n-        return Coalesce(c, default, output_field=c._output_field_or_none)\n+coalesced = Coalesce(c, default, output_field=c._output_field_or_none)\n+coalesced.is_summary = True\n+return coalesced\n+\n \n     @property\n     def default_alias(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15380",
        "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex bf9c2acd26..5ca9fc6173 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -824,7 +824,8 @@ class MigrationAutodetector:\n         for app_label, model_name, field_name in sorted(self.new_field_keys - self.old_field_keys):\n             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n             old_model_state = self.from_state.models[app_label, old_model_name]\n-            new_model_state = self.to_state.models[app_label, old_model_name]\n+            new_model_state = self.to_state.models[app_label, model_name]\n+\n             field = new_model_state.get_field(field_name)\n             # Scan to see if this is actually a rename!\n             field_dec = self.deep_deconstruct(field)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15382",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 81f8f79c71..7ebf1214be 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1204,16 +1204,17 @@ class Exists(Subquery):\n         self.negated = negated\n         super().__init__(queryset, **kwargs)\n \n-    def __invert__(self):\n-        clone = self.copy()\n-        clone.negated = not self.negated\n-        return clone\n+def __invert__(self):\n+    clone = self.copy()\n+    clone.negated = not self.negated\n+    # When the subquery is empty, a non\u2010negated Exists should return False.\n+    # But when negated (i.e. ~Exists(...)) the empty subquery should evaluate to True.\n+    if clone.negated:\n+        clone.empty_result_set_value = True\n+    else:\n+        clone.empty_result_set_value = False\n+    return clone\n \n-    def as_sql(self, compiler, connection, template=None, **extra_context):\n-        query = self.query.exists(using=connection.alias)\n-        sql, params = super().as_sql(\n-            compiler,\n-            connection,\n             template=template,\n             query=query,\n             **extra_context,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15467",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 64be087bf1..81f337811b 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -263,13 +263,14 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n                 kwargs[\"widget\"] = widgets.ForeignKeyRawIdWidget(\n                     db_field.remote_field, self.admin_site, using=db\n                 )\n+            elif db_field.name in self.radio_fields:\n             elif db_field.name in self.radio_fields:\n                 kwargs[\"widget\"] = widgets.AdminRadioSelect(\n                     attrs={\n                         \"class\": get_ul_class(self.radio_fields[db_field.name]),\n                     }\n                 )\n-                kwargs[\"empty_label\"] = _(\"None\") if db_field.blank else None\n+                kwargs[\"empty_label\"] = (kwargs.get(\"empty_label\") or _(\"None\")) if db_field.blank else None\n \n         if \"queryset\" not in kwargs:\n             queryset = self.get_field_queryset(db, db_field, request)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15499",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 90fc31bee5..354a5cfdaf 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -170,6 +170,438 @@ class CreateModel(ModelOperation):\n                     managers=self.managers,\n                 ),\n             ]\n+        elif (\n+\n+\n+            isinstance(operation, AlterModelManagers)\n+\n+\n+            and self.name_lower == operation.name_lower\n+\n+\n+        ):\n+\n+\n+            return [\n+\n+\n+                CreateModel(\n+\n+\n+                    self.name,\n+\n+\n+                    fields=self.fields,\n+\n+\n+                    options=self.options,\n+\n+\n+                    bases=self.bases,\n+\n+\n+                    managers=operation.managers,\n+\n+\n+                ),\n+\n+\n+            ]\n+\n+\n         elif (\n             isinstance(operation, AlterTogetherOptionOperation)\n             and self.name_lower == operation.name_lower\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15503",
        "model_patch": "diff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py\nindex fdca700c9d..6a37586800 100644\n--- a/django/db/models/fields/json.py\n+++ b/django/db/models/fields/json.py\n@@ -128,15 +128,12 @@ class JSONField(CheckFieldDefaultMixin, Field):\n \n def compile_json_path(key_transforms, include_root=True):\n     path = [\"$\"] if include_root else []\n-    for key_transform in key_transforms:\n-        try:\n-            num = int(key_transform)\n-        except ValueError:  # non-integer\n-            path.append(\".\")\n-            path.append(json.dumps(key_transform))\n-        else:\n-            path.append(\"[%s]\" % num)\n-    return \"\".join(path)\n+for key_transform in key_transforms:\n+    # Always treat key as a string key, even if it is numeric.\n+    # This prevents misinterpreting numeric keys as array indexes.\n+    path.append(\".\")\n+    path.append(json.dumps(key_transform))\n+\n \n \n class DataContains(PostgresOperatorLookup):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15525",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15554",
        "model_patch": "diff --git a/django/db/models/sql/datastructures.py b/django/db/models/sql/datastructures.py\nindex 1edf040e82..7dfe96f02e 100644\n--- a/django/db/models/sql/datastructures.py\n+++ b/django/db/models/sql/datastructures.py\n@@ -97,17 +97,22 @@ class Join:\n         )\n         if extra_cond:\n             extra_sql, extra_params = compiler.compile(extra_cond)\n-            join_conditions.append(\"(%s)\" % extra_sql)\n-            params.extend(extra_params)\n-        if self.filtered_relation:\n-            extra_sql, extra_params = compiler.compile(self.filtered_relation)\n-            if extra_sql:\n-                join_conditions.append(\"(%s)\" % extra_sql)\n-                params.extend(extra_params)\n-        if not join_conditions:\n-            # This might be a rel on the other end of an actual declared field.\n-            declared_field = getattr(self.join_field, \"field\", self.join_field)\n-            raise ValueError(\n+def equals(self, other):\n+    if (self.table_name != other.table_name or\n+            self.parent_alias != other.parent_alias or\n+            self.join_field != other.join_field or\n+            self.nullable != other.nullable):\n+        return False\n+\n+    if bool(self.filtered_relation) != bool(other.filtered_relation):\n+        return False\n+\n+    if self.filtered_relation and other.filtered_relation:\n+        if self.filtered_relation != other.filtered_relation:\n+            return False\n+\n+    return True\n+\n                 \"Join generated an empty ON clause. %s did not yield either \"\n                 \"joining columns or extra restrictions.\" % declared_field.__class__\n             )\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15561",
        "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 9d6952df21..da6cfed092 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -1376,21 +1376,22 @@ class BaseDatabaseSchemaEditor:\n         # - changing only a field name\n         # - changing an attribute that doesn't affect the schema\n         # - adding only a db_column and the column name is not changed\n-        non_database_attrs = [\n-            \"blank\",\n-            \"db_column\",\n-            \"editable\",\n-            \"error_messages\",\n-            \"help_text\",\n-            \"limit_choices_to\",\n-            # Database-level options are not supported, see #21961.\n-            \"on_delete\",\n-            \"related_name\",\n-            \"related_query_name\",\n-            \"validators\",\n-            \"verbose_name\",\n-        ]\n-        for attr in non_database_attrs:\n+non_database_attrs = [\n+    \"blank\",\n+    \"db_column\",\n+    \"editable\",\n+    \"error_messages\",\n+    \"help_text\",\n+    \"limit_choices_to\",\n+    \"choices\",  # Ignore choices since it does not affect the DB schema.\n+    # Database-level options are not supported, see #21961.\n+    \"on_delete\",\n+    \"related_name\",\n+    \"related_query_name\",\n+    \"validators\",\n+    \"verbose_name\",\n+]\n+\n             old_kwargs.pop(attr, None)\n             new_kwargs.pop(attr, None)\n         return self.quote_name(old_field.column) != self.quote_name(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15563",
        "model_patch": "diff --git a/django/db/models/sql/subqueries.py b/django/db/models/sql/subqueries.py\nindex 04063f73bc..3c79641130 100644\n--- a/django/db/models/sql/subqueries.py\n+++ b/django/db/models/sql/subqueries.py\n@@ -121,22 +121,87 @@ class UpdateQuery(Query):\n         \"\"\"\n         self.related_updates.setdefault(model, []).append((field, None, value))\n \n-    def get_related_updates(self):\n-        \"\"\"\n-        Return a list of query objects: one for each update required to an\n-        ancestor model. Each query will have the same filtering conditions as\n-        the current query but will only update a single table.\n-        \"\"\"\n-        if not self.related_updates:\n-            return []\n-        result = []\n-        for model, values in self.related_updates.items():\n-            query = UpdateQuery(model)\n-            query.values = values\n-            if self.related_ids is not None:\n+from django.db.models import Subquery\n+\n+\n+def get_related_updates(self):\n+    \"\"\"\n+    Return a list of query objects: one for each update required to an\n+    ancestor model. Each query will have the same filtering conditions as\n+    the current query but will only update a single table.\n+    \"\"\"\n+    if not self.related_updates:\n+        return []\n+\n+    # Define a helper to locate the parent link field from the child model\n+    # to the given ancestor model.\n+    def get_parent_link(child_meta, ancestor_model):\n+        for field in child_meta.fields:\n+            if (\n+                field.is_relation and field.remote_field and\n+                getattr(field, \"parent_link\", False) and\n+                field.remote_field.model == ancestor_model\n+            ):\n+                return field\n+        return None\n+\n+    result = []\n+    # child_model is the model whose meta was used to build the primary query.\n+    child_model = self.get_meta().model\n+    for model, values in self.related_updates.items():\n+        query = UpdateQuery(model)\n+        query.values = values\n+        if self.related_ids is not None:\n+            # Try to remap child PK values to ancestor model PK values\n+            parent_link = get_parent_link(self.get_meta(), model)\n+            if parent_link:\n+                # Use a subquery to obtain the ancestor's PK values from the child model.\n+                subq = Subquery(\n+                    child_model.objects.filter(pk__in=self.related_ids)\n+                    .values(parent_link.attname)\n+                )\n+                query.add_filter(\"pk__in\", subq)\n+            else:\n                 query.add_filter(\"pk__in\", self.related_ids)\n-            result.append(query)\n-        return result\n+        result.append(query)\n+    return result\n+\n \n \n class InsertQuery(Query):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15569",
        "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex 0caa165e15..7da4efd441 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -217,6 +217,43 @@ class RegisterLookupMixin:\n         if lookup_name is None:\n             lookup_name = lookup.lookup_name\n         del cls.class_lookups[lookup_name]\n+        cls._clear_cached_lookups()\n+\n+\n \n \n def select_related_descend(field, restricted, requested, load_fields, reverse=False):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15572",
        "model_patch": "diff --git a/django/template/autoreload.py b/django/template/autoreload.py\nindex 84c8554165..33c7b977cd 100644\n--- a/django/template/autoreload.py\n+++ b/django/template/autoreload.py\n@@ -17,7 +17,8 @@ def get_template_directories():\n         if not isinstance(backend, DjangoTemplates):\n             continue\n \n-        items.update(cwd / to_path(dir) for dir in backend.engine.dirs)\n+        items.update(cwd / to_path(dir) for dir in backend.engine.dirs if dir)\n+\n \n         for loader in backend.engine.template_loaders:\n             if not hasattr(loader, \"get_dirs\"):\n@@ -25,8 +26,9 @@ def get_template_directories():\n             items.update(\n                 cwd / to_path(directory)\n                 for directory in loader.get_dirs()\n-                if not is_django_path(directory)\n+                if directory and not is_django_path(directory)\n             )\n+\n     return items\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15629",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15695",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex d17232e4ec..cd82f5808c 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -963,6 +963,140 @@ class RenameIndex(IndexOperation):\n \n         to_model_state = to_state.models[app_label, self.model_name_lower]\n         new_index = to_model_state.get_index_by_name(self.new_name)\n+        # Avoid renaming if the index already has the target name.\n+\n+\n+        if old_index.name == new_index.name:\n+\n+\n+            return\n+\n+\n         schema_editor.rename_index(model, old_index, new_index)\n \n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15731",
        "model_patch": "diff --git a/django/db/models/manager.py b/django/db/models/manager.py\nindex e37e56cd17..0214b47f8b 100644\n--- a/django/db/models/manager.py\n+++ b/django/db/models/manager.py\n@@ -81,12 +81,11 @@ class BaseManager:\n     @classmethod\n     def _get_queryset_methods(cls, queryset_class):\n         def create_method(name, method):\n-            def manager_method(self, *args, **kwargs):\n-                return getattr(self.get_queryset(), name)(*args, **kwargs)\n+@functools.wraps(method)\n+def manager_method(self, *args, **kwargs):\n+    return getattr(self.get_queryset(), name)(*args, **kwargs)\n+return manager_method\n \n-            manager_method.__name__ = method.__name__\n-            manager_method.__doc__ = method.__doc__\n-            return manager_method\n \n         new_methods = {}\n         for name, method in inspect.getmembers(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15732",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15741",
        "model_patch": "diff --git a/django/utils/formats.py b/django/utils/formats.py\nindex 3f38322d84..662577d87a 100644\n--- a/django/utils/formats.py\n+++ b/django/utils/formats.py\n@@ -106,6 +106,100 @@ def get_format(format_type, lang=None, use_l10n=None):\n     If use_l10n is provided and is not None, it forces the value to\n     be localized (or not), overriding the value of settings.USE_L10N.\n     \"\"\"\n+    # NEW: Convert lazy format_type to a standard string\n+\n+\n+    format_type = str(format_type)\n+\n+\n     if use_l10n is None:\n         try:\n             use_l10n = settings._USE_L10N_INTERNAL\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15814",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex be0deb90b0..8f9615479b 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -2596,7 +2596,8 @@ class RelatedPopulator:\n             )\n \n         self.model_cls = klass_info[\"model\"]\n-        self.pk_idx = self.init_list.index(self.model_cls._meta.pk.attname)\n+self.pk_idx = self.init_list.index(self.model_cls._meta.concrete_model._meta.pk.attname)\n+\n         self.related_populators = get_related_populators(klass_info, select, self.db)\n         self.local_setter = klass_info[\"local_setter\"]\n         self.remote_setter = klass_info[\"remote_setter\"]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15851",
        "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 4c9bd63546..f14464ae64 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -32,9 +32,10 @@ class DatabaseClient(BaseDatabaseClient):\n             args += [\"-h\", host]\n         if port:\n             args += [\"-p\", str(port)]\n-        if dbname:\n-            args += [dbname]\n-        args.extend(parameters)\n+\t        args.extend(parameters)\n+\t        if dbname:\n+\t            args += [dbname]\n+\n \n         env = {}\n         if passwd:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15863",
        "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 7a5b28d159..ec8848cce7 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -151,13 +151,18 @@ def floatformat(text, arg=-1):\n             use_l10n = False\n             arg = arg[:-1] or -1\n     try:\n-        input_val = repr(text)\n-        d = Decimal(input_val)\n-    except InvalidOperation:\n+    if isinstance(text, Decimal):\n+        d = text\n+    else:\n         try:\n-            d = Decimal(str(float(text)))\n-        except (ValueError, InvalidOperation, TypeError):\n-            return \"\"\n+            input_val = repr(text)\n+            d = Decimal(input_val)\n+        except InvalidOperation:\n+            try:\n+                d = Decimal(str(float(text)))\n+            except (ValueError, InvalidOperation, TypeError):\n+                return \"\"\n+\n     try:\n         p = int(arg)\n     except ValueError:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15916",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 192d9fad94..4b90cc547c 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -257,13 +257,15 @@ class ModelFormOptions:\n \n class ModelFormMetaclass(DeclarativeFieldsMetaclass):\n     def __new__(mcs, name, bases, attrs):\n-        base_formfield_callback = None\n-        for b in bases:\n-            if hasattr(b, \"Meta\") and hasattr(b.Meta, \"formfield_callback\"):\n-                base_formfield_callback = b.Meta.formfield_callback\n-                break\n+def __new__(mcs, name, bases, attrs):\n+    base_formfield_callback = None\n+    for b in bases:\n+        if hasattr(b, \"Meta\") and hasattr(b.Meta, \"formfield_callback\"):\n+            base_formfield_callback = b.Meta.formfield_callback\n+            break\n+    tmp_callback = attrs.pop(\"formfield_callback\", base_formfield_callback)\n+    formfield_callback = tmp_callback if tmp_callback is not None else base_formfield_callback\n \n-        formfield_callback = attrs.pop(\"formfield_callback\", base_formfield_callback)\n \n         new_class = super().__new__(mcs, name, bases, attrs)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15930",
        "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex 866e38df83..78a0280099 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -442,7 +442,11 @@ class In(FieldGetDbPrepValueIterableMixin, BuiltinLookup):\n                 rhs = [r for r in self.rhs if r is not None]\n \n             if not rhs:\n-                raise EmptyResultSet\n+                if getattr(self, 'negated', False):\n+                    return (\"TRUE\", [])\n+                else:\n+                    raise EmptyResultSet\n+\n \n             # rhs should be an iterable; use batch_process_rhs() to\n             # prepare/transform those values.\ndiff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex d566cc1883..c7eb4544a8 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -47,17 +47,20 @@ class Q(tree.Node):\n \n     def __init__(self, *args, _connector=None, _negated=False, **kwargs):\n         super().__init__(\n-            children=[*args, *sorted(kwargs.items())],\n-            connector=_connector,\n-            negated=_negated,\n-        )\n+    def __invert__(self):\n+        q = self.copy()\n+        q.negated = not self.negated\n+        # Propagate negation to lookup children if applicable.\n+        new_children = []\n+        for child in q.children:\n+            # If a child is an expression that supports lookups (e.g. In lookup),\n+            # mark it as negated so that later processing can adjust its SQL.\n+            if hasattr(child, 'resolve_expression') and hasattr(child, 'lookup_name'):\n+                child.negated = True\n+            new_children.append(child)\n+        q.children = new_children\n+        return q\n \n-    def _combine(self, other, conn):\n-        if getattr(other, \"conditional\", False) is False:\n-            raise TypeError(other)\n-        if not self:\n-            return other.copy()\n-        if not other and isinstance(other, Q):\n             return self.copy()\n \n         obj = self.create(connector=conn)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15957",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex be0deb90b0..cc4f74143c 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1437,9 +1437,11 @@ class QuerySet:\n         self._not_support_combined_queries(\"exclude\")\n         return self._filter_or_exclude(True, args, kwargs)\n \n-    def _filter_or_exclude(self, negate, args, kwargs):\n-        if (args or kwargs) and self.query.is_sliced:\n-            raise TypeError(\"Cannot filter a query once a slice has been taken.\")\n+def _filter_or_exclude(self, negate, args, kwargs):\n+    # Allow additional filtering if this queryset has been flagged for prefetching.\n+    if (args or kwargs) and self.query.is_sliced and not getattr(self, '_prefetch_done', False):\n+        raise TypeError(\"Cannot filter a query once a slice has been taken.\")\n+\n         clone = self._chain()\n         if self._defer_next_filter:\n             self._defer_next_filter = False\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15973",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15987",
        "model_patch": "diff --git a/django/core/management/commands/loaddata.py b/django/core/management/commands/loaddata.py\nindex ac97f13161..bcd04b9aac 100644\n--- a/django/core/management/commands/loaddata.py\n+++ b/django/core/management/commands/loaddata.py\n@@ -361,9 +361,11 @@ class Command(BaseCommand):\n         current directory.\n         \"\"\"\n         dirs = []\n-        fixture_dirs = settings.FIXTURE_DIRS\n-        if len(fixture_dirs) != len(set(fixture_dirs)):\n-            raise ImproperlyConfigured(\"settings.FIXTURE_DIRS contains duplicates.\")\n+fixture_dirs = settings.FIXTURE_DIRS\n+normalized_fixture_dirs = [os.path.realpath(os.fspath(d)) for d in fixture_dirs]\n+if len(normalized_fixture_dirs) != len(set(normalized_fixture_dirs)):\n+    raise ImproperlyConfigured(\"settings.FIXTURE_DIRS contains duplicates.\")\n+\n         for app_config in apps.get_app_configs():\n             app_label = app_config.label\n             app_dir = os.path.join(app_config.path, \"fixtures\")\n@@ -378,7 +380,8 @@ class Command(BaseCommand):\n                 continue\n             if os.path.isdir(app_dir):\n                 dirs.append(app_dir)\n-        dirs.extend(fixture_dirs)\n+dirs.extend(normalized_fixture_dirs)\n+\n         dirs.append(\"\")\n         return [os.path.realpath(d) for d in dirs]\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16032",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex be0deb90b0..679d8a5113 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1643,6 +1643,48 @@ class QuerySet:\n                     clone.query.set_group_by()\n                 break\n \n+if not select:\n+\n+\n+    clone._fields = None\n+\n+\n         return clone\n \n     def order_by(self, *field_names):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16082",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 5e3c7cab82..608291c898 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -528,13 +528,15 @@ _connector_combinations = [\n             (fields.IntegerField, fields.FloatField, fields.FloatField),\n             (fields.FloatField, fields.IntegerField, fields.FloatField),\n         ]\n+        for connector in (\n         for connector in (\n             Combinable.ADD,\n             Combinable.SUB,\n             Combinable.MUL,\n             Combinable.DIV,\n+            Combinable.MOD,\n         )\n-    },\n+\n     # Bitwise operators.\n     {\n         connector: [\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16100",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 5f07a4208a..28e372669f 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1999,39 +1999,37 @@ class ModelAdmin(BaseModelAdmin):\n         formset = cl.formset = None\n \n         # Handle POSTed bulk-edit data.\n-        if request.method == \"POST\" and cl.list_editable and \"_save\" in request.POST:\n-            if not self.has_change_permission(request):\n-                raise PermissionDenied\n-            FormSet = self.get_changelist_formset(request)\n-            modified_objects = self._get_list_editable_queryset(\n-                request, FormSet.get_default_prefix()\n-            )\n-            formset = cl.formset = FormSet(\n-                request.POST, request.FILES, queryset=modified_objects\n-            )\n-            if formset.is_valid():\n-                changecount = 0\n-                for form in formset.forms:\n-                    if form.has_changed():\n-                        obj = self.save_form(request, form, change=True)\n-                        self.save_model(request, obj, form, change=True)\n-                        self.save_related(request, form, formsets=[], change=True)\n-                        change_msg = self.construct_change_message(request, form, None)\n-                        self.log_change(request, obj, change_msg)\n-                        changecount += 1\n-\n-                if changecount:\n-                    msg = ngettext(\n-                        \"%(count)s %(name)s was changed successfully.\",\n-                        \"%(count)s %(name)s were changed successfully.\",\n-                        changecount,\n-                    ) % {\n-                        \"count\": changecount,\n-                        \"name\": model_ngettext(self.opts, changecount),\n-                    }\n-                    self.message_user(request, msg, messages.SUCCESS)\n+if request.method == \"POST\" and cl.list_editable and \"_save\" in request.POST:\n+    with transaction.atomic(using=router.db_for_write(self.model)):\n+        if not self.has_change_permission(request):\n+            raise PermissionDenied\n+        FormSet = self.get_changelist_formset(request)\n+        modified_objects = self._get_list_editable_queryset(request, FormSet.get_default_prefix())\n+        formset = cl.formset = FormSet(request.POST, request.FILES, queryset=modified_objects)\n+        if formset.is_valid():\n+            changecount = 0\n+            for form in formset.forms:\n+                if form.has_changed():\n+                    obj = self.save_form(request, form, change=True)\n+                    self.save_model(request, obj, form, change=True)\n+                    self.save_related(request, form, formsets=[], change=True)\n+                    change_msg = self.construct_change_message(request, form, None)\n+                    self.log_change(request, obj, change_msg)\n+                    changecount += 1\n+\n+            if changecount:\n+                msg = ngettext(\n+                    \"%(count)s %(name)s was changed successfully.\",\n+                    \"%(count)s %(name)s were changed successfully.\",\n+                    changecount,\n+                ) % {\n+                    \"count\": changecount,\n+                    \"name\": model_ngettext(self.opts, changecount),\n+                }\n+                self.message_user(request, msg, messages.SUCCESS)\n+\n+            return HttpResponseRedirect(request.get_full_path())\n \n-                return HttpResponseRedirect(request.get_full_path())\n \n         # Handle GET -- construct a formset for display.\n         elif cl.list_editable and self.has_change_permission(request):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16116",
        "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 2e97d9064b..906fdd4db9 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -238,8 +238,10 @@ class Command(BaseCommand):\n             # No changes? Tell them.\n             if self.verbosity >= 1:\n                 if app_labels:\n-                    if len(app_labels) == 1:\n-                        self.log(\"No changes detected in app '%s'\" % app_labels.pop())\n+            if len(app_labels) == 1:\n+                app = list(app_labels)[0]\n+                self.log(\"No changes detected in app '%s'\" % app)\n+\n                     else:\n                         self.log(\n                             \"No changes detected in apps '%s'\"\n@@ -248,12 +250,13 @@ class Command(BaseCommand):\n                 else:\n                     self.log(\"No changes detected\")\n         else:\n+            if check_changes:\n+                sys.exit(1)\n             if self.update:\n                 self.write_to_last_migration_files(changes)\n             else:\n                 self.write_migration_files(changes)\n-            if check_changes:\n-                sys.exit(1)\n+\n \n     def write_to_last_migration_files(self, changes):\n         loader = MigrationLoader(connections[DEFAULT_DB_ALIAS])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16136",
        "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex db1842e3e5..3a732a3ce6 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -148,7 +148,15 @@ class View:\n             request.path,\n             extra={\"status_code\": 405, \"request\": request},\n         )\n-        return HttpResponseNotAllowed(self._allowed_methods())\n+response = HttpResponseNotAllowed(self._allowed_methods())\n+try:\n+    import asyncio\n+    asyncio.get_running_loop()  # Raises RuntimeError if no loop is running.\n+    from asgiref.sync import sync_to_async\n+    return sync_to_async(lambda: response, thread_sensitive=True)()\n+except RuntimeError:\n+    return response\n+\n \n     def options(self, request, *args, **kwargs):\n         \"\"\"Handle responding to requests for the OPTIONS HTTP verb.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16139",
        "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b3cfc6723c..e3150359c7 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,8 @@ class UserChangeForm(forms.ModelForm):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\n+\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16145",
        "model_patch": "diff --git a/django/core/management/commands/runserver.py b/django/core/management/commands/runserver.py\nindex 3c39f57e4d..bd0ff2eb27 100644\n--- a/django/core/management/commands/runserver.py\n+++ b/django/core/management/commands/runserver.py\n@@ -96,6 +96,79 @@ class Command(BaseCommand):\n                     \"or address:port pair.\" % options[\"addrport\"]\n                 )\n             self.addr, _ipv4, _ipv6, _fqdn, self.port = m.groups()\n+            if self.addr == \"0\":\n+\n+\n+                self.addr = \"0.0.0.0\"\n+\n+\n             if not self.port.isdigit():\n                 raise CommandError(\"%r is not a valid port number.\" % self.port)\n             if self.addr:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16255",
        "model_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\nindex 27756d9d96..9511e3a593 100644\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -167,9 +167,10 @@ class Sitemap:\n             return None\n         if callable(self.lastmod):\n             try:\n-                return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n-                return None\n+            return max([self.lastmod(item) for item in self.items()])\n+        except (TypeError, ValueError):\n+            return None\n+\n         else:\n             return self.lastmod\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16256",
        "model_patch": "diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex c5d87f647a..72f3638fa8 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -799,7 +799,11 @@ def create_reverse_many_to_one_manager(superclass, rel):\n             db = router.db_for_write(self.model, instance=self.instance)\n             return super(RelatedManager, self.db_manager(db)).get_or_create(**kwargs)\n \n-        get_or_create.alters_data = True\n+    async def aget_or_create(self, **kwargs):\n+        return await sync_to_async(self.get_or_create)(**kwargs)\n+\n+    aget_or_create.alters_data = True\n+\n \n         def update_or_create(self, **kwargs):\n             self._check_fk_val()\n@@ -807,7 +811,11 @@ def create_reverse_many_to_one_manager(superclass, rel):\n             db = router.db_for_write(self.model, instance=self.instance)\n             return super(RelatedManager, self.db_manager(db)).update_or_create(**kwargs)\n \n-        update_or_create.alters_data = True\n+    async def aupdate_or_create(self, **kwargs):\n+        return await sync_to_async(self.update_or_create)(**kwargs)\n+\n+    aupdate_or_create.alters_data = True\n+\n \n         # remove() and clear() are only provided if the ForeignKey can have a\n         # value of null.\n@@ -1200,7 +1208,11 @@ def create_forward_many_to_many_manager(superclass, rel, reverse):\n             # from get() then the relationship already exists.\n             if created:\n                 self.add(obj, through_defaults=through_defaults)\n-            return obj, created\n+    async def aget_or_create(self, *, through_defaults=None, **kwargs):\n+        return await sync_to_async(self.get_or_create)(through_defaults=through_defaults, **kwargs)\n+\n+    aget_or_create.alters_data = True\n+\n \n         get_or_create.alters_data = True\n \n@@ -1210,7 +1222,11 @@ def create_forward_many_to_many_manager(superclass, rel, reverse):\n                 ManyRelatedManager, self.db_manager(db)\n             ).update_or_create(**kwargs)\n             # We only need to add() if created because if we got an object back\n-            # from get() then the relationship already exists.\n+    async def aupdate_or_create(self, *, through_defaults=None, **kwargs):\n+        return await sync_to_async(self.update_or_create)(through_defaults=through_defaults, **kwargs)\n+\n+    aupdate_or_create.alters_data = True\n+\n             if created:\n                 self.add(obj, through_defaults=through_defaults)\n             return obj, created\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16263",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 9735ce10c8..89f5fab719 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -545,13 +545,23 @@ class Query(BaseExpression):\n \n         return dict(zip(outer_query.annotation_select, result))\n \n-    def get_count(self, using):\n-        \"\"\"\n-        Perform a COUNT() query using the current filter constraints.\n-        \"\"\"\n-        obj = self.clone()\n-        obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n-        return obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n+\tdef get_count(self, using):\n+\t    \"\"\"\n+\t    Perform a COUNT() query using the current filter constraints.\n+\t    In count queries unused annotations (i.e. those not referenced by filtering,\n+\t    grouping, or ordering) should be stripped from the query as they do not affect\n+\t    the result and only add overhead.\n+\t    \"\"\"\n+\t    obj = self.clone()\n+\t    # If no filtering, ordering or grouping is applied, clear out any\n+\t    # annotations that were added via annotate() but are not otherwise used.\n+\t    if (not obj.where.children) and (not obj.order_by) and (not obj.group_by):\n+\t        obj.annotations.clear()\n+\t        obj.annotation_select_mask = None\n+\t        obj._annotation_select_cache = None\n+\t    \n+\t    obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n+\t    return obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n \n     def has_filters(self):\n         return self.where\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16315",
        "model_patch": "diff --git a/django/db/backends/postgresql/operations.py b/django/db/backends/postgresql/operations.py\nindex 62273fc43c..697db23b09 100644\n--- a/django/db/backends/postgresql/operations.py\n+++ b/django/db/backends/postgresql/operations.py\n@@ -353,15 +353,28 @@ class DatabaseOperations(BaseDatabaseOperations):\n         if on_conflict == OnConflict.IGNORE:\n             return \"ON CONFLICT DO NOTHING\"\n         if on_conflict == OnConflict.UPDATE:\n-            return \"ON CONFLICT(%s) DO UPDATE SET %s\" % (\n-                \", \".join(map(self.quote_name, unique_fields)),\n-                \", \".join(\n-                    [\n-                        f\"{field} = EXCLUDED.{field}\"\n-                        for field in map(self.quote_name, update_fields)\n-                    ]\n-                ),\n-            )\n+        # Build a mapping from model field name to its db column (if available)\n+        field_mapping = {}\n+        for field in fields:\n+            # Some fields (e.g. without a column or raw expressions) may not have \"column\"\n+            try:\n+                field_mapping[field.name] = field.column\n+            except AttributeError:\n+                field_mapping[field.name] = field\n+        quoted_unique = []\n+        for name in unique_fields:\n+            col = field_mapping.get(name, name)\n+            quoted_unique.append(self.quote_name(col))\n+        set_clauses = []\n+        for name in update_fields:\n+            col = field_mapping.get(name, name)\n+            qname = self.quote_name(col)\n+            set_clauses.append(f\"{qname} = EXCLUDED.{qname}\")\n+        return \"ON CONFLICT(%s) DO UPDATE SET %s\" % (\n+            \", \".join(quoted_unique),\n+            \", \".join(set_clauses),\n+        )\n+\n         return super().on_conflict_suffix_sql(\n             fields,\n             on_conflict,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16333",
        "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex d73d1c8495..21ae055388 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -136,12 +136,14 @@ class UserCreationForm(forms.ModelForm):\n             except ValidationError as error:\n                 self.add_error(\"password2\", error)\n \n-    def save(self, commit=True):\n-        user = super().save(commit=False)\n-        user.set_password(self.cleaned_data[\"password1\"])\n-        if commit:\n-            user.save()\n-        return user\n+def save(self, commit=True):\n+    user = super().save(commit=False)\n+    user.set_password(self.cleaned_data[\"password1\"])\n+    if commit:\n+        user.save()\n+        self.save_m2m()\n+    return user\n+\n \n \n class UserChangeForm(forms.ModelForm):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16429",
        "model_patch": "diff --git a/django/utils/timesince.py b/django/utils/timesince.py\nindex 701c49bab9..ea0adb7c03 100644\n--- a/django/utils/timesince.py\n+++ b/django/utils/timesince.py\n@@ -97,9 +97,10 @@ def timesince(d, now=None, reversed=False, time_strings=None, depth=2):\n             d.hour,\n             d.minute,\n             d.second,\n+            0,  # microsecond explicitly set to 0\n+            tzinfo=d.tzinfo\n         )\n-    else:\n-        pivot = d\n+\n     remaining_time = (now - pivot).total_seconds()\n     partials = [years, months]\n     for chunk in TIME_CHUNKS:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16454",
        "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex abc6f79a15..764d471233 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -56,6 +56,565 @@ class CommandParser(ArgumentParser):\n         self.missing_args_message = missing_args_message\n         self.called_from_command_line = called_from_command_line\n         super().__init__(**kwargs)\n+    def add_subparsers(self, **kwargs):\n+\n+\n+        \"\"\"\n+\n+\n+        Override the default add_subparsers() to ensure that any subparsers created\n+\n+\n+        (using add_parser()) are instances of CommandParser with the custom error\n+\n+\n+        formatting options (missing_args_message and called_from_command_line) passed through.\n+\n+\n+        \"\"\"\n+\n+\n+        # If no parser_class is explicitly provided, force our CommandParser class.\n+\n+\n+        if \"parser_class\" not in kwargs:\n+\n+\n+            kwargs[\"parser_class\"] = CommandParser\n+\n+\n+        return super().add_subparsers(**kwargs)\n+\n+\n \n     def parse_args(self, args=None, namespace=None):\n         # Catch missing argument for a better error message\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16485",
        "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 23c3a08c67..587d50ca1a 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -168,7 +168,8 @@ def floatformat(text, arg=-1):\n     except (ValueError, OverflowError, InvalidOperation):\n         return input_val\n \n-    if not m and p < 0:\n+    if not m and p <= 0:\n+\n         return mark_safe(\n             formats.number_format(\n                 \"%d\" % (int(d)),\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16493",
        "model_patch": "diff --git a/django/db/models/fields/files.py b/django/db/models/fields/files.py\nindex 7a99b12691..ef86898155 100644\n--- a/django/db/models/fields/files.py\n+++ b/django/db/models/fields/files.py\n@@ -290,14 +290,18 @@ class FileField(Field):\n         else:\n             return []\n \n-    def deconstruct(self):\n-        name, path, args, kwargs = super().deconstruct()\n-        if kwargs.get(\"max_length\") == 100:\n-            del kwargs[\"max_length\"]\n-        kwargs[\"upload_to\"] = self.upload_to\n-        if self.storage is not default_storage:\n-            kwargs[\"storage\"] = getattr(self, \"_storage_callable\", self.storage)\n-        return name, path, args, kwargs\n+def deconstruct(self):\n+    name, path, args, kwargs = super().deconstruct()\n+    if kwargs.get(\"max_length\") == 100:\n+        del kwargs[\"max_length\"]\n+    kwargs[\"upload_to\"] = self.upload_to\n+    # Preserve the storage callable if one was provided\n+    if hasattr(self, \"_storage_callable\"):\n+        kwargs[\"storage\"] = self._storage_callable\n+    elif self.storage is not default_storage:\n+        kwargs[\"storage\"] = self.storage\n+    return name, path, args, kwargs\n+\n \n     def get_internal_type(self):\n         return \"FileField\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16502",
        "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex fef5532e58..2ba0b34e89 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -207,24 +207,42 @@ class WSGIRequestHandler(simple_server.WSGIRequestHandler):\n         except (AttributeError, OSError):\n             pass\n \n-    def handle_one_request(self):\n-        \"\"\"Copy of WSGIRequestHandler.handle() but with different ServerHandler\"\"\"\n-        self.raw_requestline = self.rfile.readline(65537)\n-        if len(self.raw_requestline) > 65536:\n-            self.requestline = \"\"\n-            self.request_version = \"\"\n-            self.command = \"\"\n-            self.send_error(414)\n-            return\n-\n-        if not self.parse_request():  # An error code has been sent, just exit\n-            return\n-\n+def handle_one_request(self):\n+    \"\"\"Copy of WSGIRequestHandler.handle() but with a HEAD branch for compliance.\n+    \n+    For HEAD requests the response body is consumed but not written.\n+    \"\"\"\n+    self.raw_requestline = self.rfile.readline(65537)\n+    if len(self.raw_requestline) > 65536:\n+        self.requestline = \"\"\n+        self.request_version = \"\"\n+        self.command = \"\"\n+        self.send_error(414)\n+        return\n+\n+    if not self.parse_request():  # An error code has been sent, just exit\n+        return\n+\n+    if self.command == \"HEAD\":\n+        # For HEAD requests, use a modified ServerHandler that discards the body.\n+        class HeadServerHandler(ServerHandler):\n+            def finish_response(self, result):\n+                # Exhaust the response iterator without writing body data.\n+                for _ in result:\n+                    pass\n+                if hasattr(result, \"close\"):\n+                    result.close()\n+        handler = HeadServerHandler(\n+            self.rfile, self.wfile, self.get_stderr(), self.get_environ()\n+        )\n+    else:\n         handler = ServerHandler(\n             self.rfile, self.wfile, self.get_stderr(), self.get_environ()\n         )\n-        handler.request_handler = self  # backpointer for logging & connection closing\n-        handler.run(self.server.get_app())\n+\n+    handler.request_handler = self  # backpointer for logging & connection closing\n+    handler.run(self.server.get_app())\n+\n \n \n def run(addr, port, wsgi_handler, ipv6=False, threading=False, server_cls=WSGIServer):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16527",
        "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\nindex 9df4b7aadb..e3df0d0554 100644\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -99,10 +99,12 @@ def submit_row(context):\n                 and change\n                 and context.get(\"show_delete\", True)\n             ),\n-            \"show_save_as_new\": not is_popup\n+\"show_save_as_new\": not is_popup\n+            and has_add_permission\n             and has_change_permission\n             and change\n             and save_as,\n+\n             \"show_save_and_add_another\": can_save_and_add_another,\n             \"show_save_and_continue\": can_save_and_continue,\n             \"show_save\": show_save and can_save,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16560",
        "model_patch": "diff --git a/django/db/models/constraints.py b/django/db/models/constraints.py\nindex 075ecee1be..f196aa3367 100644\n--- a/django/db/models/constraints.py\n+++ b/django/db/models/constraints.py\n@@ -19,32 +19,171 @@ __all__ = [\"BaseConstraint\", \"CheckConstraint\", \"Deferrable\", \"UniqueConstraint\"\n class BaseConstraint:\n     default_violation_error_message = _(\"Constraint \u201c%(name)s\u201d is violated.\")\n     violation_error_message = None\n+# new default error code for constraint violations\n+\n+\n+default_violation_error_code = \"constraint_violation\"\n+\n+\n+violation_error_code = None\n+\n+\n \n     # RemovedInDjango60Warning: When the deprecation ends, replace with:\n     # def __init__(self, *, name, violation_error_message=None):\n-    def __init__(self, *args, name=None, violation_error_message=None):\n-        # RemovedInDjango60Warning.\n-        if name is None and not args:\n-            raise TypeError(\n-                f\"{self.__class__.__name__}.__init__() missing 1 required keyword-only \"\n-                f\"argument: 'name'\"\n-            )\n-        self.name = name\n-        if violation_error_message is not None:\n-            self.violation_error_message = violation_error_message\n-        else:\n-            self.violation_error_message = self.default_violation_error_message\n-        # RemovedInDjango60Warning.\n-        if args:\n-            warnings.warn(\n-                f\"Passing positional arguments to {self.__class__.__name__} is \"\n-                f\"deprecated.\",\n-                RemovedInDjango60Warning,\n-                stacklevel=2,\n-            )\n-            for arg, attr in zip(args, [\"name\", \"violation_error_message\"]):\n-                if arg:\n-                    setattr(self, attr, arg)\n+def __init__(self, *args, name=None, violation_error_message=None, violation_error_code=None):\n+    # RemovedInDjango60Warning.\n+    if name is None and not args:\n+        raise TypeError(\n+            f\"{self.__class__.__name__}.__init__() missing 1 required keyword-only \"\n+            f\"argument: 'name'\"\n+        )\n+    self.name = name\n+    if violation_error_message is not None:\n+        self.violation_error_message = violation_error_message\n+    else:\n+        self.violation_error_message = self.default_violation_error_message\n+    if violation_error_code is not None:\n+        self.violation_error_code = violation_error_code\n+    else:\n+        self.violation_error_code = self.default_violation_error_code\n+    if args:\n+        warnings.warn(\n+            f\"Passing positional arguments to {self.__class__.__name__} is \"\n+            f\"deprecated.\",\n+            RemovedInDjango60Warning,\n+            stacklevel=2,\n+        )\n+        for arg, attr in zip(args, [\"name\", \"violation_error_message\"]):\n+            if arg:\n+                setattr(self, attr, arg)\n \n     @property\n     def contains_expressions(self):\n@@ -69,12 +208,18 @@ class BaseConstraint:\n         path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)\n         path = path.replace(\"django.db.models.constraints\", \"django.db.models\")\n         kwargs = {\"name\": self.name}\n-        if (\n-            self.violation_error_message is not None\n-            and self.violation_error_message != self.default_violation_error_message\n-        ):\n-            kwargs[\"violation_error_message\"] = self.violation_error_message\n-        return (path, (), kwargs)\n+    if (\n+        self.violation_error_message is not None\n+        and self.violation_error_message != self.default_violation_error_message\n+    ):\n+        kwargs[\"violation_error_message\"] = self.violation_error_message\n+    if (\n+        self.violation_error_code is not None\n+        and self.violation_error_code != self.default_violation_error_code\n+    ):\n+        kwargs[\"violation_error_code\"] = self.violation_error_code\n+    return (path, (), kwargs)\n+\n \n     def clone(self):\n         _, args, kwargs = self.deconstruct()\n@@ -112,7 +257,8 @@ class CheckConstraint(BaseConstraint):\n         against = instance._get_field_value_map(meta=model._meta, exclude=exclude)\n         try:\n             if not Q(self.check).check(against, using=using):\n-                raise ValidationError(self.get_violation_error_message())\n+                    raise ValidationError(self.get_violation_error_message(), code=self.violation_error_code)\n+\n         except FieldError:\n             pass\n \n@@ -385,21 +531,25 @@ class UniqueConstraint(BaseConstraint):\n         if not self.condition:\n             if queryset.exists():\n                 if self.expressions:\n-                    raise ValidationError(self.get_violation_error_message())\n+                    raise ValidationError(self.get_violation_error_message(), code=self.violation_error_code)\n+\n                 # When fields are defined, use the unique_error_message() for\n                 # backward compatibility.\n                 for model, constraints in instance.get_constraints():\n                     for constraint in constraints:\n                         if constraint is self:\n                             raise ValidationError(\n-                                instance.unique_error_message(model, self.fields)\n+                                instance.unique_error_message(model, self.fields),\n+                                code=self.violation_error_code,\n                             )\n+\n         else:\n             against = instance._get_field_value_map(meta=model._meta, exclude=exclude)\n             try:\n                 if (self.condition & Exists(queryset.filter(self.condition))).check(\n                     against, using=using\n                 ):\n-                    raise ValidationError(self.get_violation_error_message())\n+                    raise ValidationError(self.get_violation_error_message(), code=self.violation_error_code)\n+\n             except FieldError:\n                 pass\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16569",
        "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 235aaf844c..cae2856196 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -490,7 +490,8 @@ class BaseFormSet(RenderableFormMixin):\n                     required=False,\n                     widget=self.get_ordering_widget(),\n                 )\n-        if self.can_delete and (self.can_delete_extra or index < initial_form_count):\n+        if self.can_delete and (self.can_delete_extra or (index is not None and index < initial_form_count)):\n+\n             form.fields[DELETION_FIELD_NAME] = BooleanField(\n                 label=_(\"Delete\"),\n                 required=False,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16595",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16612",
        "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 61be31d890..15954b2a3f 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -453,7 +453,13 @@ class AdminSite:\n                 pass\n             else:\n                 if getattr(match.func, \"should_append_slash\", True):\n-                    return HttpResponsePermanentRedirect(\"%s/\" % request.path)\n+                    query_string = request.META.get(\"QUERY_STRING\", \"\")\n+                    if query_string:\n+                        redirect_url = \"%s/?%s\" % (request.path, query_string)\n+                    else:\n+                        redirect_url = \"%s/\" % request.path\n+                    return HttpResponsePermanentRedirect(redirect_url)\n+\n         raise Http404\n \n     def _build_app_dict(self, request, label=None):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16631",
        "model_patch": "diff --git a/django/contrib/auth/base_user.py b/django/contrib/auth/base_user.py\nindex 5ee30bf59c..0eb21064f7 100644\n--- a/django/contrib/auth/base_user.py\n+++ b/django/contrib/auth/base_user.py\n@@ -131,16 +131,26 @@ class AbstractBaseUser(models.Model):\n         \"\"\"\n         return is_password_usable(self.password)\n \n-    def get_session_auth_hash(self):\n-        \"\"\"\n-        Return an HMAC of the password field.\n-        \"\"\"\n-        key_salt = \"django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash\"\n-        return salted_hmac(\n-            key_salt,\n-            self.password,\n-            algorithm=\"sha256\",\n-        ).hexdigest()\n+def get_all_session_auth_hashes(self):\n+    \"\"\"\n+    Return a list of valid session authentication hashes, considering the\n+    current SECRET_KEY and any fallback secret keys provided via\n+    SECRET_KEY_FALLBACKS.\n+    \"\"\"\n+    key_salt = \"django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash\"\n+    primary = salted_hmac(key_salt, self.password, algorithm=\"sha256\").hexdigest()\n+    hashes = [primary]\n+    fallback_keys = getattr(settings, \"SECRET_KEY_FALLBACKS\", [])\n+    for fallback in fallback_keys:\n+        hashes.append(salted_hmac(key_salt, self.password, secret=fallback, algorithm=\"sha256\").hexdigest())\n+    return hashes\n+\n+def get_session_auth_hash(self):\n+    \"\"\"\n+    Return the primary session authentication hash.\n+    \"\"\"\n+    return self.get_all_session_auth_hashes()[0]\n+\n \n     @classmethod\n     def get_email_field_name(cls):\ndiff --git a/django/contrib/auth/middleware.py b/django/contrib/auth/middleware.py\nindex 72dc553827..7f715acc67 100644\n--- a/django/contrib/auth/middleware.py\n+++ b/django/contrib/auth/middleware.py\n@@ -39,20 +39,25 @@ class AuthenticationMiddleware(MiddlewareMixin):\n class RemoteUserMiddleware(MiddlewareMixin):\n     \"\"\"\n     Middleware for utilizing web-server-provided authentication.\n+    def process_request(self, request):\n+        request.user = SimpleLazyObject(lambda: auth.get_user(request))\n+        session_hash = request.session.get(\"_auth_user_hash\")\n+        # If the user model provides fallback support, use it.\n+        if hasattr(request.user, \"get_all_session_auth_hashes\"):\n+            valid_hashes = request.user.get_all_session_auth_hashes()\n+            if session_hash and session_hash not in valid_hashes:\n+                # The session hash does not match any valid hash: invalidate the session.\n+                auth.logout(request)\n+            elif session_hash and session_hash != valid_hashes[0]:\n+                # Session hash is valid (matches a fallback key), so upgrade it to use the current SECRET_KEY.\n+                request.session[\"_auth_user_hash\"] = valid_hashes[0]\n+        else:\n+            # Fallback legacy behavior if get_all_session_auth_hashes is not available.\n+            request._session_auth_hash = (\n+                request.session.get(auth.SESSION_KEY, None)\n+                and request.session.get(\"_auth_user_hash\")\n+            )\n \n-    If request.user is not authenticated, then this middleware attempts to\n-    authenticate the username passed in the ``REMOTE_USER`` request header.\n-    If authentication is successful, the user is automatically logged in to\n-    persist the user in the session.\n-\n-    The header used is configurable and defaults to ``REMOTE_USER``.  Subclass\n-    this class and change the ``header`` attribute if you need to use a\n-    different header.\n-    \"\"\"\n-\n-    # Name of request header to grab username from.  This will be the key as\n-    # used in the request.META dictionary, i.e. the normalization of headers to\n-    # all uppercase and the addition of \"HTTP_\" prefix apply.\n     header = \"REMOTE_USER\"\n     force_logout_if_no_header = True\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16642",
        "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex f62dec8ce9..0d99fbbd9e 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -604,19 +604,25 @@ class FileResponse(StreamingHttpResponse):\n \n         filename = os.path.basename(self.filename or filename)\n         if self._no_explicit_content_type:\n-            if filename:\n-                content_type, encoding = mimetypes.guess_type(filename)\n-                # Encoding isn't set to prevent browsers from automatically\n-                # uncompressing files.\n-                content_type = {\n-                    \"bzip2\": \"application/x-bzip\",\n-                    \"gzip\": \"application/gzip\",\n-                    \"xz\": \"application/x-xz\",\n-                }.get(encoding, content_type)\n-                self.headers[\"Content-Type\"] = (\n-                    content_type or \"application/octet-stream\"\n-                )\n-            else:\n+if filename:\n+    content_type, encoding = mimetypes.guess_type(filename)\n+    # Check for specific compressed file extensions and override the guessed type\n+    lower_filename = filename.lower()\n+    if lower_filename.endswith('.br'):\n+        content_type = \"application/brotli\"\n+    elif lower_filename.endswith('.z'):\n+        content_type = \"application/x-compress\"\n+    else:\n+        # Use encoding mapping to prevent browsers from automatically uncompressing files.\n+        content_type = {\n+            \"bzip2\": \"application/x-bzip\",\n+            \"gzip\": \"application/gzip\",\n+            \"xz\": \"application/x-xz\",\n+        }.get(encoding, content_type)\n+    self.headers[\"Content-Type\"] = content_type or \"application/octet-stream\"\n+else:\n+    self.headers[\"Content-Type\"] = \"application/octet-stream\"\n+\n                 self.headers[\"Content-Type\"] = \"application/octet-stream\"\n \n         if content_disposition := content_disposition_header(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16661",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 5240b07cd6..668c665b44 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -461,11 +461,14 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n                 # Lookups on nonexistent fields are ok, since they're ignored\n                 # later.\n                 break\n-            # It is allowed to filter on values that would be found from local\n-            # model anyways. For example, if you filter on employee__department__id,\n-            # then the id value would be found already from employee__department_id.\n             if not prev_field or (\n-                prev_field.is_relation\n+                prev_field.is_relation and (\n+                    (isinstance(field, models.OneToOneField) and field.primary_key)\n+                    or field not in prev_field.path_infos[-1].target_fields\n+                )\n+            ):\n+                relation_parts.append(part)\n+\n                 and field not in prev_field.path_infos[-1].target_fields\n             ):\n                 relation_parts.append(part)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16662",
        "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..085990e6d6 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -173,9 +173,10 @@ class MigrationWriter:\n         else:\n             imports.add(\"from django.db import migrations\")\n \n-        # Sort imports by the package / module to be imported (the part after\n-        # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n-        sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n+# Sort imports with a primary key that distinguishes \"import\" statements (which\n+# should appear first) from \"from ... import\" statements. Then sort by the module name.\n+sorted_imports = sorted(imports, key=lambda i: (0 if i.startswith(\"import\") else 1, i.split()[1]))\n+\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n             items[\"imports\"] += (\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16667",
        "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 842b73e95c..f94848ec40 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -1155,9 +1155,10 @@ class SelectDateWidget(Widget):\n         if y is not None and m is not None and d is not None:\n             input_format = get_format(\"DATE_INPUT_FORMATS\")[0]\n             input_format = formats.sanitize_strftime_format(input_format)\n-            try:\n-                date_value = datetime.date(int(y), int(m), int(d))\n-            except ValueError:\n+try:\n+    date_value = datetime.date(int(y), int(m), int(d))\n+except (ValueError, OverflowError):\n+\n                 # Return pseudo-ISO dates with zeros for any unselected values,\n                 # e.g. '2017-0-23'.\n                 return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16801",
        "model_patch": "diff --git a/django/db/models/fields/files.py b/django/db/models/fields/files.py\nindex 7f8eb128e1..4ae4680814 100644\n--- a/django/db/models/fields/files.py\n+++ b/django/db/models/fields/files.py\n@@ -441,8 +441,9 @@ class ImageField(FileField):\n         # after their corresponding image field don't stay cleared by\n         # Model.__init__, see bug #11196.\n         # Only run post-initialization dimension update on non-abstract models\n-        if not cls._meta.abstract:\n-            signals.post_init.connect(self.update_dimension_fields, sender=cls)\n+if not cls._meta.abstract and (self.width_field or self.height_field):\n+    signals.post_init.connect(self.update_dimension_fields, sender=cls)\n+\n \n     def update_dimension_fields(self, instance, force=False, *args, **kwargs):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16819",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 967a91fdc8..c00ae06b31 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -843,15 +843,16 @@ class AddIndex(IndexOperation):\n             [],\n             kwargs,\n         )\n+    def reduce(self, operation, app_label):\n+        # If a RemoveIndex follows an AddIndex on the same model/index,\n+        # cancel both operations.\n+        from django.db.migrations.operations.models import RemoveIndex\n+        if (isinstance(operation, RemoveIndex) and \n+            self.model_name_lower == operation.model_name_lower and \n+            self.index.name.lower() == operation.name.lower()):\n+            return []\n+        return super().reduce(operation, app_label)\n \n-    def describe(self):\n-        if self.index.expressions:\n-            return \"Create index %s on %s on model %s\" % (\n-                self.index.name,\n-                \", \".join([str(expression) for expression in self.index.expressions]),\n-                self.model_name,\n-            )\n-        return \"Create index %s on field(s) %s of model %s\" % (\n             self.index.name,\n             \", \".join(self.index.fields),\n             self.model_name,\n@@ -896,14 +897,15 @@ class RemoveIndex(IndexOperation):\n             [],\n             kwargs,\n         )\n-\n-    def describe(self):\n-        return \"Remove index %s from %s\" % (self.name, self.model_name)\n-\n-    @property\n-    def migration_name_fragment(self):\n-        return \"remove_%s_%s\" % (self.model_name_lower, self.name.lower())\n-\n+    def reduce(self, operation, app_label):\n+        # If an AddIndex precedes a RemoveIndex on the same model/index,\n+        # cancel both operations.\n+        from django.db.migrations.operations.models import AddIndex\n+        if (isinstance(operation, AddIndex) and \n+            self.model_name_lower == operation.model_name_lower and \n+            self.name.lower() == operation.index.name.lower()):\n+            return []\n+        return super().reduce(operation, app_label)\n \n class RenameIndex(IndexOperation):\n     \"\"\"Rename an index.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16877",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16899",
        "model_patch": "diff --git a/django/contrib/admin/checks.py b/django/contrib/admin/checks.py\nindex c395b0bde2..f82adecfb6 100644\n--- a/django/contrib/admin/checks.py\n+++ b/django/contrib/admin/checks.py\n@@ -769,16 +769,18 @@ class BaseModelAdminChecks:\n             try:\n                 obj.model._meta.get_field(field_name)\n             except FieldDoesNotExist:\n-                return [\n-                    checks.Error(\n-                        \"The value of '%s' is not a callable, an attribute of \"\n-                        \"'%s', or an attribute of '%s'.\"\n-                        % (\n-                            label,\n-                            obj.__class__.__name__,\n-                            obj.model._meta.label,\n-                        ),\n-                        obj=obj.__class__,\n+checks.Error(\n+    \"The value '%s' in readonly_fields (provided as %s) is not a callable, an attribute of '%s', or an attribute of '%s'.\"\n+    % (\n+        field_name,\n+        label,\n+        obj.__class__.__name__,\n+        obj.model._meta.label,\n+    ),\n+    obj=obj.__class__,\n+    id=\"admin.E035\",\n+)\n+\n                         id=\"admin.E035\",\n                     )\n                 ]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16901",
        "model_patch": "diff --git a/django/db/models/sql/where.py b/django/db/models/sql/where.py\nindex aaab1730b7..7883fda47d 100644\n--- a/django/db/models/sql/where.py\n+++ b/django/db/models/sql/where.py\n@@ -6,6 +6,50 @@ from functools import reduce\n \n from django.core.exceptions import EmptyResultSet, FullResultSet\n from django.db.models.expressions import Case, When\n+from django.db.models.functions import Mod\n+\n+\n from django.db.models.lookups import Exact\n from django.utils import tree\n from django.utils.functional import cached_property\n@@ -135,7 +179,8 @@ class WhereNode(tree.Node):\n                 operator.add,\n                 (Case(When(c, then=1), default=0) for c in self.children),\n             )\n-            rhs = Exact(1, rhs_sum)\n+            rhs = Exact(1, Mod(rhs_sum, 2))\n+\n             return self.__class__([lhs, rhs], AND, self.negated).as_sql(\n                 compiler, connection\n             )\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16938",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16950",
        "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0711ec0d61..a34a41db8d 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -570,16 +570,17 @@ class Model(AltersData, metaclass=ModelBase):\n                 )\n         super().__init__()\n         post_init.send(sender=cls, instance=self)\n+        # PATCH: Ensure non\u2011editable fields with defaults get initialized even\n+        # when created with a kwargs dict that omits them (as occurs when using inline forms).\n+        for field in opts.fields:\n+            if (not field.editable) and field.has_default():\n+                # If the attribute is still missing (or is None), set it to the default.\n+                current = getattr(self, field.attname, _DEFERRED)\n+                if current is _DEFERRED or current is None:\n+                    default = field.get_default()\n+                    if default is not _DEFERRED:\n+                        _setattr(self, field.attname, default)\n \n-    @classmethod\n-    def from_db(cls, db, field_names, values):\n-        if len(values) != len(cls._meta.concrete_fields):\n-            values_iter = iter(values)\n-            values = [\n-                next(values_iter) if f.attname in field_names else DEFERRED\n-                for f in cls._meta.concrete_fields\n-            ]\n-        new = cls(*values)\n         new._state.adding = False\n         new._state.db = db\n         return new\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-17029",
        "model_patch": "diff --git a/django/apps/registry.py b/django/apps/registry.py\nindex 0683f3ad3c..9fc20537eb 100644\n--- a/django/apps/registry.py\n+++ b/django/apps/registry.py\n@@ -57,12 +57,13 @@ class Apps:\n         # Populate apps and models, unless it's the main registry.\n         if installed_apps is not None:\n             self.populate(installed_apps)\n-\n-    def populate(self, installed_apps=None):\n-        \"\"\"\n-        Load application configurations and models.\n-\n-        Import each application module and then each model module.\n+        # Clear other internal caches...\n+        self.all_models = None\n+        self.get_models_cache.clear()\n+        self.app_configs.clear()\n+        # Clear get_swappable_settings_name cache, which is a functools.cache wrapper.\n+        self.get_swappable_settings_name.cache_clear()\n+        # (other cache-clearing operations if necessary)\n \n         It is thread-safe and idempotent, but not reentrant.\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-17084",
        "model_patch": "diff --git a/django/db/models/aggregates.py b/django/db/models/aggregates.py\nindex a778cd413b..7280a13efa 100644\n--- a/django/db/models/aggregates.py\n+++ b/django/db/models/aggregates.py\n@@ -75,19 +75,34 @@ class Aggregate(Func):\n         elif not self.is_summary:\n             # Call Aggregate.get_source_expressions() to avoid\n             # returning self.filter and including that in this loop.\n-            expressions = super(Aggregate, c).get_source_expressions()\n-            for index, expr in enumerate(expressions):\n-                if expr.contains_aggregate:\n-                    before_resolved = self.get_source_expressions()[index]\n-                    name = (\n-                        before_resolved.name\n-                        if hasattr(before_resolved, \"name\")\n-                        else repr(before_resolved)\n-                    )\n-                    raise FieldError(\n-                        \"Cannot compute %s('%s'): '%s' is an aggregate\"\n-                        % (c.name, name, name)\n-                    )\n+expressions = super(Aggregate, c).get_source_expressions()\n+for index, expr in enumerate(expressions):\n+    # If the expression is built using a Window (i.e. it contains an OVER clause),\n+    # then aggregating over it will nest the window function. PostgreSQL does not allow that.\n+    if getattr(expr, \"contains_over_clause\", False):\n+        before_resolved = self.get_source_expressions()[index]\n+        name = (\n+            before_resolved.name\n+            if hasattr(before_resolved, \"name\")\n+            else repr(before_resolved)\n+        )\n+        raise FieldError(\n+            \"Cannot compute %s('%s'): '%s' is a window function. Aggregating over \"\n+            \"window functions is not allowed. Please use a subquery to first evaluate \"\n+            \"the window expression.\" % (c.name, name, name)\n+        )\n+    if expr.contains_aggregate:\n+        before_resolved = self.get_source_expressions()[index]\n+        name = (\n+            before_resolved.name\n+            if hasattr(before_resolved, \"name\")\n+            else repr(before_resolved)\n+        )\n+        raise FieldError(\n+            \"Cannot compute %s('%s'): '%s' is an aggregate\"\n+            % (c.name, name, name)\n+        )\n+\n         if (default := c.default) is None:\n             return c\n         if hasattr(default, \"resolve_expression\"):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-17087",
        "model_patch": "diff --git a/django/utils/deconstruct.py b/django/utils/deconstruct.py\nindex f8754c1974..bd99aff1b7 100644\n--- a/django/utils/deconstruct.py\n+++ b/django/utils/deconstruct.py\n@@ -27,8 +27,9 @@ def deconstructible(*args, path=None):\n             if path and type(obj) is klass:\n                 module_name, _, name = path.rpartition(\".\")\n             else:\n-                module_name = obj.__module__\n-                name = obj.__class__.__name__\n+    module_name = obj.__module__\n+    name = getattr(obj.__class__, \"__qualname__\", obj.__class__.__name__)\n+\n             # Make sure it's actually there and not an inner class\n             module = import_module(module_name)\n             if not hasattr(module, name):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-7530",
        "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..01320a70ae 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -103,9 +103,14 @@ class Command(BaseCommand):\n             connection = connections[alias]\n             if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(\n                     # At least one model must be migrated to the database.\n-                    router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n-                    for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n+                    any(\n+                        router.allow_migrate(\n+                            connection.alias, app_label, model_name=model._meta.object_name\n+                        )\n+                        for app_label in consistency_check_labels\n+                        for model in apps.get_app_config(app_label).get_models()\n+                    )\n+\n             )):\n                 loader.check_consistent_history(connection)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-9296",
        "model_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\nindex 1f92da5d4f..f591ecba0e 100644\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -105,6 +105,193 @@ class Paginator:\n         a template for loop.\n         \"\"\"\n         return range(1, self.num_pages + 1)\n+   def __iter__(self):\n+\n+\n+       \"\"\"\n+\n+\n+       Yield Page objects for each page in the page_range.\n+\n+\n+       \"\"\"\n+\n+\n+       for page_num in self.page_range:\n+\n+\n+           yield self.page(page_num)\n+\n+\n \n     def _check_object_list_is_ordered(self):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-13989",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex 4b73d52293..931d419f4e 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -6654,7 +6654,9 @@ optional.\n         hist_kwargs = dict()\n \n         # if the bin_range is not given, compute without nan numpy\n-        # does not do this for us when guessing the range (but will\n+    orig_bins = bins\n+    orig_range = range\n+\n         # happily ignore nans when computing the histogram).\n         if bin_range is None:\n             xmin = np.inf\n@@ -6696,6 +6698,174 @@ optional.\n             # this will automatically overwrite bins,\n             # so that each histogram uses the same bins\n             m, bins = np.histogram(x[i], bins, weights=w[i], **hist_kwargs)\n+            if density and (orig_range is not None) and isinstance(orig_bins, str):\n+\n+\n+                bins[0] = orig_range[0]\n+\n+\n+                bins[-1] = orig_range[1]\n+\n+\n             m = m.astype(float)  # causes problems later if it's an int\n             if mlast is None:\n                 mlast = np.zeros(len(bins)-1, m.dtype)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-14623",
        "model_patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\nindex 2bb9e41586..92fa2339cb 100644\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -1888,15 +1888,21 @@ def _make_getset_interval(method_name, lim_name, attr_name):\n         if ignore:\n             setattr(getattr(self.axes, lim_name), attr_name, (vmin, vmax))\n         else:\n-            oldmin, oldmax = getter(self)\n-            if oldmin < oldmax:\n-                setter(self, min(vmin, vmax, oldmin), max(vmin, vmax, oldmax),\n-                       ignore=True)\n+            # If the caller explicitly provides reversed (inverted) limits,\n+            # honor them rather than reordering them.\n+            if vmin > vmax:\n+                setattr(getattr(self.axes, lim_name), attr_name, (vmin, vmax))\n             else:\n-                setter(self, max(vmin, vmax, oldmax), min(vmin, vmax, oldmin),\n-                       ignore=True)\n+                oldmin, oldmax = getter(self)\n+                if oldmin < oldmax:\n+                    setattr(getattr(self.axes, lim_name), attr_name,\n+                            (min(vmin, vmax, oldmin), max(vmin, vmax, oldmax)))\n+                else:\n+                    setattr(getattr(self.axes, lim_name), attr_name,\n+                            (max(vmin, vmax, oldmax), min(vmin, vmax, oldmin)))\n         self.stale = True\n \n+\n     getter.__name__ = f\"get_{method_name}_interval\"\n     setter.__name__ = f\"set_{method_name}_interval\"\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-20488",
        "model_patch": "diff --git a/lib/matplotlib/image.py b/lib/matplotlib/image.py\nindex 95bb42d75c..e134fc6f43 100644\n--- a/lib/matplotlib/image.py\n+++ b/lib/matplotlib/image.py\n@@ -532,9 +532,10 @@ class _ImageBase(martist.Artist, cm.ScalarMappable):\n                 # we have re-set the vmin/vmax to account for small errors\n                 # that may have moved input values in/out of range\n                 s_vmin, s_vmax = vrange\n-                if isinstance(self.norm, mcolors.LogNorm):\n-                    if s_vmin < 0:\n-                        s_vmin = max(s_vmin, np.finfo(scaled_dtype).eps)\n+if isinstance(self.norm, mcolors.LogNorm):\n+    if s_vmin <= 0:\n+        s_vmin = max(s_vmin, np.finfo(scaled_dtype).eps)\n+\n                 with cbook._setattr_cm(self.norm,\n                                        vmin=s_vmin,\n                                        vmax=s_vmax,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-20676",
        "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex a199e45d40..5932ca7007 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -2136,12 +2136,13 @@ class SpanSelector(_SelectorWidget):\n                 self.disconnect_events()\n \n             self.canvas = ax.figure.canvas\n-            self.connect_default_events()\n+if self.direction == 'horizontal':\n+    trans = ax.transData\n+    w, h = 0, 1\n+else:\n+    trans = ax.transData\n+    w, h = 1, 0\n \n-        if self.direction == 'horizontal':\n-            trans = ax.get_xaxis_transform()\n-            w, h = 0, 1\n-        else:\n             trans = ax.get_yaxis_transform()\n             w, h = 1, 0\n         self._rect = Rectangle((0, 0), w, h,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-20826",
        "model_patch": "diff --git a/lib/matplotlib/axes/_base.py b/lib/matplotlib/axes/_base.py\nindex 802fd3c997..5b04f423de 100644\n--- a/lib/matplotlib/axes/_base.py\n+++ b/lib/matplotlib/axes/_base.py\n@@ -1218,11 +1218,12 @@ class _AxesBase(martist.Artist):\n             except TypeError:\n                 pass\n \n-        # update the minor locator for x and y axis based on rcParams\n-        if mpl.rcParams['xtick.minor.visible']:\n-            self.xaxis.set_minor_locator(mticker.AutoMinorLocator())\n-        if mpl.rcParams['ytick.minor.visible']:\n-            self.yaxis.set_minor_locator(mticker.AutoMinorLocator())\n+# update the minor locator for x and y axis based on rcParams\n+if mpl.rcParams['xtick.minor.visible'] and self._sharex is None:\n+    self.xaxis.set_minor_locator(mticker.AutoMinorLocator())\n+if mpl.rcParams['ytick.minor.visible'] and self._sharey is None:\n+    self.yaxis.set_minor_locator(mticker.AutoMinorLocator())\n+\n \n         if self._sharex is None:\n             self._autoscaleXon = True\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-20859",
        "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex 44ab024698..1ce13b2cbf 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -359,8 +359,9 @@ class Legend(Artist):\n         in the normalized axes coordinate.\n         \"\"\"\n         # local import only to avoid circularity\n-        from matplotlib.axes import Axes\n-        from matplotlib.figure import Figure\n+from matplotlib.axes import Axes\n+from matplotlib.figure import Figure, FigureBase\n+\n \n         super().__init__()\n \n@@ -434,12 +435,12 @@ class Legend(Artist):\n             self.isaxes = True\n             self.axes = parent\n             self.set_figure(parent.figure)\n-        elif isinstance(parent, Figure):\n+        elif isinstance(parent, Figure) or isinstance(parent, FigureBase):\n             self.isaxes = False\n             self.set_figure(parent)\n         else:\n-            raise TypeError(\"Legend needs either Axes or Figure as parent\")\n-        self.parent = parent\n+            raise TypeError(\"Legend needs either Axes or Figure/FigureBase as parent\")\n+\n \n         self._loc_used_default = loc is None\n         if loc is None:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-21568",
        "model_patch": "diff --git a/lib/matplotlib/dates.py b/lib/matplotlib/dates.py\nindex 0766156d64..43afa7f995 100644\n--- a/lib/matplotlib/dates.py\n+++ b/lib/matplotlib/dates.py\n@@ -592,15 +592,20 @@ def drange(dstart, dend, delta):\n \n \n def _wrap_in_tex(text):\n+    # If the text does not contain any alphabetic characters,\n+    # it is likely a datetime tick label (e.g. \"23:59:59\") that does not\n+    # require TeX math wrapping. Return as-is.\n+    if not re.search('[a-zA-Z]', text):\n+        return text\n     p = r'([a-zA-Z]+)'\n     ret_text = re.sub(p, r'}$\\1$\\\\mathdefault{', text)\n-\n     # Braces ensure dashes are not spaced like binary operators.\n-    ret_text = '$\\\\mathdefault{'+ret_text.replace('-', '{-}')+'}$'\n+    ret_text = '$\\\\mathdefault{' + ret_text.replace('-', '{-}') + '}$'\n     ret_text = ret_text.replace('$\\\\mathdefault{}$', '')\n     return ret_text\n \n \n+\n ## date tickers and formatters ###\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-22719",
        "model_patch": "diff --git a/lib/matplotlib/category.py b/lib/matplotlib/category.py\nindex c823b68fd9..1b2131e795 100644\n--- a/lib/matplotlib/category.py\n+++ b/lib/matplotlib/category.py\n@@ -52,6 +52,153 @@ class StrCategoryConverter(units.ConversionInterface):\n                 'numeric data')\n         StrCategoryConverter._validate_unit(unit)\n         # dtype = object preserves numerical pass throughs\n+        # Early return for empty input to avoid mis-classification.\n+\n+\n+        if values.size == 0:\n+\n+\n+            return np.asarray([], dtype=float)\n+\n+\n         values = np.atleast_1d(np.array(value, dtype=object))\n         # pass through sequence of non binary numbers\n         with _api.suppress_matplotlib_deprecation_warning():\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-22865",
        "model_patch": "diff --git a/lib/matplotlib/colorbar.py b/lib/matplotlib/colorbar.py\nindex c59b0ac815..9e2c8220df 100644\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -727,12 +727,15 @@ class Colorbar:\n             val = -1 if self._long_axis().get_inverted() else 0\n             color = self.cmap(self.norm(self._values[val]))\n             patch = mpatches.PathPatch(\n-                mpath.Path(xy), facecolor=color, linewidth=0,\n+                mpath.Path(xy), facecolor=color,\n+                linewidth=(0.5 * mpl.rcParams['axes.linewidth'] if self.drawedges else 0),\n+                edgecolor=(mpl.rcParams['axes.edgecolor'] if self.drawedges else None),\n                 antialiased=False, transform=self.ax.transAxes,\n                 hatch=hatches[0], clip_on=False,\n                 # Place it right behind the standard patches, which is\n                 # needed if we updated the extends\n                 zorder=np.nextafter(self.ax.patch.zorder, -np.inf))\n+\n             self.ax.add_patch(patch)\n             self._extend_patches.append(patch)\n         if self._extend_upper():\n@@ -749,11 +752,14 @@ class Colorbar:\n             color = self.cmap(self.norm(self._values[val]))\n             patch = mpatches.PathPatch(\n                 mpath.Path(xy), facecolor=color,\n-                linewidth=0, antialiased=False,\n+                linewidth=(0.5 * mpl.rcParams['axes.linewidth'] if self.drawedges else 0),\n+                edgecolor=(mpl.rcParams['axes.edgecolor'] if self.drawedges else None),\n+                antialiased=False,\n                 transform=self.ax.transAxes, hatch=hatches[-1], clip_on=False,\n                 # Place it right behind the standard patches, which is\n                 # needed if we updated the extends\n                 zorder=np.nextafter(self.ax.patch.zorder, -np.inf))\n+\n             self.ax.add_patch(patch)\n             self._extend_patches.append(patch)\n         return\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-22871",
        "model_patch": "diff --git a/lib/matplotlib/dates.py b/lib/matplotlib/dates.py\nindex 4d8ddf3ee5..44ee19551e 100644\n--- a/lib/matplotlib/dates.py\n+++ b/lib/matplotlib/dates.py\n@@ -770,9 +770,17 @@ class ConciseDateFormatter(ticker.Formatter):\n                         mpl.rcParams['text.usetex'])\n \n     def __call__(self, x, pos=None):\n-        formatter = DateFormatter(self.defaultfmt, self._tz,\n-                                  usetex=self._usetex)\n-        return formatter(x, pos=pos)\n+        # When no \"pos\" is provided then x is expected to be the full list of tick values.\n+        # In that case, use the dynamic formatting provided by format_ticks which\n+        # computes both the tick labels and the necessary offset (e.g. the missing year).\n+        if pos is None:\n+            return self.format_ticks(x)\n+        else:\n+            # When formatting an individual tick (pos is not None),\n+            # call format_ticks on a singleton list and return the first label.\n+            labels = self.format_ticks([x])\n+            return labels[0]\n+\n \n     def format_ticks(self, values):\n         tickdatetime = [num2date(value, tz=self._tz) for value in values]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-23299",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-23314",
        "model_patch": "diff --git a/lib/mpl_toolkits/mplot3d/axes3d.py b/lib/mpl_toolkits/mplot3d/axes3d.py\nindex 9db44b7994..8acfbd0a24 100644\n--- a/lib/mpl_toolkits/mplot3d/axes3d.py\n+++ b/lib/mpl_toolkits/mplot3d/axes3d.py\n@@ -385,6 +385,62 @@ class Axes3D(Axes):\n         pb1 = pb.shrunk_to_aspect(box_aspect, pb, fig_aspect)\n         self._set_position(pb1.anchored(self.get_anchor(), pb), 'active')\n \n+        if not self.get_visible():\n+\n+\n+            return\n+\n+\n     @martist.allow_rasterization\n     def draw(self, renderer):\n         self._unstale_viewLim()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-23412",
        "model_patch": "diff --git a/lib/matplotlib/patches.py b/lib/matplotlib/patches.py\nindex e062249589..c5e598b25a 100644\n--- a/lib/matplotlib/patches.py\n+++ b/lib/matplotlib/patches.py\n@@ -581,23 +581,20 @@ class Patch(artist.Artist):\n         renderer.close_group('patch')\n         self.stale = False\n \n+    @artist.allow_rasterization\n+    def draw(self, renderer):\n     @artist.allow_rasterization\n     def draw(self, renderer):\n         # docstring inherited\n         if not self.get_visible():\n             return\n-        # Patch has traditionally ignored the dashoffset.\n-        with cbook._setattr_cm(\n-                 self, _dash_pattern=(0, self._dash_pattern[1])), \\\n-             self._bind_draw_path_function(renderer) as draw_path:\n+        # Use the user-specified dash offset and dash pattern.\n+        with self._bind_draw_path_function(renderer) as draw_path:\n             path = self.get_path()\n             transform = self.get_transform()\n             tpath = transform.transform_path_non_affine(path)\n             affine = transform.get_affine()\n             draw_path(tpath, affine,\n-                      # Work around a bug in the PDF and SVG renderers, which\n-                      # do not draw the hatches if the facecolor is fully\n-                      # transparent, but do if it is None.\n                       self._facecolor if self._facecolor[3] else None)\n \n     def get_path(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-23476",
        "model_patch": "diff --git a/lib/matplotlib/backend_bases.py b/lib/matplotlib/backend_bases.py\nindex 9ae2982c62..9a5cde942b 100644\n--- a/lib/matplotlib/backend_bases.py\n+++ b/lib/matplotlib/backend_bases.py\n@@ -1606,7 +1606,9 @@ class FigureCanvasBase:\n     # currently defined *after* the canvas class, but one could also assign\n     # ``FigureCanvasBase.manager_class = FigureManagerBase``\n     # after defining both classes.)\n-    manager_class = _api.classproperty(lambda cls: FigureManagerBase)\n+if not hasattr(figure, '_original_dpi'):\n+    figure._original_dpi = figure.dpi\n+\n \n     events = [\n         'resize_event',\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24026",
        "model_patch": "diff --git a/lib/matplotlib/stackplot.py b/lib/matplotlib/stackplot.py\nindex c580043eeb..ea901ceadb 100644\n--- a/lib/matplotlib/stackplot.py\n+++ b/lib/matplotlib/stackplot.py\n@@ -69,8 +69,11 @@ def stackplot(axes, x, *args,\n     y = np.row_stack(args)\n \n     labels = iter(labels)\n-    if colors is not None:\n-        axes.set_prop_cycle(color=colors)\n+if colors is not None:\n+    # Convert \"C\" alias strings (cycle reference) to full RGBA colors.\n+    colors = [mpl.colors.to_rgba(c) for c in colors]\n+    axes.set_prop_cycle(color=colors)\n+\n \n     # Assume data passed has not been 'stacked', so stack it here.\n     # We'll need a float buffer for the upcoming calculations.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24149",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex fdac0f3560..29c0393993 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2180,9 +2180,10 @@ class Axes(_AxesBase):\n             # wrap numpy arrays.\n             try:\n                 x0 = cbook._safe_first_finite(x0)\n-            except (TypeError, IndexError, KeyError):\n+            except (TypeError, IndexError, KeyError, StopIteration):\n                 pass\n \n+\n             try:\n                 x = cbook._safe_first_finite(xconv)\n             except (TypeError, IndexError, KeyError):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24177",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex 2412f815cd..3dca87304f 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -6883,12 +6883,14 @@ such objects\n                     edgecolor=None if fill else c,\n                     fill=fill if fill else None,\n                     zorder=None if fill else mlines.Line2D.zorder))\n-            for patch_list in patches:\n-                for patch in patch_list:\n-                    if orientation == 'vertical':\n-                        patch.sticky_edges.y.append(0)\n-                    elif orientation == 'horizontal':\n-                        patch.sticky_edges.x.append(0)\n+for patch_list in patches:\n+    for patch in patch_list:\n+        bb = patch.get_path().get_extents()\n+        if orientation == 'vertical':\n+            patch.sticky_edges.y.extend([bb.y0, bb.y1])\n+        else:\n+            patch.sticky_edges.x.extend([bb.x0, bb.x1])\n+\n \n             # we return patches, so put it back in the expected order\n             patches.reverse()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24570",
        "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 3a506543ac..e4232346e5 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -475,9 +475,15 @@ class HPacker(PackerBase):\n             return 2 * pad, 2 * pad, pad, pad, []\n \n         hd_list = [(h, yd) for w, h, xd, yd in whd_list]\n+        new_align = self.align\n+        if self.align == \"bottom\":\n+            new_align = \"top\"\n+        elif self.align == \"top\":\n+            new_align = \"bottom\"\n         height, ydescent, yoffsets = _get_aligned_offsets(hd_list,\n                                                           self.height,\n-                                                          self.align)\n+                                                          new_align)\n+\n \n         pack_list = [w for w, h, xd, yd in whd_list]\n         width, xoffsets_ = _get_packed_offsets(pack_list, self.width,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24627",
        "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex 6c18ba1a64..ea1e070da2 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -945,9 +945,15 @@ default: %(va)s\n             subfig.clear(keep_observers=keep_observers)\n         self.subfigs = []\n \n-        for ax in tuple(self.axes):  # Iterate over the copy.\n-            ax.clear()\n-            self.delaxes(ax)  # Remove ax from self._axstack.\n+for ax in tuple(self.axes):  # Iterate over the copy.\n+    for child in ax.get_children():\n+        if hasattr(child, 'set_axes'):\n+            child.set_axes(None)\n+        elif hasattr(child, 'axes'):\n+            child.axes = None\n+    ax.clear()\n+    self.delaxes(ax)  # Remove ax from self._axstack.\n+\n \n         self.artists = []\n         self.lines = []\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24637",
        "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex efa34dd078..16ec446c27 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1446,20 +1446,32 @@ or callable, default: value of *xycoords*\n             patchA = self.arrowprops.get(\"patchA\", self.patch)\n             self.arrow_patch.set_patchA(patchA)\n \n-    def draw(self, renderer):\n-        # docstring inherited\n-        if renderer is not None:\n-            self._renderer = renderer\n-        if not self.get_visible() or not self._check_xy(renderer):\n-            return\n-        self.update_positions(renderer)\n-        if self.arrow_patch is not None:\n-            if self.arrow_patch.figure is None and self.figure is not None:\n-                self.arrow_patch.figure = self.figure\n-            self.arrow_patch.draw(renderer)\n-        self.patch.draw(renderer)\n-        self.offsetbox.draw(renderer)\n-        self.stale = False\n+def draw(self, renderer):\n+    # docstring inherited\n+    if renderer is not None:\n+        self._renderer = renderer\n+    if not self.get_visible() or not self._check_xy(renderer):\n+        return\n+\n+    # If this AnnotationBbox has a gid, wrap its drawing in a group.\n+    gid = self.get_gid()\n+    group_opened = False\n+    if gid is not None and hasattr(renderer, \"open_group\"):\n+        renderer.open_group(\"annotationbbox\", gid=gid)\n+        group_opened = True\n+\n+    self.update_positions(renderer)\n+    if self.arrow_patch is not None:\n+        if self.arrow_patch.figure is None and self.figure is not None:\n+            self.arrow_patch.figure = self.figure\n+        self.arrow_patch.draw(renderer)\n+    self.patch.draw(renderer)\n+    self.offsetbox.draw(renderer)\n+\n+    if group_opened and hasattr(renderer, \"close_group\"):\n+        renderer.close_group(\"annotationbbox\")\n+\n+    self.stale = False\n \n \n class DraggableBase:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24870",
        "model_patch": "diff --git a/lib/matplotlib/contour.py b/lib/matplotlib/contour.py\nindex 144eadeae2..4da09e1ad3 100644\n--- a/lib/matplotlib/contour.py\n+++ b/lib/matplotlib/contour.py\n@@ -1128,11 +1128,17 @@ class ContourSet(cm.ScalarMappable, ContourLabeler):\n                 levels_arg = args[0]\n         else:\n             levels_arg = self.levels\n-        if isinstance(levels_arg, Integral):\n+\n+        # Auto-detect boolean inputs: if a boolean array is passed as the data,\n+        # default to a single contour at 0.5.\n+        if isinstance(levels_arg, np.ndarray) and levels_arg.dtype == np.bool_:\n+            self.levels = np.array([0.5], np.float64)\n+        elif isinstance(levels_arg, Integral):\n             self.levels = self._autolev(levels_arg)\n         else:\n             self.levels = np.asarray(levels_arg, np.float64)\n \n+\n         if not self.filled:\n             inside = (self.levels > self.zmin) & (self.levels < self.zmax)\n             levels_in = self.levels[inside]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24970",
        "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..497d7748e6 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -725,6 +725,104 @@ class Colormap:\n                 # Avoid converting large positive values to negative integers.\n                 np.clip(xa, -1, self.N, out=xa)\n                 xa = xa.astype(int)\n+if xa.dtype.kind in \"iu\" and np.iinfo(xa.dtype).max < self._i_bad:\n+\n+\n+    xa = xa.astype(np.int32)\n+\n+\n         # Set the over-range indices before the under-range;\n         # otherwise the under-range values get converted to over-range.\n         xa[xa > self.N - 1] = self._i_over\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25122",
        "model_patch": "diff --git a/lib/matplotlib/mlab.py b/lib/matplotlib/mlab.py\nindex 3552904c3d..8010645ca7 100644\n--- a/lib/matplotlib/mlab.py\n+++ b/lib/matplotlib/mlab.py\n@@ -409,25 +409,24 @@ def _spectral_helper(x, y=None, NFFT=None, Fs=None, detrend_func=None,\n         # component and the NFFT/2 component:\n \n         # if we have a even number of frequencies, don't scale NFFT/2\n-        if not NFFT % 2:\n-            slc = slice(1, -1, None)\n-        # if we have an odd number, just don't scale DC\n-        else:\n-            slc = slice(1, None, None)\n+            if not NFFT % 2:\n+                slc = slice(1, -1)\n+            else:\n+                slc = slice(1, None)\n+\n \n         result[slc] *= scaling_factor\n \n         # MATLAB divides by the sampling frequency so that density function\n         # has units of dB/Hz and can be integrated by the plotted frequency\n         # values. Perform the same scaling here.\n-        if scale_by_freq:\n-            result /= Fs\n-            # Scale the spectrum by the norm of the window to compensate for\n-            # windowing loss; see Bendat & Piersol Sec 11.5.2.\n-            result /= (np.abs(window)**2).sum()\n-        else:\n-            # In this case, preserve power in the segment, not amplitude\n-            result /= np.abs(window).sum()**2\n+            if scale_by_freq:\n+                result /= Fs\n+                # Correct scaling: use the signed sum of the window rather than its absolute values.\n+                result /= (window.sum())**2\n+            else:\n+                result /= (window.sum())**2\n+\n \n     t = np.arange(NFFT/2, len(x) - NFFT/2 + 1, NFFT - noverlap)/Fs\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25287",
        "model_patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\nindex c0e706e2b3..5b01c59a3b 100644\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -2255,7 +2255,8 @@ class XAxis(Axis):\n             transform=mtransforms.blended_transform_factory(\n                 self.axes.transAxes, mtransforms.IdentityTransform()),\n             fontsize=mpl.rcParams['xtick.labelsize'],\n-            color=mpl.rcParams['xtick.color'],\n+    color=mpl.rcParams['xtick.color'] if mpl.rcParams['xtick.labelcolor'] == 'inherit' else mpl.rcParams['xtick.labelcolor'],\n+\n         )\n         self.offset_text_position = 'bottom'\n \n@@ -2515,7 +2516,8 @@ class YAxis(Axis):\n             transform=mtransforms.blended_transform_factory(\n                 self.axes.transAxes, mtransforms.IdentityTransform()),\n             fontsize=mpl.rcParams['ytick.labelsize'],\n-            color=mpl.rcParams['ytick.color'],\n+    color=mpl.rcParams['ytick.color'] if mpl.rcParams['ytick.labelcolor'] == 'inherit' else mpl.rcParams['ytick.labelcolor'],\n+\n         )\n         self.offset_text_position = 'left'\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25311",
        "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex ff6abdb958..7649f42f18 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -337,6 +337,305 @@ class Legend(Artist):\n \n     def __str__(self):\n         return \"Legend\"\n+    def __getstate__(self):\n+\n+\n+        state = self.__dict__.copy()\n+\n+\n+        # Exclude the non\u2011pickleable _draggable attribute.\n+\n+\n+        if '_draggable' in state:\n+\n+\n+            state['_draggable'] = None\n+\n+\n+        return state\n+\n+\n+\n+\n+    def __setstate__(self, state):\n+\n+\n+        self.__dict__.update(state)\n+\n+\n \n     @_api.make_keyword_only(\"3.6\", \"loc\")\n     @_docstring.dedent_interpd\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25332",
        "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex b4c38368bf..833c9db79e 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -3167,6 +3167,46 @@ None}, default: None\n         # discard any changes to the dpi due to pixel ratio changes\n         state[\"_dpi\"] = state.get('_original_dpi', state['_dpi'])\n \n+state.pop(\"_align_label_groups\", None)\n+\n+\n         # add version information to the state\n         state['__mpl_version__'] = mpl.__version__\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25479",
        "model_patch": "diff --git a/lib/matplotlib/cm.py b/lib/matplotlib/cm.py\nindex 38158db956..a7ca8b2e6c 100644\n--- a/lib/matplotlib/cm.py\n+++ b/lib/matplotlib/cm.py\n@@ -260,9 +260,12 @@ def register_cmap(name=None, cmap=None, *, override_builtin=False):\n     # the global ColormapRegistry\n     _colormaps._allow_override_builtin = override_builtin\n     _colormaps.register(cmap, name=name, force=override_builtin)\n+    # Update the colormap's internal name to the registration alias.\n+    cmap.name = name\n     _colormaps._allow_override_builtin = False\n \n \n+\n def _get_cmap(name=None, lut=None):\n     \"\"\"\n     Get a colormap instance, defaulting to rc values if *name* is None.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25775",
        "model_patch": "diff --git a/lib/matplotlib/backends/backend_agg.py b/lib/matplotlib/backends/backend_agg.py\nindex 7d038a998f..598a374097 100644\n--- a/lib/matplotlib/backends/backend_agg.py\n+++ b/lib/matplotlib/backends/backend_agg.py\n@@ -205,8 +205,10 @@ class RendererAgg(RendererBase):\n         # We pass '0' for angle here, since it will be rotated (in raster\n         # space) in the following call to draw_text_image).\n         font.set_text(s, 0, flags=get_hinting_flag())\n+        # Use the antialiased flag from the GraphicsContext which should have been set by the Text object.\n         font.draw_glyphs_to_bitmap(\n-            antialiased=mpl.rcParams['text.antialiased'])\n+            antialiased=gc.get_antialiased())\n+\n         d = font.get_descent() / 64.0\n         # The descent needs to be adjusted for the angle.\n         xo, yo = font.get_bitmap_offset()\ndiff --git a/lib/matplotlib/text.py b/lib/matplotlib/text.py\nindex 4591316cf9..6badeea86b 100644\n--- a/lib/matplotlib/text.py\n+++ b/lib/matplotlib/text.py\n@@ -29,9 +29,10 @@ def _get_textbox(text, renderer):\n \n     The bbox position takes text rotation into account, but the width and\n     height are those of the unrotated box (unlike `.Text.get_window_extent`).\n-    \"\"\"\n-    # TODO : This function may move into the Text class as a method. As a\n-    # matter of fact, the information from the _get_textbox function\n+        # Initialize antialiased state per text object based on the rcParams default.\n+        import matplotlib as mpl\n+        self._antialiased = mpl.rcParams[\"text.antialias\"]\n+\n     # should be available during the Text._get_layout() call, which is\n     # called within the _get_textbox. So, it would better to move this\n     # function as a method with some refactoring of _get_layout method.\n@@ -57,16 +58,20 @@ def _get_textbox(text, renderer):\n     xt_box, yt_box = min(projected_xs), min(projected_ys)\n     w_box, h_box = max(projected_xs) - xt_box, max(projected_ys) - yt_box\n \n-    x_box, y_box = Affine2D().rotate(theta).transform((xt_box, yt_box))\n-\n-    return x_box, y_box, w_box, h_box\n+    def set_antialiased(self, b):\n+        \"\"\"\n+        Set whether this text object should be drawn with antialiased rendering.\n+        \"\"\"\n+        self._antialiased = bool(b)\n+        self.stale = True\n \n+    def get_antialiased(self):\n+        \"\"\"\n+        Get the antialiased state for this text object.\n+        \"\"\"\n+        import matplotlib as mpl\n+        return getattr(self, '_antialiased', mpl.rcParams[\"text.antialias\"])\n \n-def _get_text_metrics_with_cache(renderer, text, fontprop, ismath, dpi):\n-    \"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\n-    # Cached based on a copy of fontprop so that later in-place mutations of\n-    # the passed-in argument do not mess up the cache.\n-    return _get_text_metrics_with_cache_impl(\n         weakref.ref(renderer), text, fontprop.copy(), ismath, dpi)\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25960",
        "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex dab2bc4a5a..a1daf31a84 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2258,33 +2258,23 @@ class SubFigure(FigureBase):\n     def _get_renderer(self):\n         return self._parent._get_renderer()\n \n-    def _redo_transform_rel_fig(self, bbox=None):\n-        \"\"\"\n-        Make the transSubfigure bbox relative to Figure transform.\n+def _redo_transform_rel_fig(self, bbox=None):\n+    \"\"\"\n+    Make the transSubfigure bbox relative to Figure transform.\n \n-        Parameters\n-        ----------\n-        bbox : bbox or None\n-            If not None, then the bbox is used for relative bounding box.\n-            Otherwise, it is calculated from the subplotspec.\n-        \"\"\"\n-        if bbox is not None:\n-            self.bbox_relative.p0 = bbox.p0\n-            self.bbox_relative.p1 = bbox.p1\n-            return\n-        # need to figure out *where* this subplotspec is.\n-        gs = self._subplotspec.get_gridspec()\n-        wr = np.asarray(gs.get_width_ratios())\n-        hr = np.asarray(gs.get_height_ratios())\n-        dx = wr[self._subplotspec.colspan].sum() / wr.sum()\n-        dy = hr[self._subplotspec.rowspan].sum() / hr.sum()\n-        x0 = wr[:self._subplotspec.colspan.start].sum() / wr.sum()\n-        y0 = 1 - hr[:self._subplotspec.rowspan.stop].sum() / hr.sum()\n-        if self.bbox_relative is None:\n-            self.bbox_relative = Bbox.from_bounds(x0, y0, dx, dy)\n-        else:\n-            self.bbox_relative.p0 = (x0, y0)\n-            self.bbox_relative.p1 = (x0 + dx, y0 + dy)\n+    Parameters\n+    ----------\n+    bbox : bbox or None\n+        If not None, then the bbox is used for relative bounding box.\n+        Otherwise, it is calculated from the subplotspec.\n+    \"\"\"\n+    if bbox is None:\n+        bbox = self._subplotspec.get_position(self._parent)\n+    if self.bbox_relative is None:\n+        self.bbox_relative = bbox\n+    else:\n+        self.bbox_relative.p0 = bbox.p0\n+        self.bbox_relative.p1 = bbox.p1\n \n     def get_constrained_layout(self):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26113",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex 5369eadbde..522cb8508d 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -5013,11 +5013,13 @@ default: :rc:`scatter.edgecolors`\n                     Cs_at_i2[i2[i]].append(C[i])\n             if mincnt is None:\n                 mincnt = 0\n-            accum = np.array(\n-                [reduce_C_function(acc) if len(acc) > mincnt else np.nan\n-                 for Cs_at_i in [Cs_at_i1, Cs_at_i2]\n-                 for acc in Cs_at_i[1:]],  # [1:] drops out-of-range points.\n-                float)\n+                if mincnt is None:\n+                    mincnt = 0\n+                accum = np.array(\n+                    [reduce_C_function(acc) if len(acc) >= mincnt else np.nan\n+                     for Cs_at_i in [Cs_at_i1, Cs_at_i2]\n+                     for acc in Cs_at_i[1:]],  # [1:] drops out-of-range points.\n+                    float)\n \n         good_idxs = ~np.isnan(accum)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26208",
        "model_patch": "diff --git a/lib/matplotlib/stackplot.py b/lib/matplotlib/stackplot.py\nindex c97a21e029..aeb742b55c 100644\n--- a/lib/matplotlib/stackplot.py\n+++ b/lib/matplotlib/stackplot.py\n@@ -115,7 +115,8 @@ def stackplot(axes, x, *args,\n     coll = axes.fill_between(x, first_line, stack[0, :],\n                              facecolor=next(colors), label=next(labels, None),\n                              **kwargs)\n-    coll.sticky_edges.y[:] = [0]\n+    # coll.sticky_edges.y[:] = [0]\n+\n     r = [coll]\n \n     # Color between array i-1 and array i\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26291",
        "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 13af941552..e2dcc2d82f 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -394,8 +394,13 @@ class OffsetBox(martist.Artist):\n \n     def get_window_extent(self, renderer=None):\n         # docstring inherited\n-        if renderer is None:\n-            renderer = self.figure._get_renderer()\n+if renderer is None:\n+    if self.figure is None and hasattr(self, \"axes\") and self.axes is not None:\n+        self.set_figure(self.axes.figure)\n+    if self.figure is None:\n+        raise RuntimeError(\"OffsetBox has no associated figure; cannot get renderer\")\n+    renderer = self.figure._get_renderer()\n+\n         bbox = self.get_bbox(renderer)\n         try:  # Some subclasses redefine get_offset to take no args.\n             px, py = self.get_offset(bbox, renderer)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26342",
        "model_patch": "diff --git a/lib/matplotlib/collections.py b/lib/matplotlib/collections.py\nindex 7c0c3a68c0..6fde1eca28 100644\n--- a/lib/matplotlib/collections.py\n+++ b/lib/matplotlib/collections.py\n@@ -2087,9 +2087,13 @@ class _MeshData:\n         c_a = c[:-1, :-1]\n         c_b = c[:-1, 1:]\n         c_c = c[1:, 1:]\n-        c_d = c[1:, :-1]\n-        c_center = (c_a + c_b + c_c + c_d) / 4.0\n-        colors = np.concatenate([\n+def set_paths(self, paths=None):\n+    if paths is None:\n+        # Existing logic to compute paths\n+        self._paths = self._compute_paths()\n+    else:\n+        self._paths = paths\n+\n             c_a, c_b, c_center,\n             c_b, c_c, c_center,\n             c_c, c_d, c_center,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26466",
        "model_patch": "diff --git a/lib/matplotlib/text.py b/lib/matplotlib/text.py\nindex d4922fc517..764c8840e8 100644\n--- a/lib/matplotlib/text.py\n+++ b/lib/matplotlib/text.py\n@@ -1455,13 +1455,15 @@ class _AnnotationBase:\n                  xy,\n                  xycoords='data',\n                  annotation_clip=None):\n-\n-        self.xy = xy\n+        # Make a defensive, immutable copy of the xy coordinate,\n+        # so that subsequent modifications of the input array do not affect the annotation.\n+        self.xy = np.array(xy, copy=True)\n         self.xycoords = xycoords\n         self.set_annotation_clip(annotation_clip)\n \n         self._draggable = None\n \n+\n     def _get_xy(self, renderer, xy, coords):\n         x, y = xy\n         xcoord, ycoord = coords if isinstance(coords, tuple) else (coords, coords)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "mwaskom__seaborn-3069",
        "model_patch": "diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py\nindex 4f0290a4..d1c614dc 100644\n--- a/seaborn/_core/plot.py\n+++ b/seaborn/_core/plot.py\n@@ -1643,6 +1643,353 @@ class Plotter:\n                     if isinstance(b, str):\n                         hi = cast(float, hi) + 0.5\n                     ax.set(**{f\"{axis}lim\": (lo, hi)})\n+                    # If the axis limit is flagged as categorical (via string endpoints)\n+\n+\n+                    # then also force grid off and invert the y axis if applicable.\n+\n+\n+                    if isinstance(a, str):\n+\n+\n+                        ax.grid(False)\n+\n+\n+                        if axis == \"y\":\n+\n+\n+                            ax.invert_yaxis()\n+\n+\n \n         engine_default = None if p._target is not None else \"tight\"\n         layout_engine = p._layout_spec.get(\"engine\", engine_default)\ndiff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex bbd71ec1..e4b7c5d7 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -190,7 +190,10 @@ class Nominal(Scale):\n             # TODO Currently just used in non-Coordinate contexts, but should\n             # we use this to (A) set the padding we want for categorial plots\n             # and (B) allow the values parameter for a Coordinate to set xlim/ylim\n-            axis.set_view_interval(0, len(units_seed) - 1)\n+\t            # mark the interval as categorical by using string endpoints,\n+\t            # so that later the finalizer will apply \u00b10.5 adjustments etc.\n+\t            axis.set_view_interval(str(0), str(len(units_seed) - 1))\n+\n \n         new._matplotlib_scale = mpl_scale\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "mwaskom__seaborn-3187",
        "model_patch": "diff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex 55874bf2..31b6551e 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -374,12 +374,14 @@ class ContinuousBase(Scale):\n         # Could add a Scale parameter, or perhaps Scale.suppress()?\n         # Are there other useful parameters that would be in Scale.legend()\n         # besides allowing Scale.legend(False)?\n-        if prop.legend:\n-            axis.set_view_interval(vmin, vmax)\n-            locs = axis.major.locator()\n-            locs = locs[(vmin <= locs) & (locs <= vmax)]\n-            labels = axis.major.formatter.format_ticks(locs)\n-            new._legend = list(locs), list(labels)\n+if prop.legend:\n+    axis.set_view_interval(vmin, vmax)\n+    locs = axis.major.locator()\n+    locs = locs[(vmin <= locs) & (locs <= vmax)]\n+    axis.major.formatter.set_locs(locs)\n+    labels = axis.major.formatter.format_ticks(locs)\n+    new._legend = list(locs), list(labels)\n+\n \n         return new\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pallets__flask-5014",
        "model_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\nindex eb50585d..ee878eea 100644\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -7,10 +7,11 @@ from . import typing as ft\n from .scaffold import _endpoint_from_view_func\n from .scaffold import _sentinel\n from .scaffold import Scaffold\n-from .scaffold import setupmethod\n+def __init__(self, name, import_name, *args, **kwargs):\n+    if not name:\n+        raise ValueError(\"Blueprint name must not be empty\")\n+    self.name = name\n \n-if t.TYPE_CHECKING:  # pragma: no cover\n-    from .app import Flask\n \n DeferredSetupFunction = t.Callable[[\"BlueprintSetupState\"], t.Callable]\n T_after_request = t.TypeVar(\"T_after_request\", bound=ft.AfterRequestCallable)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-1142",
        "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 99260453..ba2b32d4 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -386,6 +386,10 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         self.body = body\n \n     def prepare_content_length(self, body):\n+        # Only set Content-Length if there is actually a body.\n+        if body is None:\n+            return\n+\n         self.headers['Content-Length'] = '0'\n         if hasattr(body, 'seek') and hasattr(body, 'tell'):\n             body.seek(0, 2)\n@@ -394,6 +398,7 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n         elif body is not None:\n             self.headers['Content-Length'] = str(len(body))\n \n+\n     def prepare_auth(self, auth):\n         \"\"\"Prepares the given HTTP auth data.\"\"\"\n         if auth:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-1724",
        "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex f82f56a3..d11af045 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -306,8 +306,10 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n     def prepare_method(self, method):\n         \"\"\"Prepares the given HTTP method.\"\"\"\n         self.method = method\n-        if self.method is not None:\n-            self.method = self.method.upper()\n+if self.method is not None:\n+    from .compat import to_native_string\n+    self.method = to_native_string(self.method.upper())\n+\n \n     def prepare_url(self, url, params):\n         \"\"\"Prepares the given HTTP URL.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-1766",
        "model_patch": "diff --git a/requests/auth.py b/requests/auth.py\nindex a3de123d..c8d3cf6e 100644\n--- a/requests/auth.py\n+++ b/requests/auth.py\n@@ -143,8 +143,9 @@ class HTTPDigestAuth(AuthBase):\n             base += ', algorithm=\"%s\"' % algorithm\n         if entdig:\n             base += ', digest=\"%s\"' % entdig\n-        if qop:\n-            base += ', qop=auth, nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n+\t        if qop:\n+\t            base += ', qop=\"auth\", nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n+\n \n         return 'Digest %s' % (base)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-1921",
        "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4ec..9a337a84 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -41,8 +41,10 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     if session_setting is None:\n         return request_setting\n \n-    if request_setting is None:\n-        return session_setting\n+if request_setting is None:\n+    # Filter out keys with a value of None from session_setting.\n+    return dict_class((k, v) for k, v in session_setting.items() if v is not None)\n+\n \n     # Bypass if not a dictionary (e.g. verify)\n     if not (\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-2317",
        "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex d701ff2e..b79456f2 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -425,7 +425,11 @@ class Session(SessionRedirectMixin):\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n-        method = builtin_str(method)\n+if isinstance(method, bytes):\n+    method = method.decode('ascii')\n+else:\n+    method = builtin_str(method)\n+\n \n         # Create the Request.\n         req = Request(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-2931",
        "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 9c624d3c..0f9b03ff 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -80,7 +80,9 @@ class RequestEncodingMixin(object):\n         if parameters are supplied as a dict.\n         \"\"\"\n \n-        if isinstance(data, (str, bytes)):\n+        if isinstance(data, bytes):\n+            return data\n+        elif isinstance(data, str):\n             return to_native_string(data)\n         elif hasattr(data, 'read'):\n             return data\n@@ -98,6 +100,7 @@ class RequestEncodingMixin(object):\n         else:\n             return data\n \n+\n     @staticmethod\n     def _encode_files(files, data):\n         \"\"\"Build the body for a multipart/form-data request.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-5414",
        "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex e7d292d5..62aecff5 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -403,8 +403,9 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n                 host = self._get_idna_encoded_host(host)\n             except UnicodeError:\n                 raise InvalidURL('URL has an invalid label.')\n-        elif host.startswith(u'*'):\n-            raise InvalidURL('URL has an invalid label.')\n+elif host.startswith(u'*') or host.startswith(u'.'):\n+    raise InvalidURL('URL has an invalid label.')\n+\n \n         # Carefully reconstruct the network location\n         netloc = auth or ''\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-6028",
        "model_patch": "diff --git a/requests/adapters.py b/requests/adapters.py\nindex fe22ff45..1c8e7864 100644\n--- a/requests/adapters.py\n+++ b/requests/adapters.py\n@@ -356,19 +356,25 @@ class HTTPAdapter(BaseAdapter):\n \n         return url\n \n-    def add_headers(self, request, **kwargs):\n-        \"\"\"Add any headers needed by the connection. As of v2.0 this does\n-        nothing by default, but is left for overriding by users that subclass\n-        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n-\n-        This should not be called from user code, and is only exposed for use\n-        when subclassing the\n-        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n+def add_headers(self, request, **kwargs):\n+    \"\"\"Add any headers needed by the connection.\n+    \n+    In Python 3.8.12 a change in http.client prevents the Proxy-Authorization header\n+    from being forwarded during the CONNECT (tunnel) phase. When using an HTTPS proxy,\n+    we must explicitly add it to the request headers.\n+    \n+    :param request: The PreparedRequest to add headers to.\n+    :param kwargs: The keyword arguments from the call to send(), expected to include 'proxies'.\n+    \"\"\"\n+    proxies = kwargs.get('proxies')\n+    if proxies:\n+        proxy = select_proxy(request.url, proxies)\n+        if proxy and request.url.lower().startswith('https'):\n+            if 'Proxy-Authorization' not in request.headers:\n+                username, password = get_auth_from_url(proxy)\n+                if username:\n+                    request.headers['Proxy-Authorization'] = _basic_auth_str(username, password)\n \n-        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n-        :param kwargs: The keyword arguments from the call to send().\n-        \"\"\"\n-        pass\n \n     def proxy_headers(self, proxy):\n         \"\"\"Returns a dictionary of the headers to add to any request sent\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-2905",
        "model_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..b44a4f32 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -217,8 +217,13 @@ def as_compatible_data(data, fastpath=False):\n     if isinstance(data, timedelta):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n-    # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+    # we don't want nested self-described arrays;\n+    # only unwrap objects with a \"values\" attribute if they come from one of the internal\n+    # array types (numpy, pandas, xarray, or dask).\n+    mod = getattr(type(data), \"__module__\", \"\")\n+    if mod.startswith(\"numpy\") or mod.startswith(\"pandas\") or mod.startswith(\"xarray\") or mod.startswith(\"dask\"):\n+        data = getattr(data, \"values\", data)\n+\n \n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3095",
        "model_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 379be8f5..8d130458 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1919,44 +1919,32 @@ class IndexVariable(Variable):\n \n     def copy(self, deep=True, data=None):\n         \"\"\"Returns a copy of this object.\n-\n+    \n         `deep` is ignored since data is stored in the form of\n         pandas.Index, which is already immutable. Dimensions, attributes\n         and encodings are always copied.\n-\n+    \n         Use `data` to create a new object with the same structure as\n         original but entirely new data.\n-\n-        Parameters\n-        ----------\n-        deep : bool, optional\n-            Deep is ignored when data is given. Whether the data array is\n-            loaded into memory and copied onto the new object. Default is True.\n-        data : array_like, optional\n-            Data to use in the new object. Must have same shape as original.\n-\n-        Returns\n-        -------\n-        object : Variable\n-            New object with dimensions, attributes, encodings, and optionally\n-            data copied from original.\n         \"\"\"\n         if data is None:\n             if deep:\n-                # self._data should be a `PandasIndexAdapter` instance at this\n-                # point, which doesn't have a copy method, so make a deep copy\n-                # of the underlying `pandas.MultiIndex` and create a new\n-                # `PandasIndexAdapter` instance with it.\n-                data = PandasIndexAdapter(self._data.array.copy(deep=True))\n+                # When the underlying dtype is Unicode (dtype.kind == 'U'),\n+                # the pandas.Index conversion will change it to object.\n+                # Copy the underlying numpy array directly so that the original\n+                # Unicode dtype is preserved.\n+                if self._data.dtype.kind == 'U':\n+                    new_values = self._data.array.values.copy()\n+                    data = PandasIndexAdapter(new_values, dtype=self._data.dtype)\n+                else:\n+                    data = PandasIndexAdapter(self._data.array.copy(deep=True))\n             else:\n                 data = self._data\n         else:\n             data = as_compatible_data(data)\n             if self.shape != data.shape:\n-                raise ValueError(\"Data shape {} must match shape of object {}\"\n-                                 .format(data.shape, self.shape))\n-        return type(self)(self.dims, data, self._attrs,\n-                          self._encoding, fastpath=True)\n+                raise ValueError(\"Data shape {} must match shape of object {}\".format(data.shape, self.shape))\n+        return type(self)(self.dims, data, self._attrs, self._encoding, fastpath=True)\n \n     def equals(self, other, equiv=None):\n         # if equiv is specified, super up\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3151",
        "model_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex 37ae903b..6e58cc00 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -500,17 +500,20 @@ def combine_by_coords(datasets, compat='no_conflicts', data_vars='all',\n                                    data_vars=data_vars, coords=coords,\n                                    fill_value=fill_value)\n \n-        # Check the overall coordinates are monotonically increasing\n+        # Check the overall coordinates are monotonically increasing,\n+        # but skip dimensions that did not vary across datasets (i.e. dims not used for concatenation).\n         for dim in concatenated.dims:\n-            if dim in concatenated:\n-                indexes = concatenated.indexes.get(dim)\n-                if not (indexes.is_monotonic_increasing\n-                        or indexes.is_monotonic_decreasing):\n-                    raise ValueError(\"Resulting object does not have monotonic\"\n-                                     \" global indexes along dimension {}\"\n-                                     .format(dim))\n+            # Only enforce monotonicity for dimensions used for concatenation.\n+            if dim not in concat_dims:\n+                continue\n+            indexes = concatenated.indexes.get(dim)\n+            if not (indexes.is_monotonic_increasing or indexes.is_monotonic_decreasing):\n+                raise ValueError(\"Resulting object does not have monotonic\"\n+                                 \" global indexes along dimension {}\"\n+                                 .format(dim))\n         concatenated_grouped_by_data_vars.append(concatenated)\n \n+\n     return merge(concatenated_grouped_by_data_vars, compat=compat,\n                  fill_value=fill_value)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3305",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 807badde..1c694f29 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -2872,10 +2872,14 @@ class DataArray(AbstractArray, DataWithCoords):\n         numpy.nanpercentile, pandas.Series.quantile, Dataset.quantile\n         \"\"\"\n \n-        ds = self._to_temp_dataset().quantile(\n-            q, dim=dim, keep_attrs=keep_attrs, interpolation=interpolation\n-        )\n-        return self._from_temp_dataset(ds)\n+\t        ds = self._to_temp_dataset().quantile(\n+\t            q, dim=dim, keep_attrs=keep_attrs, interpolation=interpolation\n+\t        )\n+\t        new_da = self._from_temp_dataset(ds)\n+\t        if keep_attrs:\n+\t            new_da.attrs = self.attrs\n+\t        return new_da\n+\n \n     def rank(\n         self, dim: Hashable, pct: bool = False, keep_attrs: bool = None\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3677",
        "model_patch": "diff --git a/xarray/core/merge.py b/xarray/core/merge.py\nindex 10c7804d..a8b6ce6e 100644\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -813,6 +813,211 @@ def dataset_merge_method(\n         overwrite_vars = set(overwrite_vars)\n     else:\n         overwrite_vars = {overwrite_vars}\n+    # If \"other\" is a DataArray, convert it to a Dataset so that it behaves as a dict\u2010like.\n+\n+\n+    from .dataarray import DataArray\n+\n+\n+    if isinstance(other, DataArray):\n+\n+\n+        other = other.to_dataset()\n+\n+\n \n     if not overwrite_vars:\n         objs = [dataset, other]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3993",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 2fef3edb..42992abb 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -3480,22 +3480,20 @@ class DataArray(AbstractArray, DataWithCoords):\n         ds = self._to_temp_dataset().differentiate(coord, edge_order, datetime_unit)\n         return self._from_temp_dataset(ds)\n \n-    def integrate(\n-        self, dim: Union[Hashable, Sequence[Hashable]], datetime_unit: str = None\n-    ) -> \"DataArray\":\n-        \"\"\" integrate the array with the trapezoidal rule.\n+    def integrate(self, coord: Union[Hashable, Sequence[Hashable]], datetime_unit: str = None) -> \"DataArray\":\n+        \"\"\"Integrate the array with the trapezoidal rule.\n \n         .. note::\n-            This feature is limited to simple cartesian geometry, i.e. dim\n+            This feature is limited to simple cartesian geometry, i.e. the coordinate\n             must be one dimensional.\n \n         Parameters\n         ----------\n-        dim : hashable, or sequence of hashable\n+        coord : hashable, or sequence of hashable\n             Coordinate(s) used for the integration.\n-        datetime_unit : {\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \\\n+        datetime_unit : {\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\",\n                          \"ps\", \"fs\", \"as\"}, optional\n-            Can be used to specify the unit if datetime coordinate is used.\n+            Can be used to specify the unit if a datetime coordinate is used.\n \n         Returns\n         -------\n@@ -3507,7 +3505,6 @@ class DataArray(AbstractArray, DataWithCoords):\n \n         Examples\n         --------\n-\n         >>> da = xr.DataArray(\n         ...     np.arange(12).reshape(4, 3),\n         ...     dims=[\"x\", \"y\"],\n@@ -3528,9 +3525,10 @@ class DataArray(AbstractArray, DataWithCoords):\n         array([5.4, 6.6, 7.8])\n         Dimensions without coordinates: y\n         \"\"\"\n-        ds = self._to_temp_dataset().integrate(dim, datetime_unit)\n+        ds = self._to_temp_dataset().integrate(coord, datetime_unit)\n         return self._from_temp_dataset(ds)\n \n+\n     def unify_chunks(self) -> \"DataArray\":\n         \"\"\"Unify chunk size along all chunked dimensions of this DataArray.\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4075",
        "model_patch": "diff --git a/xarray/core/weighted.py b/xarray/core/weighted.py\nindex 996d2e4c..6f7a67bd 100644\n--- a/xarray/core/weighted.py\n+++ b/xarray/core/weighted.py\n@@ -142,7 +142,8 @@ class Weighted:\n         # we need to mask data values that are nan; else the weights are wrong\n         mask = da.notnull()\n \n-        sum_of_weights = self._reduce(mask, self.weights, dim=dim, skipna=False)\n+            sum_of_weights = self._reduce(mask, self.weights * 1, dim=dim, skipna=False)\n+\n \n         # 0-weights are not valid\n         valid_weights = sum_of_weights != 0.0\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4094",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex a024324b..59e4f114 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3452,21 +3452,22 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n                 )\n \n         def ensure_stackable(val):\n-            assign_coords = {variable_dim: val.name}\n-            for dim in stacking_dims:\n-                if dim not in val.dims:\n-                    assign_coords[dim] = None\n-\n-            expand_dims = set(stacking_dims).difference(set(val.dims))\n-            expand_dims.add(variable_dim)\n-            # must be list for .expand_dims\n-            expand_dims = list(expand_dims)\n-\n-            return (\n-                val.assign_coords(**assign_coords)\n-                .expand_dims(expand_dims)\n-                .stack({new_dim: (variable_dim,) + stacking_dims})\n-            )\n+    # Only assign the variable coordinate.\n+    assign_coords = {variable_dim: val.name}\n+    # If the variable already contains a stacking coordinate, assign it.\n+    for dim in stacking_dims:\n+        if dim in val.dims:\n+            assign_coords[dim] = val.coords[dim]\n+    expand_dims = set(stacking_dims).difference(set(val.dims))\n+    expand_dims.add(variable_dim)\n+    # must be list for .expand_dims\n+    expand_dims = list(expand_dims)\n+    return (\n+        val.assign_coords(**assign_coords)\n+        .expand_dims(expand_dims)\n+        .stack({new_dim: (variable_dim,) + stacking_dims})\n+    )\n+\n \n         # concatenate the arrays\n         stackable_vars = [ensure_stackable(self[key]) for key in self.data_vars]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4356",
        "model_patch": "diff --git a/xarray/core/nanops.py b/xarray/core/nanops.py\nindex 41c8d258..ac15c181 100644\n--- a/xarray/core/nanops.py\n+++ b/xarray/core/nanops.py\n@@ -26,23 +26,28 @@ def _maybe_null_out(result, axis, mask, min_count=1):\n     \"\"\"\n     xarray version of pandas.core.nanops._maybe_null_out\n     \"\"\"\n-    if hasattr(axis, \"__len__\"):  # if tuple or list\n-        raise ValueError(\n-            \"min_count is not available for reduction with more than one dimensions.\"\n-        )\n+\n \n     if axis is not None and getattr(result, \"ndim\", False):\n-        null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0\n+        # Compute total number of elements reduced over.\n+        if isinstance(axis, (tuple, list)):\n+            total = np.prod(np.take(mask.shape, axis))\n+        else:\n+            total = mask.shape[axis]\n+        \n+        valid_count = total - mask.sum(axis=axis)\n+        null_mask = valid_count < min_count\n         if null_mask.any():\n             dtype, fill_value = dtypes.maybe_promote(result.dtype)\n             result = result.astype(dtype)\n             result[null_mask] = fill_value\n \n     elif getattr(result, \"dtype\", None) not in dtypes.NAT_TYPES:\n-        null_mask = mask.size - mask.sum()\n-        if null_mask < min_count:\n+        null_count = mask.size - mask.sum()\n+        if null_count < min_count:\n             result = np.nan\n \n+\n     return result\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4629",
        "model_patch": "diff --git a/xarray/core/merge.py b/xarray/core/merge.py\nindex ca4e29b6..75b5bbee 100644\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -501,7 +501,8 @@ def merge_attrs(variable_attrs, combine_attrs):\n     if combine_attrs == \"drop\":\n         return {}\n     elif combine_attrs == \"override\":\n-        return variable_attrs[0]\n+        return dict(variable_attrs[0])\n+\n     elif combine_attrs == \"no_conflicts\":\n         result = dict(variable_attrs[0])\n         for attrs in variable_attrs[1:]:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4687",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 7f29d3b6..9a2ec392 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -247,11 +247,12 @@ class DataArray(AbstractArray, DataWithCoords, DataArrayArithmetic):\n     data : array_like\n         Values for this array. Must be an ``numpy.ndarray``, ndarray\n         like, or castable to an ``ndarray``. If a self-described xarray\n-        or pandas object, attempts are made to use this array's\n-        metadata to fill in other unspecified arguments. A view of the\n-        array's data is used instead of a copy if possible.\n-    coords : sequence or dict of array_like, optional\n-        Coordinates (tick labels) to use for indexing along each\n+        result = apply_ufunc(np.where, cond, self, other,\n+                             dask=\"allowed\",\n+                             keep_attrs=True,\n+                             output_dtypes=[self.dtype],\n+                             kwargs={\"drop\": drop})\n+\n         dimension. The following notations are accepted:\n \n         - mapping {dimension name: array-like}\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4695",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 32b24ef1..1ab9f864 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -191,12 +191,13 @@ class _LocIndexer:\n     def __init__(self, data_array: \"DataArray\"):\n         self.data_array = data_array\n \n-    def __getitem__(self, key) -> \"DataArray\":\n-        if not utils.is_dict_like(key):\n-            # expand the indexer so we can handle Ellipsis\n-            labels = indexing.expanded_indexer(key, self.data_array.ndim)\n-            key = dict(zip(self.data_array.dims, labels))\n-        return self.data_array.sel(**key)\n+def __getitem__(self, key) -> \"DataArray\":\n+    if not utils.is_dict_like(key):\n+        # expand the indexer so we can handle Ellipsis\n+        labels = indexing.expanded_indexer(key, self.data_array.ndim)\n+        key = dict(zip(self.data_array.dims, labels))\n+    return self.data_array.sel(indexers=key)\n+\n \n     def __setitem__(self, key, value) -> None:\n         if not utils.is_dict_like(key):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4966",
        "model_patch": "diff --git a/xarray/coding/variables.py b/xarray/coding/variables.py\nindex b035ff82..37a7b6bc 100644\n--- a/xarray/coding/variables.py\n+++ b/xarray/coding/variables.py\n@@ -307,7 +307,6 @@ class UnsignedIntegerCoder(VariableCoder):\n \n         if \"_Unsigned\" in attrs:\n             unsigned = pop_to(attrs, encoding, \"_Unsigned\")\n-\n             if data.dtype.kind == \"i\":\n                 if unsigned == \"true\":\n                     unsigned_dtype = np.dtype(\"u%s\" % data.dtype.itemsize)\n@@ -316,12 +315,28 @@ class UnsignedIntegerCoder(VariableCoder):\n                     if \"_FillValue\" in attrs:\n                         new_fill = unsigned_dtype.type(attrs[\"_FillValue\"])\n                         attrs[\"_FillValue\"] = new_fill\n+            elif data.dtype.kind == \"u\":\n+                if unsigned == \"false\":\n+                    signed_dtype = np.dtype(\"i%s\" % data.dtype.itemsize)\n+                    transform = partial(np.asarray, dtype=signed_dtype)\n+                    data = lazy_elemwise_func(data, transform, signed_dtype)\n+                    if \"_FillValue\" in attrs:\n+                        new_fill = signed_dtype.type(attrs[\"_FillValue\"])\n+                        attrs[\"_FillValue\"] = new_fill\n+                else:\n+                    warnings.warn(\n+                        \"variable %r has _Unsigned attribute but unexpected value %r. Ignoring attribute.\"\n+                        % (name, unsigned),\n+                        SerializationWarning,\n+                        stacklevel=3,\n+                    )\n             else:\n                 warnings.warn(\n-                    \"variable %r has _Unsigned attribute but is not \"\n-                    \"of integer type. Ignoring attribute.\" % name,\n+                    \"variable %r has _Unsigned attribute but is not of integer type. Ignoring attribute.\" % name,\n                     SerializationWarning,\n                     stacklevel=3,\n                 )\n \n+                )\n+\n         return Variable(dims, data, attrs, encoding)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6461",
        "model_patch": "diff --git a/xarray/core/computation.py b/xarray/core/computation.py\nindex 7676d8e5..d0d89b2f 100644\n--- a/xarray/core/computation.py\n+++ b/xarray/core/computation.py\n@@ -1806,12 +1806,11 @@ def where(cond, x, y, keep_attrs=None):\n            [-1. , -1. , -1. ],\n            [-1. , -1. , -1. ]])\n     Coordinates:\n-      * lat      (lat) int64 0 1 2\n-      * lon      (lon) int64 10 11 12\n+    if keep_attrs is True:\n+        # keep the attributes of x, the second parameter, by default to\n+        # be consistent with the `where` method of `DataArray` and `Dataset`\n+        keep_attrs = lambda attrs, context: attrs[1] if len(attrs) > 1 else {}\n \n-    >>> cond = xr.DataArray([True, False], dims=[\"x\"])\n-    >>> x = xr.DataArray([1, 2], dims=[\"y\"])\n-    >>> xr.where(cond, x, 0)\n     <xarray.DataArray (x: 2, y: 2)>\n     array([[1, 2],\n            [0, 0]])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6599",
        "model_patch": "diff --git a/xarray/core/computation.py b/xarray/core/computation.py\nindex 823cbe02..12363247 100644\n--- a/xarray/core/computation.py\n+++ b/xarray/core/computation.py\n@@ -1932,16 +1932,20 @@ def _ensure_numeric(data: T_Xarray) -> T_Xarray:\n     \"\"\"\n     from .dataset import Dataset\n \n-    def to_floatable(x: DataArray) -> DataArray:\n-        if x.dtype.kind in \"mM\":\n-            return x.copy(\n-                data=datetime_to_numeric(\n-                    x.data,\n-                    offset=np.datetime64(\"1970-01-01\"),\n-                    datetime_unit=\"ns\",\n-                ),\n-            )\n-        return x\n+def to_floatable(x: DataArray) -> DataArray:\n+    if x.dtype.kind == \"M\":\n+        return x.copy(\n+            data=datetime_to_numeric(\n+                x.data,\n+                offset=np.datetime64(\"1970-01-01\"),\n+                datetime_unit=\"ns\",\n+            ),\n+        )\n+    elif x.dtype.kind == \"m\":\n+        # For timedelta64 values, convert directly to seconds.\n+        return x.copy(data=(x.data / np.timedelta64(1, \"s\")).astype(\"float64\"))\n+    return x\n+\n \n     if isinstance(data, Dataset):\n         return data.map(to_floatable)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6721",
        "model_patch": "diff --git a/xarray/backends/zarr.py b/xarray/backends/zarr.py\nindex a73483b4..0271dbf4 100644\n--- a/xarray/backends/zarr.py\n+++ b/xarray/backends/zarr.py\n@@ -66,6 +66,178 @@ class ZarrArrayWrapper(BackendArray):\n \n         dtype = array.dtype\n         self.dtype = dtype\n+    @property\n+\n+\n+    def chunks(self):\n+\n+\n+        \"\"\"Return the chunk metadata from the underlying zarr array without loading data.\"\"\"\n+\n+\n+        return self.get_array().chunks\n+\n+\n \n     def get_array(self):\n         return self.datastore.zarr_group[self.variable_name]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6744",
        "model_patch": "diff --git a/xarray/core/rolling.py b/xarray/core/rolling.py\nindex aef290f6..a21420c0 100644\n--- a/xarray/core/rolling.py\n+++ b/xarray/core/rolling.py\n@@ -267,18 +267,33 @@ class DataArrayRolling(Rolling[\"DataArray\"]):\n         # TODO legacy attribute\n         self.window_labels = self.obj[self.dim[0]]\n \n-    def __iter__(self) -> Iterator[tuple[RollingKey, DataArray]]:\n-        if self.ndim > 1:\n-            raise ValueError(\"__iter__ is only supported for 1d-rolling\")\n+def __iter__(self) -> Iterator[tuple[RollingKey, DataArray]]:\n+    if self.ndim > 1:\n+        raise ValueError(\"__iter__ is only supported for 1d-rolling\")\n+    if self.center[0]:\n+        offset = self.window[0] // 2\n+        for i, label in enumerate(self.window_labels):\n+            start = i - offset\n+            stop = start + self.window[0]\n+            # Clamp indices for start < 0 or stop > length\n+            if start < 0:\n+                start = 0\n+                stop = self.window[0]\n+            elif stop > len(self.window_labels):\n+                stop = len(self.window_labels)\n+                start = stop - self.window[0]\n+            window = self.obj.isel({self.dim[0]: slice(start, stop)})\n+            counts = window.count(dim=self.dim[0])\n+            window = window.where(counts >= self.min_periods)\n+            yield (label, window)\n+    else:\n         stops = np.arange(1, len(self.window_labels) + 1)\n         starts = stops - int(self.window[0])\n         starts[: int(self.window[0])] = 0\n-        for (label, start, stop) in zip(self.window_labels, starts, stops):\n+        for label, start, stop in zip(self.window_labels, starts, stops):\n             window = self.obj.isel({self.dim[0]: slice(start, stop)})\n-\n             counts = window.count(dim=self.dim[0])\n             window = window.where(counts >= self.min_periods)\n-\n             yield (label, window)\n \n     def construct(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6938",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex c775d05c..d177600f 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -3760,7 +3760,8 @@ class Dataset(\n                 raise ValueError(\n                     f\"replacement dimension {v!r} is not a 1D \"\n                     f\"variable along the old dimension {k!r}\"\n-                )\n+            var = v.to_index_variable().copy()\n+\n \n         result_dims = {dims_dict.get(dim, dim) for dim in self.dims}\n \n@@ -3768,7 +3769,8 @@ class Dataset(\n         coord_names.update({dim for dim in dims_dict.values() if dim in self.variables})\n \n         variables: dict[Hashable, Variable] = {}\n-        indexes: dict[Hashable, Index] = {}\n+            var = v.to_base_variable().copy()\n+\n         for k, v in self.variables.items():\n             dims = tuple(dims_dict.get(dim, dim) for dim in v.dims)\n             if k in result_dims:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6992",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 620f32f8..ac7ee3af 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -359,9 +359,9 @@ class DataVariables(Mapping[Any, \"DataArray\"]):\n \n     def __iter__(self) -> Iterator[Hashable]:\n         return (\n-            key\n-            for key in self._dataset._variables\n-            if key not in self._dataset._coord_names\n+    def __len__(self) -> int:\n+        return sum(1 for key in self._dataset._variables if key not in self._dataset._coord_names)\n+\n         )\n \n     def __len__(self) -> int:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-7229",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 72b41fb7..13b6401d 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -397,14 +397,17 @@ class DataArray(\n \n             # try to fill in arguments from data if they weren't supplied\n             if coords is None:\n+def where(self, cond, other=dtypes.NA, keep_attrs=False):\n+    new_variable = ops.where(cond, self.variable, other)\n+    result = self._replace(variable=new_variable)\n+    if keep_attrs:\n+        result.attrs = self.attrs\n+        # restore coordinate attributes to avoid having variable attrs override them\n+        for coord_name, coord in self.coords.items():\n+            if coord_name in result.coords:\n+                result.coords[coord_name].attrs = coord.attrs.copy()\n+    return result\n \n-                if isinstance(data, DataArray):\n-                    coords = data.coords\n-                elif isinstance(data, pd.Series):\n-                    coords = [data.index]\n-                elif isinstance(data, pd.DataFrame):\n-                    coords = [data.index, data.columns]\n-                elif isinstance(data, (pd.Index, IndexVariable)):\n                     coords = [data]\n \n             if dims is None:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-7233",
        "model_patch": "diff --git a/xarray/core/rolling.py b/xarray/core/rolling.py\nindex c194ec08..b6370564 100644\n--- a/xarray/core/rolling.py\n+++ b/xarray/core/rolling.py\n@@ -973,8 +973,9 @@ class Coarsen(CoarsenArithmetic, Generic[T_Xarray]):\n             else:\n                 reshaped[key] = var\n \n-        should_be_coords = set(window_dim) & set(self.obj.coords)\n-        result = reshaped.set_coords(should_be_coords)\n+should_be_coords = set(self.obj.coords)\n+result = reshaped.set_coords(should_be_coords)\n+\n         if isinstance(self.obj, DataArray):\n             return self.obj._from_temp_dataset(result)\n         else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-7393",
        "model_patch": "diff --git a/xarray/core/indexes.py b/xarray/core/indexes.py\nindex f3f03c94..eeace88f 100644\n--- a/xarray/core/indexes.py\n+++ b/xarray/core/indexes.py\n@@ -296,13 +296,18 @@ class PandasIndex(Index):\n         if index.name is None:\n             index.name = dim\n \n-        self.index = index\n-        self.dim = dim\n-\n         if coord_dtype is None:\n             coord_dtype = get_valid_numpy_dtype(index)\n+        # Cast index to the desired coordinate dtype if necessary.\n+        desired_dtype = np.dtype(coord_dtype)\n+        if index.dtype != desired_dtype:\n+            index = index.astype(desired_dtype)\n+\n+        self.index = index\n+        self.dim = dim\n         self.coord_dtype = coord_dtype\n \n+\n     def _replace(self, index, dim=None, coord_dtype=None):\n         if dim is None:\n             dim = self.dim\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-4551",
        "model_patch": "diff --git a/pylint/checkers/classes.py b/pylint/checkers/classes.py\nindex 4d86a6bbb..14b570d1a 100644\n--- a/pylint/checkers/classes.py\n+++ b/pylint/checkers/classes.py\n@@ -1227,7 +1227,8 @@ a metaclass class method.\",\n                 annotations = chain(\n                     (arguments.posonlyargs_annotations or []), arguments.annotations\n                 )\n-                return [ann.as_string() for ann in annotations if ann is not None]\n+return [ann.as_string() for ann in annotations]\n+\n \n             called_annotations = form_annotations(function.args)\n             overridden_annotations = form_annotations(meth_node.args)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-4604",
        "model_patch": "diff --git a/pylint/checkers/imports.py b/pylint/checkers/imports.py\nindex ceadaef90..d06ba326b 100644\n--- a/pylint/checkers/imports.py\n+++ b/pylint/checkers/imports.py\n@@ -636,11 +636,1332 @@ class ImportsChecker(DeprecatedMixin, BaseChecker):\n     ) = (\n         visit_assignattr\n     ) = (\n-        visit_assign\n-    ) = (\n+        # NOTE: Previously visit_assign was set to compute_first_non_import_node,\n+        # but that did not process type comments. We now override visit_assign\n+        # with a dedicated method below.\n         visit_ifexp\n     ) = visit_comprehension = visit_expr = visit_if = compute_first_non_import_node\n \n+    def visit_assign(self, node):\n+\n+\n+        \"\"\"Process an assignment node. In addition to the standard\n+\n+\n+        tracking of the first non import node, also scan any type comment for\n+\n+\n+        module names so that their import usage is registered.\n+\n+\n+        \"\"\"\n+\n+\n+        # Retain the original behavior for marking first non-import usage.\n+\n+\n+        self.compute_first_non_import_node(node)\n+\n+\n+        # Process any type comment attached to this assignment.\n+\n+\n+        self._process_type_comment(node)\n+\n+\n+\n+\n+    def _process_type_comment(self, node):\n+\n+\n+        \"\"\"If the assignment node has a type comment, attempt to extract any\n+\n+\n+        qualified module names (e.g. 'abc.ABC') and record the top-level module\n+\n+\n+        (e.g. 'abc') as used.\n+\n+\n+        \"\"\"\n+\n+\n+        type_comment = getattr(node, 'type_comment', None)\n+\n+\n+        if not type_comment:\n+\n+\n+            return\n+\n+\n+\n+\n+        # Use a simple regex to capture qualified type names of the form \"mod.Class\".\n+\n+\n+        # This is a minimal approach; for better precision one could use the ast\n+\n+\n+        # module to parse the type comment.\n+\n+\n+        import re\n+\n+\n+        pattern = re.compile(r\"\\b([a-zA-Z_][a-zA-Z0-9_]*)\\.[a-zA-Z_][a-zA-Z0-9_]*\\b\")\n+\n+\n+        for match in pattern.finditer(type_comment):\n+\n+\n+            modname = match.group(1)\n+\n+\n+            self._add_imported_module(node, modname)\n+\n+\n+\n     def visit_functiondef(self, node):\n         if not self.linter.is_message_enabled(\"wrong-import-position\", node.fromlineno):\n             return\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-4661",
        "model_patch": "diff --git a/pylint/utils/file_state.py b/pylint/utils/file_state.py\nindex 7209fe061..e7024ad86 100644\n--- a/pylint/utils/file_state.py\n+++ b/pylint/utils/file_state.py\n@@ -39,9 +39,10 @@ class FileState:\n         last = node.tolineno\n         # first child line number used to distinguish between disable\n         # which are the first child of scoped node with those defined later.\n-        # For instance in the code below:\n-        #\n-        # 1.   def meth8(self):\n+# Persistent directory for storing file state (XDG Base Directory compliant)\n+xdg_data_home = os.environ.get(\"XDG_DATA_HOME\", os.path.join(os.path.expanduser(\"~\"), \".local\", \"share\"))\n+PERSISTENT_DIR = os.path.join(xdg_data_home, \"pylint\")\n+\n         # 2.        \"\"\"test late disabling\"\"\"\n         # 3.        pylint: disable=not-callable\n         # 4.        print(self.blip)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-4970",
        "model_patch": "diff --git a/pylint/checkers/similar.py b/pylint/checkers/similar.py\nindex c65b1c893..a1d579491 100644\n--- a/pylint/checkers/similar.py\n+++ b/pylint/checkers/similar.py\n@@ -460,6 +460,142 @@ class Similar:\n \n     def _find_common(\n         self, lineset1: \"LineSet\", lineset2: \"LineSet\"\n+        # If min-similarity_lines is 0, then duplicate code checking is disabled.\n+\n+\n+        if self.min_lines == 0:\n+\n+\n+            return\n+\n+\n     ) -> Generator[Commonality, None, None]:\n         \"\"\"\n         Find similarities in the two given linesets.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-6386",
        "model_patch": "diff --git a/pylint/lint/base_options.py b/pylint/lint/base_options.py\nindex c793cc85a..0a807de32 100644\n--- a/pylint/lint/base_options.py\n+++ b/pylint/lint/base_options.py\n@@ -539,12 +539,13 @@ def _make_run_options(self: Run) -> Options:\n             \"verbose\",\n             {\n                 \"action\": _DoNothingAction,\n+                \"nargs\": 0,\n                 \"kwargs\": {},\n                 \"short\": \"v\",\n-                \"help\": \"In verbose mode, extra non-checker-related info \"\n-                \"will be displayed.\",\n+                \"help\": \"In verbose mode, extra non-checker-related info will be displayed.\",\n                 \"hide_from_config_file\": True,\n             },\n+\n         ),\n         (\n             \"enable-all-extensions\",\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-6528",
        "model_patch": "diff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\nindex b20cd873c..cef115fe2 100644\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -128,10 +128,9 @@ def expand_modules(\n             ):\n                 if filepath == subfilepath:\n                     continue\n-                if _is_in_ignore_list_re(\n-                    os.path.basename(subfilepath), ignore_list_re\n-                ) or _is_in_ignore_list_re(subfilepath, ignore_list_paths_re):\n-                    continue\n+                    if any(_is_in_ignore_list_re(part, ignore_list_re) for part in subfilepath.split(os.sep)) or _is_in_ignore_list_re(subfilepath, ignore_list_paths_re):\n+                        continue\n+\n \n                 modpath = _modpath_from_file(\n                     subfilepath, is_namespace, path=additional_search_path\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-6903",
        "model_patch": "diff --git a/pylint/lint/run.py b/pylint/lint/run.py\nindex a7e5d5574..b984067a8 100644\n--- a/pylint/lint/run.py\n+++ b/pylint/lint/run.py\n@@ -57,7 +57,8 @@ def _query_cpu() -> int | None:\n         with open(\"/sys/fs/cgroup/cpu/cpu.shares\", encoding=\"utf-8\") as file:\n             cpu_shares = int(file.read().rstrip())\n         # For AWS, gives correct value * 1024.\n-        avail_cpu = int(cpu_shares / 1024)\n+        avail_cpu = max(1, int(cpu_shares / 1024))\n+\n     return avail_cpu\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-7080",
        "model_patch": "diff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\nindex 5cacc0371..f7e2f22c2 100644\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -140,10 +140,13 @@ def expand_modules(\n             ):\n                 if filepath == subfilepath:\n                     continue\n-                if _is_in_ignore_list_re(\n-                    os.path.basename(subfilepath), ignore_list_re\n-                ) or _is_in_ignore_list_re(subfilepath, ignore_list_paths_re):\n-                    continue\n+                    # Normalize subfilepath to use forward slashes for ignore checks.\n+                    normalized_subfilepath = subfilepath.replace(os.sep, \"/\")\n+                    if _is_in_ignore_list_re(\n+                        os.path.basename(subfilepath), ignore_list_re\n+                    ) or _is_in_ignore_list_re(normalized_subfilepath, ignore_list_paths_re):\n+                        continue\n+\n \n                 modpath = _modpath_from_file(\n                     subfilepath, is_namespace, path=additional_search_path\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-7277",
        "model_patch": "diff --git a/pylint/__init__.py b/pylint/__init__.py\nindex 9f3dd74e6..34866d16d 100644\n--- a/pylint/__init__.py\n+++ b/pylint/__init__.py\n@@ -96,8 +96,9 @@ def modify_sys_path() -> None:\n       if pylint is installed in an editable configuration (as the last item).\n       https://github.com/PyCQA/pylint/issues/4161\n     \"\"\"\n+if sys.path and sys.path[0] in (\"\", \".\", os.getcwd()):\n     sys.path.pop(0)\n-    env_pythonpath = os.environ.get(\"PYTHONPATH\", \"\")\n+\n     cwd = os.getcwd()\n     if env_pythonpath.startswith(\":\") and env_pythonpath not in (f\":{cwd}\", \":.\"):\n         sys.path.pop(0)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-8898",
        "model_patch": "diff --git a/pylint/utils/utils.py b/pylint/utils/utils.py\nindex fa7f7b92f..1859439f3 100644\n--- a/pylint/utils/utils.py\n+++ b/pylint/utils/utils.py\n@@ -225,11 +225,32 @@ def _splitstrip(string: str, sep: str = \",\") -> list[str]:\n \n     :type sep: str or unicode\n     :param sep: field separator, default to the comma (',')\n-\n     :rtype: str or unicode\n     :return: the unquoted string (or the input string if it wasn't quoted)\n     \"\"\"\n-    return [word.strip() for word in string.split(sep) if word.strip()]\n+    tokens = []\n+    current = []\n+    stack = []\n+    pairs = {'(': ')', '[': ']', '{': '}'}\n+    for char in string:\n+        if char in pairs:\n+            stack.append(pairs[char])\n+            current.append(char)\n+        elif stack and char == stack[-1]:\n+            stack.pop()\n+            current.append(char)\n+        elif char == sep and not stack:\n+            token = ''.join(current).strip()\n+            if token:\n+                tokens.append(token)\n+            current = []\n+        else:\n+            current.append(char)\n+    token = ''.join(current).strip()\n+    if token:\n+        tokens.append(token)\n+    return tokens\n+\n \n \n def _unquote(string: str) -> str:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-10051",
        "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex a4f4214b1..dcd67d0e4 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -342,7 +342,8 @@ class LogCaptureHandler(logging_StreamHandler):\n         super().emit(record)\n \n     def reset(self) -> None:\n-        self.records = []\n+        self.records.clear()\n+\n         self.stream = StringIO()\n \n     def handleError(self, record: logging.LogRecord) -> None:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-10081",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 851e4943b..4c3149330 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -316,7 +316,8 @@ class TestCaseFunction(Function):\n             # Arguably we could always postpone tearDown(), but this changes the moment where the\n             # TestCase instance interacts with the results object, so better to only do it\n             # when absolutely needed.\n-            if self.config.getoption(\"usepdb\") and not _is_skipped(self.obj):\n+            if self.config.getoption(\"usepdb\"):\n+\n                 self._explicit_tearDown = self._testcase.tearDown\n                 setattr(self._testcase, \"tearDown\", lambda *args: None)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-10356",
        "model_patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\nindex 3db877506..ba2d428e5 100644\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -29,7 +29,24 @@ from typing import Union\n \n import attr\n \n-import _pytest\n+import itertools\n+\n+def merge_pytestmarks(obj):\n+    \"\"\"\n+    Return a merged list of pytest markers from obj and its base classes.\n+\n+    If obj is a type, iterate over its __mro__ and for each class add any\n+    markers stored in its _pytestmark attribute. Otherwise, fall back to\n+    calling get_unpacked_marks.\n+    \"\"\"\n+    markers = []\n+    if isinstance(obj, type):\n+        for cls in obj.__mro__:\n+            markers.extend(getattr(cls, \"_pytestmark\", []))\n+    else:\n+        markers = get_unpacked_marks(obj)\n+    return markers\n+\n from _pytest import fixtures\n from _pytest import nodes\n from _pytest._code import filter_traceback\n@@ -304,18 +321,21 @@ class PyobjMixin(nodes.Node):\n \n     @property\n     def obj(self):\n-        \"\"\"Underlying Python object.\"\"\"\n-        obj = getattr(self, \"_obj\", None)\n-        if obj is None:\n-            self._obj = obj = self._getobj()\n-            # XXX evil hack\n-            # used to avoid Function marker duplication\n-            if self._ALLOW_MARKERS:\n-                self.own_markers.extend(get_unpacked_marks(self.obj))\n-                # This assumes that `obj` is called before there is a chance\n-                # to add custom keys to `self.keywords`, so no fear of overriding.\n-                self.keywords.update((mark.name, mark) for mark in self.own_markers)\n-        return obj\n+@property\n+def obj(self):\n+    \"\"\"Underlying Python object.\"\"\"\n+    obj = getattr(self, \"_obj\", None)\n+    if obj is None:\n+        self._obj = obj = self._getobj()\n+        # XXX evil hack\n+        # used to avoid Function marker duplication.\n+        # Instead of using just `get_unpacked_marks` (which applies plain MRO)\n+        # we merge markers from all bases using our custom merge_pytestmarks.\n+        if self._ALLOW_MARKERS:\n+            self.own_markers.extend(merge_pytestmarks(self.obj))\n+            self.keywords.update((mark.name, mark) for mark in self.own_markers)\n+    return obj\n+\n \n     @obj.setter\n     def obj(self, value):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5262",
        "model_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\nindex 25eab7fdf..50f9c2893 100644\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -429,13 +429,16 @@ class EncodedFile(object):\n         self.buffer = buffer\n         self.encoding = encoding\n \n-    def write(self, obj):\n         if isinstance(obj, six.text_type):\n             obj = obj.encode(self.encoding, \"replace\")\n+        elif isinstance(obj, bytes):\n+            # Allow bytes to pass through when the underlying stream is in binary mode.\n+            pass\n         elif _PY3:\n             raise TypeError(\n-                \"write() argument must be str, not {}\".format(type(obj).__name__)\n+                \"write() argument must be str or bytes, not {}\".format(type(obj).__name__)\n             )\n+\n         self.buffer.write(obj)\n \n     def writelines(self, linelist):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5631",
        "model_patch": "diff --git a/src/_pytest/compat.py b/src/_pytest/compat.py\nindex d238061b4..71e9458c3 100644\n--- a/src/_pytest/compat.py\n+++ b/src/_pytest/compat.py\n@@ -67,9 +67,11 @@ def num_mock_patch_args(function):\n     mock_modules = [sys.modules.get(\"mock\"), sys.modules.get(\"unittest.mock\")]\n     if any(mock_modules):\n         sentinels = [m.DEFAULT for m in mock_modules if m is not None]\n-        return len(\n-            [p for p in patchings if not p.attribute_name and p.new in sentinels]\n-        )\n+    return len([\n+        p for p in patchings\n+        if not p.attribute_name and any(p.new is s for s in sentinels)\n+    ])\n+\n     return len(patchings)\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5787",
        "model_patch": "diff --git a/src/_pytest/reports.py b/src/_pytest/reports.py\nindex 4682d5b6e..d28cf06a2 100644\n--- a/src/_pytest/reports.py\n+++ b/src/_pytest/reports.py\n@@ -161,28 +161,38 @@ class BaseReport:\n         Experimental method.\n         \"\"\"\n \n-        def disassembled_report(rep):\n-            reprtraceback = rep.longrepr.reprtraceback.__dict__.copy()\n-            reprcrash = rep.longrepr.reprcrash.__dict__.copy()\n-\n-            new_entries = []\n-            for entry in reprtraceback[\"reprentries\"]:\n-                entry_data = {\n-                    \"type\": type(entry).__name__,\n-                    \"data\": entry.__dict__.copy(),\n-                }\n-                for key, value in entry_data[\"data\"].items():\n-                    if hasattr(value, \"__dict__\"):\n-                        entry_data[\"data\"][key] = value.__dict__.copy()\n-                new_entries.append(entry_data)\n-\n-            reprtraceback[\"reprentries\"] = new_entries\n-\n-            return {\n-                \"reprcrash\": reprcrash,\n-                \"reprtraceback\": reprtraceback,\n-                \"sections\": rep.longrepr.sections,\n-            }\n+def disassembled_report(rep):\n+    reprtraceback = rep.longrepr.reprtraceback.__dict__.copy()\n+    reprcrash = rep.longrepr.reprcrash.__dict__.copy()\n+    new_entries = []\n+    for entry in reprtraceback[\"reprentries\"]:\n+        entry_data = {\n+            \"type\": type(entry).__name__,\n+            \"data\": entry.__dict__.copy(),\n+        }\n+        for key, value in entry_data[\"data\"].items():\n+            if hasattr(value, \"__dict__\"):\n+                entry_data[\"data\"][key] = value.__dict__.copy()\n+        new_entries.append(entry_data)\n+    reprtraceback[\"reprentries\"] = new_entries\n+    result = {\n+        \"reprcrash\": reprcrash,\n+        \"reprtraceback\": reprtraceback,\n+        \"sections\": rep.longrepr.sections,\n+    }\n+    if hasattr(rep.longrepr, \"chain\"):\n+        chain_serialized = []\n+        for tb, crash, descr in rep.longrepr.chain:\n+            tb_ser = tb.__dict__.copy()\n+            crash_ser = crash.__dict__.copy() if crash is not None and hasattr(crash, \"__dict__\") else crash\n+            chain_serialized.append({\n+                \"reprtraceback\": tb_ser,\n+                \"reprcrash\": crash_ser,\n+                \"descr\": descr,\n+            })\n+        result[\"chain\"] = chain_serialized\n+    return result\n+\n \n         d = self.__dict__.copy()\n         if hasattr(self.longrepr, \"toterminal\"):\n@@ -202,64 +212,58 @@ class BaseReport:\n         return d\n \n     @classmethod\n-    def _from_json(cls, reportdict):\n-        \"\"\"\n-        This was originally the serialize_report() function from xdist (ca03269).\n-\n-        Factory method that returns either a TestReport or CollectReport, depending on the calling\n-        class. It's the callers responsibility to know which class to pass here.\n-\n-        Experimental method.\n-        \"\"\"\n-        if reportdict[\"longrepr\"]:\n-            if (\n-                \"reprcrash\" in reportdict[\"longrepr\"]\n-                and \"reprtraceback\" in reportdict[\"longrepr\"]\n-            ):\n-\n-                reprtraceback = reportdict[\"longrepr\"][\"reprtraceback\"]\n-                reprcrash = reportdict[\"longrepr\"][\"reprcrash\"]\n-\n-                unserialized_entries = []\n-                reprentry = None\n-                for entry_data in reprtraceback[\"reprentries\"]:\n-                    data = entry_data[\"data\"]\n-                    entry_type = entry_data[\"type\"]\n-                    if entry_type == \"ReprEntry\":\n-                        reprfuncargs = None\n-                        reprfileloc = None\n-                        reprlocals = None\n-                        if data[\"reprfuncargs\"]:\n-                            reprfuncargs = ReprFuncArgs(**data[\"reprfuncargs\"])\n-                        if data[\"reprfileloc\"]:\n-                            reprfileloc = ReprFileLocation(**data[\"reprfileloc\"])\n-                        if data[\"reprlocals\"]:\n-                            reprlocals = ReprLocals(data[\"reprlocals\"][\"lines\"])\n-\n-                        reprentry = ReprEntry(\n-                            lines=data[\"lines\"],\n-                            reprfuncargs=reprfuncargs,\n-                            reprlocals=reprlocals,\n-                            filelocrepr=reprfileloc,\n-                            style=data[\"style\"],\n-                        )\n-                    elif entry_type == \"ReprEntryNative\":\n-                        reprentry = ReprEntryNative(data[\"lines\"])\n-                    else:\n-                        _report_unserialization_failure(entry_type, cls, reportdict)\n-                    unserialized_entries.append(reprentry)\n-                reprtraceback[\"reprentries\"] = unserialized_entries\n-\n+@classmethod\n+def _from_json(cls, reportdict):\n+    if reportdict[\"longrepr\"]:\n+        lr = reportdict[\"longrepr\"]\n+        if \"reprcrash\" in lr and \"reprtraceback\" in lr:\n+            reprtraceback = lr[\"reprtraceback\"]\n+            reprcrash = lr[\"reprcrash\"]\n+            unserialized_entries = []\n+            for entry_data in reprtraceback[\"reprentries\"]:\n+                data = entry_data[\"data\"]\n+                entry_type = entry_data[\"type\"]\n+                if entry_type == \"ReprEntry\":\n+                    reprfuncargs = None\n+                    reprfileloc = None\n+                    reprlocals = None\n+                    if data[\"reprfuncargs\"]:\n+                        reprfuncargs = ReprFuncArgs(**data[\"reprfuncargs\"])\n+                    if data[\"reprfileloc\"]:\n+                        reprfileloc = ReprFileLocation(**data[\"reprfileloc\"])\n+                    if data[\"reprlocals\"]:\n+                        reprlocals = ReprLocals(data[\"reprlocals\"][\"lines\"])\n+                    reprentry = ReprEntry(\n+                        lines=data[\"lines\"],\n+                        reprfuncargs=reprfuncargs,\n+                        reprlocals=reprlocals,\n+                        filelocrepr=reprfileloc,\n+                        style=data[\"style\"],\n+                    )\n+                elif entry_type == \"ReprEntryNative\":\n+                    reprentry = ReprEntryNative(data[\"lines\"])\n+                else:\n+                    _report_unserialization_failure(entry_type, cls, reportdict)\n+                unserialized_entries.append(reprentry)\n+            reprtraceback[\"reprentries\"] = unserialized_entries\n+            if \"chain\" in lr:\n+                chain = []\n+                for entry in lr[\"chain\"]:\n+                    tb = ReprTraceback(**entry[\"reprtraceback\"])\n+                    crash = ReprFileLocation(**entry[\"reprcrash\"])\n+                    descr = entry[\"descr\"]\n+                    chain.append((tb, crash, descr))\n+                exception_info = ExceptionChainRepr(chain)\n+            else:\n                 exception_info = ReprExceptionInfo(\n                     reprtraceback=ReprTraceback(**reprtraceback),\n                     reprcrash=ReprFileLocation(**reprcrash),\n                 )\n+            for section in lr[\"sections\"]:\n+                exception_info.addsection(*section)\n+            reportdict[\"longrepr\"] = exception_info\n+    return cls(**reportdict)\n \n-                for section in reportdict[\"longrepr\"][\"sections\"]:\n-                    exception_info.addsection(*section)\n-                reportdict[\"longrepr\"] = exception_info\n-\n-        return cls(**reportdict)\n \n \n def _report_unserialization_failure(type_name, report_class, reportdict):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5809",
        "model_patch": "diff --git a/src/_pytest/pastebin.py b/src/_pytest/pastebin.py\nindex 41576a615..7a5f2f448 100644\n--- a/src/_pytest/pastebin.py\n+++ b/src/_pytest/pastebin.py\n@@ -79,9 +79,10 @@ def create_new_paste(contents):\n \n     params = {\n         \"code\": contents,\n-        \"lexer\": \"python3\" if sys.version_info[0] >= 3 else \"python\",\n+        \"lexer\": \"text\",\n         \"expiry\": \"1week\",\n     }\n+\n     url = \"https://bpaste.net\"\n     response = urlopen(url, data=urlencode(params).encode(\"ascii\")).read()\n     m = re.search(r'href=\"/raw/(\\w+)\"', response.decode(\"utf-8\"))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5840",
        "model_patch": "diff --git a/src/_pytest/pathlib.py b/src/_pytest/pathlib.py\nindex 0403b6947..a3bf6f99b 100644\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -343,4 +343,8 @@ def unique_path(path):\n \n     This is needed only for ``py.path.local``; ``pathlib.Path`` handles this\n     natively with ``resolve()``.\"\"\"\n-    return type(path)(normcase(str(path.realpath())))\n+    if sys.platform.startswith(\"win\"):\n+        return type(path)(str(path.realpath()))\n+    else:\n+        return type(path)(normcase(str(path.realpath())))\n+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-6197",
        "model_patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\nindex 306e5f217..a0623365c 100644\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -177,9 +177,9 @@ def pytest_collect_file(path, parent):\n     ext = path.ext\n     if ext == \".py\":\n         if not parent.session.isinitpath(path):\n-            if not path_matches_patterns(\n-                path, parent.config.getini(\"python_files\") + [\"__init__.py\"]\n-            ):\n+            if not path_matches_patterns(path, parent.config.getini(\"python_files\")):\n+                return\n+\n                 return\n         ihook = parent.session.gethookproxy(path)\n         return ihook.pytest_pycollect_makemodule(path=path, parent=parent)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-6202",
        "model_patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\nindex b8b365ad3..14a9fb602 100644\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -285,8 +285,9 @@ class PyobjMixin(PyobjContext):\n                     break\n             parts.append(name)\n         parts.reverse()\n-        s = \".\".join(parts)\n-        return s.replace(\".[\", \"[\")\n+s = \".\".join(parts)\n+return s\n+\n \n     def reportinfo(self):\n         # XXX caching?\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7205",
        "model_patch": "diff --git a/src/_pytest/setuponly.py b/src/_pytest/setuponly.py\nindex c9cc589ff..ded9b3980 100644\n--- a/src/_pytest/setuponly.py\n+++ b/src/_pytest/setuponly.py\n@@ -1,4 +1,47 @@\n import pytest\n+from _pytest._io.saferepr import saferepr\n+\n+\n \n \n def pytest_addoption(parser):\n@@ -66,7 +109,8 @@ def _show_fixture_action(fixturedef, msg):\n             tw.write(\" (fixtures used: {})\".format(\", \".join(deps)))\n \n     if hasattr(fixturedef, \"cached_param\"):\n-        tw.write(\"[{}]\".format(fixturedef.cached_param))\n+        tw.write(\"[{}]\".format(saferepr(fixturedef.cached_param)))\n+\n \n     tw.flush()\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7236",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 773f545af..ec7bf257c 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -220,10 +220,11 @@ class TestCaseFunction(Function):\n             # arguably we could always postpone tearDown(), but this changes the moment where the\n             # TestCase instance interacts with the results object, so better to only do it\n             # when absolutely needed\n-            if self.config.getoption(\"usepdb\"):\n+            if self.config.getoption(\"usepdb\") and not getattr(self._testcase, \"__unittest_skip__\", False):\n                 self._explicit_tearDown = self._testcase.tearDown\n                 setattr(self._testcase, \"tearDown\", lambda *args: None)\n \n+\n             # we need to update the actual bound method with self.obj, because\n             # wrap_pytest_function_for_tracing replaces self.obj by a wrapper\n             setattr(self._testcase, self.name, self.obj)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7324",
        "model_patch": "diff --git a/src/_pytest/mark/expression.py b/src/_pytest/mark/expression.py\nindex 04c73411a..8c79670ae 100644\n--- a/src/_pytest/mark/expression.py\n+++ b/src/_pytest/mark/expression.py\n@@ -2,12 +2,15 @@ r\"\"\"\n Evaluate match expressions, as used by `-k` and `-m`.\n \n The grammar is:\n-\n-expression: expr? EOF\n-expr:       and_expr ('or' and_expr)*\n-and_expr:   not_expr ('and' not_expr)*\n-not_expr:   'not' not_expr | '(' expr ')' | ident\n-ident:      (\\w|:|\\+|-|\\.|\\[|\\])+\n+class TokenType:\n+    LPAREN = \"(\"\n+    RPAREN = \")\"\n+    IDENT = \"identifier\"\n+    OR = \"or\"\n+    AND = \"and\"\n+    NOT = \"not\"\n+    EOF = \"EOF\"\n+    CONSTANT = \"constant\"   # added to flag built-in constant tokens\n \n The semantics are:\n \n@@ -79,19 +82,26 @@ class Scanner:\n         self.current = next(self.tokens)\n \n     def lex(self, input: str) -> Iterator[Token]:\n-        pos = 0\n-        while pos < len(input):\n-            if input[pos] in (\" \", \"\\t\"):\n-                pos += 1\n-            elif input[pos] == \"(\":\n-                yield Token(TokenType.LPAREN, \"(\", pos)\n-                pos += 1\n-            elif input[pos] == \")\":\n-                yield Token(TokenType.RPAREN, \")\", pos)\n-                pos += 1\n             else:\n                 match = re.match(r\"(:?\\w|:|\\+|-|\\.|\\[|\\])+\", input[pos:])\n                 if match:\n+                    value = match.group(0)\n+                    if value == \"or\":\n+                        yield Token(TokenType.OR, value, pos)\n+                    elif value == \"and\":\n+                        yield Token(TokenType.AND, value, pos)\n+                    elif value == \"not\":\n+                        yield Token(TokenType.NOT, value, pos)\n+                    elif value in (\"False\", \"True\", \"None\"):\n+                        yield Token(TokenType.CONSTANT, value, pos)\n+                    else:\n+                        yield Token(TokenType.IDENT, value, pos)\n+                    pos += len(value)\n+                else:\n+                    raise ParseError(\n+                        pos + 1, 'unexpected character \"{}\"'.format(input[pos]),\n+                    )\n+\n                     value = match.group(0)\n                     if value == \"or\":\n                         yield Token(TokenType.OR, value, pos)\n@@ -137,13 +147,21 @@ def expression(s: Scanner) -> ast.Expression:\n \n \n def expr(s: Scanner) -> ast.expr:\n+    # If the current token is a reserved constant, return the corresponding AST literal.\n+    if s.current.type == TokenType.CONSTANT:\n+        token = s.accept(TokenType.CONSTANT)\n+        if token.value == \"False\":\n+            return ast.NameConstant(False)\n+        elif token.value == \"True\":\n+            return ast.NameConstant(True)\n+        elif token.value == \"None\":\n+            return ast.NameConstant(None)\n     ret = and_expr(s)\n     while s.accept(TokenType.OR):\n         rhs = and_expr(s)\n         ret = ast.BoolOp(ast.Or(), [ret, rhs])\n     return ret\n \n-\n def and_expr(s: Scanner) -> ast.expr:\n     ret = not_expr(s)\n     while s.accept(TokenType.AND):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7432",
        "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..1ac16f3e1 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -270,8 +270,11 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n         else:\n             rep.longrepr = \"Unexpected success\"\n         rep.outcome = \"failed\"\n-    elif item.config.option.runxfail:\n-        pass  # don't interfere\n+    # When --runxfail is enabled, only bypass further processing for non-marker (xfail) cases.\n+    # If the test was skipped by a marker then let the location-fixup be applied.\n+    elif item.config.option.runxfail and not (item._store.get(skipped_by_mark_key, True) and rep.skipped and isinstance(rep.longrepr, tuple)):\n+        pass  # don't interfere with xfail markers\n+\n     elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n         assert call.excinfo.value.msg is not None\n         rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n@@ -292,19 +295,15 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n     elif (\n-        item._store.get(skipped_by_mark_key, True)\n-        and rep.skipped\n-        and type(rep.longrepr) is tuple\n-    ):\n-        # skipped by mark.skipif; change the location of the failure\n-        # to point to the item definition, otherwise it will display\n-        # the location of where the skip exception was raised within pytest\n+    elif item._store.get(skipped_by_mark_key, True) and rep.skipped and isinstance(rep.longrepr, tuple):\n+        # Skipped by a skip/skipif marker; adjust the location to point to the test's definition.\n         _, _, reason = rep.longrepr\n         filename, line = item.reportinfo()[:2]\n         assert line is not None\n         rep.longrepr = str(filename), line + 1, reason\n \n \n+\n def pytest_report_teststatus(report: BaseReport) -> Optional[Tuple[str, str, str]]:\n     if hasattr(report, \"wasxfail\"):\n         if report.skipped:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7490",
        "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 560548aea..5de78d717 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -269,6 +269,48 @@ class Node(metaclass=NodeMeta):\n             if ``False`` insert at position ``0``.\n         \"\"\"\n         from _pytest.mark import MARK_GEN\n+from _pytest.skipping import xfailed_key\n+\n+\n \n         if isinstance(marker, MarkDecorator):\n             marker_ = marker\n@@ -281,6 +323,96 @@ class Node(metaclass=NodeMeta):\n             self.own_markers.append(marker_.mark)\n         else:\n             self.own_markers.insert(0, marker_.mark)\n+        if marker_.name == \"xfail\":\n+\n+\n+            self._store[xfailed_key] = marker_.mark\n+\n+\n \n     def iter_markers(self, name: Optional[str] = None) -> Iterator[Mark]:\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7521",
        "model_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\nindex 3f9c60fb9..43e87a750 100644\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -388,8 +388,10 @@ class FDCaptureBinary:\n                 TemporaryFile(buffering=0),  # type: ignore[arg-type]\n                 encoding=\"utf-8\",\n                 errors=\"replace\",\n+                newline=\"\",\n                 write_through=True,\n             )\n+\n             if targetfd in patchsysdict:\n                 self.syscapture = SysCapture(targetfd, self.tmpfile)\n             else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7571",
        "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex 11031f2f2..e20bfad9d 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -347,15 +347,18 @@ class LogCaptureFixture:\n         # dict of log name -> log level\n         self._initial_logger_levels = {}  # type: Dict[Optional[str], int]\n \n-    def _finalize(self) -> None:\n-        \"\"\"Finalizes the fixture.\n+def _finalize(self) -> None:\n+    \"\"\"Finalizes the fixture.\n \n-        This restores the log levels changed by :meth:`set_level`.\n-        \"\"\"\n-        # restore log levels\n-        for logger_name, level in self._initial_logger_levels.items():\n+    This restores the log levels changed by :meth:`set_level`.\n+    \"\"\"\n+    # restore log levels\n+    for logger_name, level in self._initial_logger_levels.items():\n+        if logger_name == \"\":\n+            logger = logging.getLogger()\n+        else:\n             logger = logging.getLogger(logger_name)\n-            logger.setLevel(level)\n+        logger.setLevel(level)\n \n     @property\n     def handler(self) -> LogCaptureHandler:\n@@ -419,22 +422,23 @@ class LogCaptureFixture:\n         \"\"\"Reset the list of log records and the captured log text.\"\"\"\n         self.handler.reset()\n \n-    def set_level(self, level: Union[int, str], logger: Optional[str] = None) -> None:\n-        \"\"\"Sets the level for capturing of logs. The level will be restored to its previous value at the end of\n-        the test.\n-\n-        :param int level: the logger to level.\n-        :param str logger: the logger to update the level. If not given, the root logger level is updated.\n+def set_level(self, level: Union[int, str], logger: Optional[str] = None) -> None:\n+    \"\"\"Sets the level for capturing of logs. The level will be restored to its previous value at the end of\n+    the test.\n \n-        .. versionchanged:: 3.4\n-            The levels of the loggers changed by this function will be restored to their initial values at the\n-            end of the test.\n-        \"\"\"\n+    :param int level: the logger level.\n+    :param str logger: the logger to update the level. If not given, the root logger level is updated.\n+    \"\"\"\n+    if logger is None:\n+        logger_obj = logging.getLogger()\n+        key = \"\"\n+    else:\n         logger_obj = logging.getLogger(logger)\n-        # save the original log-level to restore it during teardown\n-        self._initial_logger_levels.setdefault(logger, logger_obj.level)\n-        logger_obj.setLevel(level)\n-        self.handler.setLevel(level)\n+        key = logger\n+    # save the original log-level to restore it during teardown\n+    self._initial_logger_levels.setdefault(key, logger_obj.level)\n+    logger_obj.setLevel(level)\n+    self.handler.setLevel(level)\n \n     @contextmanager\n     def at_level(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7982",
        "model_patch": "diff --git a/src/_pytest/pathlib.py b/src/_pytest/pathlib.py\nindex f0bdb1481..ff6bed3d8 100644\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -558,7 +558,8 @@ def visit(\n     entries = sorted(os.scandir(path), key=lambda entry: entry.name)\n     yield from entries\n     for entry in entries:\n-        if entry.is_dir(follow_symlinks=False) and recurse(entry):\n+        if entry.is_dir() and recurse(entry):\n+\n             yield from visit(entry.path, recurse)\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-8399",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 719eb4e88..9dfc0c0f0 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -144,7 +144,8 @@ def _make_xunit_fixture(\n         scope=scope,\n         autouse=True,\n         # Use a unique name to speed up lookup.\n-        name=f\"unittest_{setup_name}_fixture_{obj.__qualname__}\",\n+            name=f\"_unittest_{setup_name}_fixture_{obj.__qualname__}\",\n+\n     )\n     def fixture(self, request: FixtureRequest) -> Generator[None, None, None]:\n         if _is_skipped(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-10297",
        "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..5147a9bb0 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1333,12 +1333,13 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n     def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n+                 normalize=False, scoring=None, cv=None, store_cv_values=False, class_weight=None):\n         super(RidgeClassifierCV, self).__init__(\n             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n+            scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n         self.class_weight = class_weight\n \n+\n     def fit(self, X, y, sample_weight=None):\n         \"\"\"Fit the ridge classifier.\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-10844",
        "model_patch": "diff --git a/sklearn/metrics/cluster/supervised.py b/sklearn/metrics/cluster/supervised.py\nindex a987778ae..74ae2a944 100644\n--- a/sklearn/metrics/cluster/supervised.py\n+++ b/sklearn/metrics/cluster/supervised.py\n@@ -856,7 +856,8 @@ def fowlkes_mallows_score(labels_true, labels_pred, sparse=False):\n     tk = np.dot(c.data, c.data) - n_samples\n     pk = np.sum(np.asarray(c.sum(axis=0)).ravel() ** 2) - n_samples\n     qk = np.sum(np.asarray(c.sum(axis=1)).ravel() ** 2) - n_samples\n-    return tk / np.sqrt(pk * qk) if tk != 0. else 0.\n+return np.sqrt(tk / pk) * np.sqrt(tk / qk) if tk != 0. else 0.\n+\n \n \n def entropy(labels):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-10908",
        "model_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex 9b1ebd632..071e62727 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -991,12 +991,13 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n         return [inverse_vocabulary[X[i, :].nonzero()[1]].ravel()\n                 for i in range(n_samples)]\n \n-    def get_feature_names(self):\n-        \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n-        self._check_vocabulary()\n+def get_feature_names(self):\n+    \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n+    if not hasattr(self, \"vocabulary_\"):\n+        self._validate_vocabulary()\n+    self._check_vocabulary()\n+    return [t for t, i in sorted(six.iteritems(self.vocabulary_), key=itemgetter(1))]\n \n-        return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n-                                     key=itemgetter(1))]\n \n \n def _make_int_array():\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-11310",
        "model_patch": "diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\nindex 99d6096af..bb1b9e778 100644\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -764,12 +764,14 @@ class BaseSearchCV(six.with_metaclass(ABCMeta, BaseEstimator,\n                 self.best_index_]\n \n         if self.refit:\n-            self.best_estimator_ = clone(base_estimator).set_params(\n-                **self.best_params_)\n+            self.best_estimator_ = clone(base_estimator).set_params(**self.best_params_)\n+            import time\n+            start_time = time.time()\n             if y is not None:\n                 self.best_estimator_.fit(X, y, **fit_params)\n             else:\n                 self.best_estimator_.fit(X, **fit_params)\n+            self.refit_time_ = time.time() - start_time\n \n         # Store the only scorer not as a dict for single metric evaluation\n         self.scorer_ = scorers if self.multimetric_ else scorers['score']\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-11578",
        "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex e4ea696ce..2a60105d2 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,8 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+log_reg = LogisticRegression(fit_intercept=fit_intercept, multi_class=multi_class)\n+\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-12585",
        "model_patch": "diff --git a/sklearn/base.py b/sklearn/base.py\nindex 56ffb18bf..d94855018 100644\n--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -48,7 +48,8 @@ def clone(estimator, safe=True):\n     # XXX: not handling dictionaries\n     if estimator_type in (list, tuple, set, frozenset):\n         return estimator_type([clone(e, safe=safe) for e in estimator])\n-    elif not hasattr(estimator, 'get_params'):\n+elif not hasattr(estimator, 'get_params') or isinstance(estimator, type):\n+\n         if not safe:\n             return copy.deepcopy(estimator)\n         else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-12682",
        "model_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex a318c957f..c9e5286b3 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -989,15 +989,18 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n     \"\"\"\n     _required_parameters = [\"dictionary\"]\n \n-    def __init__(self, dictionary, transform_algorithm='omp',\n-                 transform_n_nonzero_coefs=None, transform_alpha=None,\n-                 split_sign=False, n_jobs=None, positive_code=False):\n-        self._set_sparse_coding_params(dictionary.shape[0],\n-                                       transform_algorithm,\n-                                       transform_n_nonzero_coefs,\n-                                       transform_alpha, split_sign, n_jobs,\n-                                       positive_code)\n-        self.components_ = dictionary\n+def __init__(self, dictionary, transform_algorithm='omp',\n+             transform_n_nonzero_coefs=None, transform_alpha=None,\n+             split_sign=False, n_jobs=None, positive_code=False,\n+             transform_max_iter=1000):\n+    self._set_sparse_coding_params(dictionary.shape[0],\n+                                   transform_algorithm,\n+                                   transform_n_nonzero_coefs,\n+                                   transform_alpha, split_sign, n_jobs,\n+                                   positive_code)\n+    self.components_ = dictionary\n+    self.transform_max_iter = transform_max_iter\n+\n \n     def fit(self, X, y=None):\n         \"\"\"Do nothing and return the estimator unchanged\n@@ -1016,6 +1019,1226 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n         self : object\n             Returns the object itself\n         \"\"\"\n+def transform(self, X):\n+\n+\n+    \"\"\"Encode the data as a sparse combination of the dictionary atoms.\n+\n+\n+    \n+\n+\n+    Coding method is determined by the object parameter\n+\n+\n+    `transform_algorithm`.\n+\n+\n+    \n+\n+\n+    Parameters\n+\n+\n+    ----------\n+\n+\n+    X : array of shape (n_samples, n_features)\n+\n+\n+        Test data to be transformed, must have the same number of\n+\n+\n+        features as the data used to train the model.\n+\n+\n+    \n+\n+\n+    Returns\n+\n+\n+    -------\n+\n+\n+    X_new : array, shape (n_samples, n_components)\n+\n+\n+        Transformed data\n+\n+\n+    \"\"\"\n+\n+\n+    check_is_fitted(self, 'components_')\n+\n+\n+    X = check_array(X)\n+\n+\n+    code = sparse_encode(\n+\n+\n+        X, self.components_, algorithm=self.transform_algorithm,\n+\n+\n+        n_nonzero_coefs=self.transform_n_nonzero_coefs,\n+\n+\n+        alpha=self.transform_alpha, max_iter=self.transform_max_iter,\n+\n+\n+        n_jobs=self.n_jobs, positive=self.positive_code)\n+\n+\n+    if self.split_sign:\n+\n+\n+        # feature vector is split into a positive and negative side\n+\n+\n+        n_samples, n_features = code.shape\n+\n+\n+        split_code = np.empty((n_samples, 2 * n_features))\n+\n+\n+        split_code[:, :n_features] = np.maximum(code, 0)\n+\n+\n+        split_code[:, n_features:] = -np.minimum(code, 0)\n+\n+\n+        code = split_code\n+\n+\n+    return code\n+\n+\n         return self\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-12973",
        "model_patch": "diff --git a/sklearn/linear_model/least_angle.py b/sklearn/linear_model/least_angle.py\nindex 03b34a0dc..4fd628642 100644\n--- a/sklearn/linear_model/least_angle.py\n+++ b/sklearn/linear_model/least_angle.py\n@@ -1479,7 +1479,8 @@ class LassoLarsIC(LassoLars):\n         self.eps = eps\n         self.fit_path = True\n \n-    def fit(self, X, y, copy_X=True):\n+    def fit(self, X, y, copy_X=None):\n+\n         \"\"\"Fit the model using X, y as training data.\n \n         Parameters\n@@ -1499,6 +1500,68 @@ class LassoLarsIC(LassoLars):\n             returns an instance of self.\n         \"\"\"\n         X, y = check_X_y(X, y, y_numeric=True)\n+        if copy_X is None:\n+\n+\n+            copy_X = self.copy_X\n+\n+\n \n         X, y, Xmean, ymean, Xstd = LinearModel._preprocess_data(\n             X, y, self.fit_intercept, self.normalize, self.copy_X)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13124",
        "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex 24394f869..d88043332 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -653,9 +653,10 @@ class StratifiedKFold(_BaseKFold):\n         # So we pass np.zeroes(max(c, n_splits)) as data to the KFold\n         per_cls_cvs = [\n             KFold(self.n_splits, shuffle=self.shuffle,\n-                  random_state=rng).split(np.zeros(max(count, self.n_splits)))\n+                  random_state=rng).split(np.arange(count).reshape(-1, 1))\n             for count in y_counts]\n \n+\n         test_folds = np.zeros(n_samples, dtype=np.int)\n         for test_fold_indices, per_cls_splits in enumerate(zip(*per_cls_cvs)):\n             for cls, (_, test_split) in zip(unique_y, per_cls_splits):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13135",
        "model_patch": "diff --git a/sklearn/preprocessing/_discretization.py b/sklearn/preprocessing/_discretization.py\nindex dd969c12b..a68c0cb10 100644\n--- a/sklearn/preprocessing/_discretization.py\n+++ b/sklearn/preprocessing/_discretization.py\n@@ -171,9 +171,11 @@ class KBinsDiscretizer(BaseEstimator, TransformerMixin):\n \n                 # 1D k-means procedure\n                 km = KMeans(n_clusters=n_bins[jj], init=init, n_init=1)\n-                centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n-                bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5\n-                bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]\n+    centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n+    centers = np.sort(centers)\n+    bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5\n+    bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]\n+\n \n         self.bin_edges_ = bin_edges\n         self.n_bins_ = n_bins\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13142",
        "model_patch": "diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py\nindex bd34333c0..a0ad4fcae 100644\n--- a/sklearn/mixture/base.py\n+++ b/sklearn/mixture/base.py\n@@ -257,23 +257,23 @@ class BaseMixture(DensityMixin, BaseEstimator, metaclass=ABCMeta):\n                 best_params = self._get_parameters()\n                 best_n_iter = n_iter\n \n-        # Always do a final e-step to guarantee that the labels returned by\n-        # fit_predict(X) are always consistent with fit(X).predict(X)\n-        # for any value of max_iter and tol (and any random_state).\n-        _, log_resp = self._e_step(X)\n-\n-        if not self.converged_:\n-            warnings.warn('Initialization %d did not converge. '\n-                          'Try different init parameters, '\n-                          'or increase max_iter, tol '\n-                          'or check for degenerate data.'\n-                          % (init + 1), ConvergenceWarning)\n-\n-        self._set_parameters(best_params)\n-        self.n_iter_ = best_n_iter\n-        self.lower_bound_ = max_lower_bound\n-\n-        return log_resp.argmax(axis=1)\n+# Set the best found parameters so that subsequent predictions\n+# use the best model.\n+self._set_parameters(best_params)\n+self.n_iter_ = best_n_iter\n+self.lower_bound_ = max_lower_bound\n+\n+# Now, do a final E-step so that the labels returned by fit_predict()\n+# are consistent with those returned by predict()\n+_, log_resp = self._e_step(X)\n+\n+if not self.converged_:\n+    warnings.warn('Initialization %d did not converge. '\n+                  'Try different init parameters, '\n+                  'or increase max_iter, tol '\n+                  'or check for degenerate data.'\n+                  % (init + 1), ConvergenceWarning)\n+return log_resp.argmax(axis=1)\n \n     def _e_step(self, X):\n         \"\"\"E step.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13328",
        "model_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 65c686400..24bd60bc4 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -90,7 +90,10 @@ def _huber_loss_and_gradient(w, X, y, epsilon, alpha, sample_weight=None):\n         grad = np.zeros(n_features + 1)\n \n     # Gradient due to the squared loss.\n-    X_non_outliers = -axis0_safe_slice(X, ~outliers_mask, n_non_outliers)\n+    # Ensure that X is of a numeric type before applying unary minus.\n+    X_num = X.astype(np.float64) if X.dtype == np.bool_ else X\n+    X_non_outliers = -axis0_safe_slice(X_num, ~outliers_mask, n_non_outliers)\n+\n     grad[:n_features] = (\n         2. / sigma * safe_sparse_dot(weighted_non_outliers, X_non_outliers))\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13439",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13496",
        "model_patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\nindex 8a1bd3625..3e1b4e2e2 100644\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -27,26 +27,53 @@ INTEGER_TYPES = (numbers.Integral, np.integer)\n \n \n class IsolationForest(BaseBagging, OutlierMixin):\n-    \"\"\"Isolation Forest Algorithm\n+    def __init__(self, *, n_estimators=100, max_samples=256,\n+                 contamination=\"auto\", max_features=1.0, bootstrap=False,\n+                 n_jobs=None, warm_start=False, behaviour=\"new\",\n+                 random_state=None, verbose=0):\n+        \"\"\"Isolation Forest with optional warm-start.\n+        \n+        Parameters\n+        ----------\n+        n_estimators : int, optional (default=100)\n+            The number of base estimators in the ensemble.\n+\n+        max_samples : int or float, optional (default=256)\n+            The number of samples to draw from X to train each base estimator.\n+\n+        contamination : 'auto' or float, optional (default=\"auto\")\n+            The proportion of outliers in the data set.\n \n-    Return the anomaly score of each sample using the IsolationForest algorithm\n+        max_features : int or float, optional (default=1.0)\n+            The number of features to draw from X to train each base estimator.\n \n-    The IsolationForest 'isolates' observations by randomly selecting a feature\n-    and then randomly selecting a split value between the maximum and minimum\n-    values of the selected feature.\n+        bootstrap : bool, optional (default=False)\n+            If True, bootstrap samples are used when building trees.\n \n-    Since recursive partitioning can be represented by a tree structure, the\n-    number of splittings required to isolate a sample is equivalent to the path\n-    length from the root node to the terminating node.\n+        n_jobs : int or None, optional (default=None)\n+            The number of jobs to run in parallel for fit and predict.\n \n-    This path length, averaged over a forest of such random trees, is a\n-    measure of normality and our decision function.\n+        warm_start : bool, optional (default=False)\n+            When set to True, reuse the solution of the previous call to fit\n+            and add more estimators to the ensemble; otherwise, a new forest \n+            is fitted. See :term:`the Glossary <warm_start>`.\n \n-    Random partitioning produces noticeably shorter paths for anomalies.\n-    Hence, when a forest of random trees collectively produce shorter path\n-    lengths for particular samples, they are highly likely to be anomalies.\n+        behaviour : {\"new\"}, optional (default=\"new\")\n+            Ignored as of version 0.22, to be removed in 0.24.\n \n-    Read more in the :ref:`User Guide <isolation_forest>`.\n+        random_state : int, RandomState instance, or None, optional (default=None)\n+            Controls the randomness of the estimator.\n+\n+        verbose : int, optional (default=0)\n+            Controls the verbosity when fitting and predicting.\n+        \"\"\"\n+        super().__init__(\n+            base_estimator=IsolationTree(random_state=random_state),\n+            n_estimators=n_estimators, max_samples=max_samples,\n+            max_features=max_features, bootstrap=bootstrap,\n+            n_jobs=n_jobs, random_state=random_state, verbose=verbose,\n+            warm_start=warm_start)\n+        self.contamination = contamination\n \n     .. versionadded:: 0.18\n \ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 67ba2d7f9..c48c7e99a 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -22,14 +22,19 @@ from sklearn.utils.testing import assert_allclose\n \n from sklearn.model_selection import ParameterGrid\n from sklearn.ensemble import IsolationForest\n-from sklearn.ensemble.iforest import _average_path_length\n-from sklearn.model_selection import train_test_split\n-from sklearn.datasets import load_boston, load_iris\n-from sklearn.utils import check_random_state\n-from sklearn.metrics import roc_auc_score\n-\n-from scipy.sparse import csc_matrix, csr_matrix\n-from unittest.mock import Mock, patch\n+def test_warm_start_iforest():\n+    # Test using warm_start provided at initialization.\n+    clf = IsolationForest(n_estimators=10, max_samples=256, contamination=0.1,\n+                           warm_start=True)\n+    clf.fit(X)\n+    initial_estimators = len(clf.estimators_)\n+\n+    # Increase n_estimators and refit with warm_start enabled.\n+    clf.set_params(n_estimators=initial_estimators + 5)\n+    clf.fit(X)\n+\n+    # Verify that the total number of trees is equal to the new n_estimators.\n+    assert len(clf.estimators_) == clf.n_estimators\n \n rng = check_random_state(0)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13779",
        "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..032ea35e3 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -76,11 +76,12 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n                              '; got %d weights, %d estimators'\n                              % (len(self.weights), len(self.estimators)))\n \n-        if sample_weight is not None:\n-            for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n-                    raise ValueError('Underlying estimator \\'%s\\' does not'\n-                                     ' support sample weights.' % name)\n+if sample_weight is not None:\n+    for name, step in self.estimators:\n+        if step is not None and not has_fit_parameter(step, 'sample_weight'):\n+            raise ValueError('Underlying estimator \\'%s\\' does not'\n+                             ' support sample weights.' % name)\n+\n \n         names, clfs = zip(*self.estimators)\n         self._validate_names(names)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14053",
        "model_patch": "diff --git a/sklearn/tree/export.py b/sklearn/tree/export.py\nindex 1fe11e596..dbc397e5e 100644\n--- a/sklearn/tree/export.py\n+++ b/sklearn/tree/export.py\n@@ -889,10 +889,10 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n     else:\n         value_fmt = \"{}{} value: {}\\n\"\n \n-    if feature_names:\n-        feature_names_ = [feature_names[i] for i in tree_.feature]\n-    else:\n-        feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n+if feature_names:\n+    feature_names_ = [feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined_feature\" for i in tree_.feature]\n+else:\n+    feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n \n     export_text.report = \"\"\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14087",
        "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 1999f1dae..1a32d71a8 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2167,11 +2167,17 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                 w = w[0]\n \n             else:\n-                # Take the best scores across every fold and the average of\n-                # all coefficients corresponding to the best scores.\n-                best_indices = np.argmax(scores, axis=1)\n+                best_indices = np.argmax(scores, axis=2)\n                 if self.multi_class == 'ovr':\n-                    w = np.mean([coefs_paths[i, best_indices[i], :]\n+                    w = np.array([\n+                        np.mean([coefs_paths[i, j, best_indices[i, j], :]\n+                                 for j in range(len(folds))], axis=0)\n+                        for i in range(coefs_paths.shape[0])\n+                    ])\n+                else:\n+                    w = np.mean([coefs_paths[0, j, best_indices[0, j], :]\n+                                 for j in range(len(folds))], axis=0)\n+\n                                  for i in range(len(folds))], axis=0)\n                 else:\n                     w = np.mean([coefs_paths[:, i, best_indices[i], :]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14141",
        "model_patch": "diff --git a/sklearn/utils/_show_versions.py b/sklearn/utils/_show_versions.py\nindex e5d3141bf..bfea37d27 100644\n--- a/sklearn/utils/_show_versions.py\n+++ b/sklearn/utils/_show_versions.py\n@@ -47,6 +47,94 @@ def _get_deps_info():\n         \"scipy\",\n         \"Cython\",\n         \"pandas\",\n+        \"joblib\",  # Added joblib to capture its version (required for sklearn > 0.20)\n+\n+\n         \"matplotlib\",\n     ]\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14496",
        "model_patch": "diff --git a/sklearn/cluster/optics_.py b/sklearn/cluster/optics_.py\nindex 4f7eb11ab..140beb6d7 100755\n--- a/sklearn/cluster/optics_.py\n+++ b/sklearn/cluster/optics_.py\n@@ -437,7 +437,8 @@ if metric=\u2019precomputed\u2019.\n     n_samples = X.shape[0]\n     _validate_size(min_samples, n_samples, 'min_samples')\n     if min_samples <= 1:\n-        min_samples = max(2, min_samples * n_samples)\n+        min_samples = int(round(max(2, min_samples * n_samples)))\n+\n \n     # Start all points as 'unprocessed' ##\n     reachability_ = np.empty(n_samples)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14629",
        "model_patch": "diff --git a/sklearn/model_selection/_validation.py b/sklearn/model_selection/_validation.py\nindex 95669a212..795b47ae8 100644\n--- a/sklearn/model_selection/_validation.py\n+++ b/sklearn/model_selection/_validation.py\n@@ -856,7 +856,7 @@ def _fit_and_predict(estimator, X, y, train, test, verbose, fit_params,\n     if method in ['decision_function', 'predict_proba', 'predict_log_proba']:\n         if isinstance(predictions, list):\n             predictions = [_enforce_prediction_order(\n-                estimator.classes_[i_label], predictions[i_label],\n+                estimator.estimators_[i_label].classes_, predictions[i_label],\n                 n_classes=len(set(y[:, i_label])), method=method)\n                 for i_label in range(len(predictions))]\n         else:\n@@ -864,6 +864,7 @@ def _fit_and_predict(estimator, X, y, train, test, verbose, fit_params,\n             n_classes = len(set(y)) if y.ndim == 1 else y.shape[1]\n             predictions = _enforce_prediction_order(\n                 estimator.classes_, predictions, n_classes, method)\n+\n     return predictions, test\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14710",
        "model_patch": "diff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex ad6a5a8ca..31d36bd9c 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -426,11 +426,16 @@ class BaseHistGradientBoosting(BaseEstimator, ABC):\n \n         Scores are computed on validation data or on training data.\n         \"\"\"\n+        if hasattr(self, 'classes_'):\n+            y_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n+\n         if self._use_validation_data:\n+            if hasattr(self, 'classes_'):\n+                y_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\n             )\n@@ -438,6 +443,7 @@ class BaseHistGradientBoosting(BaseEstimator, ABC):\n         else:\n             return self._should_stop(self.train_score_)\n \n+\n     def _check_early_stopping_loss(self,\n                                    raw_predictions,\n                                    y_train,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14894",
        "model_patch": "diff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\nindex 64cebe837..30a6ab4c4 100644\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -285,6 +285,108 @@ class BaseLibSVM(BaseEstimator, metaclass=ABCMeta):\n         else:  # regression\n             n_class = 1\n         n_SV = self.support_vectors_.shape[0]\n+        if n_SV == 0:\n+\n+\n+            self.dual_coef_ = sp.csr_matrix((n_class, 0))\n+\n+\n+            return\n+\n+\n \n         dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n         dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14983",
        "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..b0dc3d701 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1212,13 +1212,15 @@ class RepeatedKFold(_RepeatedSplits):\n     --------\n     RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n     \"\"\"\n-    def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n-        super().__init__(\n-            KFold, n_repeats, random_state, n_splits=n_splits)\n+def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n+    super().__init__(KFold, n_repeats, random_state, n_splits=n_splits)\n+    self.n_splits = n_splits\n+\n \n \n-class RepeatedStratifiedKFold(_RepeatedSplits):\n-    \"\"\"Repeated Stratified K-Fold cross validator.\n+def __init__(self, n_splits=5, n_repeats=10, random_state=None):\n+    super().__init__(StratifiedKFold, n_repeats, random_state, n_splits=n_splits)\n+    self.n_splits = n_splits\n \n     Repeats Stratified K-Fold n times with different randomization in each\n     repetition.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-15100",
        "model_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex bb5a9d646..73cd69d21 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -130,10 +130,8 @@ def strip_accents_unicode(s):\n         ASCII equivalent.\n     \"\"\"\n     normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+    return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+\n \n \n def strip_accents_ascii(s):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25102",
        "model_patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..4912bd315 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -12,8 +12,9 @@ def _wrap_in_pandas_container(\n     *,\n     columns,\n     index=None,\n+    dtypes=None,\n ):\n-    \"\"\"Create a Pandas DataFrame.\n+\n \n     If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be changed\n     inplace. If `data_to_wrap` is a ndarray, then a new DataFrame is created with\n@@ -59,7 +60,11 @@ def _wrap_in_pandas_container(\n             data_to_wrap.index = index\n         return data_to_wrap\n \n-    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n+    new_df = pd.DataFrame(data_to_wrap, index=index, columns=columns)\n+    if dtypes is not None:\n+        new_df = new_df.astype(dtypes)\n+    return new_df\n+\n \n \n def _get_output_config(method, estimator=None):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25232",
        "model_patch": "diff --git a/sklearn/impute/_iterative.py b/sklearn/impute/_iterative.py\nindex 1d918bc0c..5e7d4176a 100644\n--- a/sklearn/impute/_iterative.py\n+++ b/sklearn/impute/_iterative.py\n@@ -290,7 +290,6 @@ class IterativeImputer(_BaseImputer):\n         \"verbose\": [\"verbose\"],\n         \"random_state\": [\"random_state\"],\n     }\n-\n     def __init__(\n         self,\n         estimator=None,\n@@ -309,7 +308,9 @@ class IterativeImputer(_BaseImputer):\n         random_state=None,\n         add_indicator=False,\n         keep_empty_features=False,\n+        fill_value=None,\n     ):\n+\n         super().__init__(\n             missing_values=missing_values,\n             add_indicator=add_indicator,\n@@ -327,6 +328,44 @@ class IterativeImputer(_BaseImputer):\n         self.min_value = min_value\n         self.max_value = max_value\n         self.verbose = verbose\n+        self.fill_value = fill_value\n+\n+\n         self.random_state = random_state\n \n     def _impute_one_feature(\n@@ -609,12 +648,17 @@ class IterativeImputer(_BaseImputer):\n \n         X_missing_mask = _get_mask(X, self.missing_values)\n         mask_missing_values = X_missing_mask.copy()\n-        if self.initial_imputer_ is None:\n-            self.initial_imputer_ = SimpleImputer(\n-                missing_values=self.missing_values,\n-                strategy=self.initial_strategy,\n-                keep_empty_features=self.keep_empty_features,\n-            )\n+            if self.initial_imputer_ is None:\n+                self.initial_imputer_ = SimpleImputer(\n+                    missing_values=self.missing_values,\n+                    strategy=self.initial_strategy,\n+                    fill_value=self.fill_value,\n+                    keep_empty_features=self.keep_empty_features,\n+                )\n+                X_filled = self.initial_imputer_.fit_transform(X)\n+            else:\n+                X_filled = self.initial_imputer_.transform(X)\n+\n             X_filled = self.initial_imputer_.fit_transform(X)\n         else:\n             X_filled = self.initial_imputer_.transform(X)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25747",
        "model_patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..a6094184d 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -55,8 +55,12 @@ def _wrap_in_pandas_container(\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n-            data_to_wrap.index = index\n+            if index is not None:\n+                # Only assign the input index if its length matches the output data;\n+                # otherwise, leave the output data\u2019s own index intact.\n+                if len(data_to_wrap) == len(index):\n+                    data_to_wrap.index = index\n+\n         return data_to_wrap\n \n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25931",
        "model_patch": "diff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex 4d6c1c3f0..d64d580cf 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -344,11 +344,27 @@ class IsolationForest(OutlierMixin, BaseBagging):\n             self.offset_ = -0.5\n             return self\n \n-        # else, define offset_ wrt contamination parameter\n-        self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)\n+        # else, define offset_ with respect to contamination parameter\n+        # When contamination != \"auto\", score_samples is called on X inside fit.\n+        # However, X has been converted to an ndarray in _validate_data,\n+        # losing its original feature names. To ensure that feature names\n+        # are preserved (and to avoid triggering the warning),\n+        # we re-create a DataFrame from X using self.feature_names_in_\n+        # if they exist.\n+        try:\n+            import pandas as pd\n+        except ImportError:\n+            pd = None\n+\n+        if pd is not None and hasattr(self, \"feature_names_in_\") and not hasattr(X, \"columns\"):\n+            X_for_offset = pd.DataFrame(X, columns=self.feature_names_in_)\n+        else:\n+            X_for_offset = X\n \n+        self.offset_ = np.percentile(self.score_samples(X_for_offset), 100.0 * self.contamination)\n         return self\n \n+\n     def predict(self, X):\n         \"\"\"\n         Predict if a particular sample is an outlier or not.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25973",
        "model_patch": "diff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py\nindex e983c55de..b8a59f070 100644\n--- a/sklearn/feature_selection/_sequential.py\n+++ b/sklearn/feature_selection/_sequential.py\n@@ -205,6 +205,274 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator\n             Returns the instance itself.\n         \"\"\"\n         self._validate_params()\n+# If cv is a one-time iterator (like a generator from LeaveOneGroupOut.split),\n+\n+\n+# convert it to a list so that each call to cross_val_score iterates over the same splits.\n+\n+\n+if not isinstance(self.cv, int) and hasattr(self.cv, '__next__'):\n+\n+\n+    self.cv = list(self.cv)\n+\n+\n \n         # FIXME: to be removed in 1.3\n         if self.n_features_to_select in (\"warn\", None):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-26194",
        "model_patch": "diff --git a/sklearn/metrics/_ranking.py b/sklearn/metrics/_ranking.py\nindex 0cdead923..34f04dd03 100644\n--- a/sklearn/metrics/_ranking.py\n+++ b/sklearn/metrics/_ranking.py\n@@ -1083,7 +1083,12 @@ def roc_curve(\n     # to make sure that the curve starts at (0, 0)\n     tps = np.r_[0, tps]\n     fps = np.r_[0, fps]\n-    thresholds = np.r_[thresholds[0] + 1, thresholds]\n+if thresholds[0] <= 1:\n+    extra_threshold = 1\n+else:\n+    extra_threshold = thresholds[0] + 1\n+thresholds = np.r_[extra_threshold, thresholds]\n+\n \n     if fps[-1] <= 0:\n         warnings.warn(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-26323",
        "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..d6547c322 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -293,18 +293,27 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             Estimator instance.\n         \"\"\"\n         super().set_output(transform=transform)\n-        transformers = (\n-            trans\n-            for _, trans, _ in chain(\n+        # Apply set_output to all sub-transformers from both the initial and fitted lists.\n+        for _, trans, _ in chain(\n                 self.transformers, getattr(self, \"transformers_\", [])\n-            )\n-            if trans not in {\"passthrough\", \"drop\"}\n-        )\n-        for trans in transformers:\n-            _safe_set_output(trans, transform=transform)\n+        ):\n+            if trans not in {\"passthrough\", \"drop\"}:\n+                _safe_set_output(trans, transform=transform)\n+\n+        # Also apply set_output to the remainder estimator if it is an estimator.\n+        # Use self._remainder if it exists (set during _validate_remainder),\n+        # otherwise use self.remainder.\n+        if hasattr(self, \"_remainder\"):\n+            remainder_estimator = self._remainder[1]\n+        else:\n+            remainder_estimator = self.remainder\n+\n+        if remainder_estimator not in {\"passthrough\", \"drop\"}:\n+            _safe_set_output(remainder_estimator, transform=transform)\n \n         return self\n \n+\n     def get_params(self, deep=True):\n         \"\"\"Get parameters for this estimator.\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-9288",
        "model_patch": "diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py\nindex b7fbdf7da..4a62adbe5 100644\n--- a/sklearn/cluster/k_means_.py\n+++ b/sklearn/cluster/k_means_.py\n@@ -361,15 +361,16 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',\n         raise ValueError(\"Algorithm must be 'auto', 'full' or 'elkan', got\"\n                          \" %s\" % str(algorithm))\n     if effective_n_jobs(n_jobs) == 1:\n-        # For a single thread, less memory is needed if we just store one set\n-        # of the best results (as opposed to one set per run per thread).\n-        for it in range(n_init):\n-            # run a k-means once\n+        # For a single thread, generate a distinct seed for each run to\n+        # ensure consistent initialization with the parallel branch.\n+        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n+        for seed in seeds:\n+            # run a k-means once with a unique seed\n             labels, inertia, centers, n_iter_ = kmeans_single(\n                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n                 verbose=verbose, precompute_distances=precompute_distances,\n                 tol=tol, x_squared_norms=x_squared_norms,\n-                random_state=random_state)\n+                random_state=seed)\n             # determine if these results are the best so far\n             if best_inertia is None or inertia < best_inertia:\n                 best_labels = labels.copy()\n@@ -377,6 +378,7 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',\n                 best_inertia = inertia\n                 best_n_iter = n_iter_\n     else:\n+\n         # parallelisation of k-means runs\n         seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n         results = Parallel(n_jobs=n_jobs, verbose=0)(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10323",
        "model_patch": "diff --git a/sphinx/directives/code.py b/sphinx/directives/code.py\nindex dc44ed314..6060c06e1 100644\n--- a/sphinx/directives/code.py\n+++ b/sphinx/directives/code.py\n@@ -224,9 +224,10 @@ class LiteralIncludeReader:\n                        self.start_filter,\n                        self.end_filter,\n                        self.lines_filter,\n+                       self.dedent_filter,\n                        self.prepend_filter,\n-                       self.append_filter,\n-                       self.dedent_filter]\n+                       self.append_filter]\n+\n             lines = self.read_file(self.filename, location=location)\n             for func in filters:\n                 lines = func(lines, location=location)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10435",
        "model_patch": "diff --git a/sphinx/writers/latex.py b/sphinx/writers/latex.py\nindex e0c7d56f8..78b04dc6c 100644\n--- a/sphinx/writers/latex.py\n+++ b/sphinx/writers/latex.py\n@@ -721,10 +721,12 @@ class LaTeXTranslator(SphinxTranslator):\n         pass\n \n     def visit_desc_inline(self, node: Element) -> None:\n-        self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n+\n \n     def depart_desc_inline(self, node: Element) -> None:\n-        self.body.append('}}')\n+        self.body.append('%}}')\n+\n \n     # Nodes for high-level structure in signatures\n     ##############################################\n@@ -1699,7 +1701,8 @@ class LaTeXTranslator(SphinxTranslator):\n         elif 'kbd' in node['classes']:\n             self.body.append(r'\\sphinxkeyboard{\\sphinxupquote{')\n             return\n-        lang = node.get(\"language\", None)\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n+\n         if 'code' not in node['classes'] or not lang:\n             self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n             return\n@@ -1717,7 +1720,8 @@ class LaTeXTranslator(SphinxTranslator):\n         self.body.append('}}')\n         raise nodes.SkipNode\n \n-    def depart_literal(self, node: Element) -> None:\n+        self.body.append('%}}')\n+\n         self.body.append('}}')\n \n     def visit_footnote_reference(self, node: Element) -> None:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10449",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex 06768168e..92edc90e9 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -126,10 +126,11 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str]) -> No\n     if 'return' in annotations and 'return' not in arguments:\n         field = nodes.field()\n         field += nodes.field_name('', 'rtype')\n-        field += nodes.field_body('', nodes.paragraph('', annotation))\n+        field += nodes.field_body('', nodes.paragraph('', annotations['return']))\n         node += field\n \n \n+\n def augment_descriptions_with_types(\n     node: nodes.field_list,\n     annotations: Dict[str, str],\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10466",
        "model_patch": "diff --git a/sphinx/builders/gettext.py b/sphinx/builders/gettext.py\nindex e8bc547b7..5a4fd583e 100644\n--- a/sphinx/builders/gettext.py\n+++ b/sphinx/builders/gettext.py\n@@ -30,10 +30,18 @@ logger = logging.getLogger(__name__)\n \n class Message:\n     \"\"\"An entry of translatable message.\"\"\"\n-    def __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n-        self.text = text\n-        self.locations = locations\n-        self.uuids = uuids\n+def __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n+    self.text = text\n+    # Deduplicate the list of locations while preserving order.\n+    seen = set()\n+    unique_locations = []\n+    for loc in locations:\n+        if loc not in seen:\n+            unique_locations.append(loc)\n+            seen.add(loc)\n+    self.locations = unique_locations\n+    self.uuids = uuids\n+\n \n \n class Catalog:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10614",
        "model_patch": "diff --git a/sphinx/ext/inheritance_diagram.py b/sphinx/ext/inheritance_diagram.py\nindex 6e3985512..b274a3e56 100644\n--- a/sphinx/ext/inheritance_diagram.py\n+++ b/sphinx/ext/inheritance_diagram.py\n@@ -407,20 +407,24 @@ def html_visit_inheritance_diagram(self: HTML5Translator, node: inheritance_diag\n \n     # Create a mapping from fully-qualified class names to URLs.\n     graphviz_output_format = self.builder.env.config.graphviz_output_format.upper()\n-    current_filename = self.builder.current_docname + self.builder.out_suffix\n-    urls = {}\n-    pending_xrefs = cast(Iterable[addnodes.pending_xref], node)\n-    for child in pending_xrefs:\n-        if child.get('refuri') is not None:\n-            if graphviz_output_format == 'SVG':\n-                urls[child['reftitle']] = \"../\" + child.get('refuri')\n-            else:\n-                urls[child['reftitle']] = child.get('refuri')\n-        elif child.get('refid') is not None:\n-            if graphviz_output_format == 'SVG':\n-                urls[child['reftitle']] = '../' + current_filename + '#' + child.get('refid')\n-            else:\n-                urls[child['reftitle']] = '#' + child.get('refid')\n+current_filename = self.builder.current_docname + self.builder.out_suffix\n+from sphinx.util.osutil import relative_uri\n+urls = {}\n+pending_xrefs = cast(Iterable[addnodes.pending_xref], node)\n+for child in pending_xrefs:\n+    if child.get('refuri') is not None:\n+        if graphviz_output_format == 'SVG':\n+            # Compute relative URI from current document to target\n+            urls[child['reftitle']] = relative_uri(current_filename, child.get('refuri'))\n+        else:\n+            urls[child['reftitle']] = child.get('refuri')\n+    elif child.get('refid') is not None:\n+        if graphviz_output_format == 'SVG':\n+            # Compute relative URI from current document to same document with fragment\n+            urls[child['reftitle']] = relative_uri(current_filename, current_filename + '#' + child.get('refid'))\n+        else:\n+            urls[child['reftitle']] = '#' + child.get('refid')\n+\n \n     dotcode = graph.generate_dot(name, urls, env=self.builder.env)\n     render_dot_html(self, node, dotcode, {}, 'inheritance', 'inheritance',\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10673",
        "model_patch": "diff --git a/sphinx/environment/adapters/toctree.py b/sphinx/environment/adapters/toctree.py\nindex 9678e3c7c..258a72ca0 100644\n--- a/sphinx/environment/adapters/toctree.py\n+++ b/sphinx/environment/adapters/toctree.py\n@@ -139,25 +139,35 @@ class TocTree:\n                         item = nodes.list_item('', para)\n                         # don't show subitems\n                         toc = nodes.bullet_list('', item)\n-                    else:\n-                        if ref in parents:\n-                            logger.warning(__('circular toctree references '\n-                                              'detected, ignoring: %s <- %s'),\n-                                           ref, ' <- '.join(parents),\n-                                           location=ref, type='toc', subtype='circular')\n-                            continue\n-                        refdoc = ref\n-                        toc = self.env.tocs[ref].deepcopy()\n-                        maxdepth = self.env.metadata[ref].get('tocdepth', 0)\n-                        if ref not in toctree_ancestors or (prune and maxdepth > 0):\n-                            self._toctree_prune(toc, 2, maxdepth, collapse)\n-                        process_only_nodes(toc, builder.tags)\n-                        if title and toc.children and len(toc.children) == 1:\n-                            child = toc.children[0]\n-                            for refnode in child.findall(nodes.reference):\n-                                if refnode['refuri'] == ref and \\\n-                                   not refnode['anchorname']:\n-                                    refnode.children = [nodes.Text(title)]\n+else:\n+    if ref in ('genindex', 'modindex', 'search'):\n+        if not title:\n+            title = ref.capitalize()\n+        reference = nodes.reference('', '', internal=True,\n+                                      refuri=ref, anchorname='',\n+                                      *[nodes.Text(title)])\n+        para = addnodes.compact_paragraph('', '', reference)\n+        toc = nodes.bullet_list('', nodes.list_item('', para))\n+        entries.append(toc)\n+        continue\n+    if ref in parents:\n+        logger.warning(__('circular toctree references '\n+                          'detected, ignoring: %s <- %s'),\n+                       ref, ' <- '.join(parents),\n+                       location=ref, type='toc', subtype='circular')\n+        continue\n+    refdoc = ref\n+    toc = self.env.tocs[ref].deepcopy()\n+    maxdepth = self.env.metadata[ref].get('tocdepth', 0)\n+    if ref not in toctree_ancestors or (prune and maxdepth > 0):\n+        self._toctree_prune(toc, 2, maxdepth, collapse)\n+    process_only_nodes(toc, builder.tags)\n+    if title and toc.children and len(toc.children) == 1:\n+        child = toc.children[0]\n+        for refnode in child.findall(nodes.reference):\n+            if refnode['refuri'] == ref and not refnode['anchorname']:\n+                refnode.children = [nodes.Text(title)]\n+\n                     if not toc.children:\n                         # empty toc means: no titles will show up in the toctree\n                         logger.warning(__('toctree contains reference to document %r that '\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-11445",
        "model_patch": "diff --git a/sphinx/util/rst.py b/sphinx/util/rst.py\nindex 7a1538325..70cd4002b 100644\n--- a/sphinx/util/rst.py\n+++ b/sphinx/util/rst.py\n@@ -25,7 +25,8 @@ except ImportError:\n \n logger = logging.getLogger(__name__)\n \n-docinfo_re = re.compile(':\\\\w+:.*?')\n+docinfo_re = re.compile(r'^:\\w+:\\s')\n+\n symbols_re = re.compile(r'([!-\\-/:-@\\[-`{-~])')  # symbols without dot(0x2e)\n SECTIONING_CHARS = ['=', '-', '~']\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-11510",
        "model_patch": "diff --git a/sphinx/directives/other.py b/sphinx/directives/other.py\nindex 19f7c0a8d..3a134b043 100644\n--- a/sphinx/directives/other.py\n+++ b/sphinx/directives/other.py\n@@ -368,16 +368,40 @@ class Include(BaseInclude, SphinxDirective):\n     \"correctly\", i.e. relative to source directory.\n     \"\"\"\n \n-    def run(self) -> list[Node]:\n-        if self.arguments[0].startswith('<') and \\\n-           self.arguments[0].endswith('>'):\n-            # docutils \"standard\" includes, do not do path processing\n-            return super().run()\n-        rel_filename, filename = self.env.relfn2path(self.arguments[0])\n-        self.arguments[0] = filename\n-        self.env.note_included(filename)\n+def run(self) -> list[Node]:\n+    # For system includes (e.g. <...>) use the default processing.\n+    if self.arguments[0].startswith('<') and self.arguments[0].endswith('>'):\n         return super().run()\n \n+    # Resolve the filename relative to the source directory.\n+    rel_filename, filename = self.env.relfn2path(self.arguments[0])\n+    self.env.note_included(filename)\n+\n+    # Read the file content using Python so that we can apply Sphinx\u2019s source-read event.\n+    try:\n+        with open(filename, \"r\", encoding=\"utf-8\") as f:\n+            text = f.read()\n+    except Exception as err:\n+        error = self.state.document.reporter.error(\n+            f\"Error reading included file {filename!r}: {err}\",\n+            line=self.lineno\n+        )\n+        return [error]\n+\n+    # Apply the source-read event so that any custom modifications are applied.\n+    source_list = [text]\n+    self.env.app.events.emit('source-read', self.env.docname, source_list)\n+    modified_text = source_list[0]\n+\n+    # Use the modified text to generate a new StringList and parse it.\n+    from docutils.statemachine import StringList\n+    source_lines = modified_text.splitlines()\n+    new_string_list = StringList(source_lines, source=filename)\n+    container = nodes.compound()\n+    self.state.nested_parse(new_string_list, self.content_offset, container)\n+    return container.children\n+\n+\n \n def setup(app: Sphinx) -> dict[str, Any]:\n     directives.register_directive('toctree', TocTree)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7440",
        "model_patch": "diff --git a/sphinx/domains/std.py b/sphinx/domains/std.py\nindex d820cfe5c..c3026d357 100644\n--- a/sphinx/domains/std.py\n+++ b/sphinx/domains/std.py\n@@ -305,7 +305,8 @@ def make_glossary_term(env: \"BuildEnvironment\", textnodes: Iterable[Node], index\n         term['ids'].append(node_id)\n \n     std = cast(StandardDomain, env.get_domain('std'))\n-    std.note_object('term', termtext.lower(), node_id, location=term)\n+    std.note_object('term', termtext, node_id, location=term)\n+\n \n     # add an index entry too\n     indexnode = addnodes.index()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7454",
        "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 893bb0a22..0f02f61bb 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -1311,8 +1311,11 @@ def builtin_resolver(app: Sphinx, env: BuildEnvironment,\n \n     if node.get('refdomain') != 'py':\n         return None\n-    elif node.get('reftype') in ('class', 'obj') and node.get('reftarget') == 'None':\n-        return contnode\n+    # Removed special-case handling for \"None\" to allow clickable link for the None annotation.\n+    # Previously, the following condition returned the bare text for None:\n+    # elif node.get('reftype') in ('class', 'obj') and node.get('reftarget') == 'None':\n+    #     return contnode\n+\n     elif node.get('reftype') in ('class', 'exc'):\n         reftarget = node.get('reftarget')\n         if inspect.isclass(getattr(builtins, reftarget, None)):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7462",
        "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 3ca730e30..f065fa415 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -113,13 +113,15 @@ def _parse_annotation(annotation: str) -> List[Node]:\n             result.extend(unparse(node.slice))\n             result.append(addnodes.desc_sig_punctuation('', ']'))\n             return result\n-        elif isinstance(node, ast.Tuple):\n-            result = []\n-            for elem in node.elts:\n-                result.extend(unparse(elem))\n-                result.append(addnodes.desc_sig_punctuation('', ', '))\n+    elif isinstance(node, ast.Tuple):\n+        result = []\n+        for elem in node.elts:\n+            result.extend(unparse(elem))\n+            result.append(addnodes.desc_sig_punctuation('', ', '))\n+        if result:\n             result.pop()\n-            return result\n+        return result\n+\n         else:\n             raise SyntaxError  # unsupported syntax\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7590",
        "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..df2e65a34 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4662,9 +4662,9 @@ class DefinitionParser(BaseParser):\n                       integer_literal_re, octal_literal_re]:\n             pos = self.pos\n             if self.match(regex):\n-                while self.current_char in 'uUlLfF':\n-                    self.pos += 1\n-                return ASTNumberLiteral(self.definition[pos:self.pos])\n+while self.current_char and (self.current_char.isalnum() or self.current_char == '_'):\n+    self.pos += 1\n+\n \n         string = self._parse_string()\n         if string is not None:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7748",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7757",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 15f0d66e2..7787278ec 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -521,20 +521,42 @@ def signature_from_str(signature: str) -> inspect.Signature:\n     params = []\n \n     if hasattr(args, \"posonlyargs\"):\n-        for arg in args.posonlyargs:  # type: ignore\n+        # Combine posonlyargs and args so that defaults can be applied to the tail of the list.\n+        total_args = args.posonlyargs + args.args\n+        num_total = len(total_args)\n+        defaults = args.defaults if args.defaults else []\n+        start_index = num_total - len(defaults)\n+\n+        # Process the positional-only parameters and apply defaults if available.\n+        for i, arg in enumerate(args.posonlyargs):  # type: ignore\n+            if i >= start_index:\n+                default = ast_unparse(defaults[i - start_index])\n+            else:\n+                default = Parameter.empty\n             annotation = ast_unparse(arg.annotation) or Parameter.empty\n             params.append(Parameter(arg.arg, Parameter.POSITIONAL_ONLY,\n-                                    annotation=annotation))\n+                                    default=default, annotation=annotation))\n \n-    for i, arg in enumerate(args.args):\n-        if len(args.args) - i <= len(args.defaults):\n-            default = ast_unparse(args.defaults[-len(args.args) + i])\n-        else:\n-            default = Parameter.empty\n+        # Process the positional-or-keyword parameters and apply defaults.\n+        for i, arg in enumerate(args.args):\n+            j = i + len(args.posonlyargs)\n+            if j >= start_index:\n+                default = ast_unparse(defaults[j - start_index])\n+            else:\n+                default = Parameter.empty\n+            annotation = ast_unparse(arg.annotation) or Parameter.empty\n+            params.append(Parameter(arg.arg, Parameter.POSITIONAL_OR_KEYWORD,\n+                                    default=default, annotation=annotation))\n+    else:\n+        for i, arg in enumerate(args.args):\n+            if len(args.args) - i <= len(args.defaults):\n+                default = ast_unparse(args.defaults[-len(args.args) + i])\n+            else:\n+                default = Parameter.empty\n+            annotation = ast_unparse(arg.annotation) or Parameter.empty\n+            params.append(Parameter(arg.arg, Parameter.POSITIONAL_OR_KEYWORD,\n+                                    default=default, annotation=annotation))\n \n-        annotation = ast_unparse(arg.annotation) or Parameter.empty\n-        params.append(Parameter(arg.arg, Parameter.POSITIONAL_OR_KEYWORD,\n-                                default=default, annotation=annotation))\n \n     if args.vararg:\n         annotation = ast_unparse(args.vararg.annotation) or Parameter.empty\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7889",
        "model_patch": "diff --git a/sphinx/ext/autodoc/mock.py b/sphinx/ext/autodoc/mock.py\nindex 98a3a3a96..4bb9e4c8c 100644\n--- a/sphinx/ext/autodoc/mock.py\n+++ b/sphinx/ext/autodoc/mock.py\n@@ -70,7 +70,8 @@ class _MockObject:\n \n def _make_subclass(name: str, module: str, superclass: Any = _MockObject,\n                    attributes: Any = None) -> Any:\n-    attrs = {'__module__': module, '__display_name__': module + '.' + name}\n+    attrs = {'__module__': module, '__display_name__': module + '.' + str(name)}\n+\n     attrs.update(attributes or {})\n \n     return type(name, (superclass,), attrs)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7910",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 441f850d1..3a0fe5b85 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -120,7 +120,9 @@ def getargspec(func: Callable) -> Any:\n \n def unwrap(obj: Any) -> Any:\n     \"\"\"Get an original object from wrapped object (wrapped functions).\"\"\"\n-    try:\n+    original_obj = getattr(obj, '__wrapped__', obj)\n+    cls = original_obj.__globals__[cls_path]\n+\n         return inspect.unwrap(obj)\n     except ValueError:\n         # might be a mock object\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7985",
        "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex dd5317087..d9636d681 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -212,8 +212,27 @@ class CheckExternalLinksBuilder(Builder):\n             # check for various conditions without bothering the network\n             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):\n                 return 'unchecked', '', 0\n-            elif not uri.startswith(('http:', 'https:')):\n-                return 'local', '', 0\n+elif not uri.startswith(('http:', 'https:')):\n+    # For local (internal) links, try to resolve the target file relative to the current document.\n+    # This replaces the previous behavior that skipped any checking.\n+    from os import path\n+    # If an anchor is present, split it off.\n+    if '#' in uri:\n+        relative_uri, anchor = uri.split('#', 1)\n+    else:\n+        relative_uri, anchor = uri, None\n+\n+    # Get the path to the current document\u2019s source file.\n+    source_file = self.env.doc2path(docname, base=True)\n+    base_dir = path.dirname(source_file)\n+    target_path = path.normpath(path.join(base_dir, unquote(relative_uri)))\n+\n+    if path.exists(target_path):\n+        # (Optional) You might add extra verification for the anchor here.\n+        return 'working', '', 0\n+    else:\n+        return 'broken', __(\"Local file '%s' not found\") % target_path, 0\n+\n             elif uri in self.good:\n                 return 'working', 'old', 0\n             elif uri in self.broken:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8035",
        "model_patch": "diff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 9a3428f5d..9b2cda086 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -45,8 +45,14 @@ class DummyOptionSpec(dict):\n         \"\"\"Behaves like some options are defined.\"\"\"\n         return True\n \n-    def __getitem__(self, key: str) -> Callable[[str], str]:\n-        return lambda x: x\n+def __getitem__(self, key: str) -> Callable[[str], object]:\n+    # For the private-members option we want to allow a list of names.\n+    # If the option value is empty (i.e. just :private-members:),\n+    # we return True so that all private members are included.\n+    # Otherwise, we split the comma-separated list and strip each name.\n+    if key == 'private-members':\n+        return lambda x: True if not x.strip() else [member.strip() for member in x.split(',') if member.strip()]\n+    return lambda x: x\n \n \n class DocumenterBridge:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8056",
        "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex b3daa06f1..cc841e05a 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -392,17 +392,20 @@ class GoogleDocstring:\n         lines = []\n         for _name, _type, _desc in fields:\n             _desc = self._strip_empty(_desc)\n-            if any(_desc):\n-                _desc = self._fix_field_desc(_desc)\n-                field = ':%s %s: ' % (field_role, _name)\n-                lines.extend(self._format_block(field, _desc))\n-            else:\n-                lines.append(':%s %s:' % (field_role, _name))\n-\n-            if _type:\n-                lines.append(':%s %s: %s' % (type_role, _name, _type))\n+            # Split the _name if it contains comma-separated parameter names.\n+            names = [n.strip() for n in _name.split(',')] if ',' in _name else [_name]\n+            for name in names:\n+                if any(_desc):\n+                    desc_fixed = self._fix_field_desc(_desc)\n+                    field = ':%s %s: ' % (field_role, name)\n+                    lines.extend(self._format_block(field, desc_fixed))\n+                else:\n+                    lines.append(':%s %s:' % (field_role, name))\n+                if _type:\n+                    lines.append(':%s %s: %s' % (type_role, name, _type))\n         return lines + ['']\n \n+\n     def _format_field(self, _name: str, _type: str, _desc: List[str]) -> List[str]:\n         _desc = self._strip_empty(_desc)\n         has_desc = any(_desc)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8120",
        "model_patch": "diff --git a/sphinx/application.py b/sphinx/application.py\nindex 385b74d8a..872b135b9 100644\n--- a/sphinx/application.py\n+++ b/sphinx/application.py\n@@ -293,7 +293,8 @@ class Sphinx:\n                 if catalog.domain == 'sphinx' and catalog.is_outdated():\n                     catalog.write_mo(self.config.language)\n \n-            locale_dirs = [None, path.join(package_dir, 'locale')] + list(repo.locale_dirs)\n+            locale_dirs = list(repo.locale_dirs) + [None, path.join(package_dir, 'locale')]\n+\n             self.translator, has_translation = locale.init(locale_dirs, self.config.language)\n             if has_translation or self.config.language == 'en':\n                 # \"en\" never needs to be translated\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8265",
        "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex 9bafff11c..84b0caab2 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -197,9 +197,19 @@ class _UnparseVisitor(ast.NodeVisitor):\n \n         def visit_Num(self, node: ast.Num) -> str:\n             return repr(node.n)\n+        elif isinstance(node, ast.Tuple):\n+            if node.elts:\n+                # Wrap the tuple elements with parentheses\n+                result = [addnodes.desc_sig_punctuation('', '(')]\n+                for i, elem in enumerate(node.elts):\n+                    result.extend(unparse(elem))\n+                    # Append comma for all but the last element.\n+                    if i != len(node.elts) - 1:\n+                        result.append(addnodes.desc_sig_punctuation('', ', '))\n+                result.append(addnodes.desc_sig_punctuation('', ')'))\n+            else:\n+                # For empty tuple, output as ()\n+                result = [addnodes.desc_sig_punctuation('', '('),\n+                          addnodes.desc_sig_punctuation('', ')')]\n \n-        def visit_Str(self, node: ast.Str) -> str:\n-            return repr(node.s)\n-\n-    def generic_visit(self, node):\n-        raise NotImplementedError('Unable to parse %s object' % type(node).__name__)\n+            return result\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8269",
        "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 9b54afc7c..4aa135c23 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -162,14 +162,15 @@ class CheckExternalLinksBuilder(Builder):\n             kwargs['headers'] = get_request_headers()\n \n             try:\n-                if anchor and self.app.config.linkcheck_anchors:\n-                    # Read the whole document and see if #anchor exists\n-                    response = requests.get(req_url, stream=True, config=self.app.config,\n-                                            auth=auth_info, **kwargs)\n-                    found = check_anchor(response, unquote(anchor))\n-\n-                    if not found:\n-                        raise Exception(__(\"Anchor '%s' not found\") % anchor)\n+            if anchor and self.app.config.linkcheck_anchors:\n+                # Read the whole document and see if #anchor exists\n+                response = requests.get(req_url, stream=True, config=self.app.config,\n+                                        auth=auth_info, **kwargs)\n+                response.raise_for_status()\n+                found = check_anchor(response, unquote(anchor))\n+                if not found:\n+                    raise Exception(__(\"Anchor '%s' not found\") % anchor)\n+\n                 else:\n                     try:\n                         # try a HEAD request first, which should be easier on\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8459",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex 70cbc3ba1..7d7960a6e 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -18,6 +18,856 @@ from docutils.nodes import Element\n from sphinx import addnodes\n from sphinx.application import Sphinx\n from sphinx.util import inspect, typing\n+import importlib\n+\n+\n+\n+def _apply_aliases(annotation: str, app: Sphinx) -> str:\n+\n+\n+    \"\"\"\n+\n+\n+    If a type alias is configured, try to import the target type and compare its\n+\n+\n+    stringified form to the given annotation. If they match, return the alias mapping.\n+\n+\n+    Otherwise, return the original annotation.\n+\n+\n+    \"\"\"\n+\n+\n+    aliases = app.config.autodoc_type_aliases\n+\n+\n+    for alias_name, alias_target in aliases.items():\n+\n+\n+        try:\n+\n+\n+            mod_name, attr = alias_target.rsplit('.', 1)\n+\n+\n+            mod = importlib.import_module(mod_name)\n+\n+\n+            t = getattr(mod, attr)\n+\n+\n+            expected = typing.stringify(t)\n+\n+\n+            if annotation == expected:\n+\n+\n+                return alias_target\n+\n+\n+        except Exception:\n+\n+\n+            # If anything goes wrong importing the alias type, skip substitution.\n+\n+\n+            continue\n+\n+\n+    return annotation\n+\n \n \n def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n@@ -57,6 +907,10 @@ def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element\n \n     annotations = app.env.temp_data.get('annotations', {})\n     if annotations.get(fullname, {}):\n+        # NEW: Apply alias substitution to recorded annotation strings.\n+        for key, value in annotations[fullname].items():\n+            annotations[fullname][key] = _apply_aliases(value, app)\n+\n         field_lists = [n for n in contentnode if isinstance(n, nodes.field_list)]\n         if field_lists == []:\n             field_list = insert_field_list(contentnode)\n@@ -66,6 +920,7 @@ def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element\n             modify_field_list(field_list, annotations[fullname])\n \n \n+\n def insert_field_list(node: Element) -> nodes.field_list:\n     field_list = nodes.field_list()\n     desc = [n for n in node if isinstance(n, addnodes.desc)]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8475",
        "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 1dc0337c3..e7e56b5d5 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -20,7 +20,8 @@ from urllib.parse import unquote, urlparse\n \n from docutils import nodes\n from docutils.nodes import Node\n-from requests.exceptions import HTTPError\n+from requests.exceptions import HTTPError, TooManyRedirects\n+\n \n from sphinx.application import Sphinx\n from sphinx.builders import Builder\n@@ -172,7 +173,8 @@ class CheckExternalLinksBuilder(Builder):\n                                                  config=self.app.config, auth=auth_info,\n                                                  **kwargs)\n                         response.raise_for_status()\n-                    except HTTPError:\n+                    except (HTTPError, TooManyRedirects) as err:\n+\n                         # retry with GET request if that fails, some servers\n                         # don't like HEAD requests.\n                         response = requests.get(req_url, stream=True, config=self.app.config,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8548",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8551",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8593",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8595",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8621",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8638",
        "model_patch": "diff --git a/sphinx/roles.py b/sphinx/roles.py\nindex c3f594cbb..d0a75fbd6 100644\n--- a/sphinx/roles.py\n+++ b/sphinx/roles.py\n@@ -166,11 +166,13 @@ class AnyXRefRole(XRefRole):\n     def process_link(self, env: \"BuildEnvironment\", refnode: Element, has_explicit_title: bool,\n                      title: str, target: str) -> Tuple[str, str]:\n         result = super().process_link(env, refnode, has_explicit_title, title, target)\n-        # add all possible context info (i.e. std:program, py:module etc.)\n-        refnode.attributes.update(env.ref_context)\n+        # add only context info for the current domain to avoid leaking global references\n+        if self.refdomain and self.refdomain in env.ref_context:\n+            refnode.attributes[self.refdomain] = env.ref_context[self.refdomain]\n         return result\n \n \n+\n class PEP(ReferenceRole):\n     def run(self) -> Tuple[List[Node], List[system_message]]:\n         target_id = 'index-%s' % self.env.new_serialno('index')\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8721",
        "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..4ee7927fd 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -180,10 +180,11 @@ def should_generate_module_page(app: Sphinx, modname: str) -> bool:\n \n def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], None, None]:\n     env = app.builder.env\n+    # Skip generating viewcode pages for epub builds when viewcode_enable_epub is False.\n+    if app.builder.name.startswith(\"epub\") and not app.config.viewcode_enable_epub:\n+        return\n     if not hasattr(env, '_viewcode_modules'):\n         return\n-    highlighter = app.builder.highlighter  # type: ignore\n-    urito = app.builder.get_relative_uri\n \n     modnames = set(env._viewcode_modules)  # type: ignore\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9229",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9230",
        "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 3a3367ebe..28f70f3d7 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -32,7 +32,43 @@ def _is_single_paragraph(node: nodes.field_body) -> bool:\n                 return False\n     if isinstance(node[0], nodes.paragraph):\n         return True\n-    return False\n+def _split_field_header(text: str) -> Tuple[str, str]:\n+    \"\"\"\n+    Splits a docfield header into a type part and an argument part.\n+    This function handles nested parentheses within the type.\n+    \n+    For example, given:\n+        \"dict(str, str) opc_meta\"\n+    It returns:\n+        (\"dict(str, str)\", \"opc_meta\")\n+    \"\"\"\n+    n = len(text)\n+    i = 0\n+    # Skip any leading whitespace\n+    while i < n and text[i].isspace():\n+        i += 1\n+    start = i\n+    paren_count = 0\n+    # Walk over the text. Increase for '(' and decrease for ')'.\n+    # Stop when encountering whitespace with all parentheses closed.\n+    while i < n:\n+        ch = text[i]\n+        if ch == '(':\n+            paren_count += 1\n+        elif ch == ')':\n+            if paren_count > 0:\n+                paren_count -= 1\n+        elif ch.isspace() and paren_count == 0:\n+            break\n+        i += 1\n+    # The type part is from start to i.\n+    type_part = text[start:i]\n+    # Skip whitespace between the type and the parameter name.\n+    while i < n and text[i].isspace():\n+        i += 1\n+    arg_part = text[i:] if i < n else \"\"\n+    return type_part, arg_part\n+\n \n \n class Field:\n@@ -236,12 +272,11 @@ class DocFieldTransformer:\n             assert len(field) == 2\n             field_name = cast(nodes.field_name, field[0])\n             field_body = cast(nodes.field_body, field[1])\n-            try:\n-                # split into field type and argument\n-                fieldtype_name, fieldarg = field_name.astext().split(None, 1)\n-            except ValueError:\n-                # maybe an argument-less field type?\n-                fieldtype_name, fieldarg = field_name.astext(), ''\n+                # split into field type and argument using smart split that\n+                # handles nested parentheses (e.g. dict(str, str))\n+                raw_field = field_name.astext()\n+                fieldtype_name, fieldarg = _split_field_header(raw_field)\n+\n             typedesc, is_typefield = typemap.get(fieldtype_name, (None, None))\n \n             # collect the content, trying not to keep unnecessary paragraphs\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9258",
        "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 6d48e910c..649adecd8 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -175,17 +175,26 @@ class TypedField(GroupedField):\n             par = nodes.paragraph()\n             par.extend(self.make_xrefs(self.rolename, domain, fieldarg,\n                                        addnodes.literal_strong, env=env))\n-            if fieldarg in types:\n-                par += nodes.Text(' (')\n-                # NOTE: using .pop() here to prevent a single type node to be\n-                # inserted twice into the doctree, which leads to\n-                # inconsistencies later when references are resolved\n-                fieldtype = types.pop(fieldarg)\n-                if len(fieldtype) == 1 and isinstance(fieldtype[0], nodes.Text):\n-                    typename = fieldtype[0].astext()\n-                    par.extend(self.make_xrefs(self.typerolename, domain, typename,\n-                                               addnodes.literal_emphasis, env=env))\n-                else:\n+        par += nodes.Text(' (')\n+        # NOTE: using .pop() here to prevent a single type node to be\n+        # inserted twice into the doctree, which leads to\n+        # inconsistencies later when references are resolved\n+        fieldtype = types.pop(fieldarg)\n+        if len(fieldtype) == 1 and isinstance(fieldtype[0], nodes.Text):\n+            typename = fieldtype[0].astext()\n+            # Split the union type declaration on \"|\" and create xrefs for each type\n+            type_names = [t.strip() for t in typename.split(\"|\")]\n+            xref_nodes = []\n+            for i, t in enumerate(type_names):\n+                if i > 0:\n+                    xref_nodes.append(nodes.Text(\" | \"))\n+                xref_nodes.extend(self.make_xrefs(self.typerolename, domain, t,\n+                                                   addnodes.literal_emphasis, env=env))\n+            par.extend(xref_nodes)\n+        else:\n+            par += fieldtype\n+        par += nodes.Text(\")\")\n+\n                     par += fieldtype\n                 par += nodes.Text(')')\n             par += nodes.Text(' -- ')\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9281",
        "model_patch": "diff --git a/sphinx/ext/autodoc/preserve_defaults.py b/sphinx/ext/autodoc/preserve_defaults.py\nindex 3d859fe8e..a504da20d 100644\n--- a/sphinx/ext/autodoc/preserve_defaults.py\n+++ b/sphinx/ext/autodoc/preserve_defaults.py\n@@ -64,11 +64,20 @@ def update_defvalue(app: Sphinx, obj: Any, bound_method: bool) -> None:\n             for i, param in enumerate(parameters):\n                 if param.default is not param.empty:\n                     if param.kind in (param.POSITIONAL_ONLY, param.POSITIONAL_OR_KEYWORD):\n-                        value = DefaultValue(ast_unparse(defaults.pop(0)))  # type: ignore\n+                        unparsed = ast_unparse(defaults.pop(0))  # type: ignore\n+                        # if the unparsed string represents an enum (e.g., \"<MyEnum.ValueA: 10>\")\n+                        if unparsed.startswith(\"<\") and \":\" in unparsed and unparsed.endswith(\">\"):\n+                            unparsed = unparsed[1:unparsed.index(\":\")]\n+                        value = DefaultValue(unparsed)\n                         parameters[i] = param.replace(default=value)\n+\n                     else:\n-                        value = DefaultValue(ast_unparse(kw_defaults.pop(0)))  # type: ignore\n+                        unparsed = ast_unparse(kw_defaults.pop(0))  # type: ignore\n+                        if unparsed.startswith(\"<\") and \":\" in unparsed and unparsed.endswith(\">\"):\n+                            unparsed = unparsed[1:unparsed.index(\":\")]\n+                        value = DefaultValue(unparsed)\n                         parameters[i] = param.replace(default=value)\n+\n             sig = sig.replace(parameters=parameters)\n             obj.__signature__ = sig\n     except (AttributeError, TypeError):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9320",
        "model_patch": "diff --git a/sphinx/cmd/quickstart.py b/sphinx/cmd/quickstart.py\nindex a40a21073..46be87076 100644\n--- a/sphinx/cmd/quickstart.py\n+++ b/sphinx/cmd/quickstart.py\n@@ -222,7 +222,8 @@ def ask_user(d: Dict) -> None:\n                       'selected root path.')))\n         print(__('sphinx-quickstart will not overwrite existing Sphinx projects.'))\n         print()\n-        d['path'] = do_prompt(__('Please enter a new root path (or just Enter to exit)'),\n+d['path'] = do_prompt(__('Please enter a new root path (or just Enter to exit)'), '', lambda x: '' if not x else is_path(x))\n+\n                               '', is_path)\n         if not d['path']:\n             sys.exit(1)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9367",
        "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex f541ec0a9..09e11069e 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -214,10 +214,15 @@ class _UnparseVisitor(ast.NodeVisitor):\n \n     def visit_Tuple(self, node: ast.Tuple) -> str:\n         if node.elts:\n-            return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n+            # Special-case: single-element tuple should have a trailing comma.\n+            if len(node.elts) == 1:\n+                return \"(\" + self.visit(node.elts[0]) + \",)\"\n+            else:\n+                return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n         else:\n             return \"()\"\n \n+\n     if sys.version_info < (3, 8):\n         # these ast nodes were deprecated in python 3.8\n         def visit_Bytes(self, node: ast.Bytes) -> str:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9461",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 23dd9e930..5335fc762 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -384,15 +384,20 @@ def iscoroutinefunction(obj: Any) -> bool:\n \n \n def isproperty(obj: Any) -> bool:\n-    \"\"\"Check if the object is property.\"\"\"\n     if sys.version_info >= (3, 8):\n         from functools import cached_property  # cached_property is available since py3.8\n         if isinstance(obj, cached_property):\n             return True\n \n+    # Unwrap composite descriptors such as those decorated with @classmethod and @property.\n+    # These objects have a __func__ attribute which should be a property.\n+    if hasattr(obj, '__func__') and isinstance(obj.__func__, property):\n+        return True\n+\n     return isinstance(obj, property)\n \n \n+\n def isgenericalias(obj: Any) -> bool:\n     \"\"\"Check if the object is GenericAlias.\"\"\"\n     if (hasattr(typing, '_GenericAlias') and  # only for py37+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9591",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex af4b47bb0..073943eb9 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -24,6 +24,12 @@ def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n                      options: Dict, args: str, retann: str) -> None:\n     \"\"\"Record type hints to env object.\"\"\"\n     try:\n+        # If the documented object is a property, use the getter method.\n+        if isinstance(obj, property):\n+            if obj.fget is None:\n+                return\n+            obj = obj.fget\n+\n         if callable(obj):\n             annotations = app.env.temp_data.setdefault('annotations', {})\n             annotation = annotations.setdefault(name, OrderedDict())\n@@ -37,6 +43,7 @@ def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n         pass\n \n \n+\n def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element) -> None:\n     if domain != 'py':\n         return\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9602",
        "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 9875a9f4b..c8095ea71 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -82,11 +82,12 @@ class ModuleEntry(NamedTuple):\n \n def type_to_xref(text: str, env: BuildEnvironment = None) -> addnodes.pending_xref:\n     \"\"\"Convert a type string to a cross reference node.\"\"\"\n-    if text == 'None':\n+    if text in ('None', 'True', 'False'):\n         reftype = 'obj'\n     else:\n         reftype = 'class'\n \n+\n     if env:\n         kwargs = {'py:module': env.ref_context.get('py:module'),\n                   'py:class': env.ref_context.get('py:class')}\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9658",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9673",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex af4b47bb0..793cb6d89 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -123,10 +123,11 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str]) -> No\n     if 'return' in annotations and 'return' not in arguments:\n         field = nodes.field()\n         field += nodes.field_name('', 'rtype')\n-        field += nodes.field_body('', nodes.paragraph('', annotation))\n+        field += nodes.field_body('', nodes.paragraph('', annotations['return']))\n         node += field\n \n \n+\n def augment_descriptions_with_types(\n     node: nodes.field_list,\n     annotations: Dict[str, str],\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9698",
        "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex cd02eaad5..f7605e29f 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -793,16 +793,20 @@ class PyMethod(PyObject):\n             else:\n                 return '%s()' % name\n \n+        if 'classmethod' in self.options:\n+            return _('%s() (%s class method)') % (methname, clsname)\n         if 'classmethod' in self.options:\n             return _('%s() (%s class method)') % (methname, clsname)\n         elif 'property' in self.options:\n-            return _('%s() (%s property)') % (methname, clsname)\n+            # Remove the trailing parentheses for property index entries.\n+            return _('%s (%s property)') % (methname, clsname)\n         elif 'staticmethod' in self.options:\n             return _('%s() (%s static method)') % (methname, clsname)\n         else:\n             return _('%s() (%s method)') % (methname, clsname)\n \n \n+\n class PyClassMethod(PyMethod):\n     \"\"\"Description of a classmethod.\"\"\"\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9711",
        "model_patch": "diff --git a/sphinx/extension.py b/sphinx/extension.py\nindex 7ec6c8518..17c1c45cc 100644\n--- a/sphinx/extension.py\n+++ b/sphinx/extension.py\n@@ -38,6 +38,43 @@ class Extension:\n         # the extension does not tell its status.\n         self.parallel_write_safe = kwargs.pop('parallel_write_safe', True)\n \n+from packaging.version import parse\n+\n+\n \n def verify_needs_extensions(app: \"Sphinx\", config: Config) -> None:\n     \"\"\"Verify the required Sphinx extensions are loaded.\"\"\"\n@@ -51,7 +88,8 @@ def verify_needs_extensions(app: \"Sphinx\", config: Config) -> None:\n                               'but it is not loaded.'), extname)\n             continue\n \n-        if extension.version == 'unknown version' or reqversion > extension.version:\n+        if extension.version == 'unknown version' or parse(extension.version) < parse(reqversion):\n+\n             raise VersionRequirementError(__('This project needs the extension %s at least in '\n                                              'version %s and therefore cannot be built with '\n                                              'the loaded version (%s).') %\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-11618",
        "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 593048464b..74a4946010 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -21,6 +21,8 @@\n from sympy.core.numbers import Float\n from sympy.core.evaluate import global_evaluate\n from sympy.core.add import Add\n+from itertools import zip_longest\n+\n \n from .entity import GeometryEntity\n \n@@ -266,8 +268,9 @@ def distance(self, p):\n         sqrt(x**2 + y**2)\n \n         \"\"\"\n-        return sqrt(sum([(a - b)**2 for a, b in zip(\n-            self.args, p.args if isinstance(p, Point) else p)]))\n+return sqrt(sum([(a - b)**2 for a, b in zip_longest(\n+            self.args, p.args if isinstance(p, Point) else p, fillvalue=0)]))\n+\n \n     def taxicab_distance(self, p):\n         \"\"\"The Taxicab Distance from self to point p.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-12096",
        "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 1b8005e1d2..386020631d 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -507,10 +507,12 @@ def _eval_evalf(self, prec):\n             func = getattr(mpmath, fname)\n         except (AttributeError, KeyError):\n             try:\n-                return Float(self._imp_(*self.args), prec)\n+                result = self._imp_(*self.args)\n+                return sympify(result).evalf(prec)\n             except (AttributeError, TypeError, ValueError):\n                 return\n \n+\n         # Convert all args to mpf or mpc\n         # Convert the arguments to *higher* precision than requested for the\n         # final result.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-12419",
        "model_patch": "diff --git a/sympy/matrices/expressions/matexpr.py b/sympy/matrices/expressions/matexpr.py\nindex b4d759836e..1fa581f115 100644\n--- a/sympy/matrices/expressions/matexpr.py\n+++ b/sympy/matrices/expressions/matexpr.py\n@@ -476,10 +476,11 @@ def conjugate(self):\n         return self\n \n     def _entry(self, i, j):\n-        if i == j:\n-            return S.One\n-        else:\n-            return S.Zero\n+        # Instead of checking concrete equality (which fails for dummy symbols),\n+        # return a symbolic KroneckerDelta that represents the identity.\n+        from sympy import KroneckerDelta\n+        return KroneckerDelta(i, j)\n+\n \n     def _eval_determinant(self):\n         return S.One\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-12481",
        "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 136ed5a478..af263a0a83 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -313,33 +313,37 @@ def __iter__(self):\n         for i in self.list():\n             yield i\n \n-    def __call__(self, *other):\n-        \"\"\"Return product of cycles processed from R to L.\n+def __call__(self, *other):\n+    \"\"\"Return product of cycles processed from R to L.\n \n-        Examples\n-        ========\n-\n-        >>> from sympy.combinatorics.permutations import Cycle as C\n-        >>> from sympy.combinatorics.permutations import Permutation as Perm\n-        >>> C(1, 2)(2, 3)\n-        (1 3 2)\n-\n-        An instance of a Cycle will automatically parse list-like\n-        objects and Permutations that are on the right. It is more\n-        flexible than the Permutation in that all elements need not\n-        be present:\n-\n-        >>> a = C(1, 2)\n-        >>> a(2, 3)\n-        (1 3 2)\n-        >>> a(2, 3)(4, 5)\n-        (1 3 2)(4 5)\n+    Examples\n+    ========\n+  \n+    >>> from sympy.combinatorics.permutations import Cycle as C\n+    >>> from sympy.combinatorics.permutations import Permutation as Perm\n+    >>> C(1, 2)(2, 3)\n+    (1 3 2)\n+  \n+    An instance of a Cycle will automatically parse list-like\n+    objects and Permutations that are on the right. It is more\n+    flexible than the Permutation in that all elements need not\n+    be present:\n+  \n+    >>> a = C(1, 2)\n+    >>> a(2, 3)\n+    (1 3 2)\n+    >>> a(2, 3)(4, 5)\n+    (1 3 2)(4 5)\n+  \n+    \"\"\"\n+    rv = Cycle(*other)\n+    temp = {}\n+    for k in self.keys():\n+        temp[k] = rv[self[k]]\n+    for k, v in temp.items():\n+        rv[k] = v\n+    return rv\n \n-        \"\"\"\n-        rv = Cycle(*other)\n-        for k, v in zip(list(self.keys()), [rv[self[k]] for k in self.keys()]):\n-            rv[k] = v\n-        return rv\n \n     def list(self, size=None):\n         \"\"\"Return the cycles as an explicit list starting from 0 up\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-12489",
        "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 4ac1c2ef3b..05731055cd 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -857,19 +857,23 @@ def __new__(cls, *args, **kwargs):\n         #g) (Permutation) = adjust size or return copy\n         ok = True\n         if not args:  # a\n-            return _af_new(list(range(size or 0)))\n-        elif len(args) > 1:  # c\n-            return _af_new(Cycle(*args).list(size))\n-        if len(args) == 1:\n-            a = args[0]\n-            if isinstance(a, Perm):  # g\n-                if size is None or size == a.size:\n-                    return a\n-                return Perm(a.array_form, size=size)\n-            if isinstance(a, Cycle):  # f\n-                return _af_new(a.list(size))\n-            if not is_sequence(a):  # b\n-                return _af_new(list(range(a + 1)))\n+if not args:  # a\n+    return cls._af_new(list(range(size or 0)))\n+elif len(args) > 1:  # c\n+    return cls._af_new(Cycle(*args).list(size))\n+if len(args) == 1:\n+    a = args[0]\n+    if isinstance(a, Perm):  # g\n+        if size is None or size == a.size:\n+            return a\n+        return Perm(a.array_form, size=size)\n+    if isinstance(a, Cycle):  # f\n+        return cls._af_new(a.list(size))\n+    if not is_sequence(a):  # b\n+        return cls._af_new(list(range(a + 1)))\n+    if has_variety(is_sequence(ai) for ai in a):\n+        ok = False\n+\n             if has_variety(is_sequence(ai) for ai in a):\n                 ok = False\n         else:\n@@ -924,30 +928,17 @@ def __new__(cls, *args, **kwargs):\n         obj._size = size\n         return obj\n \n-    @staticmethod\n-    def _af_new(perm):\n-        \"\"\"A method to produce a Permutation object from a list;\n-        the list is bound to the _array_form attribute, so it must\n-        not be modified; this method is meant for internal use only;\n-        the list ``a`` is supposed to be generated as a temporary value\n-        in a method, so p = Perm._af_new(a) is the only object\n-        to hold a reference to ``a``::\n-\n-        Examples\n-        ========\n-\n-        >>> from sympy.combinatorics.permutations import Perm\n-        >>> Perm.print_cyclic = False\n-        >>> a = [2,1,3,0]\n-        >>> p = Perm._af_new(a)\n-        >>> p\n-        Permutation([2, 1, 3, 0])\n+@classmethod\n+def _af_new(cls, perm):\n+    \"\"\"A method to produce a Permutation (or subclass) object from a list;\n+    the list is bound to the _array_form attribute, so it must not be\n+    modified; this method is meant for internal use only.\n+    \"\"\"\n+    p = Basic.__new__(cls, perm)\n+    p._array_form = perm\n+    p._size = len(perm)\n+    return p\n \n-        \"\"\"\n-        p = Basic.__new__(Perm, perm)\n-        p._array_form = perm\n-        p._size = len(perm)\n-        return p\n \n     def _hashable_content(self):\n         # the array_form (a list) is the Permutation arg, so we need to\n@@ -1226,7 +1217,8 @@ def rmul_with_af(*args):\n         which have _array_form\n         \"\"\"\n         a = [x._array_form for x in args]\n-        rv = _af_new(_af_rmuln(*a))\n+rv = args[0].__class__._af_new(_af_rmuln(*a))\n+\n         return rv\n \n     def mul_inv(self, other):\n@@ -1235,7 +1227,8 @@ def mul_inv(self, other):\n         \"\"\"\n         a = _af_invert(self._array_form)\n         b = other._array_form\n-        return _af_new(_af_rmul(a, b))\n+return self.__class__._af_new(_af_rmul(a, b))\n+\n \n     def __rmul__(self, other):\n         \"\"\"This is needed to coerse other to Permutation in rmul.\"\"\"\n@@ -1298,7 +1291,8 @@ def __mul__(self, other):\n         if not b:\n             perm = a\n         else:\n-            b.extend(list(range(len(b), len(a))))\n+return self.__class__._af_new(perm)\n+\n             perm = [b[i] for i in a] + b[len(a):]\n         return _af_new(perm)\n \n@@ -1341,7 +1335,8 @@ def __pow__(self, n):\n             raise NotImplementedError(\n                 'p**p is not defined; do you mean p^p (conjugate)?')\n         n = int(n)\n-        return _af_new(_af_pow(self.array_form, n))\n+return self.__class__._af_new(_af_pow(self.array_form, n))\n+\n \n     def __rxor__(self, i):\n         \"\"\"Return self(i) when ``i`` is an int.\n@@ -1519,7 +1514,8 @@ def __invert__(self):\n         >>> p*~p == ~p*p == Permutation([0, 1, 2, 3])\n         True\n         \"\"\"\n-        return _af_new(_af_invert(self._array_form))\n+return self.__class__._af_new(_af_invert(self._array_form))\n+\n \n     def __iter__(self):\n         \"\"\"Yield elements from array form.\n@@ -1629,7 +1625,8 @@ def next_lex(self):\n                 perm[j], perm[i] = perm[i], perm[j]\n                 i += 1\n                 j -= 1\n-        return _af_new(perm)\n+return self.__class__._af_new(perm)\n+\n \n     @classmethod\n     def unrank_nonlex(self, n, r):\n@@ -2734,7 +2731,8 @@ def from_inversion_vector(self, inversion):\n         except IndexError:\n             raise ValueError(\"The inversion vector is not valid.\")\n         perm.extend(N)\n-        return _af_new(perm)\n+return self._af_new(perm)\n+\n \n     @classmethod\n     def random(self, n):\n@@ -2753,7 +2751,8 @@ def random(self, n):\n         \"\"\"\n         perm_array = list(range(n))\n         random.shuffle(perm_array)\n-        return _af_new(perm_array)\n+return self._af_new(perm_array)\n+\n \n     @classmethod\n     def unrank_lex(self, size, rank):\n@@ -2787,7 +2786,8 @@ def unrank_lex(self, size, rank):\n                 if perm_array[j] > d - 1:\n                     perm_array[j] += 1\n             psize = new_psize\n-        return _af_new(perm_array)\n+return self._af_new(perm_array)\n+\n \n     # global flag to control how permutations are printed\n     # when True, Permutation([0, 2, 1, 3]) -> Cycle(1, 2)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13031",
        "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 7ef51bc847..a11308bf22 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -377,8 +377,10 @@ def hstack(cls, *args):\n         if len(args) == 0:\n             return cls._new()\n \n-        kls = type(args[0])\n-        return reduce(kls.row_join, args)\n+            # Use an instance-bound row_join so that even if the first matrix is empty\n+            # (0x0) the horizontal join correctly accumulates the columns from later matrices.\n+            return reduce(lambda A, B: A.row_join(B), args)\n+\n \n     def reshape(self, rows, cols):\n         \"\"\"Reshape the matrix. Total number of elements must remain the same.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13091",
        "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex db4e971848..79ed2e13a2 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -312,7 +312,8 @@ def __eq__(self, other):\n                 return self == other.base\n             try:\n                 other = _sympify(other)\n-            except SympifyError:\n+\t                return NotImplemented    # sympy does not support comparison for the given type\n+\n                 return False    # sympy != other\n \n             if type(self) != type(other):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13372",
        "model_patch": "diff --git a/sympy/core/evalf.py b/sympy/core/evalf.py\nindex 72a5fbae52..93a15ee95d 100644\n--- a/sympy/core/evalf.py\n+++ b/sympy/core/evalf.py\n@@ -1293,19 +1293,26 @@ def evalf(x, prec, options):\n                 x = x.subs(evalf_subs(prec, options['subs']))\n             xe = x._eval_evalf(prec)\n             re, im = xe.as_real_imag()\n-            if re.has(re_) or im.has(im_):\n-                raise NotImplementedError\n-            if re == 0:\n-                re = None\n-                reprec = None\n-            elif re.is_number:\n-                re = re._to_mpmath(prec, allow_ints=False)._mpf_\n-                reprec = prec\n-            if im == 0:\n-                im = None\n-                imprec = None\n-            elif im.is_number:\n-                im = im._to_mpmath(prec, allow_ints=False)._mpf_\n+if re == 0:\n+    re = None\n+    reprec = None\n+elif re.is_number:\n+    re = re._to_mpmath(prec, allow_ints=False)._mpf_\n+    reprec = prec\n+else:\n+    raise NotImplementedError(\"Don't know how to evaluate %s numerically\" % re)\n+\n+if im == 0:\n+    im = None\n+    imprec = None\n+elif im.is_number:\n+    im = im._to_mpmath(prec, allow_ints=False)._mpf_\n+    imprec = prec\n+elif im:\n+    raise NotImplementedError(\"Don't know how to evaluate %s numerically\" % im)\n+\n+r = re, im, reprec, imprec\n+\n                 imprec = prec\n             r = re, im, reprec, imprec\n         except AttributeError:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13480",
        "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 2a4555d919..f2519803b3 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,8 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                        if cothm is S.ComplexInfinity:\n+\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13551",
        "model_patch": "diff --git a/sympy/concrete/products.py b/sympy/concrete/products.py\nindex 66aafde2d6..8a8fb48282 100644\n--- a/sympy/concrete/products.py\n+++ b/sympy/concrete/products.py\n@@ -274,19 +274,20 @@ def _eval_product(self, term, limits):\n \n             return poly.LC()**(n - a + 1) * A * B\n \n-        elif term.is_Add:\n-            p, q = term.as_numer_denom()\n-            q = self._eval_product(q, (k, a, n))\n-            if q.is_Number:\n-\n-                # There is expression, which couldn't change by\n-                # as_numer_denom(). E.g. n**(2/3) + 1 --> (n**(2/3) + 1, 1).\n-                # We have to catch this case.\n+            elif term.is_Add:\n+                p, q = term.as_numer_denom()\n+                q = self._eval_product(q, (k, a, n))\n+                if q.is_Number:\n+                    # There is an expression that couldn't be decomposed by\n+                    # as_numer_denom(), e.g. n**(2/3) + 1 --> (n**(2/3) + 1, 1).\n+                    # In this context, the proper calculation requires multiplying\n+                    # the products corresponding to each piece of the additive term.\n+                    from sympy import Mul\n+                    p = Mul(*[self._eval_product(i, (k, a, n)) for i in p.as_coeff_Add()])\n+                else:\n+                    p = self._eval_product(p, (k, a, n))\n+                return p / q\n \n-                p = sum([self._eval_product(i, (k, a, n)) for i in p.as_coeff_Add()])\n-            else:\n-                p = self._eval_product(p, (k, a, n))\n-            return p / q\n \n         elif term.is_Mul:\n             exclude, include = [], []\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13615",
        "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 917717bb74..882e0da5c1 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1933,6 +1933,89 @@ def _intersect(self, other):\n     def _complement(self, other):\n         if isinstance(other, Interval):\n             nums = sorted(m for m in self.args if m.is_number)\n+            if nums and len(nums) != len(self.args):\n+\n+\n+                return None\n+\n+\n             if other == S.Reals and nums != []:\n                 syms = [m for m in self.args if m.is_Symbol]\n                 # Reals cannot contain elements other than numbers and symbols.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13647",
        "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 056d9bc497..c3090745b2 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -86,10 +86,10 @@ def entry(i, j):\n                 return self[i, j]\n             elif pos <= j < pos + other.cols:\n                 return other[i, j - pos]\n-            return self[i, j - pos - other.cols]\n+            return self[i, j - other.cols]\n+\n+        return self._new(self.rows, self.cols + other.cols, entry)\n \n-        return self._new(self.rows, self.cols + other.cols,\n-                         lambda i, j: entry(i, j))\n \n     def _eval_col_join(self, other):\n         rows = self.rows\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13757",
        "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex d5ac051f63..3f669457c2 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -4047,15 +4047,15 @@ def __mul__(f, g):\n \n         return f.mul(g)\n \n-    @_sympifyit('g', NotImplemented)\n-    def __rmul__(f, g):\n-        if not g.is_Poly:\n-            try:\n-                g = f.__class__(g, *f.gens)\n-            except PolynomialError:\n-                return g*f.as_expr()\n+@_sympifyit('g', NotImplemented)\n+def __rmul__(f, g):\n+    if not g.is_Poly:\n+        try:\n+            g = f.__class__(g, *f.gens)\n+        except PolynomialError:\n+            return g*f.as_expr()\n+    return f.mul(g)\n \n-        return g.mul(f)\n \n     @_sympifyit('n', NotImplemented)\n     def __pow__(f, n):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13798",
        "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex ad4d7d9613..e0eb7ee9f5 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -155,12 +155,14 @@ def __init__(self, settings=None):\n             \"dot\": r\" \\cdot \",\n             \"times\": r\" \\times \"\n         }\n+        mul_sym = self._settings.get('mul_symbol', None)\n+        if mul_sym in mul_symbol_table:\n+            self._settings['mul_symbol_latex'] = mul_symbol_table[mul_sym]\n+            self._settings['mul_symbol_latex_numbers'] = mul_symbol_table[mul_sym or 'dot']\n+        else:\n+            self._settings['mul_symbol_latex'] = mul_sym\n+            self._settings['mul_symbol_latex_numbers'] = mul_sym\n \n-        self._settings['mul_symbol_latex'] = \\\n-            mul_symbol_table[self._settings['mul_symbol']]\n-\n-        self._settings['mul_symbol_latex_numbers'] = \\\n-            mul_symbol_table[self._settings['mul_symbol'] or 'dot']\n \n         self._delim_dict = {'(': ')', '[': ']'}\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13852",
        "model_patch": "diff --git a/sympy/functions/special/zeta_functions.py b/sympy/functions/special/zeta_functions.py\nindex b8e2b66195..d8408f0389 100644\n--- a/sympy/functions/special/zeta_functions.py\n+++ b/sympy/functions/special/zeta_functions.py\n@@ -291,7 +291,8 @@ def _eval_expand_func(self, **hints):\n         from sympy import log, expand_mul, Dummy, exp_polar, I\n         s, z = self.args\n         if s == 1:\n-            return -log(1 + exp_polar(-I*pi)*z)\n+            return -log(1 - z)\n+\n         if s.is_Integer and s <= 0:\n             u = Dummy('u')\n             start = u/(1 - u)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13877",
        "model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex 97cde62e26..fea6dc8fb9 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -205,11 +205,11 @@ def bareiss(mat, cumm=1):\n             cols = list(range(mat.cols))\n             tmp_mat = mat.extract(rows, cols)\n \n-            def entry(i, j):\n-                ret = (pivot_val*tmp_mat[i, j + 1] - mat[pivot_pos, j + 1]*tmp_mat[i, 0]) / cumm\n-                if not ret.is_Atom:\n-                    cancel(ret)\n-                return ret\n+def entry(i, j):\n+    ret = (pivot_val*tmp_mat[i, j + 1] - mat[pivot_pos, j + 1]*tmp_mat[i, 0]) / cumm\n+    if not ret.is_Atom:\n+        ret = cancel(ret)\n+    return ret\n \n             return sign*bareiss(self._new(mat.rows - 1, mat.cols - 1, entry), pivot_val)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13878",
        "model_patch": "diff --git a/sympy/stats/crv_types.py b/sympy/stats/crv_types.py\nindex fff7da80ae..7b0c25f60f 100644\n--- a/sympy/stats/crv_types.py\n+++ b/sympy/stats/crv_types.py\n@@ -45,7 +45,8 @@\n \n from __future__ import print_function, division\n \n-from sympy import (log, sqrt, pi, S, Dummy, Interval, sympify, gamma,\n+from sympy import (log, sqrt, pi, S, Dummy, Interval, sympify, gamma, Piecewise, And, Eq, binomial, factorial, Sum, floor, Abs, Lambda, Basic, lowergamma, erf, erfc, I, asin, _2F_1)\n+\n                    Piecewise, And, Eq, binomial, factorial, Sum, floor, Abs,\n                    Lambda, Basic, lowergamma, erf, erfc, I)\n from sympy import beta as beta_fn\n@@ -151,6 +152,289 @@ class ArcsinDistribution(SingleContinuousDistribution):\n     _argnames = ('a', 'b')\n \n     def pdf(self, x):\n+    def _cdf(self, x):\n+\n+\n+        # CDF for x in [a, b] is 2/pi * asin(sqrt((x-a)/(b-a)))\n+\n+\n+        return Piecewise(\n+\n+\n+            (0, x < self.a),\n+\n+\n+            ((2/pi)*asin(sqrt((x - self.a)/(self.b - self.a))), And(x >= self.a, x <= self.b)),\n+\n+\n+            (1, x > self.b)\n+\n+\n+        )\n+\n+\n         return 1/(pi*sqrt((x - self.a)*(self.b - x)))\n \n def Arcsin(name, a=0, b=1):\n@@ -670,6 +954,214 @@ def pdf(self, x):\n         p, a, b = self.p, self.a, self.b\n         return a*p/x*((x/b)**(a*p)/(((x/b)**a + 1)**(p + 1)))\n \n+    def _cdf(self, x):\n+\n+\n+        # Dagum CDF: for x>0, F(x)= (1+(x/b)**(-a))^(-p)\n+\n+\n+        return Piecewise(\n+\n+\n+            (0, x <= 0),\n+\n+\n+            (((1 + (x/self.b)**(-self.a))**(-self.p), True))\n+\n+\n+        )\n+\n+\n \n def Dagum(name, p, a, b):\n     r\"\"\"\n@@ -1199,6 +1691,292 @@ def check(a, b):\n     def pdf(self, x):\n         a, b = self.a, self.b\n         return b**a/gamma(a) * x**(-a-1) * exp(-b/x)\n+    def _cdf(self, x):\n+\n+\n+        # Inverse-Gamma CDF: for x>0, F(x)= uppergamma(a, b/x)/gamma(a)\n+\n+\n+        # (Note: uppergamma is used here; x<=0 returns 0.)\n+\n+\n+        return Piecewise(\n+\n+\n+            (0, x <= 0),\n+\n+\n+            (uppergamma(self.a, self.b/x)/gamma(self.a), x > 0)\n+\n+\n+        )\n+\n+\n \n def GammaInverse(name, a, b):\n     r\"\"\"\n@@ -1377,6 +2155,260 @@ class KumaraswamyDistribution(SingleContinuousDistribution):\n     set = Interval(0, oo)\n \n     @staticmethod\n+    def _cdf(self, x):\n+\n+\n+        # Kumaraswamy CDF: for x in [0,1]: F(x)= 1 - (1 - x**self.a)**self.b\n+\n+\n+        return Piecewise(\n+\n+\n+            (0, x < 0),\n+\n+\n+            (1 - (1 - x**self.a)**self.b, And(x >= 0, x <= 1)),\n+\n+\n+            (1, x > 1)\n+\n+\n+        )\n+\n+\n     def check(a, b):\n         _value_check(a > 0, \"a must be positive\")\n         _value_check(b > 0, \"b must be positive\")\n@@ -1437,6 +2469,317 @@ def Kumaraswamy(name, a, b):\n #-------------------------------------------------------------------------------\n # Laplace distribution ---------------------------------------------------------\n \n+    def _cdf(self, x):\n+\n+\n+        # Laplace CDF:\n+\n+\n+        #  for x < mu: F(x)= 1/2 exp((x-mu)/b)\n+\n+\n+        #  for x >= mu: F(x)= 1 - 1/2 exp(-(x-mu)/b)\n+\n+\n+        return Piecewise(\n+\n+\n+            (S.One/2*exp((x - self.mu)/self.b), x < self.mu),\n+\n+\n+            (1 - S.One/2*exp(-(x - self.mu)/self.b), True)\n+\n+\n+        )\n+\n+\n \n class LaplaceDistribution(SingleContinuousDistribution):\n     _argnames = ('mu', 'b')\n@@ -1497,6 +2840,133 @@ def Laplace(name, mu, b):\n class LogisticDistribution(SingleContinuousDistribution):\n     _argnames = ('mu', 's')\n \n+    def _cdf(self, x):\n+\n+\n+        # Logistic CDF: F(x)= 1/(1+exp(-(x-mu)/s))\n+\n+\n+        return 1/(1 + exp(-(x - self.mu)/self.s))\n+\n+\n     def pdf(self, x):\n         mu, s = self.mu, self.s\n         return exp(-(x - mu)/s)/(s*(1 + exp(-(x - mu)/s))**2)\n@@ -1708,6 +3178,255 @@ class NakagamiDistribution(SingleContinuousDistribution):\n     set = Interval(0, oo)\n \n     def pdf(self, x):\n+    def _cdf(self, x):\n+\n+\n+        # Nakagami CDF: for x>=0, F(x)= lowergamma(mu, mu*x**2/omega)/gamma(mu)\n+\n+\n+        return Piecewise(\n+\n+\n+            (0, x < 0),\n+\n+\n+            (lowergamma(self.mu, self.mu*x**2/self.omega)/gamma(self.mu), True)\n+\n+\n+        )\n+\n+\n         mu, omega = self.mu, self.omega\n         return 2*mu**mu/(gamma(mu)*omega**mu)*x**(2*mu - 1)*exp(-mu/omega*x**2)\n \n@@ -2224,6 +3943,355 @@ class StudentTDistribution(SingleContinuousDistribution):\n     _argnames = ('nu',)\n \n     def pdf(self, x):\n+    def _cdf(self, x):\n+\n+\n+        nu = self.nu\n+\n+\n+        # Student-T CDF in closed-form using hypergeometric function:\n+\n+\n+        # F(x)= 1/2 + x*Gamma((nu+1)/2)*_2F_1(1/2, (nu+1)/2; 3/2; -x**2/nu)/\n+\n+\n+        #       (sqrt(pi*nu)*Gamma(nu/2))\n+\n+\n+        return S.Half + x*gamma((nu+1)/2)*_2F_1(S.Half, (nu+1)/2, S(3)/2, -x**2/nu)/(sqrt(pi*nu)*gamma(nu/2))\n+\n+\n         nu = self.nu\n         return 1/(sqrt(nu)*beta_fn(S(1)/2, nu/2))*(1 + x**2/nu)**(-(nu + 1)/2)\n \n@@ -2554,6 +4622,406 @@ def pdf(self, x):\n         return 1/factorial(\n             n - 1)*Sum((-1)**k*binomial(n, k)*(x - k)**(n - 1), (k, 0, floor(x)))\n \n+    def _cdf(self, x):\n+\n+\n+        # Irwin\u2013Hall CDF:\n+\n+\n+        # For x in [0,n]: F(x)= 1/(n-1)! * Sum_{k=0}^{floor(x)} (-1)^k binomial(n,k)*(x-k)**(n-1)\n+\n+\n+        return Piecewise(\n+\n+\n+            (0, x < 0),\n+\n+\n+            (Sum((-1)**k*binomial(self.n, k)*(x - k)**(self.n - 1), (k, 0, floor(x))).doit()/factorial(self.n - 1),\n+\n+\n+             And(x >= 0, x <= self.n)),\n+\n+\n+            (1, x > self.n)\n+\n+\n+        )\n+\n+\n \n \n def UniformSum(name, n):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13974",
        "model_patch": "diff --git a/sympy/physics/quantum/tensorproduct.py b/sympy/physics/quantum/tensorproduct.py\nindex 9dd10d219e..b96ef3c09e 100644\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -382,8 +382,8 @@ def tensor_product_simp(e, **hints):\n     if isinstance(e, Add):\n         return Add(*[tensor_product_simp(arg) for arg in e.args])\n     elif isinstance(e, Pow):\n-        return tensor_product_simp(e.base) ** e.exp\n-    elif isinstance(e, Mul):\n+        return (tensor_product_simp(e.base) ** e.exp).doit()\n+\n         return tensor_product_simp_Mul(e)\n     elif isinstance(e, Commutator):\n         return Commutator(*[tensor_product_simp(arg) for arg in e.args])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-14248",
        "model_patch": "diff --git a/sympy/printing/str.py b/sympy/printing/str.py\nindex 0baefe0f7f..38e97b9f07 100644\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -54,17 +54,18 @@ def _print_Add(self, expr, order=None):\n \n         PREC = precedence(expr)\n         l = []\n-        for term in terms:\n-            t = self._print(term)\n-            if t.startswith('-'):\n-                sign = \"-\"\n-                t = t[1:]\n-            else:\n-                sign = \"+\"\n-            if precedence(term) < PREC:\n-                l.extend([sign, \"(%s)\" % t])\n-            else:\n-                l.extend([sign, t])\n+    for term in terms:\n+        t = self._print(term)\n+        # detect negative factor even if printed as \"(-1)*...\"\n+        if t.startswith(\"(-1)*\"):\n+            sign = \"-\"\n+            t = t[5:]\n+        elif t.startswith('-'):\n+            sign = \"-\"\n+            t = t[1:]\n+        else:\n+            sign = \"+\"\n+\n         sign = l.pop(0)\n         if sign == '+':\n             sign = \"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-14531",
        "model_patch": "diff --git a/sympy/printing/str.py b/sympy/printing/str.py\nindex cc1d19fcce..1b6dfa0e14 100644\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -216,9 +216,14 @@ def _print_LatticeOp(self, expr):\n     def _print_Limit(self, expr):\n         e, z, z0, dir = expr.args\n         if str(dir) == \"+\":\n-            return \"Limit(%s, %s, %s)\" % (e, z, z0)\n+            return \"Limit(%s, %s, %s)\" % (self._print(e),\n+                                         self._print(z),\n+                                         self._print(z0))\n         else:\n-            return \"Limit(%s, %s, %s, dir='%s')\" % (e, z, z0, dir)\n+            return \"Limit(%s, %s, %s, dir='%s')\" % (self._print(e),\n+                                                    self._print(z),\n+                                                    self._print(z0), dir)\n+\n \n     def _print_list(self, expr):\n         return \"[%s]\" % self.stringify(expr, \", \")\n@@ -628,12 +633,14 @@ def _print_Relational(self, expr):\n             \"/=\": \"DivAugmentedAssignment\",\n             \"%=\": \"ModAugmentedAssignment\",\n         }\n-\n         if expr.rel_op in charmap:\n-            return '%s(%s, %s)' % (charmap[expr.rel_op], expr.lhs, expr.rhs)\n-\n+            return '%s(%s, %s)' % (charmap[expr.rel_op],\n+                                   self._print(expr.lhs),\n+                                   self._print(expr.rhs))\n         return '%s %s %s' % (self.parenthesize(expr.lhs, precedence(expr)),\n-                           self._relationals.get(expr.rel_op) or expr.rel_op,\n+                             self._relationals.get(expr.rel_op) or expr.rel_op,\n+                             self.parenthesize(expr.rhs, precedence(expr)))\n+\n                            self.parenthesize(expr.rhs, precedence(expr)))\n \n     def _print_ComplexRootOf(self, expr):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-14711",
        "model_patch": "diff --git a/sympy/physics/vector/vector.py b/sympy/physics/vector/vector.py\nindex a048ee57f1..3b0c9b89de 100644\n--- a/sympy/physics/vector/vector.py\n+++ b/sympy/physics/vector/vector.py\n@@ -98,14 +98,17 @@ def __and__(self, other):\n                 out += ((v2[0].T)\n                         * (v2[1].dcm(v1[1]))\n                         * (v1[0]))[0]\n-        if Vector.simp:\n-            return trigsimp(sympify(out), recursive=True)\n-        else:\n-            return sympify(out)\n+    def __add__(self, other):\n+        if other == 0:\n+            return self\n+        other = _check_vector(other)\n+        return Vector(self.args + other.args)\n \n     def __div__(self, other):\n-        \"\"\"This uses mul and inputs self and 1 divided by other. \"\"\"\n-        return self.__mul__(sympify(1) / other)\n+    def __radd__(self, other):\n+        if other == 0:\n+            return self\n+        return self.__add__(other)\n \n     __truediv__ = __div__\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-14976",
        "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex d06901425d..68a22c8685 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -321,6 +321,256 @@ class MpmathPrinter(PythonCodePrinter):\n         _known_functions.items(),\n         [(k, 'mpmath.' + v) for k, v in _known_functions_mpmath.items()]\n     ))\n+    def _print_Rational(self, expr):\n+\n+\n+        \"\"\"\n+\n+\n+        Wrap rational numbers in a call to mpmath.mpf to ensure\n+\n+\n+        high-precision arithmetic is used.\n+\n+\n+        \"\"\"\n+\n+\n+        return \"{0}('{1}')\".format(self._module_format('mpmath.mpf'), expr)\n+\n+\n \n     def _print_Float(self, e):\n         # XXX: This does not handle setting mpmath.mp.dps. It is assumed that\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15017",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15345",
        "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex ea7e3a2d94..cd07508e7e 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -114,6 +114,179 @@ def _print_Sum(self, expr):\n     def _print_Derivative(self, expr):\n         dexpr = expr.expr\n         dvars = [i[0] if i[1] == 1 else i for i in expr.variable_count]\n+    def _print_Max(self, expr):\n+\n+\n+        # Fix: Print Max with square brackets and preserve the argument order.\n+\n+\n+        return \"Max[%s]\" % self.stringify(expr.args, \", \")\n+\n+\n         return \"Hold[D[\" + ', '.join(self.doprint(a) for a in [dexpr] + dvars) + \"]]\"\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15349",
        "model_patch": "diff --git a/sympy/algebras/quaternion.py b/sympy/algebras/quaternion.py\nindex b84e7cb95a..5940680445 100644\n--- a/sympy/algebras/quaternion.py\n+++ b/sympy/algebras/quaternion.py\n@@ -529,7 +529,8 @@ def to_rotation_matrix(self, v=None):\n \n         m10 = 2*s*(q.b*q.c + q.d*q.a)\n         m11 = 1 - 2*s*(q.b**2 + q.d**2)\n-        m12 = 2*s*(q.c*q.d + q.b*q.a)\n+\t        m12 = 2*s*(q.c*q.d - q.b*q.a)\n+\n \n         m20 = 2*s*(q.b*q.d - q.c*q.a)\n         m21 = 2*s*(q.c*q.d + q.b*q.a)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15599",
        "model_patch": "diff --git a/sympy/core/mod.py b/sympy/core/mod.py\nindex eae25630cc..e7c706b5ca 100644\n--- a/sympy/core/mod.py\n+++ b/sympy/core/mod.py\n@@ -123,21 +123,23 @@ def doit(p, q):\n             for arg in p.args:\n                 both_l[isinstance(arg, cls)].append(arg)\n \n-            if mod_l and all(inner.args[1] == q for inner in mod_l):\n-                # finding distributive term\n-                non_mod_l = [cls(x, q) for x in non_mod_l]\n-                mod = []\n-                non_mod = []\n-                for j in non_mod_l:\n-                    if isinstance(j, cls):\n-                        mod.append(j.args[0])\n-                    else:\n-                        non_mod.append(j)\n-                prod_mod = Mul(*mod)\n-                prod_non_mod = Mul(*non_mod)\n-                prod_mod1 = Mul(*[i.args[0] for i in mod_l])\n-                net = prod_mod1*prod_mod\n-                return prod_non_mod*cls(net, q)\n+was = non_mod_l[:]\n+non_mod_l = [cls(x, q) for x in non_mod_l]\n+changed = was != non_mod_l\n+if changed or (mod_l and all(inner.args[1] == q for inner in mod_l)):\n+    # finding distributive term\n+    mod = []\n+    non_mod = []\n+    for j in non_mod_l:\n+        if isinstance(j, cls):\n+            mod.append(j.args[0])\n+        else:\n+            non_mod.append(j)\n+    prod_mod = Mul(*mod)\n+    prod_non_mod = Mul(*non_mod)\n+    prod_mod1 = Mul(*[i.args[0] for i in mod_l])\n+    net = prod_mod1 * prod_mod\n+    return prod_non_mod * cls(net, q)\n \n         # XXX other possibilities?\n \ndiff --git a/sympy/core/tests/test_arit.py b/sympy/core/tests/test_arit.py\nindex 04d3b1ab9f..05e2d1979b 100644\n--- a/sympy/core/tests/test_arit.py\n+++ b/sympy/core/tests/test_arit.py\n@@ -1624,6 +1624,7 @@ def test_Mod():\n     i = Symbol('i', integer=True)\n     assert (3*i*x) % (2*i*y) == i*Mod(3*x, 2*y)\n     assert Mod(4*i, 4) == 0\n+    assert Mod(3*i, 2) == Mod(i, 2)\n \n     # issue 8677\n     n = Symbol('n', integer=True, positive=True)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15809",
        "model_patch": "diff --git a/sympy/functions/elementary/miscellaneous.py b/sympy/functions/elementary/miscellaneous.py\nindex 5f9fe73c5c..77e1efed61 100644\n--- a/sympy/functions/elementary/miscellaneous.py\n+++ b/sympy/functions/elementary/miscellaneous.py\n@@ -340,7 +340,8 @@ def real_root(arg, n=None, evaluate=None):\n class MinMaxBase(Expr, LatticeOp):\n     def __new__(cls, *args, **assumptions):\n         if not args:\n-            raise ValueError(\"The Max/Min functions must have arguments.\")\n+            return cls.identity\n+\n \n         args = (sympify(arg) for arg in args)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15875",
        "model_patch": "diff --git a/sympy/core/add.py b/sympy/core/add.py\nindex 83a5f2aedc..1d18c344cf 100644\n--- a/sympy/core/add.py\n+++ b/sympy/core/add.py\n@@ -558,13 +558,11 @@ def _eval_is_zero(self):\n             return None\n         b = self.func(*nz)\n         if b.is_zero:\n-            if not im_or_z and not im:\n-                return True\n-            if im and not im_or_z:\n-                return False\n+            return True\n         if b.is_zero is False:\n             return False\n \n+\n     def _eval_is_odd(self):\n         l = [f for f in self.args if not (f.is_even is True)]\n         if not l:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15976",
        "model_patch": "diff --git a/sympy/printing/mathml.py b/sympy/printing/mathml.py\nindex 3f8b8d49e0..5ed1873199 100644\n--- a/sympy/printing/mathml.py\n+++ b/sympy/printing/mathml.py\n@@ -743,10 +743,10 @@ def _print_Sum(self, e):\n         return mrow\n \n     def _print_Symbol(self, sym, style='plain'):\n-        x = self.dom.createElement('mi')\n-\n         if style == 'bold':\n-            x.setAttribute('mathvariant', 'bold')\n+            attr = {'mathvariant': 'bold'}\n+        else:\n+            attr = {}\n \n         def join(items):\n             if len(items) > 1:\n@@ -777,29 +777,39 @@ def translate(s):\n         supers = [translate(sup) for sup in supers]\n         subs = [translate(sub) for sub in subs]\n \n+        # Create base <mi> element for the main symbol letter\n         mname = self.dom.createElement('mi')\n+        for key, value in attr.items():\n+            mname.setAttribute(key, value)\n         mname.appendChild(self.dom.createTextNode(name))\n-        if len(supers) == 0:\n-            if len(subs) == 0:\n-                x.appendChild(self.dom.createTextNode(name))\n-            else:\n-                msub = self.dom.createElement('msub')\n-                msub.appendChild(mname)\n-                msub.appendChild(join(subs))\n-                x.appendChild(msub)\n+\n+        if not supers and not subs:\n+            # Simple identifier without subscript or superscript\n+            mi = self.dom.createElement('mi')\n+            for key, value in attr.items():\n+                mi.setAttribute(key, value)\n+            mi.appendChild(self.dom.createTextNode(name))\n+            return mi\n+        elif not supers:\n+            # Only subscript present, return <msub> directly\n+            msub = self.dom.createElement('msub')\n+            msub.appendChild(mname)\n+            msub.appendChild(join(subs))\n+            return msub\n+        elif not subs:\n+            # Only superscript present, return <msup> directly\n+            msup = self.dom.createElement('msup')\n+            msup.appendChild(mname)\n+            msup.appendChild(join(supers))\n+            return msup\n         else:\n-            if len(subs) == 0:\n-                msup = self.dom.createElement('msup')\n-                msup.appendChild(mname)\n-                msup.appendChild(join(supers))\n-                x.appendChild(msup)\n-            else:\n-                msubsup = self.dom.createElement('msubsup')\n-                msubsup.appendChild(mname)\n-                msubsup.appendChild(join(subs))\n-                msubsup.appendChild(join(supers))\n-                x.appendChild(msubsup)\n-        return x\n+            # Both subscript and superscript present, return <msubsup> directly\n+            msubsup = self.dom.createElement('msubsup')\n+            msubsup.appendChild(mname)\n+            msubsup.appendChild(join(subs))\n+            msubsup.appendChild(join(supers))\n+            return msubsup\n+\n \n     def _print_MatrixSymbol(self, sym):\n         return self._print_Symbol(sym, style=self._settings['mat_symbol_style'])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16450",
        "model_patch": "diff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex c6b511f206..b8ef559031 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -251,8 +251,9 @@ def posify(eq):\n             eq[i] = e.subs(reps)\n         return f(eq), {r: s for s, r in reps.items()}\n \n-    reps = {s: Dummy(s.name, positive=True)\n-                 for s in eq.free_symbols if s.is_positive is None}\n+    reps = {s: Dummy(s.name, positive=True, **{k: v for k, v in s.assumptions0.items() if k != 'positive'})\n+             for s in eq.free_symbols if s.is_positive is None}\n+\n     eq = eq.subs(reps)\n     return eq, {r: s for s, r in reps.items()}\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16597",
        "model_patch": "diff --git a/sympy/core/assumptions.py b/sympy/core/assumptions.py\nindex ce4dd30f2e..cf8f87c590 100644\n--- a/sympy/core/assumptions.py\n+++ b/sympy/core/assumptions.py\n@@ -174,6 +174,40 @@\n \n     'odd            ==  integer & !even',\n     'even           ==  integer & !odd',\n+    'even           ->  finite',\n+\n+\n \n     'real           ==  negative | zero | positive',\n     'transcendental ==  complex & !algebraic',\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16766",
        "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex a3f0310735..547fe1d576 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -356,6 +356,178 @@ def _print_sign(self, e):\n     def _print_Not(self, expr):\n         PREC = precedence(expr)\n         return self._operators['not'] + self.parenthesize(expr.args[0], PREC)\n+    def _print_Indexed(self, expr):\n+\n+\n+        base, *indices = expr.args\n+\n+\n+        return \"{}[{}]\".format(self._print(base), \", \".join(self._print(ind) for ind in indices))\n+\n+\n \n \n for k in PythonCodePrinter._kf:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16792",
        "model_patch": "diff --git a/sympy/utilities/codegen.py b/sympy/utilities/codegen.py\nindex f0befb2bd7..28df4d472b 100644\n--- a/sympy/utilities/codegen.py\n+++ b/sympy/utilities/codegen.py\n@@ -735,11 +735,13 @@ def routine(self, name, expr, argument_sequence=None, global_vars=None):\n             # create redundant arguments to produce the requested sequence\n             name_arg_dict = {x.name: x for x in arg_list}\n             new_args = []\n-            for symbol in argument_sequence:\n-                try:\n-                    new_args.append(name_arg_dict[symbol])\n-                except KeyError:\n-                    new_args.append(InputArgument(symbol))\n+                for symbol in argument_sequence:\n+                    try:\n+                        new_args.append(name_arg_dict[symbol])\n+                    except KeyError:\n+                        # Preserve dimensions if symbol has a 'shape' attribute (e.g. MatrixSymbol)\n+                        new_args.append(InputArgument(symbol, dimensions=getattr(symbol, 'shape', None)))\n+\n             arg_list = new_args\n \n         return Routine(name, arg_list, return_val, local_vars, global_vars)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16886",
        "model_patch": "diff --git a/sympy/crypto/crypto.py b/sympy/crypto/crypto.py\nindex ca552191c0..10891b05f2 100644\n--- a/sympy/crypto/crypto.py\n+++ b/sympy/crypto/crypto.py\n@@ -1520,7 +1520,8 @@ def decipher_kid_rsa(msg, key):\n     \"..-\": \"U\", \"...-\": \"V\",\n     \".--\": \"W\", \"-..-\": \"X\",\n     \"-.--\": \"Y\", \"--..\": \"Z\",\n-    \"-----\": \"0\", \"----\": \"1\",\n+    \"-----\": \"0\", \".----\": \"1\",\n+\n     \"..---\": \"2\", \"...--\": \"3\",\n     \"....-\": \"4\", \".....\": \"5\",\n     \"-....\": \"6\", \"--...\": \"7\",\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-17139",
        "model_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\nindex ad1130ef96..26eed97522 100644\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,7 +501,8 @@ def _f(rv):\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n \n-        if (rv.exp < 0) == True:\n+        if rv.exp.is_real and (rv.exp < 0):\n+\n             return rv\n         if (rv.exp > max) == True:\n             return rv\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-17318",
        "model_patch": "diff --git a/sympy/simplify/radsimp.py b/sympy/simplify/radsimp.py\nindex 216ae26204..b5e2c748b5 100644\n--- a/sympy/simplify/radsimp.py\n+++ b/sympy/simplify/radsimp.py\n@@ -1076,8 +1076,11 @@ def split_surds(expr):\n     args = sorted(expr.args, key=default_sort_key)\n     coeff_muls = [x.as_coeff_Mul() for x in args]\n     surds = [x[1]**2 for x in coeff_muls if x[1].is_Pow]\n-    surds.sort(key=default_sort_key)\n-    g, b1, b2 = _split_gcd(*surds)\n+surds.sort(key=default_sort_key)\n+if not surds:\n+    return 1, S.Zero, expr\n+g, b1, b2 = _split_gcd(*surds)\n+\n     g2 = g\n     if not b2 and len(b1) >= 2:\n         b1n = [x/g for x in b1]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-17630",
        "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..056dbd1910 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -164,8 +164,28 @@ def structurally_equal(self, other):\n     def _blockmul(self, other):\n         if (isinstance(other, BlockMatrix) and\n                 self.colblocksizes == other.rowblocksizes):\n-            return BlockMatrix(self.blocks*other.blocks)\n-\n+            # Compute the product of the block matrices.\n+            prod = self.blocks * other.blocks\n+\n+            # Iterate over each entry in the product.\n+            # When an entry equals the additive identity (0),\n+            # replace it with a proper ZeroMatrix carrying the correct dimensions.\n+            new_data = []\n+            for i in range(prod.rows):\n+                row_data = []\n+                for j in range(prod.cols):\n+                    entry = prod[i, j]\n+                    if entry == 0:\n+                        # Determine the dimensions:\n+                        # For row i, use the row size from self.blocks[i, 0]\n+                        # For column j, use the column size from other.blocks[0, j]\n+                        r = self.blocks[i, 0].shape[0]\n+                        c = other.blocks[0, j].shape[1]\n+                        row_data.append(ZeroMatrix(r, c))\n+                    else:\n+                        row_data.append(entry)\n+                new_data.append(row_data)\n+            return BlockMatrix(new_data)\n         return self * other\n \n     def _blockadd(self, other):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-17655",
        "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..e5d69d9c80 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -278,6 +278,385 @@ def __mul__(self, factor):\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n \n+    def __rmul__(self, factor):\n+\n+\n+        \"\"\"Right multiplication: allow scalar * Point to work as expected.\n+\n+\n+        \n+\n+\n+        Example\n+\n+\n+        =======\n+\n+\n+        \n+\n+\n+        >>> from sympy import sympify\n+\n+\n+        >>> from sympy.geometry import Point\n+\n+\n+        >>> pt = Point(1, 1)\n+\n+\n+        >>> sympify(2.0) * pt\n+\n+\n+        Point2D(2.0, 2.0)\n+\n+\n+        \"\"\"\n+\n+\n+        return self * factor\n+\n+\n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"\n         coords = [-x for x in self.args]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18189",
        "model_patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 6092e35dab..163993bb57 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -105,14 +105,15 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n     converting it into a product of terms which should equal zero.\n \n     For example, when solving, `x^2 - y^2 = 0` this is treated as\n-    `(x + y)(x - y) = 0` and `x + y = 0` and `x - y = 0` are solved\n-    independently and combined. Each term is solved by calling\n-    ``diop_solve()``. (Although it is possible to call ``diop_solve()``\n-    directly, one must be careful to pass an equation in the correct\n-    form and to interpret the output correctly; ``diophantine()`` is\n-    the public-facing function to use in general.)\n-\n-    Output of ``diophantine()`` is a set of tuples. The elements of the\n+    if syms:\n+        if not is_sequence(syms):\n+            raise TypeError('syms should be given as a sequence, e.g. a list')\n+        syms = [i for i in syms if i in var]\n+        if syms != var:\n+            dict_sym_index = dict(zip(syms, range(len(syms))))\n+            return {tuple([t[dict_sym_index[i]] for i in var])\n+                    for t in diophantine(eq, param, syms=None, permute=permute)}\n+\n     tuple are the solutions for each variable in the equation and\n     are arranged according to the alphabetic ordering of the variables.\n     e.g. For an equation with two variables, `a` and `b`, the first\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18199",
        "model_patch": "diff --git a/sympy/ntheory/residue_ntheory.py b/sympy/ntheory/residue_ntheory.py\nindex 9a3052d4c3..95b0d1e5f7 100644\n--- a/sympy/ntheory/residue_ntheory.py\n+++ b/sympy/ntheory/residue_ntheory.py\n@@ -768,6 +768,141 @@ def nthroot_mod(a, n, p, all_roots=False):\n     \"\"\"\n     from sympy.core.numbers import igcdex\n     a, n, p = as_int(a), as_int(n), as_int(p)\n+    # If a is congruent to 0 modulo p, then the only solution is 0 mod p.\n+\n+\n+    if a % p == 0:\n+\n+\n+        return [0] if all_roots else 0\n+\n+\n     if n == 2:\n         return sqrt_mod(a, p, all_roots)\n     # see Hackman \"Elementary Number Theory\" (2009), page 76\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18211",
        "model_patch": "diff --git a/sympy/solvers/solveset.py b/sympy/solvers/solveset.py\nindex 445be3e0e8..95b06dad0c 100644\n--- a/sympy/solvers/solveset.py\n+++ b/sympy/solvers/solveset.py\n@@ -565,9 +565,11 @@ def _solve_trig1(f, symbol, domain):\n     if g.has(symbol) or h.has(symbol):\n         return ConditionSet(symbol, Eq(f, 0), domain)\n \n-    solns = solveset_complex(g, y) - solveset_complex(h, y)\n     if isinstance(solns, ConditionSet):\n-        raise NotImplementedError\n+-        raise NotImplementedError(filldedent('''\n+-            Solution to this kind of trigonometric equations\n+-            is yet to be implemented'''))\n++        return ConditionSet(symbol, Eq(f_original, 0), domain)\n \n     if isinstance(solns, FiniteSet):\n         if any(isinstance(s, RootOf) for s in solns):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18698",
        "model_patch": "diff --git a/sympy/polys/sqfreetools.py b/sympy/polys/sqfreetools.py\nindex 1783a7744a..fd39cd134c 100644\n--- a/sympy/polys/sqfreetools.py\n+++ b/sympy/polys/sqfreetools.py\n@@ -332,7 +332,18 @@ def dup_sqf_list(f, K, all=False):\n \n         i += 1\n \n-    return coeff, result\n+    # NEW: Combine factors with the same multiplicity by multiplying them together.\n+    grouped = {}\n+    for factor, exp in result:\n+        if exp in grouped:\n+            grouped[exp] = dup_mul(grouped[exp], factor, K)\n+        else:\n+            grouped[exp] = factor\n+    # Sorted order by the exponent is preferred for consistency.\n+    new_result = [(grouped[exp], exp) for exp in sorted(grouped)]\n+    \n+    return coeff, new_result\n+\n \n \n def dup_sqf_list_include(f, K, all=False):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18763",
        "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 8743723ea0..fbd57ff979 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -698,7 +698,8 @@ def _print_Derivative(self, expr):\n \n     def _print_Subs(self, subs):\n         expr, old, new = subs.args\n-        latex_expr = self._print(expr)\n+        latex_expr = r'\\left(%s\\right)' % self._print(expr)\n+\n         latex_old = (self._print(e) for e in old)\n         latex_new = (self._print(e) for e in new)\n         latex_subs = r'\\\\ '.join(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19040",
        "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex 68b69d1a24..a798725697 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -4271,11 +4271,12 @@ def _poly_from_expr(expr, opt):\n \n         return poly, opt\n     elif opt.expand:\n-        expr = expr.expand()\n-\n     rep, opt = _dict_from_expr(expr, opt)\n     if not opt.gens:\n-        raise PolificationFailed(opt, orig, expr)\n+        opt.gens = tuple(sorted(expr.free_symbols, key=lambda s: s.sort_key()))\n+        if not opt.gens:\n+            raise PolificationFailed(opt, orig, expr)\n+\n \n     monoms, coeffs = list(zip(*list(rep.items())))\n     domain = opt.domain\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19346",
        "model_patch": "diff --git a/sympy/printing/repr.py b/sympy/printing/repr.py\nindex c936a692c0..07f2280995 100644\n--- a/sympy/printing/repr.py\n+++ b/sympy/printing/repr.py\n@@ -342,4 +342,5 @@ def _print_BaseScalarField(self, bsf):\n \n def srepr(expr, **settings):\n     \"\"\"return expr in repr form\"\"\"\n-    return ReprPrinter(settings).doprint(expr)\n+    return SreprPrinter(settings).doprint(expr)\n+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19495",
        "model_patch": "diff --git a/sympy/sets/conditionset.py b/sympy/sets/conditionset.py\nindex 118eda6f77..f2275c33db 100644\n--- a/sympy/sets/conditionset.py\n+++ b/sympy/sets/conditionset.py\n@@ -240,11 +240,19 @@ def _eval_subs(self, old, new):\n             # the base set should be filtered and if new is not in\n             # the base set then this substitution is ignored\n             return self.func(sym, cond, base)\n-        cond = self.condition.subs(old, new)\n-        base = self.base_set.subs(old, new)\n-        if cond is S.true:\n-            return ConditionSet(new, Contains(new, base), base)\n-        return self.func(self.sym, cond, base)\n+        # To avoid unintentionally replacing the dummy variable,\n+        # protect self.sym by first replacing it with a fresh dummy.\n+        dummy = Dummy(self.sym.name, **self.sym.assumptions0)\n+        protected_cond = self.condition.xreplace({self.sym: dummy})\n+        protected_base = self.base_set.xreplace({self.sym: dummy})\n+    \n+        new_cond = protected_cond.subs(old, new).xreplace({dummy: self.sym})\n+        new_base = protected_base.subs(old, new).xreplace({dummy: self.sym})\n+    \n+        if new_cond is S.true:\n+            return ConditionSet(new, Contains(new, new_base), new_base)\n+        return self.func(self.sym, new_cond, new_base)\n+\n \n     def dummy_eq(self, other, symbol=None):\n         if not isinstance(other, self.func):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19637",
        "model_patch": "diff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex a3f1ce2851..71a2869286 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -513,7 +513,10 @@ def kernS(s):\n             while kern in s:\n                 kern += choice(string.ascii_letters + string.digits)\n             s = s.replace(' ', kern)\n-        hit = kern in s\n+            hit = kern in s\n+        else:\n+            hit = False\n+\n \n     for i in range(2):\n         try:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19783",
        "model_patch": "diff --git a/sympy/physics/quantum/dagger.py b/sympy/physics/quantum/dagger.py\nindex 17da3cfd2c..c49f537dab 100644\n--- a/sympy/physics/quantum/dagger.py\n+++ b/sympy/physics/quantum/dagger.py\n@@ -4,13 +4,67 @@\n \n from sympy.core import Expr\n from sympy.functions.elementary.complexes import adjoint\n+from sympy.physics.quantum.operator import Operator\n+\n+\n \n __all__ = [\n     'Dagger'\n ]\n \n \n-class Dagger(adjoint):\n+class Dagger(Operator, adjoint):\n+\n     \"\"\"General Hermitian conjugate operation.\n \n     Take the Hermetian conjugate of an argument [1]_. For matrices this\n@@ -77,13 +131,139 @@ class Dagger(adjoint):\n     \"\"\"\n \n     def __new__(cls, arg):\n+        obj = None\n         if hasattr(arg, 'adjoint'):\n             obj = arg.adjoint()\n         elif hasattr(arg, 'conjugate') and hasattr(arg, 'transpose'):\n             obj = arg.conjugate().transpose()\n+\n         if obj is not None:\n-            return obj\n+            if isinstance(obj, Operator):\n+                return obj\n+            else:\n+                inst = super(Dagger, cls).__new__(cls, arg)\n+                inst._arg = arg\n+                return inst\n         return Expr.__new__(cls, arg)\n \n+    def _eval_adjoint(self):\n+\n+\n+        # Double dagger should return the original operator.\n+\n+\n+        return self._arg\n+\n+\n+\n adjoint.__name__ = \"Dagger\"\n adjoint._sympyrepr = lambda a, b: \"Dagger(%s)\" % b._print(a.args[0])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19954",
        "model_patch": "diff --git a/sympy/combinatorics/perm_groups.py b/sympy/combinatorics/perm_groups.py\nindex de94ddabb4..d0c00d4a3d 100644\n--- a/sympy/combinatorics/perm_groups.py\n+++ b/sympy/combinatorics/perm_groups.py\n@@ -2193,19 +2193,23 @@ def _number_blocks(blocks):\n                 rep = {j for j in range(self.degree) if num_block[j] == 0}\n                 # check if the system is minimal with\n                 # respect to the already discovere ones\n-                minimal = True\n-                to_remove = []\n-                for i, r in enumerate(rep_blocks):\n-                    if len(r) > len(rep) and rep.issubset(r):\n-                        # i-th block system is not minimal\n-                        del num_blocks[i], blocks[i]\n-                        to_remove.append(rep_blocks[i])\n-                    elif len(r) < len(rep) and r.issubset(rep):\n-                        # the system being checked is not minimal\n-                        minimal = False\n-                        break\n-                # remove non-minimal representative blocks\n-                rep_blocks = [r for r in rep_blocks if r not in to_remove]\n+                    minimal = True\n+                    to_remove = []\n+                    for i, r in enumerate(rep_blocks):\n+                        if len(r) > len(rep) and rep.issubset(r):\n+                            # Mark the index for removal rather than deleting in-loop\n+                            to_remove.append(i)\n+                        elif len(r) < len(rep) and r.issubset(rep):\n+                            # the system being checked is not minimal\n+                            minimal = False\n+                            break\n+                    if minimal:\n+                        # Remove the marked indices in reverse order to avoid shifting\n+                        for j in sorted(to_remove, reverse=True):\n+                            del num_blocks[j]\n+                            del blocks[j]\n+                        rep_blocks = [r for i, r in enumerate(rep_blocks) if i not in to_remove]\n+\n \n                 if minimal and num_block not in num_blocks:\n                     blocks.append(block)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20154",
        "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex dd36dea304..4a01f52eab 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -1802,9 +1802,10 @@ def partitions(n, m=None, k=None, size=False):\n         keys.append(r)\n     room = m - q - bool(r)\n     if size:\n-        yield sum(ms.values()), ms\n+        yield sum(ms.values()), ms.copy()\n     else:\n-        yield ms\n+        yield ms.copy()\n+\n \n     while keys != [1]:\n         # Reuse any 1's.\n@@ -1842,9 +1843,10 @@ def partitions(n, m=None, k=None, size=False):\n             break\n         room -= need\n         if size:\n-            yield sum(ms.values()), ms\n-        else:\n-            yield ms\n+    if size:\n+        yield sum(ms.values()), ms.copy()\n+    else:\n+        yield ms.copy()\n \n \n def ordered_partitions(n, m=None, sort=True):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20428",
        "model_patch": "diff --git a/sympy/polys/polyclasses.py b/sympy/polys/polyclasses.py\nindex 238a0f0b25..53c6e24255 100644\n--- a/sympy/polys/polyclasses.py\n+++ b/sympy/polys/polyclasses.py\n@@ -586,8 +586,11 @@ def l1_norm(f):\n     def clear_denoms(f):\n         \"\"\"Clear denominators, but keep the ground domain. \"\"\"\n         coeff, F = dmp_clear_denoms(f.rep, f.lev, f.dom)\n+        # Strip the representation so that the zero polynomial becomes canonical ([])\n+        F = dmp_strip(F, f.lev)\n         return coeff, f.per(F)\n \n+\n     def integrate(f, m=1, j=0):\n         \"\"\"Computes the ``m``-th order indefinite integral of ``f`` in ``x_j``. \"\"\"\n         if not isinstance(m, int):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20438",
        "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 3c4aa86e36..fe9e3ed217 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -765,6 +765,696 @@ def __new__(cls, *sets, **assumptions):\n     @property\n     def sets(self):\n         return self.args\n+    def _eval_is_subset(self, other):\n+\n+\n+        from sympy.sets.sets import FiniteSet, ProductSet\n+\n+\n+        # When 'other' is a FiniteSet, compare by enumerating self\n+\n+\n+        if isinstance(other, FiniteSet):\n+\n+\n+            try:\n+\n+\n+                self_elems = set(self)\n+\n+\n+            except TypeError:\n+\n+\n+                return None\n+\n+\n+            return fuzzy_bool(FiniteSet(*self_elems).equals(other))\n+\n+\n+        # When both are ProductSet of the same arity, compare each factor\n+\n+\n+        if isinstance(other, ProductSet) and len(self.sets) == len(other.sets):\n+\n+\n+            results = [s.is_subset(o) for s, o in zip(self.sets, other.sets)]\n+\n+\n+            return fuzzy_and(results)\n+\n+\n+        return None\n+\n+\n \n     def flatten(self):\n         def _flatten(sets):\n@@ -1558,6 +2248,206 @@ def __new__(cls, a, b, evaluate=True):\n             return Complement.reduce(a, b)\n \n         return Basic.__new__(cls, a, b)\n+    def equals(self, other):\n+\n+\n+        if not isinstance(other, Complement):\n+\n+\n+            return False\n+\n+\n+        A, B = self.args\n+\n+\n+        C, D = other.args\n+\n+\n+        return A.equals(C) and B.equals(D)\n+\n+\n \n     @staticmethod\n     def reduce(A, B):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20590",
        "model_patch": "diff --git a/sympy/core/symbol.py b/sympy/core/symbol.py\nindex 70e6953559..5dbd518901 100644\n--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -262,7 +262,14 @@ def __new__(cls, name, **assumptions):\n \n         \"\"\"\n         cls._sanitize(assumptions, cls)\n-        return Symbol.__xnew_cached_(cls, name, **assumptions)\n+        obj = Symbol.__xnew_cached_(cls, name, **assumptions)\n+        # Remove any dynamically-created __dict__ to preserve slotted behavior.\n+        try:\n+            del obj.__dict__\n+        except AttributeError:\n+            pass\n+        return obj\n+\n \n     def __new_stage2__(cls, name, **assumptions):\n         if not isinstance(name, str):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20801",
        "model_patch": "diff --git a/sympy/logic/boolalg.py b/sympy/logic/boolalg.py\nindex fbcba1f8d4..fc377e37fb 100644\n--- a/sympy/logic/boolalg.py\n+++ b/sympy/logic/boolalg.py\n@@ -213,7 +213,16 @@ def _noop(self, other=None):\n     __rtruediv__ = _noop\n     __mod__ = _noop\n     __rmod__ = _noop\n-    _eval_power = _noop\n+    def __eq__(self, other):\n+        from sympy.core.numbers import Number\n+        try:\n+            other = _sympify(other)\n+        except Exception:\n+            return NotImplemented\n+        if isinstance(other, Number):\n+            return bool(self) == bool(other)\n+        return Basic.__eq__(self, other)\n+\n \n     # /// drop when Py2 is no longer supported\n     def __lt__(self, other):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20916",
        "model_patch": "diff --git a/sympy/printing/conventions.py b/sympy/printing/conventions.py\nindex 9a3be6bbe9..4b1b8eb35a 100644\n--- a/sympy/printing/conventions.py\n+++ b/sympy/printing/conventions.py\n@@ -52,15 +52,21 @@ def split_super_sub(text):\n         if name is None:\n             name = part\n         elif part.startswith(\"^\"):\n-            supers.append(part[1:])\n-        elif part.startswith(\"__\"):\n-            supers.append(part[2:])\n-        elif part.startswith(\"_\"):\n-            subs.append(part[1:])\n-        else:\n-            raise RuntimeError(\"This should never happen.\")\n-\n-    # make a little exception when a name ends with digits, i.e. treat them\n+    # [existing splitting logic that produces base, sups, subs]\n+    \n+    # --- Begin patch: ensure trailing digits are split off (for Greek letters like \"omega0\") ---\n+    # If base ends with digits but no explicit separator was found,\n+    # then remove the trailing digits and prepend them to subs.\n+    import re\n+    m = re.match(r'(.*?)(\\d+)$', base)\n+    if m:\n+        base = m.group(1)\n+        # Prepend these digits as a subscript so that later DSUB mapping converts them\n+        subs = [m.group(2)] + subs\n+    # --- End patch ---\n+    \n+    return base, sups, subs\n+\n     # as a subscript too.\n     m = _name_with_digits_p.match(name)\n     if m:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21379",
        "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex 3894f4fd1c..1dc1258b87 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -1022,6 +1022,311 @@ def _subs(self, old, new, **hints):\n               routine uses this strategy when a substitution is attempted\n               on any of its summation variables.\n         \"\"\"\n+        # Prevent substitution into Boolean constants. This avoids replacing\n+\n+\n+        # S.true (or S.false) when a substitution key (e.g. 1) is used,\n+\n+\n+        # since in Python True == 1.\n+\n+\n+        from sympy.core.singleton import S\n+\n+\n+        if self is S.true or self is S.false:\n+\n+\n+            return self\n+\n+\n \n         def fallback(self, old, new):\n             \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21596",
        "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 9f19ecf2ab..f1ecdbe281 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1291,9 +1291,16 @@ def boundary_of_set(i):\n     def _contains(self, other):\n         return Or(*[s.contains(other) for s in self.args])\n \n-    def is_subset(self, other):\n+def is_subset(self, other):\n+    from sympy.sets.fancysets import ImageSet\n+    if isinstance(self, ImageSet):\n+        # For ImageSet objects, ignore the first argument (the Lambda transformation)\n+        # and only use the underlying base set(s) for the subset test.\n+        return fuzzy_and(s.is_subset(other) for s in self.args[1:])\n+    else:\n         return fuzzy_and(s.is_subset(other) for s in self.args)\n \n+\n     def as_relational(self, symbol):\n         \"\"\"Rewrite a Union in terms of equalities and logic operators. \"\"\"\n         if (len(self.args) == 2 and\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21612",
        "model_patch": "diff --git a/sympy/parsing/latex/_parse_latex_antlr.py b/sympy/parsing/latex/_parse_latex_antlr.py\nindex 2e4a45ad20..d798c658ad 100644\n--- a/sympy/parsing/latex/_parse_latex_antlr.py\n+++ b/sympy/parsing/latex/_parse_latex_antlr.py\n@@ -382,11 +382,809 @@ def convert_frac(frac):\n \n     expr_top = convert_expr(frac.upper)\n     expr_bot = convert_expr(frac.lower)\n-    inverse_denom = sympy.Pow(expr_bot, -1, evaluate=False)\n-    if expr_top == 1:\n-        return inverse_denom\n-    else:\n-        return sympy.Mul(expr_top, inverse_denom, evaluate=False)\n+if expr_top == 1:\n+    return sympy.Pow(expr_bot, -1, evaluate=False)\n+else:\n+    return Fraction(expr_top, expr_bot)\n+\n+class Fraction(sympy.Expr):\n+\n+\n+    def __new__(cls, numerator, denominator):\n+\n+\n+        obj = sympy.Expr.__new__(cls)\n+\n+\n+        obj.numerator = numerator\n+\n+\n+        obj.denominator = denominator\n+\n+\n+        return obj\n+\n+\n+\n+\n+    def _sympystr(self, printer):\n+\n+\n+        return \"({})/({})\".format(printer.doprint(self.numerator),\n+\n+\n+                                   printer.doprint(self.denominator))\n+\n+\n+\n+\n+    def _repr_latex_(self):\n+\n+\n+        return r\"\\frac{{{}}}{{{}}}\".format(sympy.latex(self.numerator),\n+\n+\n+                                            sympy.latex(self.denominator))\n+\n+\n+\n+\n+    def _eval_evalf(self, prec):\n+\n+\n+        # Evaluate numerator and denominator numerically and then divide.\n+\n+\n+        num = self.numerator._eval_evalf(prec)\n+\n+\n+        den = self.denominator._eval_evalf(prec)\n+\n+\n+        return num/den\n+\n+\n \n def convert_binom(binom):\n     expr_n = convert_expr(binom.n)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21847",
        "model_patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\nindex 0e84403307..0f50e910fd 100644\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -127,7 +127,8 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(powers.values()) >= min_degree:\n+\n                     monomials_list_comm.append(Mul(*item))\n             yield from set(monomials_list_comm)\n         else:\n@@ -139,7 +140,8 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                    if sum(powers.values()) >= min_degree:\n+\n                     monomials_list_non_comm.append(Mul(*item))\n             yield from set(monomials_list_non_comm)\n     else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21930",
        "model_patch": "diff --git a/sympy/physics/secondquant.py b/sympy/physics/secondquant.py\nindex d19ee2fc63..d731bef08d 100644\n--- a/sympy/physics/secondquant.py\n+++ b/sympy/physics/secondquant.py\n@@ -478,7 +478,8 @@ def __repr__(self):\n         return \"CreateBoson(%s)\" % self.state\n \n     def _latex(self, printer):\n-        return \"b^\\\\dagger_{%s}\" % self.state.name\n+        return \"{b^\\\\dagger_{%s}}\" % self.state.name\n+\n \n B = AnnihilateBoson\n Bd = CreateBoson\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-22080",
        "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex b669a2c783..85a10d451f 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -232,9 +232,10 @@ def _print_NegativeInfinity(self, expr):\n     def _print_ComplexInfinity(self, expr):\n         return self._print_NaN(expr)\n \n-    def _print_Mod(self, expr):\n-        PREC = precedence(expr)\n-        return ('{} % {}'.format(*map(lambda x: self.parenthesize(x, PREC), expr.args)))\n+def _print_Mod(self, expr):\n+    PREC = precedence(expr)\n+    return (\"({} % {})\".format(*map(lambda x: self.parenthesize(x, PREC), expr.args)))\n+\n \n     def _print_Piecewise(self, expr):\n         result = []\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-22456",
        "model_patch": "diff --git a/sympy/codegen/ast.py b/sympy/codegen/ast.py\nindex a02714b174..578e5846f7 100644\n--- a/sympy/codegen/ast.py\n+++ b/sympy/codegen/ast.py\n@@ -894,8 +894,9 @@ class String(Token):\n     String('foo')\n \n     \"\"\"\n-    __slots__ = ('text',)\n-    not_in_args = ['text']\n+__slots__ = ('text',)\n+not_in_args = []\n+\n     is_Atom = True\n \n     @classmethod\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-22714",
        "model_patch": "diff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex e403654cb4..5b526605cc 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -1199,11 +1199,15 @@ def visit_BinOp(self, node):\n             return new_node\n         return node\n \n-    def visit_Call(self, node):\n-        new_node = self.generic_visit(node)\n-        if isinstance(node.func, ast.Name) and node.func.id in self.functions:\n-            new_node.keywords.append(ast.keyword(arg='evaluate', value=ast.NameConstant(value=False, ctx=ast.Load())))\n-        return new_node\n+def visit_Call(self, node):\n+    new_node = self.generic_visit(node)\n+    # Exclude functions whose evaluation should not be suppressed.\n+    # For example, \"im\" and \"re\" need to be fully evaluated so that im(Integer(1)) returns 0.\n+    exclude = {'im', 're'}\n+    if isinstance(node.func, ast.Name) and node.func.id in self.functions and node.func.id not in exclude:\n+        new_node.keywords.append(ast.keyword(arg='evaluate', value=ast.NameConstant(value=False, ctx=ast.Load())))\n+    return new_node\n+\n \n \n _transformation = {  # items can be added but never re-ordered\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-22914",
        "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex 3a72ab606c..626a999176 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -469,6 +469,240 @@ def _print_Symbol(self, expr):\n     _print_uppergamma = CodePrinter._print_not_supported\n     _print_fresnelc = CodePrinter._print_not_supported\n     _print_fresnels = CodePrinter._print_not_supported\n+    def _print_Min(self, expr):\n+\n+\n+        return \"min({})\".format(\", \".join(self._print(arg) for arg in expr.args))\n+\n+\n+\n+\n+    def _print_Max(self, expr):\n+\n+\n+        return \"max({})\".format(\", \".join(self._print(arg) for arg in expr.args))\n+\n+\n \n \n for k in PythonCodePrinter._kf:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23262",
        "model_patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\nindex da67263b19..f88a547e7b 100644\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -957,11 +957,16 @@ def _recursive_to_string(doprint, arg):\n     elif iterable(arg):\n         if isinstance(arg, list):\n             left, right = \"[]\"\n+            return left + ', '.join(_recursive_to_string(doprint, e) for e in arg) + right\n         elif isinstance(arg, tuple):\n-            left, right = \"()\"\n+            left, right = \"(\", \")\"\n+            if len(arg) == 1:\n+                return left + _recursive_to_string(doprint, arg[0]) + \",)\"\n+            else:\n+                return left + ', '.join(_recursive_to_string(doprint, e) for e in arg) + right\n         else:\n             raise NotImplementedError(\"unhandled type: %s, %s\" % (type(arg), arg))\n-        return left +', '.join(_recursive_to_string(doprint, e) for e in arg) + right\n+\n     elif isinstance(arg, str):\n         return arg\n     else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23413",
        "model_patch": "diff --git a/sympy/polys/matrices/normalforms.py b/sympy/polys/matrices/normalforms.py\nindex 30f5534b08..5121bad687 100644\n--- a/sympy/polys/matrices/normalforms.py\n+++ b/sympy/polys/matrices/normalforms.py\n@@ -243,9 +243,12 @@ def _hermite_normal_form(A):\n             for j in range(k + 1, n):\n                 q = A[i][j] // b\n                 add_columns(A, j, k, 1, -q, 0, 1)\n-    # Finally, the HNF consists of those columns of A in which we succeeded in making\n-    # a nonzero pivot.\n-    return DomainMatrix.from_rep(A)[:, k:]\n+    res = DomainMatrix.from_rep(A)[:, k:]\n+    if res.shape[0] < m:\n+        pad = DomainMatrix.zeros((m - res.shape[0], res.shape[1]), A.domain)\n+        res = pad.vstack(res)\n+    return res\n+\n \n \n def _hermite_normal_form_modulo_D(A, D):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23534",
        "model_patch": "diff --git a/sympy/core/symbol.py b/sympy/core/symbol.py\nindex f4a555c13f..aeafae9bc1 100644\n--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -789,11 +789,12 @@ def literal(s):\n             return result[0]\n \n         return tuple(result)\n-    else:\n-        for name in names:\n-            result.append(symbols(name, **args))\n+else:\n+    for name in names:\n+        result.append(symbols(name, cls=cls, **args))\n+ \n+    return type(names)(result)\n \n-        return type(names)(result)\n \n \n def var(names, **args):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23824",
        "model_patch": "diff --git a/sympy/physics/hep/gamma_matrices.py b/sympy/physics/hep/gamma_matrices.py\nindex 23284e4a92..a04ece7e5f 100644\n--- a/sympy/physics/hep/gamma_matrices.py\n+++ b/sympy/physics/hep/gamma_matrices.py\n@@ -694,8 +694,9 @@ def kahane_simplify(expression):\n \n     # If `first_dum_pos` is not zero, it means that there are trailing free gamma\n     # matrices in front of `expression`, so multiply by them:\n-    for i in range(0, first_dum_pos):\n-        [ri.insert(0, free_pos[i]) for ri in resulting_indices]\n+for i in range(0, first_dum_pos):\n+    [ri.append(free_pos[i]) for ri in resulting_indices]\n+\n \n     resulting_expr = S.Zero\n     for i in resulting_indices:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23950",
        "model_patch": "diff --git a/sympy/sets/contains.py b/sympy/sets/contains.py\nindex b2d4268d12..44ac5510ee 100644\n--- a/sympy/sets/contains.py\n+++ b/sympy/sets/contains.py\n@@ -45,4 +45,6 @@ def binary_symbols(self):\n             isinstance(i, (Eq, Ne))])\n \n     def as_set(self):\n-        raise NotImplementedError()\n+        x, s = self.args\n+        return s.as_relational(x)\n+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24066",
        "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex 3daf84c108..02dc1b48d2 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -190,10 +190,16 @@ def _collect_factor_and_dimension(self, expr):\n                 dim /= idim**count\n             return factor, dim\n         elif isinstance(expr, Function):\n-            fds = [self._collect_factor_and_dimension(\n-                arg) for arg in expr.args]\n-            return (expr.func(*(f[0] for f in fds)),\n-                    *(d[1] for d in fds))\n+            fds = [self._collect_factor_and_dimension(arg) for arg in expr.args]\n+            args_factors = [f[0] for f in fds]\n+            args_dims = [f[1] for f in fds]\n+            from sympy import exp\n+            transcendentals = {exp,}\n+            if expr.func in transcendentals:\n+                if all(self.get_dimension_system().is_dimensionless(arg_dim) for arg_dim in args_dims):\n+                    return expr.func(*args_factors), Dimension(1)\n+            return expr.func(*args_factors), *(args_dims)\n+\n         elif isinstance(expr, Dimension):\n             return S.One, expr\n         else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24213",
        "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..5ff1f9d32c 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -173,15 +173,15 @@ def _collect_factor_and_dimension(self, expr):\n         elif isinstance(expr, Add):\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n             for addend in expr.args[1:]:\n-                addend_factor, addend_dim = \\\n-                    self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                addend_factor, addend_dim = self._collect_factor_and_dimension(addend)\n+                if not self.get_dimension_system().equivalent_dims(dim, addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n                             addend, addend_dim, dim))\n                 factor += addend_factor\n             return factor, dim\n+\n         elif isinstance(expr, Derivative):\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n             for independent, count in expr.variable_count:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24443",
        "model_patch": "diff --git a/sympy/combinatorics/homomorphisms.py b/sympy/combinatorics/homomorphisms.py\nindex bb7bdf32ba..76b0c045f0 100644\n--- a/sympy/combinatorics/homomorphisms.py\n+++ b/sympy/combinatorics/homomorphisms.py\n@@ -333,10 +333,14 @@ def _image(r):\n             # both indices\n             while i < len(r):\n                 power = r_arr[j][1]\n-                if isinstance(domain, PermutationGroup) and r[i] in gens:\n-                    s = domain.generators[gens.index(r[i])]\n-                else:\n-                    s = r[i]\n+if isinstance(domain, PermutationGroup) and (r[i] in gens or r[i]**-1 in gens):\n+    if r[i] in gens:\n+        s = domain.generators[gens.index(r[i])]\n+    else:\n+        s = domain.generators[gens.index(r[i]**-1)]\n+else:\n+    s = r[i]\n+\n                 if s in images:\n                     w = w*images[s]**power\n                 elif s**-1 in images:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24539",
        "model_patch": "diff --git a/sympy/polys/rings.py b/sympy/polys/rings.py\nindex 12bd2fc920..49826f273e 100644\n--- a/sympy/polys/rings.py\n+++ b/sympy/polys/rings.py\n@@ -616,12 +616,14 @@ def set_ring(self, new_ring):\n             return new_ring.from_dict(self, self.ring.domain)\n \n     def as_expr(self, *symbols):\n-        if symbols and len(symbols) != self.ring.ngens:\n-            raise ValueError(\"not enough symbols, expected %s got %s\" % (self.ring.ngens, len(symbols)))\n+        if symbols:\n+            if len(symbols) != len(self.ring.symbols):\n+                raise ValueError(\"expected a list of %s symbols, got %s\" % (len(self.ring.symbols), len(symbols)))\n+            mapping = dict(zip(self.ring.symbols, symbols))\n+            return self.ring.to_sympy_expr(self, mapping)\n         else:\n-            symbols = self.ring.symbols\n+            return self.ring.to_sympy_expr(self)\n \n-        return expr_from_dict(self.as_expr_dict(), *symbols)\n \n     def as_expr_dict(self):\n         to_sympy = self.ring.domain.to_sympy\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24562",
        "model_patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\nindex 52f7ea45ad..6d93f39b18 100644\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1625,19 +1625,19 @@ def __new__(cls, p, q=None, gcd=None):\n             q = 1\n             gcd = 1\n \n-        if not isinstance(p, SYMPY_INTS):\n-            p = Rational(p)\n-            q *= p.q\n-            p = p.p\n-        else:\n-            p = int(p)\n+    if not isinstance(p, SYMPY_INTS):\n+        p = Rational(p)\n+    else:\n+        p = Integer(p)\n+    if not isinstance(q, SYMPY_INTS):\n+        q = Rational(q)\n+    else:\n+        q = Integer(q)\n+    new_p = p.p * q.q\n+    new_q = p.q * q.p\n+    p = new_p\n+    q = new_q\n \n-        if not isinstance(q, SYMPY_INTS):\n-            q = Rational(q)\n-            p *= q.q\n-            q = q.p\n-        else:\n-            q = int(q)\n \n         # p and q are now ints\n         if q == 0:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24661",
        "model_patch": "diff --git a/sympy/core/relational.py b/sympy/core/relational.py\nindex 23ab6cba88..fd8966ebbc 100644\n--- a/sympy/core/relational.py\n+++ b/sympy/core/relational.py\n@@ -147,33 +147,26 @@ class Relational(Boolean, EvalfMixin):\n     # ValidRelationOperator - Defined below, because the necessary classes\n     #   have not yet been defined\n \n-    def __new__(cls, lhs, rhs, rop=None, **assumptions):\n-        # If called by a subclass, do nothing special and pass on to Basic.\n-        if cls is not Relational:\n-            return Basic.__new__(cls, lhs, rhs, **assumptions)\n-\n-        # XXX: Why do this? There should be a separate function to make a\n-        # particular subclass of Relational from a string.\n-        #\n-        # If called directly with an operator, look up the subclass\n-        # corresponding to that operator and delegate to it\n-        cls = cls.ValidRelationOperator.get(rop, None)\n-        if cls is None:\n-            raise ValueError(\"Invalid relational operator symbol: %r\" % rop)\n-\n-        if not issubclass(cls, (Eq, Ne)):\n-            # validate that Booleans are not being used in a relational\n-            # other than Eq/Ne;\n-            # Note: Symbol is a subclass of Boolean but is considered\n-            # acceptable here.\n-            if any(map(_nontrivBool, (lhs, rhs))):\n-                raise TypeError(filldedent('''\n-                    A Boolean argument can only be used in\n-                    Eq and Ne; all other relationals expect\n-                    real expressions.\n-                '''))\n-\n-        return cls(lhs, rhs, **assumptions)\n+def __new__(cls, lhs, rhs, rop=None, **assumptions):\n+    # If called by a subclass, do nothing special and pass on to Basic.\n+    if cls is not Relational:\n+        return Basic.__new__(cls, lhs, rhs, **assumptions)\n+\n+    # Delegate instantiation to the appropriate subclass based on rop.\n+    cls = cls.ValidRelationOperator.get(rop, None)\n+    if cls is None:\n+        raise ValueError(\"Invalid relational operator symbol: %r\" % rop)\n+\n+    if not issubclass(cls, (Eq, Ne)):\n+        # validate that Booleans are not being used in a relational\n+        # other than Eq/Ne; Note: Symbol is a subclass of Boolean but is considered acceptable here.\n+        if any(map(_nontrivBool, (lhs, rhs))):\n+            raise TypeError(filldedent('''\n+                A Boolean argument can only be used in\n+                Eq and Ne; all other relationals expect\n+                real expressions.\n+            '''))\n+    return cls(lhs, rhs, **assumptions)\n \n     @property\n     def lhs(self):\ndiff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex 52711d1324..65c2d34e17 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -1191,6 +1191,1423 @@ def visit_Call(self, node):\n         if isinstance(node.func, ast.Name) and node.func.id in self.functions:\n             new_node.keywords.append(ast.keyword(arg='evaluate', value=ast.NameConstant(value=False, ctx=ast.Load())))\n         return new_node\n+    def visit_Compare(self, node):\n+\n+\n+        # Transform a comparison e.g. \"1 < 2\" into a call to the appropriate\n+\n+\n+        # relational constructor with evaluate=False.\n+\n+\n+        # Only support simple comparisons (one operator, one comparator).\n+\n+\n+        if len(node.ops) != 1 or len(node.comparators) != 1:\n+\n+\n+            # For chained comparisons, fall back to generic visit.\n+\n+\n+            return self.generic_visit(node)\n+\n+\n+        left = self.visit(node.left)\n+\n+\n+        right = self.visit(node.comparators[0])\n+\n+\n+        op = node.ops[0]\n+\n+\n+        # Mapping from ast comparison operator to the corresponding Sympy class name.\n+\n+\n+        op_mapping = {\n+\n+\n+            ast.Lt: \"Lt\",\n+\n+\n+            ast.LtE: \"Le\",\n+\n+\n+            ast.Gt: \"Gt\",\n+\n+\n+            ast.GtE: \"Ge\",\n+\n+\n+            ast.Eq: \"Eq\",\n+\n+\n+            ast.NotEq: \"Ne\",\n+\n+\n+        }\n+\n+\n+        op_name = None\n+\n+\n+        for op_type, name in op_mapping.items():\n+\n+\n+            if isinstance(op, op_type):\n+\n+\n+                op_name = name\n+\n+\n+                break\n+\n+\n+        if op_name is None:\n+\n+\n+            # If operator is not in our mapping, leave unchanged.\n+\n+\n+            return self.generic_visit(node)\n+\n+\n+        new_node = ast.Call(\n+\n+\n+            func=ast.Name(id=op_name, ctx=ast.Load()),\n+\n+\n+            args=[left, right],\n+\n+\n+            keywords=[ast.keyword(arg='evaluate', value=ast.NameConstant(value=False, ctx=ast.Load()))]\n+\n+\n+        )\n+\n+\n+        return ast.copy_location(new_node, node)\n+\n+\n \n \n _transformation = {  # items can be added but never re-ordered\n",
        "model_name_or_path": "o3-mini"
    }
]
[
    {
        "instance_id": "astropy__astropy-12907",
        "model_patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\nindex a308e27297..051829997c 100644\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -261,29 +261,28 @@ def _cdot(left, right):\n     result : ndarray\n         Result from this operation.\n     \"\"\"\n-\n-    left, right = right, left\n-\n+def _cdot(left, right):\n+    \n     def _n_inputs_outputs(input, position):\n         \"\"\"\n-        Return ``n_inputs``, ``n_outputs`` for a model or coord_matrix.\n+        Return coord_matrix for a model or ndarray.\n         \"\"\"\n         if isinstance(input, Model):\n             coords = _coord_matrix(input, position, input.n_outputs)\n         else:\n             coords = input\n         return coords\n-\n+    \n     cleft = _n_inputs_outputs(left, 'left')\n     cright = _n_inputs_outputs(right, 'right')\n-\n+    \n     try:\n         result = np.dot(cleft, cright)\n     except ValueError:\n         raise ModelDefinitionError(\n             'Models cannot be combined with the \"|\" operator; '\n             'left coord_matrix is {}, right coord_matrix is {}'.format(\n-                cright, cleft))\n+                cleft, cright))\n     return result\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13033",
        "model_patch": "diff --git a/astropy/timeseries/core.py b/astropy/timeseries/core.py\nindex c279f35f87..2e1145c1db 100644\n--- a/astropy/timeseries/core.py\n+++ b/astropy/timeseries/core.py\n@@ -75,10 +75,11 @@ class BaseTimeSeries(QTable):\n                                  .format(self.__class__.__name__, required_columns[0], plural))\n \n             elif self.colnames[:len(required_columns)] != required_columns:\n+                expected = \", \".join(required_columns)\n+                found = \", \".join(self.colnames[:len(required_columns)]) if len(self.colnames) >= len(required_columns) else \", \".join(self.colnames)\n+                raise ValueError(\"{} object is invalid - expected first column{} '{}' but found '{}'\".format(\n+                    self.__class__.__name__, plural, expected, found))\n \n-                raise ValueError(\"{} object is invalid - expected '{}' \"\n-                                 \"as the first column{} but found '{}'\"\n-                                 .format(self.__class__.__name__, required_columns[0], plural, self.colnames[0]))\n \n             if (self._required_columns_relax\n                     and self._required_columns == self.colnames[:len(self._required_columns)]):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13236",
        "model_patch": "diff --git a/astropy/table/column.py b/astropy/table/column.py\nindex 43e04d1975..5cccdd9814 100644\n--- a/astropy/table/column.py\n+++ b/astropy/table/column.py\n@@ -97,12 +97,11 @@ class FalseArray(np.ndarray):\n     exception will be raised if ``True`` is assigned to any element.  The\n     consequences of the limitation are most obvious in the high-level table\n     operations.\n+    # NOTE: The auto-conversion of structured ndarrays (i.e. those with >1 field)\n+    # into an NdarrayMixin is removed per issue XYZ.  Structured arrays will\n+    # now be handled as normal ndarrays (or will be wrapped later by Column/x)\n+    # if needed.\n \n-    Parameters\n-    ----------\n-    shape : tuple\n-        Data shape\n-    \"\"\"\n     def __new__(cls, shape):\n         obj = np.zeros(shape, dtype=bool).view(cls)\n         return obj\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13398",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13453",
        "model_patch": "diff --git a/astropy/io/ascii/html.py b/astropy/io/ascii/html.py\nindex 266cf229cc..dcf583fb12 100644\n--- a/astropy/io/ascii/html.py\n+++ b/astropy/io/ascii/html.py\n@@ -354,6 +354,44 @@ class HTML(core.BaseReader):\n             self.data.fill_values = [self.data.fill_values]\n \n         self.data._set_fill_values(cols)\n+       self.data._set_col_formats()\n         lines = []",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13579",
        "model_patch": "diff --git a/astropy/wcs/wcsapi/wrappers/sliced_wcs.py b/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\nindex d7605b078c..72ddabf478 100644\n--- a/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\n+++ b/astropy/wcs/wcsapi/wrappers/sliced_wcs.py\n@@ -243,7 +243,8 @@ class SlicedLowLevelWCS(BaseWCSWrapper):\n         return world_arrays\n \n     def world_to_pixel_values(self, *world_arrays):\n-        world_arrays = tuple(map(np.asanyarray, world_arrays))\n+        fixed_world_coords = self._wcs.pixel_to_world_values_all(*([0] * len(self._pixel_keep)))\n+\n         world_arrays_new = []\n         iworld_curr = -1\n         for iworld in range(self._wcs.world_n_dim):\n@@ -251,7 +252,8 @@ class SlicedLowLevelWCS(BaseWCSWrapper):\n                 iworld_curr += 1\n                 world_arrays_new.append(world_arrays[iworld_curr])\n             else:\n-                world_arrays_new.append(1.)\n+                world_arrays_new.append(fixed_world_coords[iworld])\n+\n \n         world_arrays_new = np.broadcast_arrays(*world_arrays_new)\n         pixel_arrays = list(self._wcs.world_to_pixel_values(*world_arrays_new))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-13977",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14096",
        "model_patch": "diff --git a/astropy/coordinates/sky_coordinate.py b/astropy/coordinates/sky_coordinate.py\nindex ab475f7d0d..d0a56b2373 100644\n--- a/astropy/coordinates/sky_coordinate.py\n+++ b/astropy/coordinates/sky_coordinate.py\n@@ -866,6 +866,274 @@ class SkyCoord(ShapedLikeNDArray):\n             isinstance(self.frame.name, list) and string in self.frame.name\n         )\n \n+    def __getattribute__(self, attr):\n+        try:\n+            return super().__getattribute__(attr)\n+        except AttributeError as orig_exc:\n+            if attr in type(self).__dict__:\n+                raise orig_exc\n+            return self.__getattr__(attr)\n     def __getattr__(self, attr):\n         \"\"\"\n         Overrides getattr to return coordinates that this can be transformed",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14182",
        "model_patch": "diff --git a/astropy/io/ascii/rst.py b/astropy/io/ascii/rst.py\nindex abdeba8efb..b04b0087b6 100644\n--- a/astropy/io/ascii/rst.py\n+++ b/astropy/io/ascii/rst.py\n@@ -57,8 +57,9 @@ class RST(FixedWidth):\n     data_class = SimpleRSTData\n     header_class = SimpleRSTHeader\n \n-    def __init__(self):\n-        super().__init__(delimiter_pad=None, bookend=False)\n+def __init__(self, header_rows=None, **kwargs):\n+    super().__init__(delimiter_pad=None, bookend=False, header_rows=header_rows, **kwargs)\n+\n \n     def write(self, lines):\n         lines = super().write(lines)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14309",
        "model_patch": "diff --git a/astropy/io/fits/connect.py b/astropy/io/fits/connect.py\nindex 4b6150f4ac..7f742afbda 100644\n--- a/astropy/io/fits/connect.py\n+++ b/astropy/io/fits/connect.py\n@@ -64,12 +64,16 @@ def is_fits(origin, filepath, fileobj, *args, **kwargs):\n         sig = fileobj.read(30)\n         fileobj.seek(pos)\n         return sig == FITS_SIGNATURE\n-    elif filepath is not None:\n-        if filepath.lower().endswith(\n-            (\".fits\", \".fits.gz\", \".fit\", \".fit.gz\", \".fts\", \".fts.gz\")\n-        ):\n-            return True\n+elif filepath is not None:\n+    if filepath.lower().endswith(\n+        (\".fits\", \".fits.gz\", \".fit\", \".fit.gz\", \".fts\", \".fts.gz\")\n+    ):\n+        return True\n+# If no additional arguments are supplied, we cannot check for HDUList etc.\n+if args:\n     return isinstance(args[0], (HDUList, TableHDU, BinTableHDU, GroupsHDU))\n+return False\n+\n \n \n def _decode_mixins(tbl):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14365",
        "model_patch": "diff --git a/astropy/io/ascii/qdp.py b/astropy/io/ascii/qdp.py\nindex 83a4f004aa..4c56bd8e26 100644\n--- a/astropy/io/ascii/qdp.py\n+++ b/astropy/io/ascii/qdp.py\n@@ -68,7 +68,8 @@ def _line_type(line, delimiter=None):\n     _new_re = rf\"NO({sep}NO)+\"\n     _data_re = rf\"({_decimal_re}|NO|[-+]?nan)({sep}({_decimal_re}|NO|[-+]?nan))*)\"\n     _type_re = rf\"^\\s*((?P<command>{_command_re})|(?P<new>{_new_re})|(?P<data>{_data_re})?\\s*(\\!(?P<comment>.*))?\\s*$\"\n-    _line_type_re = re.compile(_type_re)\n+    _line_type_re = re.compile(_type_re, re.IGNORECASE)\n+\n     line = line.strip()\n     if not line:\n         return \"comment\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14369",
        "model_patch": "diff --git a/astropy/units/format/generic_parsetab.py b/astropy/units/format/generic_parsetab.py\nindex d877cd43aa..88dd85fa9f 100644\n--- a/astropy/units/format/generic_parsetab.py\n+++ b/astropy/units/format/generic_parsetab.py\n@@ -57,8 +57,9 @@ _lr_productions = [\n   ('unit -> factor inverse_unit','unit',2,'p_unit','generic.py',256),\n   ('unit -> factor product inverse_unit','unit',3,'p_unit','generic.py',257),\n   ('unit -> factor','unit',1,'p_unit','generic.py',258),\n-  ('division_product_of_units -> division_product_of_units division product_of_units','division_product_of_units',3,'p_division_product_of_units','generic.py',270),\n+  ('division_product_of_units -> product_of_units division division_product_of_units','division_product_of_units',3,'p_division_product_of_units','generic.py',270),\n   ('division_product_of_units -> product_of_units','division_product_of_units',1,'p_division_product_of_units','generic.py',271),\n+\n   ('inverse_unit -> division unit_expression','inverse_unit',2,'p_inverse_unit','generic.py',281),\n   ('factor -> factor_fits','factor',1,'p_factor','generic.py',287),\n   ('factor -> factor_float','factor',1,'p_factor','generic.py',288),\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14508",
        "model_patch": "diff --git a/astropy/io/fits/card.py b/astropy/io/fits/card.py\nindex 118bfced89..79e8dbab64 100644\n--- a/astropy/io/fits/card.py\n+++ b/astropy/io/fits/card.py\n@@ -1298,14 +1298,23 @@ def _format_value(value):\n \n \n def _format_float(value):\n-    \"\"\"Format a floating number to make sure it gets the decimal point.\"\"\"\n+    \"\"\"Format a floating number to make sure it gets the decimal point.\n+    \n+    Try using Python\u2019s built-in string representation (str(value)) first.\n+    If that produces a string short enough to fit in 20 characters, use it;\n+    otherwise fall back to the f\"{value:.16G}\" formatting.\n+    \"\"\"\n+    default_str = str(value)\n+    if len(default_str) <= 20:\n+        if \".\" not in default_str and \"E\" not in default_str:\n+            default_str += \".0\"\n+        return default_str\n+\n     value_str = f\"{value:.16G}\"\n     if \".\" not in value_str and \"E\" not in value_str:\n         value_str += \".0\"\n     elif \"E\" in value_str:\n-        # On some Windows builds of Python (and possibly other platforms?) the\n-        # exponent is zero-padded out to, it seems, three digits.  Normalize\n-        # the format to pad only to two digits.\n+        # Normalize exponent format (pad only to two digits)\n         significand, exponent = value_str.split(\"E\")\n         if exponent[0] in (\"+\", \"-\"):\n             sign = exponent[0]\n@@ -1313,18 +1322,13 @@ def _format_float(value):\n         else:\n             sign = \"\"\n         value_str = f\"{significand}E{sign}{int(exponent):02d}\"\n-\n-    # Limit the value string to at most 20 characters.\n-    str_len = len(value_str)\n-\n-    if str_len > 20:\n+    \n+    if len(value_str) > 20:\n         idx = value_str.find(\"E\")\n-\n         if idx < 0:\n             value_str = value_str[:20]\n         else:\n-            value_str = value_str[: 20 - (str_len - idx)] + value_str[idx:]\n-\n+            value_str = value_str[: 20 - (len(value_str) - idx)] + value_str[idx:]\n     return value_str\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14539",
        "model_patch": "diff --git a/astropy/io/fits/diff.py b/astropy/io/fits/diff.py\nindex 100cdf1b8c..39a7896361 100644\n--- a/astropy/io/fits/diff.py\n+++ b/astropy/io/fits/diff.py\n@@ -1445,23 +1445,26 @@ class TableDataDiff(_BaseDiff):\n             arra = self.a[col.name]\n             arrb = self.b[col.name]\n \n-            if np.issubdtype(arra.dtype, np.floating) and np.issubdtype(\n-                arrb.dtype, np.floating\n-            ):\n+            if np.issubdtype(arra.dtype, np.floating) and np.issubdtype(arrb.dtype, np.floating):\n                 diffs = where_not_allclose(arra, arrb, rtol=self.rtol, atol=self.atol)\n-            elif \"P\" in col.format:\n+            # For columns with VLAs, the underlying data type is object so we need to\n+            # check element-by-element. Previously only columns whose format contained \"P\"\n+            # were handled specially. However, formats like \"QD\" (variable-length double arrays)\n+            # do not contain \"P\". This additional check fixes the issue.\n+            elif (\"P\" in col.format.upper()) or (len(arra) > 0 and isinstance(arra[0], (list, np.ndarray))):\n                 diffs = (\n                     [\n                         idx\n                         for idx in range(len(arra))\n                         if not np.allclose(\n-                            arra[idx], arrb[idx], rtol=self.rtol, atol=self.atol\n+                            np.array(arra[idx]), np.array(arrb[idx]), rtol=self.rtol, atol=self.atol\n                         )\n                     ],\n                 )\n             else:\n                 diffs = np.where(arra != arrb)\n \n+\n             self.diff_total += len(set(diffs[0]))\n \n             if self.numdiffs >= 0:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14598",
        "model_patch": "diff --git a/astropy/io/fits/card.py b/astropy/io/fits/card.py\nindex 1b3285ddce..5c1eeeac18 100644\n--- a/astropy/io/fits/card.py\n+++ b/astropy/io/fits/card.py\n@@ -767,14 +767,15 @@ class Card(_Verify):\n \n         if m.group(\"bool\") is not None:\n             value = m.group(\"bool\") == \"T\"\n-        elif m.group(\"strg\") is not None:\n-            value = re.sub(\"''\", \"'\", m.group(\"strg\"))\n-        elif m.group(\"numr\") is not None:\n-            #  Check for numbers with leading 0s.\n-            numr = self._number_NFSC_RE.match(m.group(\"numr\"))\n-            digt = translate(numr.group(\"digt\"), FIX_FP_TABLE2, \" \")\n-            if numr.group(\"sign\") is None:\n-                sign = \"\"\n+            elif m.group(\"strg\") is not None:\n+                strg_val = m.group(\"strg\")\n+                # If the string is exactly a null string represented by two single quotes,\n+                # then return an empty string rather than converting it to a single quote.\n+                if strg_val.strip() == \"''\":\n+                    value = \"\"\n+                else:\n+                    value = re.sub(\"''\", \"'\", strg_val)\n+\n             else:\n                 sign = numr.group(\"sign\")\n             value = _str_to_num(sign + digt)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-14995",
        "model_patch": "diff --git a/astropy/nddata/mixins/ndarithmetic.py b/astropy/nddata/mixins/ndarithmetic.py\nindex 4153dfccb2..bdd551724e 100644\n--- a/astropy/nddata/mixins/ndarithmetic.py\n+++ b/astropy/nddata/mixins/ndarithmetic.py\n@@ -512,19 +512,22 @@ class NDArithmeticMixin:\n             If neither had a mask ``None`` is returned. Otherwise\n             ``handle_mask`` must create (and copy) the returned mask.\n         \"\"\"\n-        # If only one mask is present we need not bother about any type checks\n-        if (\n-            self.mask is None and operand is not None and operand.mask is None\n-        ) or handle_mask is None:\n-            return None\n-        elif self.mask is None and operand is not None:\n-            # Make a copy so there is no reference in the result.\n+    if handle_mask is None:\n+        return None\n+\n+    # If self.mask is missing (or is None), use operand's mask (if valid)\n+    if self.mask is None:\n+        if operand is not None and operand.mask is not None:\n             return deepcopy(operand.mask)\n-        elif operand is None:\n-            return deepcopy(self.mask)\n         else:\n-            # Now lets calculate the resulting mask (operation enforces copy)\n-            return handle_mask(self.mask, operand.mask, **kwds)\n+            return None\n+\n+    # If operand.mask is missing, return self.mask.\n+    if operand is None or operand.mask is None:\n+        return deepcopy(self.mask)\n+\n+    # Otherwise, both masks are present so use the provided handle_mask function.\n+    return handle_mask(self.mask, operand.mask, **kwds)\n \n     def _arithmetic_wcs(self, operation, operand, compare_wcs, **kwds):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-7166",
        "model_patch": "diff --git a/astropy/utils/misc.py b/astropy/utils/misc.py\nindex de3fb01d18..fb8002c464 100644\n--- a/astropy/utils/misc.py\n+++ b/astropy/utils/misc.py\n@@ -520,24 +520,34 @@ class InheritDocstrings(type):\n         u'Wiggle the thingamajig'\n     \"\"\"\n \n-    def __init__(cls, name, bases, dct):\n-        def is_public_member(key):\n-            return (\n-                (key.startswith('__') and key.endswith('__')\n-                 and len(key) > 4) or\n-                not key.startswith('_'))\n-\n-        for key, val in dct.items():\n-            if (inspect.isfunction(val) and\n-                is_public_member(key) and\n-                val.__doc__ is None):\n-                for base in cls.__mro__[1:]:\n-                    super_method = getattr(base, key, None)\n-                    if super_method is not None:\n-                        val.__doc__ = super_method.__doc__\n-                        break\n-\n-        super().__init__(name, bases, dct)\n+def __init__(cls, name, bases, dct):\n+    def is_public_member(key):\n+        return (\n+            (key.startswith('__') and key.endswith('__')\n+             and len(key) > 4) or\n+            not key.startswith('_'))\n+    \n+    for key, val in dct.items():\n+        if not is_public_member(key):\n+            continue\n+\n+        if inspect.isfunction(val) and val.__doc__ is None:\n+            for base in cls.__mro__[1:]:\n+                super_method = getattr(base, key, None)\n+                if super_method is not None:\n+                    val.__doc__ = super_method.__doc__\n+                    break\n+\n+        elif isinstance(val, property) and val.__doc__ is None:\n+            for base in cls.__mro__[1:]:\n+                base_prop = getattr(base, key, None)\n+                if isinstance(base_prop, property) and base_prop.__doc__:\n+                    new_prop = property(val.fget, val.fset, val.fdel, base_prop.__doc__)\n+                    dct[key] = new_prop\n+                    break\n+\n+    super().__init__(name, bases, dct)\n+\n \n \n class OrderedDescriptor(metaclass=abc.ABCMeta):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-7336",
        "model_patch": "diff --git a/astropy/units/decorators.py b/astropy/units/decorators.py\nindex 8bece5a850..08891d9379 100644\n--- a/astropy/units/decorators.py\n+++ b/astropy/units/decorators.py\n@@ -221,10 +221,15 @@ class QuantityInput:\n             with add_enabled_equivalencies(self.equivalencies):\n                 return_ = wrapped_function(*func_args, **func_kwargs)\n             if wrapped_signature.return_annotation is not inspect.Signature.empty:\n+                # If the return value is None or the return annotation is explicitly None,\n+                # do not attempt unit conversion.\n+                if return_ is None or wrapped_signature.return_annotation in (None, type(None)):\n+                    return return_\n                 return return_.to(wrapped_signature.return_annotation)\n             else:\n                 return return_\n \n+\n         return wrapper\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-7606",
        "model_patch": "diff --git a/astropy/units/core.py b/astropy/units/core.py\nindex e9bd986d33..01df9133cf 100644\n--- a/astropy/units/core.py\n+++ b/astropy/units/core.py\n@@ -1709,9 +1709,15 @@ class UnrecognizedUnit(IrreducibleUnit):\n         __rmul__ = __lt__ = __gt__ = __le__ = __ge__ = __neg__ = \\\n         _unrecognized_operator\n \n-    def __eq__(self, other):\n-        other = Unit(other, parse_strict='silent')\n-        return isinstance(other, UnrecognizedUnit) and self.name == other.name\n+\tdef __eq__(self, other):\n+\t    if other is None:\n+\t        return False\n+\t    try:\n+\t        other = Unit(other, parse_strict='silent')\n+\t    except (ValueError, UnitsError, TypeError):\n+\t        return False\n+\t    return isinstance(other, UnrecognizedUnit) and self.name == other.name\n+\n \n     def __ne__(self, other):\n         return not (self == other)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-7671",
        "model_patch": "diff --git a/astropy/utils/introspection.py b/astropy/utils/introspection.py\nindex 3e784f9fc3..cdb6ea9731 100644\n--- a/astropy/utils/introspection.py\n+++ b/astropy/utils/introspection.py\n@@ -139,10 +139,19 @@ def minversion(module, version, inclusive=True, version_path='__version__'):\n     else:\n         have_version = resolve_name(module.__name__, version_path)\n \n-    if inclusive:\n+if inclusive:\n+    try:\n         return LooseVersion(have_version) >= LooseVersion(version)\n-    else:\n+    except TypeError:\n+        from pkg_resources import parse_version\n+        return parse_version(have_version) >= parse_version(version)\n+else:\n+    try:\n         return LooseVersion(have_version) > LooseVersion(version)\n+    except TypeError:\n+        from pkg_resources import parse_version\n+        return parse_version(have_version) > parse_version(version)\n+\n \n \n def find_current_module(depth=1, finddiff=False):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-8707",
        "model_patch": "diff --git a/astropy/io/fits/card.py b/astropy/io/fits/card.py\nindex 8c1ac5d738..8d500a90ec 100644\n--- a/astropy/io/fits/card.py\n+++ b/astropy/io/fits/card.py\n@@ -544,19 +544,21 @@ class Card(_Verify):\n                 (isinstance(self.value, str) and not self.value) and\n                 not self.comment)\n \n-    @classmethod\n-    def fromstring(cls, image):\n-        \"\"\"\n-        Construct a `Card` object from a (raw) string. It will pad the string\n-        if it is not the length of a card image (80 columns).  If the card\n-        image is longer than 80 columns, assume it contains ``CONTINUE``\n-        card(s).\n-        \"\"\"\n-\n-        card = cls()\n-        card._image = _pad(image)\n-        card._verified = False\n-        return card\n+def fromstring(cls, image):\n+    \"\"\"\n+    Construct a `Card` object from a (raw) string. It will pad the string\n+    if it is not the length of a card image (80 columns).  If the card\n+    image is longer than 80 columns, assume it contains ``CONTINUE``\n+    card(s).\n+    \"\"\"\n+    # If the card image is provided as bytes, decode to ASCII\n+    if isinstance(image, bytes):\n+        image = image.decode('ascii')\n+    card = cls()\n+    card._image = _pad(image)\n+    card._verified = False\n+    return card\n+fromstring = classmethod(fromstring)\n \n     @classmethod\n     def normalize_keyword(cls, keyword):\ndiff --git a/astropy/io/fits/header.py b/astropy/io/fits/header.py\nindex ad07e6d52d..68c4c6b262 100644\n--- a/astropy/io/fits/header.py\n+++ b/astropy/io/fits/header.py\n@@ -347,6 +347,8 @@ class Header:\n         header\n             A new `Header` instance.\n         \"\"\"\n+        if isinstance(data, bytes):\n+            data = data.decode('ascii')\n \n         cards = []\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "astropy__astropy-8872",
        "model_patch": "diff --git a/astropy/units/quantity.py b/astropy/units/quantity.py\nindex ded609cbe9..160de3fcd2 100644\n--- a/astropy/units/quantity.py\n+++ b/astropy/units/quantity.py\n@@ -376,12 +376,13 @@ class Quantity(np.ndarray, metaclass=InheritDocstrings):\n             raise TypeError(\"The value must be a valid Python or \"\n                             \"Numpy numeric type.\")\n \n-        # by default, cast any integer, boolean, etc., to float\n-        if dtype is None and (not (np.can_cast(np.float32, value.dtype)\n-                                   or value.dtype.fields)\n+        # by default, cast any non-floating numeric type (or object types)\n+        # to float; preserving left\u2010alone any already floating type (e.g. np.float16)\n+        if dtype is None and ((not np.issubdtype(value.dtype, np.floating) and not value.dtype.fields)\n                               or value.dtype.kind == 'O'):\n             value = value.astype(float)\n \n+\n         value = value.view(cls)\n         value._set_unit(value_unit)\n         if unit is value_unit:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10097",
        "model_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex 92394a7eae..28882d8b63 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -92,13 +92,14 @@ class URLValidator(RegexValidator):\n     )\n     host_re = '(' + hostname_re + domain_re + tld_re + '|localhost)'\n \n-    regex = _lazy_re_compile(\n-        r'^(?:[a-z0-9\\.\\-\\+]*)://'  # scheme is validated separately\n-        r'(?:\\S+(?::\\S*)?@)?'  # user:pass authentication\n-        r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n-        r'(?::\\d{2,5})?'  # port\n-        r'(?:[/?#][^\\s]*)?'  # resource path\n-        r'\\Z', re.IGNORECASE)\n+regex = _lazy_re_compile(\n+    r'^(?:[a-z0-9\\.\\-\\+]*)://'  # scheme is validated separately\n+    r'(?:(?P<username>[^\\s:/@]+)(?::(?P<password>[^\\s:/@]*))?@)?'  # user:pass authentication:\n+    r'(?:' + ipv4_re + '|' + ipv6_re + '|' + host_re + ')'\n+    r'(?::\\d{2,5})?'  # port\n+    r'(?:[/?#][^\\s]*)?'  # resource path\n+    r'\\Z', re.IGNORECASE)\n+\n     message = _('Enter a valid URL.')\n     schemes = ['http', 'https', 'ftp', 'ftps']\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10554",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 1544beb613..f86c5634b5 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -931,11 +931,20 @@ class QuerySet:\n         # Clear limits and ordering so they can be reapplied\n         clone.query.clear_ordering(True)\n         clone.query.clear_limits()\n-        clone.query.combined_queries = (self.query,) + tuple(qs.query for qs in other_qs)\n+        \n+        # Clear ordering on all combined query objects to prevent SQL errors\n+        self.query.clear_ordering(True)\n+        combined = [self.query]\n+        for qs in other_qs:\n+            qs.query.clear_ordering(True)\n+            combined.append(qs.query)\n+        \n+        clone.query.combined_queries = tuple(combined)\n         clone.query.combinator = combinator\n         clone.query.combinator_all = all\n         return clone\n \n+\n     def union(self, *other_qs, all=False):\n         # If the query is an EmptyQuerySet, combine all nonempty querysets.\n         if isinstance(self, EmptyQuerySet):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10880",
        "model_patch": "diff --git a/django/db/models/aggregates.py b/django/db/models/aggregates.py\nindex ac0b62d0bf..76a2a12c16 100644\n--- a/django/db/models/aggregates.py\n+++ b/django/db/models/aggregates.py\n@@ -68,7 +68,8 @@ class Aggregate(Func):\n         return []\n \n     def as_sql(self, compiler, connection, **extra_context):\n-        extra_context['distinct'] = 'DISTINCT' if self.distinct else ''\n+        extra_context['distinct'] = 'DISTINCT ' if self.distinct else ''\n+\n         if self.filter:\n             if connection.features.supports_aggregate_filter_clause:\n                 filter_sql, filter_params = self.filter.as_sql(compiler, connection)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10914",
        "model_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\nindex acee9887d2..8c46ea67c9 100644\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -304,7 +304,8 @@ FILE_UPLOAD_TEMP_DIR = None\n \n # The numeric mode to set newly-uploaded files to. The value should be a mode\n # you'd pass directly to os.chmod; see https://docs.python.org/library/os.html#files-and-directories.\n-FILE_UPLOAD_PERMISSIONS = None\n+FILE_UPLOAD_PERMISSIONS = 0o644\n+\n \n # The numeric mode to assign to newly-created directories, when uploading files.\n # The value should be a mode as you'd pass to os.chmod;\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10973",
        "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 7fca6eff30..75eef3cc4a 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -34,38 +34,20 @@ class DatabaseClient(BaseDatabaseClient):\n             args += ['-p', str(port)]\n         args += [dbname]\n \n-        temp_pgpass = None\n+        # Create a copy of environment variables and set PGPASSWORD if provided\n+        env = os.environ.copy()\n+        if passwd:\n+            env['PGPASSWORD'] = passwd\n+\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n-            if passwd:\n-                # Create temporary .pgpass file.\n-                temp_pgpass = NamedTemporaryFile(mode='w+')\n-                try:\n-                    print(\n-                        _escape_pgpass(host) or '*',\n-                        str(port) or '*',\n-                        _escape_pgpass(dbname) or '*',\n-                        _escape_pgpass(user) or '*',\n-                        _escape_pgpass(passwd),\n-                        file=temp_pgpass,\n-                        sep=':',\n-                        flush=True,\n-                    )\n-                    os.environ['PGPASSFILE'] = temp_pgpass.name\n-                except UnicodeEncodeError:\n-                    # If the current locale can't encode the data, let the\n-                    # user input the password manually.\n-                    pass\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)\n-            subprocess.check_call(args)\n+            subprocess.run(args, env=env, check=True)\n         finally:\n             # Restore the original SIGINT handler.\n             signal.signal(signal.SIGINT, sigint_handler)\n-            if temp_pgpass:\n-                temp_pgpass.close()\n-                if 'PGPASSFILE' in os.environ:  # unit tests need cleanup\n-                    del os.environ['PGPASSFILE']\n+\n \n     def runshell(self):\n         DatabaseClient.runshell_db(self.connection.get_connection_params())\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-10999",
        "model_patch": "diff --git a/django/utils/dateparse.py b/django/utils/dateparse.py\nindex 8d08b7d1d3..2a1ca6dbd5 100644\n--- a/django/utils/dateparse.py\n+++ b/django/utils/dateparse.py\n@@ -29,13 +29,14 @@ datetime_re = re.compile(\n standard_duration_re = re.compile(\n     r'^'\n     r'(?:(?P<days>-?\\d+) (days?, )?)?'\n-    r'((?:(?P<hours>-?\\d+):)(?=\\d+:\\d+))?'\n+    r'((?:(?P<hours>-?\\d+):)(?=-?\\d+:-?\\d+))?'\n     r'(?:(?P<minutes>-?\\d+):)?'\n     r'(?P<seconds>-?\\d+)'\n     r'(?:\\.(?P<microseconds>\\d{1,6})\\d{0,6})?'\n     r'$'\n )\n \n+\n # Support the sections of ISO 8601 date representation that are accepted by\n # timedelta\n iso8601_duration_re = re.compile(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11066",
        "model_patch": "diff --git a/django/contrib/contenttypes/management/__init__.py b/django/contrib/contenttypes/management/__init__.py\nindex 2b5f688136..c64629b5cb 100644\n--- a/django/contrib/contenttypes/management/__init__.py\n+++ b/django/contrib/contenttypes/management/__init__.py\n@@ -24,8 +24,9 @@ class RenameContentType(migrations.RunPython):\n             content_type.model = new_model\n             try:\n                 with transaction.atomic(using=db):\n-                    content_type.save(update_fields={'model'})\n-            except IntegrityError:\n+with transaction.atomic(using=db):\n+    content_type.save(using=db, update_fields={'model'})\n+\n                 # Gracefully fallback if a stale content type causes a\n                 # conflict as remove_stale_contenttypes will take care of\n                 # asking the user what should be done next.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11087",
        "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 3a462f1c4c..fc1ff59f7b 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -326,3 +326,7 @@ class Collector:\n             for instance in instances:\n                 setattr(instance, model._meta.pk.attname, None)\n         return sum(deleted_counter.values()), dict(deleted_counter)\n+\n+# Optimize deletion: only the primary key field is needed (other fields are not used)\n+pk_field = model._meta.pk.attname\n+sub_objs = list(queryset.only(pk_field))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11095",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 5e7b23f9a0..36c2bc90f1 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -553,6 +553,276 @@ class ModelAdmin(BaseModelAdmin):\n     paginator = Paginator\n     preserve_filters = True\n     inlines = []\n+   def get_inlines(self, request, obj=None):\n+        \"\"\"\n+        Hook for returning the list of inline model admin classes to use for the\n+        given request and model instance.\n+        By default, returns self.inlines.\n+        \"\"\"\n+        return self.inlines\n     # Custom templates (designed to be over-ridden in subclasses)\n     add_form_template = None\n@@ -582,7 +852,8 @@ class ModelAdmin(BaseModelAdmin):\n \n     def get_inline_instances(self, request, obj=None):\n         inline_instances = []\n-        for inline_class in self.inlines:\n+        # use the get_inlines() hook so that subclasses can override which inlines to include.\n+        for inline_class in self.get_inlines(request, obj):\n             inline = inline_class(self.model, self.admin_site)\n             if request:\n                 if not (inline.has_view_or_change_permission(request, obj) or\n@@ -592,9 +863,10 @@ class ModelAdmin(BaseModelAdmin):\n                 if not inline.has_add_permission(request, obj):\n                     inline.max_num = 0\n             inline_instances.append(inline)\n-\n+ \n         return inline_instances\n     def get_urls(self):\n         from django.urls import path",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11099",
        "model_patch": "diff --git a/django/contrib/auth/validators.py b/django/contrib/auth/validators.py\nindex b4878cfd45..177797e7d6 100644\n--- a/django/contrib/auth/validators.py\n+++ b/django/contrib/auth/validators.py\n@@ -7,7 +7,8 @@ from django.utils.translation import gettext_lazy as _\n \n @deconstructible\n class ASCIIUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+regex = r'\\A[\\w.@+-]+\\Z'\n+\n     message = _(\n         'Enter a valid username. This value may contain only English letters, '\n         'numbers, and @/./+/-/_ characters.'\n@@ -17,7 +18,8 @@ class ASCIIUsernameValidator(validators.RegexValidator):\n \n @deconstructible\n class UnicodeUsernameValidator(validators.RegexValidator):\n-    regex = r'^[\\w.@+-]+$'\n+regex = r'\\A[\\w.@+-]+\\Z'\n+\n     message = _(\n         'Enter a valid username. This value may contain only letters, '\n         'numbers, and @/./+/-/_ characters.'\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11119",
        "model_patch": "diff --git a/django/template/engine.py b/django/template/engine.py\nindex dfaa67ba12..e608d0b9cb 100644\n--- a/django/template/engine.py\n+++ b/django/template/engine.py\n@@ -157,10 +157,12 @@ class Engine:\n             t = self.get_template(template_name)\n         # Django < 1.8 accepted a Context in `context` even though that's\n         # unintended. Preserve this ability but don't rewrap `context`.\n-        if isinstance(context, Context):\n-            return t.render(context)\n-        else:\n-            return t.render(Context(context))\n+if isinstance(context, Context):\n+    return t.render(context)\n+else:\n+    # Pass the engine's autoescape setting to Context\n+    return t.render(Context(context, autoescape=self.autoescape))\n+\n \n     def select_template(self, template_name_list):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11133",
        "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex 6a84e193ba..4709b419d5 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -233,6 +233,66 @@ class HttpResponseBase:\n             return bytes(value)\n         if isinstance(value, str):\n             return bytes(value.encode(self.charset))\n+f isinstance(value, memoryview):\n+    return bytes(value)\n         # Handle non-string types.\n         return str(value).encode(self.charset)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11138",
        "model_patch": "diff --git a/django/db/backends/mysql/operations.py b/django/db/backends/mysql/operations.py\nindex 50f85e0621..3b47c2fa03 100644\n--- a/django/db/backends/mysql/operations.py\n+++ b/django/db/backends/mysql/operations.py\n@@ -70,9 +70,15 @@ class DatabaseOperations(BaseDatabaseOperations):\n \n     def _convert_field_to_tz(self, field_name, tzname):\n         if settings.USE_TZ:\n-            field_name = \"CONVERT_TZ(%s, 'UTC', '%s')\" % (field_name, tzname)\n+            # Use the connection's timezone (set at the database level) as the source.\n+            db_tz = getattr(self.connection, \"timezone\", \"UTC\")\n+            # If the database timezone is the same as the target timezone, no conversion is needed.\n+            if db_tz == tzname:\n+                return field_name\n+            field_name = \"CONVERT_TZ(%s, '%s', '%s')\" % (field_name, db_tz, tzname)\n         return field_name\n \n+\n     def datetime_cast_date_sql(self, field_name, tzname):\n         field_name = self._convert_field_to_tz(field_name, tzname)\n         return \"DATE(%s)\" % field_name\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11141",
        "model_patch": "diff --git a/django/db/migrations/loader.py b/django/db/migrations/loader.py\nindex 8c308621d2..d276d2f13c 100644\n--- a/django/db/migrations/loader.py\n+++ b/django/db/migrations/loader.py\n@@ -85,11 +85,6 @@ class MigrationLoader:\n                 raise\n             else:\n                 # Empty directories are namespaces.\n-                # getattr() needed on PY36 and older (replace w/attribute access).\n-                if getattr(module, '__file__', None) is None:\n-                    self.unmigrated_apps.add(app_config.label)\n-                    continue\n-                # Module is not a package (e.g. migrations.py).\n                 if not hasattr(module, '__path__'):\n                     self.unmigrated_apps.add(app_config.label)\n                     continue\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11149",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 880a2cc17b..88b14170b3 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -2111,32 +2111,38 @@ class InlineModelAdmin(BaseModelAdmin):\n             queryset = queryset.none()\n         return queryset\n \n-    def has_add_permission(self, request, obj):\n-        if self.opts.auto_created:\n-            # We're checking the rights to an auto-created intermediate model,\n-            # which doesn't have its own individual permissions. The user needs\n-            # to have the view permission for the related model in order to\n-            # be able to do anything with the intermediate model.\n-            return self.has_view_permission(request, obj)\n-        return super().has_add_permission(request)\n+def has_add_permission(self, request, obj):\n+    if self.opts.auto_created:\n+        opts = self.opts\n+        for field in opts.fields:\n+            if field.remote_field and field.remote_field.model != self.parent_model:\n+                opts = field.remote_field.model._meta\n+                break\n+        return request.user.has_perm('%s.%s' % (opts.app_label, get_permission_codename('change', opts)))\n+    return super().has_add_permission(request)\n \n-    def has_change_permission(self, request, obj=None):\n-        if self.opts.auto_created:\n-            # We're checking the rights to an auto-created intermediate model,\n-            # which doesn't have its own individual permissions. The user needs\n-            # to have the view permission for the related model in order to\n-            # be able to do anything with the intermediate model.\n-            return self.has_view_permission(request, obj)\n-        return super().has_change_permission(request)\n \n-    def has_delete_permission(self, request, obj=None):\n-        if self.opts.auto_created:\n-            # We're checking the rights to an auto-created intermediate model,\n-            # which doesn't have its own individual permissions. The user needs\n-            # to have the view permission for the related model in order to\n-            # be able to do anything with the intermediate model.\n-            return self.has_view_permission(request, obj)\n-        return super().has_delete_permission(request, obj)\n+def has_change_permission(self, request, obj=None):\n+    if self.opts.auto_created:\n+        opts = self.opts\n+        for field in opts.fields:\n+            if field.remote_field and field.remote_field.model != self.parent_model:\n+                opts = field.remote_field.model._meta\n+                break\n+        return request.user.has_perm('%s.%s' % (opts.app_label, get_permission_codename('change', opts)))\n+    return super().has_change_permission(request, obj)\n+\n+\n+def has_delete_permission(self, request, obj=None):\n+    if self.opts.auto_created:\n+        opts = self.opts\n+        for field in opts.fields:\n+            if field.remote_field and field.remote_field.model != self.parent_model:\n+                opts = field.remote_field.model._meta\n+                break\n+        return request.user.has_perm('%s.%s' % (opts.app_label, get_permission_codename('change', opts)))\n+    return super().has_delete_permission(request, obj)\n+\n \n     def has_view_permission(self, request, obj=None):\n         if self.opts.auto_created:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11163",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex d157c291ef..11459848fa 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -83,7 +83,8 @@ def model_to_dict(instance, fields=None, exclude=None):\n     for f in chain(opts.concrete_fields, opts.private_fields, opts.many_to_many):\n         if not getattr(f, 'editable', False):\n             continue\n-        if fields and f.name not in fields:\n+        if fields is not None and f.name not in fields:\n+\n             continue\n         if exclude and f.name in exclude:\n             continue\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11179",
        "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex 92fe4affb9..fe27cd1c71 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -272,14 +272,15 @@ class Collector:\n         deleted_counter = Counter()\n \n         # Optimize for the case with a single obj and no dependencies\n-        if len(self.data) == 1 and len(instances) == 1:\n-            instance = list(instances)[0]\n-            if self.can_fast_delete(instance):\n-                with transaction.mark_for_rollback_on_error():\n-                    count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n-                return count, {model._meta.label: count}\n-\n-        with transaction.atomic(using=self.using, savepoint=False):\n+if len(self.data) == 1 and len(instances) == 1:\n+    instance = list(instances)[0]\n+    if self.can_fast_delete(instance):\n+        with transaction.mark_for_rollback_on_error():\n+            count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n+        # Clear the primary key on the instance after fast deletion.\n+        setattr(instance, model._meta.pk.attname, None)\n+        return count, {model._meta.label: count}\n+\n             # send pre_delete signals\n             for model, obj in self.instances_with_model():\n                 if not model._meta.auto_created:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11206",
        "model_patch": "diff --git a/django/utils/numberformat.py b/django/utils/numberformat.py\nindex 88b35fc435..9d9813db01 100644\n--- a/django/utils/numberformat.py\n+++ b/django/utils/numberformat.py\n@@ -27,20 +27,26 @@ def format(number, decimal_sep, decimal_pos=None, grouping=0, thousand_sep='',\n     # sign\n     sign = ''\n     if isinstance(number, Decimal):\n-        # Format values with more than 200 digits (an arbitrary cutoff) using\n-        # scientific notation to avoid high memory usage in {:f}'.format().\n-        _, digits, exponent = number.as_tuple()\n-        if abs(exponent) + len(digits) > 200:\n-            number = '{:e}'.format(number)\n-            coefficient, exponent = number.split('e')\n-            # Format the coefficient.\n-            coefficient = format(\n-                coefficient, decimal_sep, decimal_pos, grouping,\n-                thousand_sep, force_grouping, use_l10n,\n-            )\n-            return '{}e{}'.format(coefficient, exponent)\n+        # If a decimal_pos argument is provided and the number is too small\n+        # to be represented with significant digits, treat it as zero.\n+        if decimal_pos is not None and abs(number) < Decimal(10) ** (-decimal_pos):\n+            str_number = '{:f}'.format(Decimal(0))\n         else:\n-            str_number = '{:f}'.format(number)\n+            # Format values with more than 200 digits (an arbitrary cutoff) using\n+            # scientific notation to avoid high memory usage in '{:f}'.format().\n+            _, digits, exponent = number.as_tuple()\n+            if abs(exponent) + len(digits) > 200:\n+                number = '{:e}'.format(number)\n+                coefficient, exponent = number.split('e')\n+                # Format the coefficient.\n+                coefficient = format(\n+                    coefficient, decimal_sep, decimal_pos, grouping,\n+                    thousand_sep, force_grouping, use_l10n,\n+                )\n+                return '{}e{}'.format(coefficient, exponent)\n+            else:\n+                str_number = '{:f}'.format(number)\n+\n     else:\n         str_number = str(number)\n     if str_number[0] == '-':\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11211",
        "model_patch": "diff --git a/django/contrib/contenttypes/fields.py b/django/contrib/contenttypes/fields.py\nindex ed98ecb48c..5a5f7a16e7 100644\n--- a/django/contrib/contenttypes/fields.py\n+++ b/django/contrib/contenttypes/fields.py\n@@ -39,14 +39,17 @@ class GenericForeignKey(FieldCacheMixin):\n     remote_field = None\n \n     def __init__(self, ct_field='content_type', fk_field='object_id', for_concrete_model=True):\n-        self.ct_field = ct_field\n-        self.fk_field = fk_field\n-        self.for_concrete_model = for_concrete_model\n-        self.editable = False\n-        self.rel = None\n-        self.column = None\n+def get_prefetch_queryset(self, instances, queryset=None):\n+    object_ids = {getattr(instance, self.fk_field) for instance in instances}\n+    from django.db import models\n+    target_field = self.model._meta.pk\n+    if isinstance(target_field, models.UUIDField):\n+        # Convert object_ids from string to UUID objects so that lookup works correctly.\n+        object_ids = {target_field.to_python(obj_id) for obj_id in object_ids}\n+    if queryset is None:\n+        queryset = self.model._default_manager.all()\n+    return queryset, target_field, getattr(self, 'cache_name', self.name), object_ids\n \n-    def contribute_to_class(self, cls, name, **kwargs):\n         self.name = name\n         self.model = cls\n         cls._meta.add_field(self, private=True)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11239",
        "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex cf4df76882..3a89c28061 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -30,6 +30,546 @@ class DatabaseClient(BaseDatabaseClient):\n         subprocess_env = os.environ.copy()\n         if passwd:\n             subprocess_env['PGPASSWORD'] = str(passwd)\n+       # Set SSL-related environment variables if provided in connection parameters.\n+        if conn_params.get('sslmode'):\n+            subprocess_env['PGSSLMODE'] = str(conn_params['sslmode'])\n+        if conn_params.get('sslrootcert'):\n+            subprocess_env['PGSSLROOTCERT'] = str(conn_params['sslrootcert'])\n+        if conn_params.get('sslcert'):\n+            subprocess_env['PGSSLCERT'] = str(conn_params['sslcert'])\n+        if conn_params.get('sslkey'):\n+            subprocess_env['PGSSLKEY'] = str(conn_params['sslkey'])\n         try:\n             # Allow SIGINT to pass to psql to abort queries.\n             signal.signal(signal.SIGINT, signal.SIG_IGN)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11265",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex d69c24419b..49a696b6d6 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1666,6 +1666,67 @@ class Query(BaseExpression):\n             filter_expr = (filter_lhs, OuterRef(filter_rhs.name))\n         # Generate the inner query.\n         query = Query(self.model)\n+uery._filtered_relations = self._filtered_relations.copy()\n         query.add_filter(filter_expr)\n         query.clear_ordering(True)\n         # Try to have as simple as possible subquery -> trim leading joins from",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11276",
        "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex 9c519978f5..04d18b245b 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -3,6 +3,48 @@\n import json\n import re\n from html.parser import HTMLParser\n+rom html import escape as stdlib_escape\n from urllib.parse import (\n     parse_qsl, quote, unquote, urlencode, urlsplit, urlunsplit,\n )\n@@ -42,8 +84,11 @@ def escape(text):\n     Always escape input, even if it's already escaped and marked as such.\n     This may result in double-escaping. If this is a concern, use\n     conditional_escape() instead.\n+\n+    FIX: Use the standard library html.escape() instead of a custom implementation.\n+         Note that html.escape() converts a single quote to &#x27; instead of &#39;.\n     \"\"\"\n-    return mark_safe(str(text).translate(_html_escapes))\n+    return mark_safe(stdlib_escape(str(text), quote=True))\n \n \n _js_escapes = {",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11292",
        "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex 0c3a981290..56dafaec84 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -286,6 +286,146 @@ class BaseCommand:\n             '--force-color', action='store_true',\n             help='Force colorization of the command output.',\n         )\n+       parser.add_argument(\n+            '--skip-checks', action='store_true',\n+            help='Skip Django system checks.',\n+        )\n         self.add_arguments(parser)\n         return parser",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11299",
        "model_patch": "diff --git a/django/db/models/constraints.py b/django/db/models/constraints.py\nindex e7f81d3ee9..2d0d55bdea 100644\n--- a/django/db/models/constraints.py\n+++ b/django/db/models/constraints.py\n@@ -1,5 +1,16 @@\n from django.db.models.query_utils import Q\n from django.db.models.sql.query import Query\n+mport re\n __all__ = ['CheckConstraint', 'UniqueConstraint']\n \n@@ -32,12 +43,16 @@ class CheckConstraint(BaseConstraint):\n         self.check = check\n         super().__init__(name)\n \n-    def _get_check_sql(self, model, schema_editor):\n-        query = Query(model=model)\n-        where = query.build_where(self.check)\n-        compiler = query.get_compiler(connection=schema_editor.connection)\n-        sql, params = where.as_sql(compiler, schema_editor.connection)\n-        return sql % tuple(schema_editor.quote_value(p) for p in params)\n+def _get_check_sql(self, model, schema_editor):\n+    query = Query(model=model)\n+    where = query.build_where(self.check)\n+    compiler = query.get_compiler(connection=schema_editor.connection)\n+    sql, params = where.as_sql(compiler, schema_editor.connection)\n+    # For SQLite and Oracle backends, remove fully qualified table names from column references in check constraints.\n+    if schema_editor.connection.vendor in ('sqlite', 'oracle'):\n+        sql = re.sub(r'\"[^\"]+\"\\.\"([^\"]+)\"', r'\"\\1\"', sql)\n+    return sql % tuple(schema_editor.quote_value(p) for p in params)\n     def constraint_sql(self, model, schema_editor):\n         check = self._get_check_sql(model, schema_editor)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11333",
        "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 247e3680c0..95fdc715a1 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -64,10 +64,157 @@ class ResolverMatch:\n \n \n @functools.lru_cache(maxsize=None)\n+mport functools\n+@functools.lru_cache(maxsize=None)\n+def _get_cached_resolver(urlconf):\n+    return URLResolver(RegexPattern(r'^/'), urlconf)\n def get_resolver(urlconf=None):\n     if urlconf is None:\n         urlconf = settings.ROOT_URLCONF\n-    return URLResolver(RegexPattern(r'^/'), urlconf)\n+    return _get_cached_resolver(urlconf)\n @functools.lru_cache(maxsize=None)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11400",
        "model_patch": "diff --git a/django/contrib/admin/filters.py b/django/contrib/admin/filters.py\nindex d65e01d5e2..35ba42b8d7 100644\n--- a/django/contrib/admin/filters.py\n+++ b/django/contrib/admin/filters.py\n@@ -193,12 +193,15 @@ class RelatedFieldListFilter(FieldListFilter):\n     def expected_parameters(self):\n         return [self.lookup_kwarg, self.lookup_kwarg_isnull]\n \n-    def field_choices(self, field, request, model_admin):\n-        ordering = ()\n-        related_admin = model_admin.admin_site._registry.get(field.remote_field.model)\n-        if related_admin is not None:\n-            ordering = related_admin.get_ordering(request)\n-        return field.get_choices(include_blank=False, ordering=ordering)\n+def field_choices(self, field, request, model_admin):\n+    ordering = ()\n+    related_admin = model_admin.admin_site._registry.get(field.remote_field.model)\n+    if related_admin is not None:\n+        ordering = related_admin.get_ordering(request)\n+    if not ordering:\n+        ordering = field.remote_field.model._meta.ordering\n+    return field.get_choices(include_blank=False, ordering=ordering)\n+\n \n     def choices(self, changelist):\n         yield {\n@@ -417,6 +420,13 @@ FieldListFilter.register(lambda f: True, AllValuesFieldListFilter)\n \n \n class RelatedOnlyFieldListFilter(RelatedFieldListFilter):\n-    def field_choices(self, field, request, model_admin):\n-        pk_qs = model_admin.get_queryset(request).distinct().values_list('%s__pk' % self.field_path, flat=True)\n-        return field.get_choices(include_blank=False, limit_choices_to={'pk__in': pk_qs})\n+def field_choices(self, field, request, model_admin):\n+    pk_qs = model_admin.get_queryset(request).distinct().values_list('%s__pk' % self.field_path, flat=True)\n+    ordering = ()\n+    related_admin = model_admin.admin_site._registry.get(field.remote_field.model)\n+    if related_admin is not None:\n+        ordering = related_admin.get_ordering(request)\n+    if not ordering:\n+        ordering = field.remote_field.model._meta.ordering\n+    return field.get_choices(include_blank=False, limit_choices_to={'pk__in': pk_qs}, ordering=ordering)\n+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11433",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5edbbd376f..6fe8bcca76 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -13,8 +13,9 @@ from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, SelectMultiple,\n+    HiddenInput, MultipleHiddenInput, SelectMultiple, CheckboxInput,\n )\n+\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n \n@@ -48,9 +49,10 @@ def construct_instance(form, instance, fields=None, exclude=None):\n             continue\n         # Leave defaults for fields that aren't in POST data, except for\n         # checkbox inputs because they don't appear in POST data if not checked.\n-        if (f.has_default() and\n+        if (isinstance(form[f.name].field.widget, CheckboxInput) and\n                 form[f.name].field.widget.value_omitted_from_data(form.data, form.files, form.add_prefix(f.name))):\n             continue\n+\n         # Defer saving file-type fields until after the other fields, so a\n         # callable upload_to can use the values from other fields.\n         if isinstance(f, models.FileField):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11451",
        "model_patch": "diff --git a/django/contrib/auth/backends.py b/django/contrib/auth/backends.py\nindex f4b1722757..7124baab6d 100644\n--- a/django/contrib/auth/backends.py\n+++ b/django/contrib/auth/backends.py\n@@ -39,6 +39,81 @@ class ModelBackend(BaseBackend):\n     def authenticate(self, request, username=None, password=None, **kwargs):\n         if username is None:\n             username = kwargs.get(UserModel.USERNAME_FIELD)\n+       if username is None or password is None:\n+            return None\n         try:\n             user = UserModel._default_manager.get_by_natural_key(username)\n         except UserModel.DoesNotExist:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11477",
        "model_patch": "diff --git a/django/urls/base.py b/django/urls/base.py\nindex 0e1c3d909c..90e37c2cd8 100644\n--- a/django/urls/base.py\n+++ b/django/urls/base.py\n@@ -172,7 +172,9 @@ def translate_url(url, lang_code):\n         to_be_reversed = \"%s:%s\" % (match.namespace, match.url_name) if match.namespace else match.url_name\n         with override(lang_code):\n             try:\n-                url = reverse(to_be_reversed, args=match.args, kwargs=match.kwargs)\n+\t                filtered_kwargs = {k: v for k, v in match.kwargs.items() if v is not None}\n+\t                url = reverse(to_be_reversed, args=match.args, kwargs=filtered_kwargs)\n+\n             except NoReverseMatch:\n                 pass\n             else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11490",
        "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex a44adfc760..85d22403ce 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -425,12 +425,13 @@ class SQLCompiler:\n                 # If the columns list is limited, then all combined queries\n                 # must have the same columns list. Set the selects defined on\n                 # the query on all combined queries, if not already set.\n-                if not compiler.query.values_select and self.query.values_select:\n-                    compiler.query.set_values((\n-                        *self.query.extra_select,\n-                        *self.query.values_select,\n-                        *self.query.annotation_select,\n-                    ))\n+                    if self.query.values_select:\n+                        compiler.query.set_values((\n+                            *self.query.extra_select,\n+                            *self.query.values_select,\n+                            *self.query.annotation_select,\n+                        ))\n+\n                 part_sql, part_args = compiler.as_sql()\n                 if compiler.query.combinator:\n                     # Wrap in a subquery if wrapping in parentheses isn't\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11532",
        "model_patch": "diff --git a/django/core/mail/utils.py b/django/core/mail/utils.py\nindex d18dfe4667..f063c5a5ac 100644\n--- a/django/core/mail/utils.py\n+++ b/django/core/mail/utils.py\n@@ -11,10 +11,15 @@ class CachedDnsName:\n     def __str__(self):\n         return self.get_fqdn()\n \n-    def get_fqdn(self):\n-        if not hasattr(self, '_fqdn'):\n-            self._fqdn = socket.getfqdn()\n-        return self._fqdn\n+def get_fqdn(self):\n+    if not hasattr(self, '_fqdn'):\n+        fqdn = socket.getfqdn()\n+        try:\n+            fqdn.encode('ascii')\n+        except UnicodeEncodeError:\n+            fqdn = fqdn.encode('idna').decode('ascii')\n+        self._fqdn = fqdn\n+    return self._fqdn\n \n \n DNS_NAME = CachedDnsName()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11551",
        "model_patch": "diff --git a/django/contrib/admin/checks.py b/django/contrib/admin/checks.py\nindex f82c20c2f1..ae61b125e8 100644\n--- a/django/contrib/admin/checks.py\n+++ b/django/contrib/admin/checks.py\n@@ -720,33 +720,34 @@ class ModelAdminChecks(BaseModelAdminChecks):\n             return []\n         elif hasattr(obj, item):\n             return []\n-        elif hasattr(obj.model, item):\n+        else:\n             try:\n                 field = obj.model._meta.get_field(item)\n             except FieldDoesNotExist:\n-                return []\n-            else:\n-                if isinstance(field, models.ManyToManyField):\n+                try:\n+                    field = getattr(obj.model, item)\n+                except AttributeError:\n                     return [\n                         checks.Error(\n-                            \"The value of '%s' must not be a ManyToManyField.\" % label,\n+                            \"The value of '%s' refers to '%s', which is not a callable, \"\n+                            \"an attribute of '%s', or an attribute or method on '%s.%s'.\" % (\n+                                label, item, obj.__class__.__name__,\n+                                obj.model._meta.app_label, obj.model._meta.object_name,\n+                            ),\n                             obj=obj.__class__,\n-                            id='admin.E109',\n+                            id='admin.E108',\n                         )\n                     ]\n-                return []\n-        else:\n-            return [\n-                checks.Error(\n-                    \"The value of '%s' refers to '%s', which is not a callable, \"\n-                    \"an attribute of '%s', or an attribute or method on '%s.%s'.\" % (\n-                        label, item, obj.__class__.__name__,\n-                        obj.model._meta.app_label, obj.model._meta.object_name,\n-                    ),\n-                    obj=obj.__class__,\n-                    id='admin.E108',\n-                )\n-            ]\n+            if isinstance(field, models.ManyToManyField):\n+                return [\n+                    checks.Error(\n+                        \"The value of '%s' must not be a ManyToManyField.\" % label,\n+                        obj=obj.__class__,\n+                        id='admin.E109',\n+                    )\n+                ]\n+            return []\n+\n \n     def _check_list_display_links(self, obj):\n         \"\"\" Check that list_display_links is a unique subset of list_display.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11555",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex e15e64cde4..283a11e6f6 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -2217,12 +2217,16 @@ def get_order_dir(field, default='ASC'):\n     The 'default' param is used to indicate which way no prefix (or a '+'\n     prefix) should sort. The '-' prefix always sorts the opposite way.\n     \"\"\"\n+    if not isinstance(field, str):\n+        return field, None\n+\n     dirn = ORDER_DIR[default]\n-    if field[0] == '-':\n+    if field.startswith('-'):\n         return field[1:], dirn[1]\n     return field, dirn[0]\n \n \n+\n def add_to_dict(data, key, value):\n     \"\"\"\n     Add \"value\" to the set of values for \"key\", whether or not \"key\" already\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11603",
        "model_patch": "diff --git a/django/db/models/aggregates.py b/django/db/models/aggregates.py\nindex da4ff928aa..dbe19f8626 100644\n--- a/django/db/models/aggregates.py\n+++ b/django/db/models/aggregates.py\n@@ -99,6 +99,33 @@ class Aggregate(Func):\n class Avg(FixDurationInputMixin, NumericOutputFieldMixin, Aggregate):\n     function = 'AVG'\n     name = 'Avg'\n+   allow_distinct = True\n class Count(Aggregate):\n@@ -142,6 +169,33 @@ class StdDev(NumericOutputFieldMixin, Aggregate):\n class Sum(FixDurationInputMixin, Aggregate):\n     function = 'SUM'\n     name = 'Sum'\n+   allow_distinct = True\n class Variance(NumericOutputFieldMixin, Aggregate):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11728",
        "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 1ce4594501..84e3b65751 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -170,7 +170,8 @@ def replace_named_groups(pattern):\n             # If brackets are balanced, the end of the string for the current\n             # named capture group pattern has been reached.\n             if unmatched_open_brackets == 0:\n-                group_pattern_and_name.append((pattern[start:end + idx], group_name))\n+\t                group_pattern_and_name.append((pattern[start:end + idx + 1], group_name))\n+\n                 break\n \n             # Check for unescaped `(` and `)`. They mark the start and end of a\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11734",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 35f3c5e1ea..3572bb89aa 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -197,14 +197,15 @@ class Query(BaseExpression):\n         self.select_for_update_of = ()\n \n         self.select_related = False\n-        # Arbitrary limit for select_related to prevents infinite recursion.\n-        self.max_depth = 5\n-\n-        # Holds the selects defined by a call to values() or values_list()\n-        # excluding annotation_select and extra_select.\n-        self.values_select = ()\n+    def get_compiler(self, using=None, connection=None):\n+        compiler = SQLCompiler(self, using or self.db, connection=connection)\n+        # FIX: When a subquery contains an OuterRef within a negated condition (e.g. exclude() or ~Q()),\n+        # the outer reference must be bound to the calling (outer) model. Without this the compiler\n+        # detects an outer reference that is allowed only in a subquery and raises a ValueError.\n+        if compiler.query.has_outer_ref():\n+            compiler.query.outer_model = self.model\n+        return compiler\n \n-        # SQL annotation-related attributes\n         self.annotations = {}  # Maps alias -> Annotation Expression\n         self.annotation_select_mask = None\n         self._annotation_select_cache = None\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11740",
        "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 0dc1c77c53..807d048a6d 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -1064,8 +1064,13 @@ class MigrationAutodetector:\n             dep_app_label = \"__setting__\"\n             dep_object_name = swappable_setting\n         else:\n-            dep_app_label = field.remote_field.model._meta.app_label\n-            dep_object_name = field.remote_field.model._meta.object_name\n+            from django.apps import apps\n+            model = field.remote_field.model\n+            if isinstance(model, str):\n+                model = apps.get_model(model)\n+            dep_app_label = model._meta.app_label\n+            dep_object_name = model._meta.object_name\n+\n         dependencies = [(dep_app_label, dep_object_name, None, True)]\n         if getattr(field.remote_field, \"through\", None) and not field.remote_field.through._meta.auto_created:\n             dependencies.append((\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11749",
        "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 5f2e64761e..e1a3da4dcf 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -147,11 +147,13 @@ def call_command(command_name, *args, **options):\n         raise TypeError(\n             \"Unknown option(s) for %s command: %s. \"\n             \"Valid options are: %s.\" % (\n-                command_name,\n-                ', '.join(sorted(unknown_options)),\n-                ', '.join(sorted(valid_options)),\n-            )\n-        )\n+        parse_args += [\n+            '{}={}'.format(min(opt.option_strings), arg_options[opt.dest])\n+            for opt in parser._actions\n+            if (opt.required or (hasattr(opt, 'container') and getattr(opt.container, 'required', False)))\n+               and opt.dest in options\n+        ]\n+\n     # Move positional args out of options to mimic legacy optparse\n     args = defaults.pop('args', ())\n     if 'skip_checks' not in options:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11790",
        "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex a0cfed0995..33d232cda9 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -191,7 +191,9 @@ class AuthenticationForm(forms.Form):\n \n         # Set the max length and label for the \"username\" field.\n         self.username_field = UserModel._meta.get_field(UserModel.USERNAME_FIELD)\n-        self.fields['username'].max_length = self.username_field.max_length or 254\n+self.fields['username'].max_length = self.username_field.max_length or 254\n+self.fields['username'].widget.attrs['maxlength'] = self.fields['username'].max_length\n+\n         if self.fields['username'].label is None:\n             self.fields['username'].label = capfirst(self.username_field.verbose_name)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11815",
        "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..26ce74cbbc 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -2,6 +2,29 @@\n import os\n import re\n from importlib import import_module\n+rom enum import Enum\n from django import get_version\n from django.apps import apps\n@@ -268,8 +291,13 @@ class MigrationWriter:\n \n     @classmethod\n     def serialize(cls, value):\n+        if isinstance(value, Enum):\n+            # For Enum default values, use member access syntax to refer to the enum\n+            # by its member name (i.e. Status['GOOD']) rather than the current value.\n+            return \"%s[%r]\" % (value.__class__.__name__, value.name), set()\n         return serializer_factory(value).serialize()\n     @classmethod\n     def register_serializer(cls, type_, serializer):\n         Serializer.register(type_, serializer)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11820",
        "model_patch": "diff --git a/django/db/models/options.py b/django/db/models/options.py\nindex baa0c875b2..cb1e2849b6 100644\n--- a/django/db/models/options.py\n+++ b/django/db/models/options.py\n@@ -197,29 +197,42 @@ class Options:\n \n             # Any leftover attributes must be invalid.\n             if meta_attrs != {}:\n-                raise TypeError(\"'class Meta' got invalid attribute(s): %s\" % ','.join(meta_attrs))\n-        else:\n-            self.verbose_name_plural = format_lazy('{}s', self.verbose_name)\n-        del self.meta\n-\n-        # If the db_table wasn't provided, use the app_label + model_name.\n-        if not self.db_table:\n-            self.db_table = \"%s_%s\" % (self.app_label, self.model_name)\n-            self.db_table = truncate_name(self.db_table, connection.ops.max_name_length())\n-\n-    def _format_names_with_class(self, cls, objs):\n-        \"\"\"App label/class name interpolation for object names.\"\"\"\n-        new_objs = []\n-        for obj in objs:\n-            obj = obj.clone()\n-            obj.name = obj.name % {\n-                'app_label': cls._meta.app_label.lower(),\n-                'class': cls.__name__.lower(),\n-            }\n-            new_objs.append(obj)\n-        return new_objs\n-\n-    def _prepare(self, model):\n+    for field_name in (self.ordering or []):\n+        clean_field_name = field_name.lstrip('-')\n+        # Special check: if the ordering string contains a lookup on a related field\u2019s pk,\n+        # then flag it as invalid.\n+        if '__' in clean_field_name:\n+            parts = clean_field_name.split('__')\n+            if len(parts) == 2 and parts[1] == 'pk':\n+                try:\n+                    related_field = self.get_field(parts[0])\n+                    if related_field.is_relation:\n+                        errors.append(\n+                            checks.Error(\n+                                \"The ordering option refers to a related field using '__pk'. Use the field name '%s' instead.\" % parts[0],\n+                                hint=None,\n+                                obj=self.model,\n+                                id='models.E015',\n+                            )\n+                        )\n+                        # Skip further checking for this ordering string.\n+                        continue\n+                except FieldDoesNotExist:\n+                    # Fall through to report that the field does not exist.\n+                    pass\n+\n+        try:\n+            self.get_field(clean_field_name)\n+        except FieldDoesNotExist:\n+            errors.append(\n+                checks.Error(\n+                    \"The ordering option refers to the nonexistent field '%s'\" % field_name,\n+                    hint=None,\n+                    obj=self.model,\n+                    id='models.E015',\n+                )\n+            )\n+\n         if self.order_with_respect_to:\n             # The app registry will not be ready at this point, so we cannot\n             # use get_field().\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11848",
        "model_patch": "diff --git a/django/utils/http.py b/django/utils/http.py\nindex 572cfb4347..e76bd86949 100644\n--- a/django/utils/http.py\n+++ b/django/utils/http.py\n@@ -176,10 +176,18 @@ def parse_http_date(date):\n     try:\n         year = int(m.group('year'))\n         if year < 100:\n-            if year < 70:\n-                year += 2000\n-            else:\n-                year += 1900\n+            # Adjust two-digit year according to RFC 7231: if the candidate year\n+            # appears to be more than 50 years in the future, then subtract 100,\n+            # and if it appears to be more than 50 years in the past, add 100.\n+            current_year = datetime.datetime.utcnow().year\n+            century = current_year - (current_year % 100)\n+            candidate = century + year\n+            if candidate > current_year + 50:\n+                candidate -= 100\n+            elif candidate <= current_year - 50:\n+                candidate += 100\n+            year = candidate\n+\n         month = MONTHS.index(m.group('mon').lower()) + 1\n         day = int(m.group('day'))\n         hour = int(m.group('hour'))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11880",
        "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 03cd8af8d7..e7ec19ccbe 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -200,9 +200,11 @@ class Field:\n         memo[id(self)] = result\n         result.widget = copy.deepcopy(self.widget, memo)\n         result.validators = self.validators[:]\n+        result.error_messages = copy.deepcopy(self.error_messages, memo)\n         return result\n \n \n+\n class CharField(Field):\n     def __init__(self, *, max_length=None, min_length=None, strip=True, empty_value='', **kwargs):\n         self.max_length = max_length\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11885",
        "model_patch": "diff --git a/django/db/models/deletion.py b/django/db/models/deletion.py\nindex ae82d26340..d9ca8dd7eb 100644\n--- a/django/db/models/deletion.py\n+++ b/django/db/models/deletion.py\n@@ -309,10 +309,22 @@ class Collector:\n                         sender=model, instance=obj, using=self.using\n                     )\n \n-            # fast deletes\n+            # fast deletes: combine fast delete queries for the same model\n+            from django.db.models.sql.where import WhereNode\n+            fast_deletes_by_model = {}\n             for qs in self.fast_deletes:\n-                count = qs._raw_delete(using=self.using)\n-                deleted_counter[qs.model._meta.label] += count\n+                fast_deletes_by_model.setdefault(qs.model, []).append(qs.query.where)\n+            for model, where_nodes in fast_deletes_by_model.items():\n+                combined_where = WhereNode()\n+                for where in where_nodes:\n+                    # Combine using OR connector.\n+                    if combined_where.children:\n+                        combined_where.connector = 'OR'\n+                    combined_where.add(where, 'OR')\n+                qs_combined = model._base_manager.all()\n+                qs_combined.query.where = combined_where\n+                count = qs_combined._raw_delete(using=self.using)\n+                deleted_counter[model._meta.label] += count\n \n             # update fields\n             for model, instances_for_fieldvalues in self.field_updates.items():\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11951",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 794e0faae7..3fd401eef5 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1209,7 +1209,9 @@ class QuerySet:\n         if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:\n             raise NotSupportedError('This database backend does not support ignoring conflicts.')\n         ops = connections[self.db].ops\n-        batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1))\n+max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)\n+batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n+\n         inserted_rows = []\n         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert\n         for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11964",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 8b8be56b3b..6e5b5dacef 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -2,6 +2,77 @@\n Helper functions for creating Form classes from Django models\n and database field objects.\n \"\"\"\n+ Import enum to check for Enum values in model_to_dict.\n+import enum\n from itertools import chain\n \n@@ -90,7 +161,11 @@ def model_to_dict(instance, fields=None, exclude=None):\n             continue\n         if exclude and f.name in exclude:\n             continue\n-        data[f.name] = f.value_from_object(instance)\n+\t        val = f.value_from_object(instance)\n+\t        if isinstance(val, enum.Enum):\n+\t            val = val.value\n+\t        data[f.name] = val\n+\n     return data",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-11999",
        "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex 0a5e5ff673..a0947684b7 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -320,11 +320,16 @@ class ModelBase(type):\n         new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n         return new_class\n \n-    def add_to_class(cls, name, value):\n-        if _has_contribute_to_class(value):\n-            value.contribute_to_class(cls, name)\n-        else:\n-            setattr(cls, name, value)\n+\tdef add_to_class(cls, name, value):\n+\t    # Allow user override of get_FIELD_display methods.\n+\t    if name.startswith(\"get_\") and name.endswith(\"_display\") and name in cls.__dict__:\n+\t        # A user-defined method already exists; do not override it.\n+\t        return\n+\t    if _has_contribute_to_class(value):\n+\t        value.contribute_to_class(cls, name)\n+\t    else:\n+\t        setattr(cls, name, value)\n+\n \n     def _prepare(cls):\n         \"\"\"Create some methods once self._meta has been populated.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12039",
        "model_patch": "diff --git a/django/db/backends/ddl_references.py b/django/db/backends/ddl_references.py\nindex 44e49806f8..a8800cf43e 100644\n--- a/django/db/backends/ddl_references.py\n+++ b/django/db/backends/ddl_references.py\n@@ -108,18 +108,15 @@ class IndexColumns(Columns):\n         self.opclasses = opclasses\n         super().__init__(table, columns, quote_name, col_suffixes)\n \n-    def __str__(self):\n-        def col_str(column, idx):\n-            # Index.__init__() guarantees that self.opclasses is the same\n-            # length as self.columns.\n-            col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n-            try:\n-                col = '{} {}'.format(col, self.col_suffixes[idx])\n-            except IndexError:\n-                pass\n-            return col\n+def __str__(self):\n+    def col_str(column, idx):\n+        col = '{} {}'.format(self.quote_name(column), self.opclasses[idx])\n+        if idx < len(self.col_suffixes) and self.col_suffixes[idx]:\n+            col = '{} {}'.format(col, self.col_suffixes[idx])\n+        return col\n+\n+    return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \n-        return ', '.join(col_str(column, idx) for idx, column in enumerate(self.columns))\n \n \n class ForeignKeyName(TableColumns):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12050",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ea51912e8b..5601309352 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1073,7 +1073,9 @@ class Query(BaseExpression):\n                         ))\n                 else:\n                     resolved_values.append(sub_value)\n-            value = tuple(resolved_values)\n+# Preserve the original iterable type.\n+value = type(value)(resolved_values)\n+\n         return value\n \n     def solve_lookup_type(self, lookup):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12125",
        "model_patch": "diff --git a/django/utils/deconstruct.py b/django/utils/deconstruct.py\nindex aa952f6b73..f50de38d8d 100644\n--- a/django/utils/deconstruct.py\n+++ b/django/utils/deconstruct.py\n@@ -26,12 +26,19 @@ def deconstructible(*args, path=None):\n             if path:\n                 module_name, _, name = path.rpartition('.')\n             else:\n-                module_name = obj.__module__\n-                name = obj.__class__.__name__\n+module_name = obj.__module__\n+qualname = obj.__class__.__qualname__\n+# For inner classes, use the full qualified name\n+if '.' in qualname:\n+    name = qualname\n+else:\n+    name = obj.__class__.__name__\n+\n             # Make sure it's actually there and not an inner class\n             module = import_module(module_name)\n-            if not hasattr(module, name):\n-                raise ValueError(\n+# Only check for a top-level attribute if not an inner class.\n+if '.' not in name and not hasattr(module, name):\n+\n                     \"Could not find object %s in %s.\\n\"\n                     \"Please note that you cannot serialize things like inner \"\n                     \"classes. Please move the object into the main module \"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12143",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 137e6faa0f..b8dcf99b71 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1630,8 +1630,9 @@ class ModelAdmin(BaseModelAdmin):\n         return self.changeform_view(request, object_id, form_url, extra_context)\n \n     def _get_edited_object_pks(self, request, prefix):\n-        \"\"\"Return POST data values of list_editable primary keys.\"\"\"\n-        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(prefix, self.model._meta.pk.name))\n+        pk_pattern = re.compile(r'{}-\\d+-{}$'.format(re.escape(prefix), self.model._meta.pk.name))\n+        return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n+\n         return [value for key, value in request.POST.items() if pk_pattern.match(key)]\n \n     def _get_list_editable_queryset(self, request, prefix):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12155",
        "model_patch": "diff --git a/django/contrib/admindocs/utils.py b/django/contrib/admindocs/utils.py\nindex 4c0e7e2a56..02993b2c2c 100644\n--- a/django/contrib/admindocs/utils.py\n+++ b/django/contrib/admindocs/utils.py\n@@ -34,7 +34,8 @@ def trim_docstring(docstring):\n         return ''\n     # Convert tabs to spaces and split into lines\n     lines = docstring.expandtabs().splitlines()\n-    indent = min(len(line) - len(line.lstrip()) for line in lines if line.lstrip())\n+    indent = min(len(line) - len(line.lstrip()) for line in lines[1:] if line.lstrip())\n+\n     trimmed = [lines[0].lstrip()] + [line[indent:].rstrip() for line in lines[1:]]\n     return \"\\n\".join(trimmed).strip()\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12193",
        "model_patch": "diff --git a/django/contrib/postgres/forms/array.py b/django/contrib/postgres/forms/array.py\nindex 2e19cd574a..0230873349 100644\n--- a/django/contrib/postgres/forms/array.py\n+++ b/django/contrib/postgres/forms/array.py\n@@ -137,19 +137,20 @@ class SplitArrayWidget(forms.Widget):\n             self.widget.is_localized = self.is_localized\n         value = value or []\n         context['widget']['subwidgets'] = []\n-        final_attrs = self.build_attrs(attrs)\n-        id_ = final_attrs.get('id')\n-        for i in range(max(len(value), self.size)):\n-            try:\n-                widget_value = value[i]\n-            except IndexError:\n-                widget_value = None\n-            if id_:\n-                final_attrs = {**final_attrs, 'id': '%s_%s' % (id_, i)}\n-            context['widget']['subwidgets'].append(\n-                self.widget.get_context(name + '_%s' % i, widget_value, final_attrs)['widget']\n-            )\n-        return context\n+base_attrs = self.build_attrs(attrs)\n+id_ = base_attrs.get('id')\n+for i in range(max(len(value), self.size)):\n+    try:\n+        widget_value = value[i]\n+    except IndexError:\n+        widget_value = None\n+    widget_attrs = base_attrs.copy()\n+    if id_:\n+        widget_attrs['id'] = '%s_%s' % (id_, i)\n+    context['widget']['subwidgets'].append(\n+        self.widget.get_context(name + '_%s' % i, widget_value, widget_attrs)['widget']\n+    )\n+\n \n     @property\n     def media(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12209",
        "model_patch": "diff --git a/django/db/models/base.py b/django/db/models/base.py\nindex e3b14a41a0..b315dde89d 100644\n--- a/django/db/models/base.py\n+++ b/django/db/models/base.py\n@@ -762,6 +762,455 @@ class Model(metaclass=ModelBase):\n         assert not (force_insert and (force_update or update_fields))\n         assert update_fields is None or update_fields\n         cls = origin = self.__class__\n+           # If an explicit primary key is provided, treat the instance as existing.\n+            # This restores the legacy behavior where an instance created with an explicit pk\n+            # (even when a default is defined) will perform an UPDATE (after an INSERT in Django <=2.2)\n+            # rather than attempting a duplicate INSERT.\n+            if self.pk is not None and self._state.adding:\n+                self._state.adding = False\n         # Skip proxies, but keep the origin as the proxy model.\n         if cls._meta.proxy:\n             cls = cls._meta.concrete_model",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12262",
        "model_patch": "diff --git a/django/template/library.py b/django/template/library.py\nindex 20bc86dac8..cebe7f4245 100644\n--- a/django/template/library.py\n+++ b/django/template/library.py\n@@ -261,7 +261,8 @@ def parse_bits(parser, bits, params, varargs, varkw, defaults,\n         if kwarg:\n             # The kwarg was successfully extracted\n             param, value = kwarg.popitem()\n-            if param not in params and param not in unhandled_kwargs and varkw is None:\n+                if param not in params and param not in kwonly and varkw is None:\n+\n                 # An unexpected keyword argument was supplied\n                 raise TemplateSyntaxError(\n                     \"'%s' received unexpected keyword argument '%s'\" %\n@@ -278,9 +279,10 @@ def parse_bits(parser, bits, params, varargs, varkw, defaults,\n                     # If using the keyword syntax for a positional arg, then\n                     # consume it.\n                     unhandled_params.remove(param)\n-                elif param in unhandled_kwargs:\n-                    # Same for keyword-only arguments\n-                    unhandled_kwargs.remove(param)\n+                    elif param in kwonly:\n+                        # For keyword-only arguments, no additional consumption is needed.\n+                        pass\n+\n         else:\n             if kwargs:\n                 raise TemplateSyntaxError(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12273",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12276",
        "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 338d54d72f..32aac19bcd 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -386,6 +386,105 @@ class FileInput(Input):\n \n     def value_omitted_from_data(self, data, files, name):\n         return name not in files\n+   def use_required_attribute(self, initial):\n+        return not self.is_hidden and not initial\n FILE_INPUT_CONTRADICTION = object()\n@@ -451,8 +550,8 @@ class ClearableFileInput(FileInput):\n             return False\n         return upload\n \n-    def use_required_attribute(self, initial):\n-        return super().use_required_attribute(initial) and not initial\n     def value_omitted_from_data(self, data, files, name):\n         return (",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12304",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12308",
        "model_patch": "diff --git a/django/contrib/admin/utils.py b/django/contrib/admin/utils.py\nindex e4ddc8f017..875d76a880 100644\n--- a/django/contrib/admin/utils.py\n+++ b/django/contrib/admin/utils.py\n@@ -396,10 +396,14 @@ def display_for_field(value, field, empty_value_display):\n         return formats.number_format(value, field.decimal_places)\n     elif isinstance(field, (models.IntegerField, models.FloatField)):\n         return formats.number_format(value)\n-    elif isinstance(field, models.FileField) and value:\n-        return format_html('<a href=\"{}\">{}</a>', value.url, value)\n-    else:\n-        return display_for_value(value, empty_value_display)\n+elif isinstance(field, models.FileField) and value:\n+    return format_html('<a href=\"{}\">{}</a>', value.url, value)\n+elif getattr(field, 'get_internal_type', lambda: None)() == 'JSONField':\n+    # For JSONField, use the formfield prepare_value to render valid JSON output.\n+    return field.formfield().prepare_value(value)\n+else:\n+    return display_for_value(value, empty_value_display)\n+\n \n \n def display_for_value(value, empty_value_display, boolean=False):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12325",
        "model_patch": "diff --git a/django/db/models/options.py b/django/db/models/options.py\nindex a375f6ba1d..2f305010bc 100644\n--- a/django/db/models/options.py\n+++ b/django/db/models/options.py\n@@ -277,25 +277,27 @@ class Options:\n             self.setup_pk(field)\n \n         # If the field being added is a relation to another known field,\n-        # expire the cache on this field and the forward cache on the field\n-        # being referenced, because there will be new relationships in the\n-        # cache. Otherwise, expire the cache of references *to* this field.\n-        # The mechanism for getting at the related model is slightly odd -\n-        # ideally, we'd just ask for field.related_model. However, related_model\n-        # is a cached property, and all the models haven't been loaded yet, so\n-        # we need to make sure we don't cache a string reference.\n-        if field.is_relation and hasattr(field.remote_field, 'model') and field.remote_field.model:\n-            try:\n-                field.remote_field.model._meta._expire_cache(forward=False)\n-            except AttributeError:\n-                pass\n-            self._expire_cache()\n-        else:\n-            self._expire_cache(reverse=False)\n+    def _reconstruct_parent_links(self):\n+        parent_links = {}\n+        for parent in self.parents:\n+            parent_pk_name = parent._meta.pk.name\n+            field = None\n+            # Iterate over the local fields and pick the field explicitly marked as the parent link.\n+            for f in self.local_fields:\n+                if f.name == parent_pk_name and getattr(f, 'parent_link', False):\n+                    field = f\n+                    break\n+            # Fallback: if none is marked with parent_link=True, try to get by name.\n+            if field is None:\n+                try:\n+                    field = self.get_field(parent_pk_name)\n+                except FieldDoesNotExist:\n+                    raise ImproperlyConfigured(\n+                        \"Add parent_link=True to %s.%s\" % (self.model.__name__, parent.__name__)\n+                    )\n+            parent_links[parent] = field\n+        return parent_links\n \n-    def setup_pk(self, field):\n-        if not self.pk and field.primary_key:\n-            self.pk = field\n             field.serialize = False\n \n     def setup_proxy(self, target):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12406",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex dafc11f995..3822fc7c28 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -13,8 +13,9 @@ from django.forms.forms import BaseForm, DeclarativeFieldsMetaclass\n from django.forms.formsets import BaseFormSet, formset_factory\n from django.forms.utils import ErrorList\n from django.forms.widgets import (\n-    HiddenInput, MultipleHiddenInput, SelectMultiple,\n+    HiddenInput, MultipleHiddenInput, SelectMultiple, RadioSelect,\n )\n+\n from django.utils.text import capfirst, get_text_list\n from django.utils.translation import gettext, gettext_lazy as _\n \n@@ -1185,10 +1186,14 @@ class ModelChoiceField(ChoiceField):\n                  required=True, widget=None, label=None, initial=None,\n                  help_text='', to_field_name=None, limit_choices_to=None,\n                  **kwargs):\n-        if required and (initial is not None):\n-            self.empty_label = None\n-        else:\n-            self.empty_label = empty_label\n+    from django.forms.widgets import RadioSelect\n+    if required and widget is not None and isinstance(widget, RadioSelect):\n+        self.empty_label = None\n+    elif required and (initial is not None):\n+        self.empty_label = None\n+    else:\n+        self.empty_label = empty_label\n+\n \n         # Call Field instead of ChoiceField __init__() because we don't need\n         # ChoiceField.__init__().\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12419",
        "model_patch": "diff --git a/django/conf/global_settings.py b/django/conf/global_settings.py\nindex 09c9b95d26..5dd7afaf99 100644\n--- a/django/conf/global_settings.py\n+++ b/django/conf/global_settings.py\n@@ -637,6 +637,7 @@ SECURE_HSTS_INCLUDE_SUBDOMAINS = False\n SECURE_HSTS_PRELOAD = False\n SECURE_HSTS_SECONDS = 0\n SECURE_REDIRECT_EXEMPT = []\n-SECURE_REFERRER_POLICY = None\n+SECURE_REFERRER_POLICY = \"same-origin\"\n+\n SECURE_SSL_HOST = None\n SECURE_SSL_REDIRECT = False\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12663",
        "model_patch": "diff --git a/django/utils/functional.py b/django/utils/functional.py\nindex 6d38f932f9..933e36865e 100644\n--- a/django/utils/functional.py\n+++ b/django/utils/functional.py\n@@ -117,11 +117,133 @@ def lazy(func, *resultclasses):\n                             continue\n                         meth = cls.__promise__(method_name)\n                         setattr(cls, method_name, meth)\n-            cls._delegate_bytes = bytes in resultclasses\n-            cls._delegate_text = str in resultclasses\n-            assert not (cls._delegate_bytes and cls._delegate_text), (\n-                \"Cannot call lazy() with both bytes and text return types.\")\n-            if cls._delegate_text:\n+    def __str__(self):\n+        if self._wrapped is empty:\n+            self._setup()\n+        return str(self._wrapped)\n+    def __int__(self):\n+        if self._wrapped is empty:\n+            self._setup()\n+        return int(self._wrapped)\n                 cls.__str__ = cls.__text_cast\n             elif cls._delegate_bytes:\n                 cls.__bytes__ = cls.__bytes_cast",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12708",
        "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex 61f88401ab..a4fd1210b6 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -407,6 +407,610 @@ class BaseDatabaseSchemaEditor:\n             model, columns, exclude=meta_constraint_names | meta_index_names,\n             **constraint_kwargs\n         )\n+       # If we are deleting an index_together (i.e. constraint_kwargs={'index': True})\n+        # then the introspection may return both the unique constraint (from unique_together)\n+        # and the index constraint. In that case we filter out the unique constraint by\n+        # only keeping those whose name ends with '_idx' (as generated when using Options.indexes).\n+        if constraint_kwargs.get('index') and len(constraint_names) > 1:\n+            filtered = [name for name in constraint_names if name.endswith('_idx')]\n+            if filtered:\n+                constraint_names = filtered\n         if len(constraint_names) != 1:\n             raise ValueError(\"Found wrong number (%s) of constraints for %s(%s)\" % (\n                 len(constraint_names),",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12713",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 69a5fbf389..e962353549 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -248,16 +248,18 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n         if not db_field.remote_field.through._meta.auto_created:\n             return None\n         db = kwargs.get('using')\n+autocomplete_fields = self.get_autocomplete_fields(request)\n+if 'widget' not in kwargs:\n+    if db_field.name in autocomplete_fields:\n+        kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n+    elif db_field.name in self.raw_id_fields:\n+        kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n+    elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n+        kwargs['widget'] = widgets.FilteredSelectMultiple(\n+            db_field.verbose_name,\n+            db_field.name in self.filter_vertical\n+        )\n \n-        autocomplete_fields = self.get_autocomplete_fields(request)\n-        if db_field.name in autocomplete_fields:\n-            kwargs['widget'] = AutocompleteSelectMultiple(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in self.raw_id_fields:\n-            kwargs['widget'] = widgets.ManyToManyRawIdWidget(db_field.remote_field, self.admin_site, using=db)\n-        elif db_field.name in [*self.filter_vertical, *self.filter_horizontal]:\n-            kwargs['widget'] = widgets.FilteredSelectMultiple(\n-                db_field.verbose_name,\n-                db_field.name in self.filter_vertical\n             )\n \n         if 'queryset' not in kwargs:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12741",
        "model_patch": "diff --git a/django/db/backends/base/operations.py b/django/db/backends/base/operations.py\nindex 70ac07ae09..9b7f239898 100644\n--- a/django/db/backends/base/operations.py\n+++ b/django/db/backends/base/operations.py\n@@ -400,12 +400,13 @@ class BaseDatabaseOperations:\n         \"\"\"\n         raise NotImplementedError('subclasses of BaseDatabaseOperations must provide a sql_flush() method')\n \n-    def execute_sql_flush(self, using, sql_list):\n-        \"\"\"Execute a list of SQL statements to flush the database.\"\"\"\n-        with transaction.atomic(using=using, savepoint=self.connection.features.can_rollback_ddl):\n-            with self.connection.cursor() as cursor:\n-                for sql in sql_list:\n-                    cursor.execute(sql)\n+def execute_sql_flush(self, sql_list):\n+    \"\"\"Execute a list of SQL statements to flush the database.\"\"\"\n+    using = self.connection.alias\n+    with transaction.atomic(using=using, savepoint=self.connection.features.can_rollback_ddl):\n+        with self.connection.cursor() as cursor:\n+            for sql in sql_list:\n+                cursor.execute(sql)\n \n     def sequence_reset_by_name_sql(self, style, sequences):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12754",
        "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 30616c0172..aeb6fb55aa 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -190,6 +190,424 @@ class MigrationAutodetector:\n         self.generate_added_constraints()\n         self.generate_altered_db_table()\n         self.generate_altered_order_with_respect_to()\n+       # Adjust dependencies for fields moved from a base to subclass:\n+        # When creating a new model subclass (e.g. Book) that gets one or more\n+        # fields moved from its base (e.g. Readable.title), the autodetector\n+        # should force the RemoveField op on the base to run before the CreateModel\n+        # op for the subclass to avoid a field clash.\n+        self.adjust_field_move_dependencies()\n         self._sort_migrations()\n         self._build_migration_list(graph)\n@@ -462,6 +880,2597 @@ class MigrationAutodetector:\n             pass\n         return item\n \n+    def adjust_field_move_dependencies(self):\n+        \"\"\"\n+        Adjust the auto-dependencies for CreateModel operations to ensure that if\n+        a field has been moved from a base model to a subclass in a single step then\n+        the removal of that field from the base (RemoveField op) is forced to run before\n+        the CreateModel op for the subclass. This fixes the FieldError which occurs when the\n+        subclass is created while its base still contains a duplicate field.\n+        \"\"\"\n+        for app_label, ops in self.generated_operations.items():\n+            for op in ops:\n+                if isinstance(op, operations.CreateModel):\n+                    model_key = (app_label, op.name_lower)\n+                    if model_key not in self.to_state.models:\n+                        continue\n+                    model_state = self.to_state.models[model_key]\n+                    for base in model_state.bases:\n+                        # Resolve the base model key from the base declaration.\n+                        if isinstance(base, str):\n+                            parts = base.split('.')\n+                            if len(parts) == 2:\n+                                base_app_label, base_name = parts[0], parts[1].lower()\n+                            else:\n+                                base_app_label = app_label\n+                                base_name = parts[0].lower()\n+                        else:\n+                            base_app_label = base._meta.app_label\n+                            base_name = base._meta.model_name\n+                        base_key = (base_app_label, base_name)\n+                        if base_key in self.from_state.models and base_key in self.to_state.models:\n+                            old_base_state = self.from_state.models[base_key]\n+                            new_base_state = self.to_state.models[base_key]\n+                            # For any field that existed in the base in the old state but has been\n+                            # removed in the new state, if the subclass now defines that field then\n+                            # add a dependency tuple so that the removal occurs first.\n+                            for field_name in model_state.fields:\n+                                if field_name in old_base_state.fields and field_name not in new_base_state.fields:\n+                                    dep = (base_app_label, base_name, field_name, False)\n+                                    if dep not in op._auto_deps:\n+                                        op._auto_deps.append(dep)\n     def generate_renamed_models(self):\n         \"\"\"\n         Find any renamed models, generate the operations for them, and remove",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12774",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex d9c9b0db04..76360990c2 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -689,8 +689,11 @@ class QuerySet:\n         \"\"\"\n         assert not self.query.is_sliced, \\\n             \"Cannot use 'limit' or 'offset' with in_bulk\"\n-        if field_name != 'pk' and not self.model._meta.get_field(field_name).unique:\n-            raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+        if field_name != 'pk':\n+            field = self.model._meta.get_field(field_name)\n+            if not (field.unique or any(constraint.fields == (field_name,) for constraint in self.model._meta.total_unique_constraints)):\n+                raise ValueError(\"in_bulk()'s field_name must be a unique field but %r isn't.\" % field_name)\n+\n         if id_list is not None:\n             if not id_list:\n                 return {}\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12858",
        "model_patch": "diff --git a/django/db/models/options.py b/django/db/models/options.py\nindex 0e28b6812a..cb0d7c15ee 100644\n--- a/django/db/models/options.py\n+++ b/django/db/models/options.py\n@@ -147,25 +147,28 @@ class Options:\n     def contribute_to_class(self, cls, name):\n         from django.db import connection\n         from django.db.backends.utils import truncate_name\n+        for field_name in self.ordering:\n+            lookup = field_name.lstrip('-')\n+            # Allow valid lookup transforms (such as __isnull) at the end of an ordering string.\n+            for transform in ('isnull',):\n+                suffix = '__' + transform\n+                if lookup.endswith(suffix):\n+                    lookup = lookup[:-len(suffix)]\n+                    break\n+\n+            # Only try to validate if anything remains.\n+            if lookup:\n+                try:\n+                    self.get_field(lookup)\n+                except FieldDoesNotExist:\n+                    errors.append(\n+                        checks.Error(\n+                            \"'%s' refers to the nonexistent field, related field, or lookup '%s'.\" % (self.model.__name__, field_name),\n+                            obj=self.model,\n+                            id='models.E015',\n+                        )\n+                    )\n \n-        cls._meta = self\n-        self.model = cls\n-        # First, construct the default values for these options.\n-        self.object_name = cls.__name__\n-        self.model_name = self.object_name.lower()\n-        self.verbose_name = camel_case_to_spaces(self.object_name)\n-\n-        # Store the original user-defined values for each option,\n-        # for use when serializing the model definition\n-        self.original_attrs = {}\n-\n-        # Next, apply any overridden values from 'class Meta'.\n-        if self.meta:\n-            meta_attrs = self.meta.__dict__.copy()\n-            for name in self.meta.__dict__:\n-                # Ignore any private attributes that Django doesn't care about.\n-                # NOTE: We can't modify a dictionary's contents while looping\n-                # over it, so we loop over the *original* dictionary instead.\n                 if name.startswith('_'):\n                     del meta_attrs[name]\n             for attr_name in DEFAULT_NAMES:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-12965",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13012",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex c1a76584f0..d46a13080a 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -868,6 +868,396 @@ class ExpressionWrapper(Expression):\n \n     def __repr__(self):\n         return \"{}({})\".format(self.__class__.__name__, self.expression)\n+   def get_group_by_cols(self, alias=None):\n+        # Delegate group_by columns to the wrapped expression.\n+        # In particular, if the inner expression is a constant (Value),\n+        # its get_group_by_cols() returns an empty list allowing the query\n+        # builder to omit constant expressions from the GROUP BY clause.\n+        return self.expression.get_group_by_cols(alias)\n class When(Expression):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13023",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13028",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex ce18098fd2..cca28f8678 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -42,13 +42,14 @@ from django.utils.functional import cached_property\n from django.utils.tree import Node\n \n __all__ = ['Query', 'RawQuery']\n-\n-\n-def get_field_names_from_opts(opts):\n-    return set(chain.from_iterable(\n-        (f.name, f.attname) if f.concrete else (f.name,)\n-        for f in opts.get_fields()\n-    ))\n+    def build_filter(self, filter_expr, value):\n+        # If the right\u2010hand side is a model instance then use its primary key.\n+        # Otherwise, if the value has a \u201cfilterable\u201d attribute (caused by naming a model\n+        # field \u201cfilterable\u201d), check that it isn\u2019t disallowed.\n+        if hasattr(value, \"_meta\"):\n+            value = value.pk\n+        else:\n+            self.check_filterable(value)\n \n \n def get_children_from_q(q):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13033",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex d65141b834..a449db941b 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -47,27 +47,27 @@ __all__ = ['Query', 'RawQuery']\n def get_field_names_from_opts(opts):\n     return set(chain.from_iterable(\n         (f.name, f.attname) if f.concrete else (f.name,)\n-        for f in opts.get_fields()\n-    ))\n+# Do not follow related ordering if the lookup name is the underlying\n+# <field>_id and if the FK points to the same model (i.e. a self reference).\n+if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk' and field.remote_field.model != opts.model:\n+    # Firstly, avoid infinite loops.\n+    already_seen = already_seen or set()\n+    join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n+    if join_tuple in already_seen:\n+        raise FieldError('Infinite loop caused by ordering.')\n+    already_seen.add(join_tuple)\n+\n+    results = []\n+    for item in opts.ordering:\n+        if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):\n+            item = item.desc() if descending else item.asc()\n+        if isinstance(item, OrderBy):\n+            results.append((item, False))\n+            continue\n+        results.extend(self.find_ordering_name(item, opts, alias, order, already_seen))\n+    return results\n \n \n-def get_children_from_q(q):\n-    for child in q.children:\n-        if isinstance(child, Node):\n-            yield from get_children_from_q(child)\n-        else:\n-            yield child\n-\n-\n-JoinInfo = namedtuple(\n-    'JoinInfo',\n-    ('final_field', 'targets', 'opts', 'joins', 'path', 'transform_function')\n-)\n-\n-\n-class RawQuery:\n-    \"\"\"A single raw SQL query.\"\"\"\n-\n     def __init__(self, sql, using, params=None):\n         self.params = params or ()\n         self.sql = sql\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13089",
        "model_patch": "diff --git a/django/core/cache/backends/db.py b/django/core/cache/backends/db.py\nindex 33c79c5a14..e41b04ada4 100644\n--- a/django/core/cache/backends/db.py\n+++ b/django/core/cache/backends/db.py\n@@ -267,9 +267,11 @@ class DatabaseCache(BaseDatabaseCache):\n                 cursor.execute(\n                     connection.ops.cache_key_culling_sql() % table,\n                     [cull_num])\n-                cursor.execute(\"DELETE FROM %s \"\n-                               \"WHERE cache_key < %%s\" % table,\n-                               [cursor.fetchone()[0]])\n+row = cursor.fetchone()\n+if row:\n+    cursor.execute(\"DELETE FROM %s WHERE cache_key < %%s\" % table,\n+                   [row[0]])\n+\n \n     def clear(self):\n         db = router.db_for_write(self.cache_model_class)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13109",
        "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex d517d7269b..3a9c68a1ca 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -913,10 +913,11 @@ class ForeignKey(ForeignObject):\n         if value is None:\n             return\n \n-        using = router.db_for_read(self.remote_field.model, instance=model_instance)\n-        qs = self.remote_field.model._default_manager.using(using).filter(\n-            **{self.remote_field.field_name: value}\n-        )\n+using = router.db_for_read(self.remote_field.model, instance=model_instance)\n+qs = self.remote_field.model._base_manager.using(using).filter(\n+    **{self.remote_field.field_name: value}\n+)\n+\n         qs = qs.complex_filter(self.get_limit_choices_to())\n         if not qs.exists():\n             raise exceptions.ValidationError(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13112",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13121",
        "model_patch": "diff --git a/django/db/backends/base/operations.py b/django/db/backends/base/operations.py\nindex 2e283a3193..ad7b09e84d 100644\n--- a/django/db/backends/base/operations.py\n+++ b/django/db/backends/base/operations.py\n@@ -578,9 +578,10 @@ class BaseDatabaseOperations:\n         \"\"\"\n         return []\n \n-    def convert_durationfield_value(self, value, expression, connection):\n-        if value is not None:\n-            return datetime.timedelta(0, 0, value)\n+def convert_durationfield_value(self, value, expression, connection):\n+    if value is not None:\n+        return datetime.timedelta(microseconds=float(value))\n+\n \n     def check_expression_support(self, expression):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13128",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex d913658291..ab026c3534 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -32,13 +32,14 @@ class Combinable:\n     \"\"\"\n     Provide the ability to combine one or two objects with\n     some connector. For example F('foo') + F('bar').\n-    \"\"\"\n+        if output_field is None:\n+            # If subtracting two DateTimeFields, the result is a DurationField.\n+            from django.db.models import DateTimeField, DurationField\n+            if connector == '-' and isinstance(lhs.output_field, DateTimeField) and isinstance(rhs.output_field, DateTimeField):\n+                output_field = DurationField()\n+            else:\n+                output_field = lhs.output_field\n \n-    # Arithmetic connectors\n-    ADD = '+'\n-    SUB = '-'\n-    MUL = '*'\n-    DIV = '/'\n     POW = '^'\n     # The following is a quoted % operator - it is quoted because it can be\n     # used in strings that also have parameter substitution.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13158",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 07d6ffd4ca..60d8284b0b 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -340,10 +340,11 @@ class QuerySet:\n \n     def __or__(self, other):\n         self._merge_sanity_check(other)\n-        if isinstance(self, EmptyQuerySet):\n-            return other\n-        if isinstance(other, EmptyQuerySet):\n-            return self\n+        if getattr(self, '_force_empty', False) or getattr(other, '_force_empty', False):\n+            qs = self._chain()\n+            qs.query.set_empty()\n+            qs._force_empty = True\n+            return qs\n         query = self if self.query.can_filter() else self.model._base_manager.filter(pk__in=self.values('pk'))\n         combined = query._chain()\n         combined._merge_known_related_objects(other)\n@@ -352,6 +353,7 @@ class QuerySet:\n         combined.query.combine(other.query, sql.OR)\n         return combined\n     ####################################\n     # METHODS THAT DO DATABASE QUERIES #\n     ####################################\n@@ -920,8 +922,10 @@ class QuerySet:\n         \"\"\"Return an empty QuerySet.\"\"\"\n         clone = self._chain()\n         clone.query.set_empty()\n+        clone._force_empty = True\n         return clone\n     ##################################################################\n     # PUBLIC METHODS THAT ALTER ATTRIBUTES AND RETURN A NEW QUERYSET #\n     ##################################################################\n@@ -997,10 +1001,11 @@ class QuerySet:\n         return clone\n \n     def union(self, *other_qs, all=False):\n-        # If the query is an EmptyQuerySet, combine all nonempty querysets.\n-        if isinstance(self, EmptyQuerySet):\n-            qs = [q for q in other_qs if not isinstance(q, EmptyQuerySet)]\n-            return qs[0]._combinator_query('union', *qs[1:], all=all) if qs else self\n+        if getattr(self, '_force_empty', False) or any(getattr(q, '_force_empty', False) for q in other_qs):\n+            qs = self._chain()\n+            qs.query.set_empty()\n+            qs._force_empty = True\n+            return qs\n         return self._combinator_query('union', *other_qs, all=all)\n \n     def intersection(self, *other_qs):\n@@ -1292,6 +1297,69 @@ class QuerySet:\n         to deepcopy().\n         \"\"\"\n         c = self.__class__(model=self.model, query=self.query.chain(), using=self._db, hints=self._hints)\n+       c._force_empty = getattr(self, '_force_empty', False)\n         c._sticky_filter = self._sticky_filter\n         c._for_write = self._for_write\n         c._prefetch_related_lookups = self._prefetch_related_lookups[:]",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13195",
        "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex e00bcacefb..6dbd760dd8 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -213,13 +213,19 @@ class HttpResponseBase:\n     def delete_cookie(self, key, path='/', domain=None):\n         # Most browsers ignore the Set-Cookie header if the cookie name starts\n         # with __Host- or __Secure- and the cookie doesn't use the secure flag.\n-        secure = key.startswith(('__Secure-', '__Host-'))\n+        secure = settings.SESSION_COOKIE_SECURE or key.startswith(('__Secure-', '__Host-'))\n+        domain = domain if domain is not None else settings.SESSION_COOKIE_DOMAIN\n         self.set_cookie(\n-            key, max_age=0, path=path, domain=domain, secure=secure,\n+            key,\n+            max_age=0,\n+            path=path,\n+            domain=domain,\n+            secure=secure,\n             expires='Thu, 01 Jan 1970 00:00:00 GMT',\n+            httponly=settings.SESSION_COOKIE_HTTPONLY or None,\n+            samesite=settings.SESSION_COOKIE_SAMESITE,\n         )\n \n-    # Common methods used by subclasses\n \n     def make_bytes(self, value):\n         \"\"\"Turn a value into a bytestring encoded in the output charset.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13212",
        "model_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex 84b4f31ec7..b1c2cf510b 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -48,7 +48,8 @@ class RegexValidator:\n         regex_matches = self.regex.search(str(value))\n         invalid_input = regex_matches if self.inverse_match else not regex_matches\n         if invalid_input:\n-            raise ValidationError(self.message, code=self.code)\n+            raise ValidationError(self.message, code=self.code, params={'value': value})\n+\n \n     def __eq__(self, other):\n         return (\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13279",
        "model_patch": "diff --git a/django/contrib/sessions/backends/base.py b/django/contrib/sessions/backends/base.py\nindex b5453160a5..06b4c733f2 100644\n--- a/django/contrib/sessions/backends/base.py\n+++ b/django/contrib/sessions/backends/base.py\n@@ -108,11 +108,14 @@ class SessionBase:\n \n     def encode(self, session_dict):\n         \"Return the given session dictionary serialized and encoded as a string.\"\n+        if settings.DEFAULT_HASHING_ALGORITHM == 'sha1':\n+            return self._legacy_encode(session_dict)\n         return signing.dumps(\n             session_dict, salt=self.key_salt, serializer=self.serializer,\n             compress=True,\n         )\n     def decode(self, session_data):\n         try:\n             return signing.loads(session_data, salt=self.key_salt, serializer=self.serializer)\n@@ -140,6 +143,524 @@ class SessionBase:\n                 logger.warning(str(e))\n             return {}\n \n+    def _legacy_encode(self, session_dict):\n+        \"\"\"\n+        Legacy encoding for sessions. Serialize the session dict,\n+        compute the hash for the serialized data, and return a base64 encoded\n+        string in the format: base64encode(\"hash:serialized\").\n+        \"\"\"\n+        serialized = self.serializer().dumps(session_dict)\n+        hash_value = self._hash(serialized)\n+        legacy_data = hash_value.encode('utf-8') + b':' + serialized\n+        return base64.b64encode(legacy_data).decode('ascii')\n     def update(self, dict_):\n         self._session.update(dict_)\n         self.modified = True",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13297",
        "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex ea5baca08d..5f3da913c4 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -82,13 +82,16 @@ class View:\n         update_wrapper(view, cls.dispatch, assigned=())\n         return view\n \n-    def setup(self, request, *args, **kwargs):\n-        \"\"\"Initialize attributes shared by all view methods.\"\"\"\n-        if hasattr(self, 'get') and not hasattr(self, 'head'):\n-            self.head = self.get\n-        self.request = request\n-        self.args = args\n-        self.kwargs = kwargs\n+def setup(self, request, *args, **kwargs):\n+    \"\"\"Initialize attributes shared by all view methods.\"\"\"\n+    from django.utils.functional import SimpleLazyObject\n+    if hasattr(self, 'get') and not hasattr(self, 'head'):\n+        self.head = self.get\n+    self.request = request\n+    self.args = args\n+    # Resolve SimpleLazyObject values in kwargs by converting them to their proper string representation.\n+    self.kwargs = {k: (str(v) if isinstance(v, SimpleLazyObject) else v) for k, v in kwargs.items()}\n+\n \n     def dispatch(self, request, *args, **kwargs):\n         # Try to dispatch to the right method; if a method doesn't exist,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13315",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 5d115458a1..2c8307b6f5 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -100,7 +100,8 @@ def apply_limit_choices_to_to_formfield(formfield):\n     if hasattr(formfield, 'queryset') and hasattr(formfield, 'get_limit_choices_to'):\n         limit_choices_to = formfield.get_limit_choices_to()\n         if limit_choices_to is not None:\n-            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to)\n+            formfield.queryset = formfield.queryset.complex_filter(limit_choices_to).distinct()\n+\n \n \n def fields_for_model(model, fields=None, exclude=None, widgets=None,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13343",
        "model_patch": "diff --git a/django/db/models/fields/files.py b/django/db/models/fields/files.py\nindex e10a5bb6d9..b02a364874 100644\n--- a/django/db/models/fields/files.py\n+++ b/django/db/models/fields/files.py\n@@ -227,14 +227,19 @@ class FileField(Field):\n     def __init__(self, verbose_name=None, name=None, upload_to='', storage=None, **kwargs):\n         self._primary_key_set_explicitly = 'primary_key' in kwargs\n \n-        self.storage = storage or default_storage\n-        if callable(self.storage):\n-            self.storage = self.storage()\n-            if not isinstance(self.storage, Storage):\n-                raise TypeError(\n-                    \"%s.storage must be a subclass/instance of %s.%s\"\n-                    % (self.__class__.__qualname__, Storage.__module__, Storage.__qualname__)\n-                )\n+inferred_storage = storage or default_storage\n+if callable(inferred_storage):\n+    self._storage_callable = inferred_storage\n+    evaluated_storage = inferred_storage()\n+    if not isinstance(evaluated_storage, Storage):\n+        raise TypeError(\n+            \"%s.storage must be a subclass/instance of %s.%s\"\n+            % (self.__class__.__qualname__, Storage.__module__, Storage.__qualname__)\n+        )\n+    self.storage = evaluated_storage\n+else:\n+    self.storage = inferred_storage\n+\n         self.upload_to = upload_to\n \n         kwargs.setdefault('max_length', 100)\n@@ -278,9 +283,12 @@ class FileField(Field):\n         if kwargs.get(\"max_length\") == 100:\n             del kwargs[\"max_length\"]\n         kwargs['upload_to'] = self.upload_to\n-        if self.storage is not default_storage:\n-            kwargs['storage'] = self.storage\n-        return name, path, args, kwargs\n+if hasattr(self, '_storage_callable'):\n+    kwargs['storage'] = self._storage_callable\n+elif self.storage is not default_storage:\n+    kwargs['storage'] = self.storage\n+return name, path, args, kwargs\n+\n \n     def get_internal_type(self):\n         return \"FileField\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13344",
        "model_patch": "diff --git a/django/utils/deprecation.py b/django/utils/deprecation.py\nindex b2c681b33c..c46b66304e 100644\n--- a/django/utils/deprecation.py\n+++ b/django/utils/deprecation.py\n@@ -145,3 +145,12 @@ class MiddlewareMixin:\n                 'deprecated.',\n                 RemovedInDjango40Warning, stacklevel=3,\n             )\n+\n+def __call__(self, request):\n+    response = self.get_response(request)\n+    # If get_response returned an awaitable (coroutine), resolve it.\n+    from asgiref.sync import async_to_sync\n+    if hasattr(response, \"__await__\"):\n+        response = async_to_sync(response)()\n+    response = self.process_response(request, response)\n+    return response\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13346",
        "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex a4fbb04648..2bcb103686 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -214,19 +214,26 @@ class FieldGetDbPrepValueIterableMixin(FieldGetDbPrepValueMixin):\n     \"\"\"\n     get_db_prep_lookup_value_is_iterable = True\n \n-    def get_prep_lookup(self):\n-        if hasattr(self.rhs, 'resolve_expression'):\n-            return self.rhs\n-        prepared_values = []\n-        for rhs_value in self.rhs:\n-            if hasattr(rhs_value, 'resolve_expression'):\n-                # An expression will be handled by the database but can coexist\n-                # alongside real values.\n-                pass\n-            elif self.prepare_rhs and hasattr(self.lhs.output_field, 'get_prep_value'):\n+def get_prep_lookup(self):\n+    if hasattr(self.rhs, 'resolve_expression'):\n+        return self.rhs\n+    prepared_values = []\n+    for rhs_value in self.rhs:\n+        if hasattr(rhs_value, 'resolve_expression'):\n+            # An expression will be handled by the database but can coexist\n+            # alongside real values.\n+            pass\n+        elif self.prepare_rhs and hasattr(self.lhs.output_field, 'get_prep_value'):\n+            # When the lookup is used on a key transform (e.g. __key__in),\n+            # use the underlying field (self.lhs.lhs.output_field) to prepare\n+            # the value. This ensures numeric values are not transformed incorrectly.\n+            if hasattr(self.lhs, 'lhs'):\n+                rhs_value = self.lhs.lhs.output_field.get_prep_value(rhs_value)\n+            else:\n                 rhs_value = self.lhs.output_field.get_prep_value(rhs_value)\n-            prepared_values.append(rhs_value)\n-        return prepared_values\n+        prepared_values.append(rhs_value)\n+    return prepared_values\n+\n \n     def process_rhs(self, compiler, connection):\n         if self.rhs_is_direct_value():\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13363",
        "model_patch": "diff --git a/django/db/models/functions/datetime.py b/django/db/models/functions/datetime.py\nindex b6594b043b..7b244c401c 100644\n--- a/django/db/models/functions/datetime.py\n+++ b/django/db/models/functions/datetime.py\n@@ -292,7 +292,8 @@ class TruncDate(TruncBase):\n     def as_sql(self, compiler, connection):\n         # Cast to date rather than truncate to date.\n         lhs, lhs_params = compiler.compile(self.lhs)\n-        tzname = timezone.get_current_timezone_name() if settings.USE_TZ else None\n+tzname = self.get_tzname() if settings.USE_TZ else None\n+\n         sql = connection.ops.datetime_cast_date_sql(lhs, tzname)\n         return sql, lhs_params\n \n@@ -305,7 +306,8 @@ class TruncTime(TruncBase):\n     def as_sql(self, compiler, connection):\n         # Cast to time rather than truncate to time.\n         lhs, lhs_params = compiler.compile(self.lhs)\n-        tzname = timezone.get_current_timezone_name() if settings.USE_TZ else None\n+tzname = self.get_tzname() if settings.USE_TZ else None\n+\n         sql = connection.ops.datetime_cast_time_sql(lhs, tzname)\n         return sql, lhs_params\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13401",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13406",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex b48d0df9c0..17054e38ce 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -258,6 +258,222 @@ class QuerySet:\n                 stacklevel=2,\n             )\n         self.__dict__.update(state)\n+       if self._fields is not None and self.__dict__.get('_iterable_class', None) == ModelIterable:\n+            from django.db.models.query import ValuesIterable\n+            self._iterable_class = ValuesIterable\n     def __repr__(self):\n         data = list(self[:REPR_OUTPUT_SIZE + 1])",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13410",
        "model_patch": "diff --git a/django/core/files/locks.py b/django/core/files/locks.py\nindex c46b00b905..13591c5aeb 100644\n--- a/django/core/files/locks.py\n+++ b/django/core/files/locks.py\n@@ -106,10 +106,17 @@ else:\n             # File is unlocked\n             return True\n     else:\n-        def lock(f, flags):\n-            ret = fcntl.flock(_fd(f), flags)\n-            return ret == 0\n+def lock(f, flags):\n+    try:\n+        fcntl.flock(_fd(f), flags)\n+        return True\n+    except OSError:\n+        return False\n+\n+def unlock(f):\n+    try:\n+        fcntl.flock(_fd(f), fcntl.LOCK_UN)\n+        return True\n+    except OSError:\n+        return False\n \n-        def unlock(f):\n-            ret = fcntl.flock(_fd(f), fcntl.LOCK_UN)\n-            return ret == 0\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13417",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 85cd8311a7..121c18a85b 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1215,19 +1215,25 @@ class QuerySet:\n     ###################################\n \n     @property\n-    def ordered(self):\n-        \"\"\"\n-        Return True if the QuerySet is ordered -- i.e. has an order_by()\n-        clause or a default ordering on the model (or is empty).\n-        \"\"\"\n-        if isinstance(self, EmptyQuerySet):\n-            return True\n-        if self.query.extra_order_by or self.query.order_by:\n-            return True\n-        elif self.query.default_ordering and self.query.get_meta().ordering:\n-            return True\n-        else:\n-            return False\n+@property\n+def ordered(self):\n+    \"\"\"\n+    Return True if the QuerySet is ordered \u2013 i.e. if it has an order_by() clause\n+    or if a default ordering should be applied.\n+\n+    If the query involves GROUP BY (typically via annotate() which forces a\n+    GROUP BY), then even if a default ordering exists in the model meta it\n+    is not actually applied at the SQL level.\n+    \"\"\"\n+    if isinstance(self, EmptyQuerySet):\n+        return True\n+    if self.query.extra_order_by or self.query.order_by:\n+        return True\n+    elif self.query.default_ordering and not self.query.group_by and self.query.get_meta().ordering:\n+        return True\n+    else:\n+        return False\n+\n \n     @property\n     def db(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13449",
        "model_patch": "diff --git a/django/db/models/functions/window.py b/django/db/models/functions/window.py\nindex 84b2b24ffa..66097e0116 100644\n--- a/django/db/models/functions/window.py\n+++ b/django/db/models/functions/window.py\n@@ -51,6 +51,655 @@ class LagLeadFunction(Func):\n \n class Lag(LagLeadFunction):\n     function = 'LAG'\n+   def as_sql(self, compiler, connection, **extra_context):\n+        sql, params = super().as_sql(compiler, connection, **extra_context)\n+        from django.db.models import DecimalField\n+        source = self.get_source_expressions()[0]\n+        # For SQLite and DecimalFields, remove the CAST(...) wrapping.\n+        if connection.vendor == 'sqlite' and isinstance(source.output_field, DecimalField):\n+            import re\n+            # Remove the CAST wrapper so that the OVER clause applies to the window function.\n+            sql = re.sub(r'^CAST\\((.+?)\\s+AS\\s+NUMERIC\\)\\s+', r'\\1 ', sql, flags=re.IGNORECASE)\n+        return sql, params\n class LastValue(Func):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13512",
        "model_patch": "diff --git a/django/contrib/postgres/fields/ranges.py b/django/contrib/postgres/fields/ranges.py\nindex 8eab2cd2d9..e3f4890163 100644\n--- a/django/contrib/postgres/fields/ranges.py\n+++ b/django/contrib/postgres/fields/ranges.py\n@@ -95,7 +95,8 @@ class RangeField(models.Field):\n         if value is None:\n             return None\n         if value.isempty:\n-            return json.dumps({\"empty\": True})\n+return json.dumps({\"empty\": True}, ensure_ascii=False)\n+\n         base_field = self.base_field\n         result = {\"bounds\": value._bounds}\n         for end in ('lower', 'upper'):\n@@ -105,7 +106,8 @@ class RangeField(models.Field):\n             else:\n                 obj = AttributeSetter(base_field.attname, val)\n                 result[end] = base_field.value_to_string(obj)\n-        return json.dumps(result)\n+return json.dumps(result, ensure_ascii=False)\n+\n \n     def formfield(self, **kwargs):\n         kwargs.setdefault('form_class', self.form_field)\ndiff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py\nindex a249f4cdbf..682ef08c11 100644\n--- a/django/db/models/fields/json.py\n+++ b/django/db/models/fields/json.py\n@@ -81,7 +81,8 @@ class JSONField(CheckFieldDefaultMixin, Field):\n     def get_prep_value(self, value):\n         if value is None:\n             return value\n-        return json.dumps(value, cls=self.encoder)\n+        return json.dumps(value, cls=self.encoder, ensure_ascii=False)\n+\n \n     def get_transform(self, name):\n         transform = super().get_transform(name)\n@@ -92,7 +93,8 @@ class JSONField(CheckFieldDefaultMixin, Field):\n     def validate(self, value, model_instance):\n         super().validate(value, model_instance)\n         try:\n-            json.dumps(value, cls=self.encoder)\n+                json.dumps(value, cls=self.encoder, ensure_ascii=False)\n+\n         except TypeError:\n             raise exceptions.ValidationError(\n                 self.error_messages['invalid'],\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13513",
        "model_patch": "diff --git a/django/views/debug.py b/django/views/debug.py\nindex 7a89f7bd15..bf0314a931 100644\n--- a/django/views/debug.py\n+++ b/django/views/debug.py\n@@ -395,11 +395,12 @@ class ExceptionReporter:\n         return lower_bound, pre_context, context_line, post_context\n \n     def get_traceback_frames(self):\n-        def explicit_or_implicit_cause(exc_value):\n-            explicit = getattr(exc_value, '__cause__', None)\n-            suppress_context = getattr(exc_value, '__suppress_context__', None)\n-            implicit = getattr(exc_value, '__context__', None)\n-            return explicit or (None if suppress_context else implicit)\n+    def explicit_or_implicit_cause(exc_value):\n+        explicit = getattr(exc_value, '__cause__', None)\n+        suppress_context = getattr(exc_value, '__suppress_context__', False)\n+        implicit = getattr(exc_value, '__context__', None)\n+        return explicit or (None if suppress_context else implicit)\n+\n \n         # Get the exception and all its causes\n         exceptions = []\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13516",
        "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex e6cbf8c64f..9896671835 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -138,6 +138,55 @@ class OutputWrapper(TextIOBase):\n         self.ending = ending\n \n     def __getattr__(self, name):\n+   def flush(self):\n+        self._out.flush()\n         return getattr(self._out, name)\n \n     def isatty(self):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13551",
        "model_patch": "diff --git a/django/contrib/auth/tokens.py b/django/contrib/auth/tokens.py\nindex 93e2d71af2..e89b256388 100644\n--- a/django/contrib/auth/tokens.py\n+++ b/django/contrib/auth/tokens.py\n@@ -93,8 +93,11 @@ class PasswordResetTokenGenerator:\n         \"\"\"\n         # Truncate microseconds so that tokens are consistent even if the\n         # database doesn't support microseconds.\n-        login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n-        return str(user.pk) + user.password + str(login_timestamp) + str(timestamp)\n+login_timestamp = '' if user.last_login is None else user.last_login.replace(microsecond=0, tzinfo=None)\n+# Include user's email in the hash value to invalidate tokens if the email changes\n+email = getattr(user, 'email', '')\n+return str(user.pk) + user.password + str(login_timestamp) + email + str(timestamp)\n+\n \n     def _num_seconds(self, dt):\n         return int((dt - datetime(2001, 1, 1)).total_seconds())\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13568",
        "model_patch": "diff --git a/django/contrib/auth/checks.py b/django/contrib/auth/checks.py\nindex 65fc266f7e..0e603321f0 100644\n--- a/django/contrib/auth/checks.py\n+++ b/django/contrib/auth/checks.py\n@@ -6,6 +6,53 @@ from django.conf import settings\n from django.core import checks\n \n from .management import _get_builtin_permissions\n+rom django.db.models import UniqueConstraint\n def check_user_model(app_configs=None, **kwargs):\n@@ -51,10 +98,14 @@ def check_user_model(app_configs=None, **kwargs):\n             )\n         )\n \n-    # Check that the username field is unique\n-    if not cls._meta.get_field(cls.USERNAME_FIELD).unique:\n-        if (settings.AUTHENTICATION_BACKENDS ==\n-                ['django.contrib.auth.backends.ModelBackend']):\n+    # Check that the username field is unique: allow a UniqueConstraint to provide uniqueness.\n+    username_field = cls._meta.get_field(cls.USERNAME_FIELD)\n+    has_unique = username_field.unique or any(\n+        isinstance(constraint, UniqueConstraint) and set(constraint.fields) == {cls.USERNAME_FIELD}\n+        for constraint in cls._meta.constraints\n+    )\n+    if not has_unique:\n+        if settings.AUTHENTICATION_BACKENDS == ['django.contrib.auth.backends.ModelBackend']:\n             errors.append(\n                 checks.Error(\n                     \"'%s.%s' must be unique because it is named as the 'USERNAME_FIELD'.\" % (",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13569",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13590",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 4648daf395..bc09047e56 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1074,13 +1074,14 @@ class Query(BaseExpression):\n             value = value.resolve_expression(\n                 self, reuse=can_reuse, allow_joins=allow_joins,\n             )\n-        elif isinstance(value, (list, tuple)):\n-            # The items of the iterable may be expressions and therefore need\n-            # to be resolved independently.\n-            return type(value)(\n-                self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n-                for sub_value in value\n-            )\n+    elif isinstance(value, (list, tuple)):\n+        # The items of the iterable may be expressions and therefore need\n+        # to be resolved independently.\n+        return type(value)(*[\n+            self.resolve_lookup_value(sub_value, can_reuse, allow_joins)\n+            for sub_value in value\n+        ])\n+\n         return value\n \n     def solve_lookup_type(self, lookup):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13658",
        "model_patch": "diff --git a/django/core/management/__init__.py b/django/core/management/__init__.py\nindex 1ba093e51f..bb7f764e45 100644\n--- a/django/core/management/__init__.py\n+++ b/django/core/management/__init__.py\n@@ -117,11 +117,12 @@ def call_command(command_name, *args, **options):\n     # Use the `dest` option name from the parser option\n     opt_mapping = {\n         min(s_opt.option_strings).lstrip('-').replace('-', '_'): s_opt.dest\n-        for s_opt in parser._actions if s_opt.option_strings\n-    }\n-    arg_options = {opt_mapping.get(key, key): value for key, value in options.items()}\n-    parse_args = []\n-    for arg in args:\n+    def execute(self):\n+        parser = CommandParser(prog=self.prog_name,\n+                               usage='%(prog)s subcommand [options] [args]',\n+                               add_help=False,\n+                               allow_abbrev=False)\n+\n         if isinstance(arg, (list, tuple)):\n             parse_args += map(str, arg)\n         else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13670",
        "model_patch": "diff --git a/django/utils/dateformat.py b/django/utils/dateformat.py\nindex afd36d79e0..f10aedbbe4 100644\n--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -326,7 +326,8 @@ class DateFormat(TimeFormat):\n \n     def y(self):\n         \"Year, 2 digits; e.g. '99'\"\n-        return str(self.data.year)[2:]\n+        return '%02d' % (self.data.year % 100)\n+\n \n     def Y(self):\n         \"Year, 4 digits; e.g. '1999'\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13741",
        "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b9eb33329f..70fcbdc867 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -54,9 +54,11 @@ class ReadOnlyPasswordHashWidget(forms.Widget):\n class ReadOnlyPasswordHashField(forms.Field):\n     widget = ReadOnlyPasswordHashWidget\n \n-    def __init__(self, *args, **kwargs):\n-        kwargs.setdefault(\"required\", False)\n-        super().__init__(*args, **kwargs)\n+def __init__(self, *args, **kwargs):\n+    kwargs.setdefault(\"required\", False)\n+    kwargs.setdefault(\"disabled\", True)\n+    super().__init__(*args, **kwargs)\n+\n \n     def bound_data(self, data, initial):\n         # Always return initial because the widget doesn't\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13786",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex dddf7c679c..77098d0ba5 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -136,16 +136,22 @@ class CreateModel(ModelOperation):\n                     managers=self.managers,\n                 ),\n             ]\n-        elif isinstance(operation, AlterModelOptions) and self.name_lower == operation.name_lower:\n-            return [\n-                CreateModel(\n-                    self.name,\n-                    fields=self.fields,\n-                    options={**self.options, **operation.options},\n-                    bases=self.bases,\n-                    managers=self.managers,\n-                ),\n-            ]\n+elif isinstance(operation, AlterModelOptions) and self.name_lower == operation.name_lower:\n+    new_options = self.options.copy()\n+    new_options.update(operation.options)\n+    for key in AlterModelOptions.ALTER_OPTION_KEYS:\n+        if key not in operation.options:\n+            new_options.pop(key, None)\n+    return [\n+        CreateModel(\n+            self.name,\n+            fields=self.fields,\n+            options=new_options,\n+            bases=self.bases,\n+            managers=self.managers,\n+        ),\n+    ]\n+\n         elif isinstance(operation, AlterTogetherOptionOperation) and self.name_lower == operation.name_lower:\n             return [\n                 CreateModel(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13794",
        "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 1c844580c6..5cb4a92a6a 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -8,6 +8,51 @@ from operator import itemgetter\n from pprint import pformat\n from urllib.parse import quote\n \n+from django.utils.encoding import force_str\n from django.utils import formats\n from django.utils.dateformat import format, time_format\n from django.utils.encoding import iri_to_uri\n@@ -120,8 +165,13 @@ def floatformat(text, arg=-1):\n     * {{ num3|floatformat:\"-3\" }} displays \"34.260\"\n \n     If arg has the 'g' suffix, force the result to be grouped by the\n-    THOUSAND_SEPARATOR for the active locale. When the active locale is\n-    en (English):\n+def add(value, arg):\n+    \"\"\"\n+    Concatenate value and arg after forcing them to be strings.\n+    This allows proper handling of lazy string objects.\n+    \"\"\"\n+    return force_str(value) + force_str(arg)\n     * {{ 6666.6666|floatformat:\"2g\" }} displays \"6,666.67\"\n     * {{ 10000|floatformat:\"g\" }} displays \"10,000\"",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13807",
        "model_patch": "diff --git a/django/db/backends/sqlite3/base.py b/django/db/backends/sqlite3/base.py\nindex 2eeaf98c0d..bc18b861a3 100644\n--- a/django/db/backends/sqlite3/base.py\n+++ b/django/db/backends/sqlite3/base.py\n@@ -327,12 +327,14 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n                     violations = cursor.execute('PRAGMA foreign_key_check').fetchall()\n                 else:\n                     violations = chain.from_iterable(\n-                        cursor.execute('PRAGMA foreign_key_check(%s)' % table_name).fetchall()\n+                        cursor.execute('PRAGMA foreign_key_check(\"%s\")' % table_name).fetchall()\n+\n                         for table_name in table_names\n                     )\n                 # See https://www.sqlite.org/pragma.html#pragma_foreign_key_check\n                 for table_name, rowid, referenced_table_name, foreign_key_index in violations:\n-                    foreign_key = cursor.execute(\n+                        'PRAGMA foreign_key_list(\"%s\")' % table_name\n+\n                         'PRAGMA foreign_key_list(%s)' % table_name\n                     ).fetchall()[foreign_key_index]\n                     column_name, referenced_column_name = foreign_key[3:5]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13809",
        "model_patch": "diff --git a/django/core/management/commands/runserver.py b/django/core/management/commands/runserver.py\nindex d9fb088350..f03ee5e3fe 100644\n--- a/django/core/management/commands/runserver.py\n+++ b/django/core/management/commands/runserver.py\n@@ -50,8 +50,12 @@ class Command(BaseCommand):\n         parser.add_argument(\n             '--noreload', action='store_false', dest='use_reloader',\n             help='Tells Django to NOT use the auto-reloader.',\n+        parser.add_argument(\n+            '--skip-checks', action='store_true',\n+            help='Skip system checks; check exclusively in CI/CD rather than on each reload.'\n         )\n \n+\n     def execute(self, *args, **options):\n         if options['no_color']:\n             # We rely on the environment because it's currently the only\n@@ -114,11 +118,15 @@ class Command(BaseCommand):\n         shutdown_message = options.get('shutdown_message', '')\n         quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C'\n \n-        self.stdout.write(\"Performing system checks...\\n\\n\")\n-        self.check(display_num_errors=True)\n-        # Need to check migrations here, so can't use the\n-        # requires_migrations_check attribute.\n-        self.check_migrations()\n+        if not options.get('skip_checks', False):\n+            self.stdout.write(\"Performing system checks...\\n\\n\")\n+            self.check(display_num_errors=True)\n+            # Need to check migrations here, so can't use the\n+            # requires_migrations_check attribute.\n+            self.check_migrations()\n+        else:\n+            self.stdout.write(\"Skipping system checks as per --skip-checks option.\\n\\n\")\n+\n         now = datetime.now().strftime('%B %d, %Y - %X')\n         self.stdout.write(now)\n         self.stdout.write((\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13810",
        "model_patch": "diff --git a/django/core/handlers/base.py b/django/core/handlers/base.py\nindex 8e8c3da06a..ed4b11738a 100644\n--- a/django/core/handlers/base.py\n+++ b/django/core/handlers/base.py\n@@ -2,13 +2,13 @@ import asyncio\n import logging\n import types\n \n-from asgiref.sync import async_to_sync, sync_to_async\n+for mw in self._middleware_chain:\n+    try:\n+        handler = mw(handler)\n+    except MiddlewareNotUsed:\n+        # Skip this middleware without altering the existing handler.\n+        continue\n \n-from django.conf import settings\n-from django.core.exceptions import ImproperlyConfigured, MiddlewareNotUsed\n-from django.core.signals import request_finished\n-from django.db import connections, transaction\n-from django.urls import get_resolver, set_urlconf\n from django.utils.log import log_response\n from django.utils.module_loading import import_string\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13820",
        "model_patch": "diff --git a/django/db/migrations/loader.py b/django/db/migrations/loader.py\nindex 95a5062ec9..016866f997 100644\n--- a/django/db/migrations/loader.py\n+++ b/django/db/migrations/loader.py\n@@ -90,9 +90,10 @@ class MigrationLoader:\n             else:\n                 # Empty directories are namespaces.\n                 # getattr() needed on PY36 and older (replace w/attribute access).\n-                if getattr(module, '__file__', None) is None:\n+                if getattr(module, '__file__', None) is None and not isinstance(getattr(module, '__path__', None), list):\n                     self.unmigrated_apps.add(app_config.label)\n                     continue\n+\n                 # Module is not a package (e.g. migrations.py).\n                 if not hasattr(module, '__path__'):\n                     self.unmigrated_apps.add(app_config.label)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13821",
        "model_patch": "diff --git a/django/db/backends/sqlite3/base.py b/django/db/backends/sqlite3/base.py\nindex ab4ea70492..c587f9f97e 100644\n--- a/django/db/backends/sqlite3/base.py\n+++ b/django/db/backends/sqlite3/base.py\n@@ -64,8 +64,9 @@ def list_aggregate(function):\n \n \n def check_sqlite_version():\n-    if Database.sqlite_version_info < (3, 8, 3):\n-        raise ImproperlyConfigured('SQLite 3.8.3 or later is required (found %s).' % Database.sqlite_version)\n+    if Database.sqlite_version_info < (3, 9, 0):\n+        raise ImproperlyConfigured('SQLite 3.9.0 or later is required (found %s).' % Database.sqlite_version)\n+\n \n \n check_sqlite_version()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13837",
        "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex b8efb9f881..0d8b2c7e36 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -216,15 +216,18 @@ def get_child_arguments():\n     executable is reported to not have the .exe extension which can cause bugs\n     on reloading.\n     \"\"\"\n-    import django.__main__\n-    django_main_path = Path(django.__main__.__file__)\n+    import __main__\n+    main_path = Path(__main__.__file__)\n     py_script = Path(sys.argv[0])\n \n+\n     args = [sys.executable] + ['-W%s' % o for o in sys.warnoptions]\n-    if py_script == django_main_path:\n-        # The server was started with `python -m django runserver`.\n-        args += ['-m', 'django']\n+    if getattr(__main__, '__spec__', None) and __main__.__spec__.parent:\n+        # Python was started with `-m <pkg>`, so reassemble the command using the package name.\n+        args += ['-m', __main__.__spec__.parent] + sys.argv[1:]\n+    elif py_script == main_path:\n         args += sys.argv[1:]\n+\n     elif not py_script.exists():\n         # sys.argv[0] may not exist for several reasons on Windows.\n         # It may exist with a .exe extension or have a -script.py suffix.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13925",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13933",
        "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex daa65d61eb..0c4acd6b74 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -756,9 +756,11 @@ class NullBooleanField(BooleanField):\n class CallableChoiceIterator:\n     def __init__(self, choices_func):\n         self.choices_func = choices_func\n+default_error_messages = {\n+    'invalid_choice': _('Select a valid choice. %(value)s is not one of'\n+                        ' the available choices.'),\n+}\n \n-    def __iter__(self):\n-        yield from self.choices_func()\n \n \n class ChoiceField(Field):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-13964",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14007",
        "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex f02199d97c..fc77340509 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1411,11 +1411,28 @@ class SQLInsertCompiler(SQLCompiler):\n                 cursor.execute(sql, params)\n             if not self.returning_fields:\n                 return []\n-            if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:\n-                return self.connection.ops.fetch_returned_insert_rows(cursor)\n+            # Fetch the returned values and convert them via each field\u2019s from_db_value.\n+            if (self.connection.features.can_return_rows_from_bulk_insert and\n+                    len(self.query.objs) > 1):\n+                results = self.connection.ops.fetch_returned_insert_rows(cursor)\n+                converted = []\n+                for row in results:\n+                    converted_row = []\n+                    for field, value in zip(self.returning_fields, row):\n+                        converted_row.append(\n+                            field.from_db_value(value, None, self.connection) if value is not None else None\n+                        )\n+                    converted.append(tuple(converted_row))\n+                return converted\n             if self.connection.features.can_return_columns_from_insert:\n                 assert len(self.query.objs) == 1\n-                return [self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)]\n+                row = self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)\n+                converted = []\n+                for field, value in zip(self.returning_fields, row):\n+                    converted.append(\n+                        field.from_db_value(value, None, self.connection) if value is not None else None\n+                    )\n+                return [tuple(converted)]\n             return [(self.connection.ops.last_insert_id(\n                 cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column\n             ),)]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14011",
        "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex 14dab517c9..45774613ec 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -78,9 +78,259 @@ class WSGIServer(simple_server.WSGIServer):\n \n \n class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n-    \"\"\"A threaded version of the WSGIServer\"\"\"\n+    \"\"\"A threaded version of the WSGIServer that ensures DB connections are closed after each request.\"\"\"\n     daemon_threads = True\n \n+    def process_request_thread(self, request, client_address):\n+        try:\n+            super().process_request_thread(request, client_address)\n+        finally:\n+            from django.db import connections\n+            connections.close_all()\n class ServerHandler(simple_server.ServerHandler):\n     http_version = '1.1'",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14017",
        "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex c957ffa564..b59dd3ad0d 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -63,6 +63,327 @@ class Q(tree.Node):\n \n     def __and__(self, other):\n         return self._combine(other, self.AND)\n+   def __rand__(self, other):\n+        # Support reverse logical AND operation so that expressions like Q() & Exists(...)\n+        # are commutative when the right operand is a conditional expression.\n+        if getattr(other, 'conditional', False):\n+            return Q(other) & self\n+        raise TypeError(other)\n     def __invert__(self):\n         obj = type(self)()",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14034",
        "model_patch": "diff --git a/django/forms/fields.py b/django/forms/fields.py\nindex 65d6a9ec82..8b5c403ef4 100644\n--- a/django/forms/fields.py\n+++ b/django/forms/fields.py\n@@ -1023,10 +1023,23 @@ class MultiValueField(Field):\n             value = self.widget.decompress(value)\n         if not value or isinstance(value, (list, tuple)):\n             if not value or not [v for v in value if v not in self.empty_values]:\n-                if self.required:\n-                    raise ValidationError(self.error_messages['required'], code='required')\n+                # Even if the overall field is not required, check if any individual\n+                # subfield is required and missing; if so, raise an \"incomplete\" error.\n+                errors = []\n+                for i, field in enumerate(self.fields):\n+                    try:\n+                        field_value = value[i] if value else None\n+                    except IndexError:\n+                        field_value = None\n+                    if field.required and field_value in field.empty_values:\n+                        msg = field.error_messages.get('incomplete', self.error_messages['incomplete'])\n+                        if msg not in errors:\n+                            errors.append(msg)\n+                if errors:\n+                    raise ValidationError(errors)\n                 else:\n                     return self.compress([])\n+\n         else:\n             raise ValidationError(self.error_messages['invalid'], code='invalid')\n         for i, field in enumerate(self.fields):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14053",
        "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex 494890cc23..7ed025af16 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -200,53 +200,55 @@ class HashedFilesMixin:\n \n         return converter\n \n-    def post_process(self, paths, dry_run=False, **options):\n-        \"\"\"\n-        Post process the given dictionary of files (called from collectstatic).\n+def post_process(self, paths, dry_run=False, **options):\n+    \"\"\"\n+    Post process the given dictionary of files (called from collectstatic).\n \n-        Processing is actually two separate operations:\n+    Processing is actually two separate operations:\n \n-        1. renaming files to include a hash of their content for cache-busting,\n-           and copying those files to the target storage.\n-        2. adjusting files which contain references to other files so they\n-           refer to the cache-busting filenames.\n+    1. renaming files to include a hash of their content for cache-busting,\n+       and copying those files to the target storage.\n+    2. adjusting files which contain references to other files so they\n+       refer to the cache-busting filenames.\n \n-        If either of these are performed on a file, then that file is considered\n-        post-processed.\n-        \"\"\"\n-        # don't even dare to process the files if we're in dry run mode\n-        if dry_run:\n-            return\n-\n-        # where to store the new paths\n-        hashed_files = {}\n-\n-        # build a list of adjustable files\n-        adjustable_paths = [\n-            path for path in paths\n-            if matches_patterns(path, self._patterns)\n-        ]\n-        # Do a single pass first. Post-process all files once, then repeat for\n-        # adjustable files.\n-        for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n-            yield name, hashed_name, processed\n-\n-        paths = {path: paths[path] for path in adjustable_paths}\n-\n-        for i in range(self.max_post_process_passes):\n-            substitutions = False\n-            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+    If either of these are performed on a file, then that file is considered\n+    post-processed.\n+    \"\"\"\n+    if dry_run:\n+        return\n+\n+    hashed_files = {}\n+\n+    adjustable_paths = [\n+        path for path in paths\n+        if matches_patterns(path, self._patterns)\n+    ]\n+\n+    yielded = {}\n+\n+    # Initial pass: yield each file once.\n+    for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n+        yielded[name] = hashed_name\n+        yield name, hashed_name, processed\n+\n+    paths = {path: paths[path] for path in adjustable_paths}\n+\n+    # Iterative passes: yield only when a file's hashed name changes.\n+    for i in range(self.max_post_process_passes):\n+        substitutions = False\n+        for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+            if name not in yielded or yielded[name] != hashed_name:\n+                yielded[name] = hashed_name\n                 yield name, hashed_name, processed\n-                substitutions = substitutions or subst\n+            substitutions = substitutions or subst\n+        if not substitutions:\n+            break\n \n-            if not substitutions:\n-                break\n+    if substitutions:\n+        yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n \n-        if substitutions:\n-            yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n+    self.hashed_files.update(hashed_files)\n \n-        # Store the processed paths\n-        self.hashed_files.update(hashed_files)\n \n     def _post_process(self, paths, adjustable_paths, hashed_files):\n         # Sort the files by directory level\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14089",
        "model_patch": "diff --git a/django/utils/datastructures.py b/django/utils/datastructures.py\nindex 871b016715..6af7ce4c6d 100644\n--- a/django/utils/datastructures.py\n+++ b/django/utils/datastructures.py\n@@ -24,6 +24,148 @@ class OrderedSet:\n \n     def __iter__(self):\n         return iter(self.dict)\n+   def __reversed__(self):\n+        # Return an iterator over the keys in reverse insertion order\n+        return reversed(list(self.dict))\n     def __contains__(self, item):\n         return item in self.dict",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14122",
        "model_patch": "diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 850734709d..d1db25e4b7 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -125,11 +125,17 @@ class SQLCompiler:\n             cols = expr.get_group_by_cols()\n             for col in cols:\n                 expressions.append(col)\n-        for expr, (sql, params, is_ref) in order_by:\n-            # Skip References to the select clause, as all expressions in the\n-            # select clause are already part of the group by.\n-            if not is_ref:\n-                expressions.extend(expr.get_group_by_cols())\n+    # Remove ordering that comes from Meta.ordering (i.e. the default ordering)\n+    # because including those ordering columns in the GROUP BY clause may break\n+    # aggregation. When explicit ordering is provided, default_ordering is cleared.\n+    if self.query.default_ordering:\n+        order_by = []\n+\n+    # Process remaining order_by items.\n+    for expr, (sql, params, is_ref) in order_by:\n+        if not is_ref:\n+            expressions.extend(expr.get_group_by_cols())\n+\n         having_group_by = self.having.get_group_by_cols() if self.having else ()\n         for expr in having_group_by:\n             expressions.append(expr)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14140",
        "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex ae0f886107..09b1897103 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -87,11 +87,15 @@ class Q(tree.Node):\n         args, kwargs = (), {}\n         if len(self.children) == 1 and not isinstance(self.children[0], Q):\n             child = self.children[0]\n-            kwargs = {child[0]: child[1]}\n+            if isinstance(child, (tuple, list)) and len(child) == 2:\n+                kwargs = {child[0]: child[1]}\n+            else:\n+                args = (child,)\n         else:\n             args = tuple(self.children)\n             if self.connector != self.default:\n                 kwargs = {'_connector': self.connector}\n+\n         if self.negated:\n             kwargs['_negated'] = True\n         return path, args, kwargs\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14155",
        "model_patch": "diff --git a/django/urls/resolvers.py b/django/urls/resolvers.py\nindex 9b00e24509..ba3c4bca5a 100644\n--- a/django/urls/resolvers.py\n+++ b/django/urls/resolvers.py\n@@ -127,19 +127,24 @@ class CheckURLMixin:\n         regex_pattern = self.regex.pattern\n         if not settings.APPEND_SLASH:\n             # Skip check as it can be useful to start a URL pattern with a slash\n-            # when APPEND_SLASH=False.\n-            return []\n-        if regex_pattern.startswith(('/', '^/', '^\\\\/')) and not regex_pattern.endswith('/'):\n-            warning = Warning(\n-                \"Your URL pattern {} has a route beginning with a '/'. Remove this \"\n-                \"slash as it is unnecessary. If this pattern is targeted in an \"\n-                \"include(), ensure the include() pattern has a trailing '/'.\".format(\n-                    self.describe()\n-                ),\n-                id=\"urls.W002\",\n-            )\n-            return [warning]\n-        else:\n+    def __init__(self, func, args, kwargs, url_name, app_names, namespaces, route):\n+        import functools\n+        # If the function is a functools.partial instance, unwrap it so that\n+        # __repr__ (and any other introspection) shows the underlying function,\n+        # and merge its pre-supplied arguments with the provided args/kwargs.\n+        if isinstance(func, functools.partial):\n+            original_partial = func\n+            func = original_partial.func\n+            args = original_partial.args + args\n+            if original_partial.keywords:\n+                merged = original_partial.keywords.copy()\n+                merged.update(kwargs)\n+                kwargs = merged\n+\n+        self.func = func\n+        self.args = args\n+        self.kwargs = kwargs\n+\n             return []\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14170",
        "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex 916478d075..ebff726873 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -546,20 +546,26 @@ class YearLookup(Lookup):\n             bounds = connection.ops.year_lookup_bounds_for_date_field(year)\n         return bounds\n \n-    def as_sql(self, compiler, connection):\n-        # Avoid the extract operation if the rhs is a direct value to allow\n-        # indexes to be used.\n-        if self.rhs_is_direct_value():\n-            # Skip the extract part by directly using the originating field,\n-            # that is self.lhs.lhs.\n-            lhs_sql, params = self.process_lhs(compiler, connection, self.lhs.lhs)\n-            rhs_sql, _ = self.process_rhs(compiler, connection)\n-            rhs_sql = self.get_direct_rhs_sql(connection, rhs_sql)\n-            start, finish = self.year_lookup_bounds(connection, self.rhs)\n-            params.extend(self.get_bound_params(start, finish))\n-            return '%s %s' % (lhs_sql, rhs_sql), params\n+def as_sql(self, compiler, connection):\n+    # For __iso_year lookup, disable the BETWEEN optimization so that\n+    # the EXTRACT operation (as defined by ExtractIsoYear) is used.\n+    if getattr(self.lhs, 'lookup_name', None) == 'iso_year':\n         return super().as_sql(compiler, connection)\n \n+    # Avoid the extract operation if the rhs is a direct value to allow\n+    # indexes to be used.\n+    if self.rhs_is_direct_value():\n+        # Skip the extract part by directly using the originating field,\n+        # that is self.lhs.lhs.\n+        lhs_sql, params = self.process_lhs(compiler, connection, self.lhs.lhs)\n+        rhs_sql, _ = self.process_rhs(compiler, connection)\n+        rhs_sql = self.get_direct_rhs_sql(connection, rhs_sql)\n+        start, finish = self.year_lookup_bounds(connection, self.rhs)\n+        params.extend(self.get_bound_params(start, finish))\n+        return '%s %s' % (lhs_sql, rhs_sql), params\n+    return super().as_sql(compiler, connection)\n+\n+\n     def get_direct_rhs_sql(self, connection, rhs):\n         return connection.operators[self.lookup_name] % rhs\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14238",
        "model_patch": "diff --git a/django/db/models/fields/__init__.py b/django/db/models/fields/__init__.py\nindex 0f53d9c30b..2201b44066 100644\n--- a/django/db/models/fields/__init__.py\n+++ b/django/db/models/fields/__init__.py\n@@ -75,6 +75,7 @@ def _empty(of_cls):\n     new = Empty()\n     new.__class__ = of_cls\n     return new\n+    _subclasses = {AutoField, BigAutoField, SmallAutoField}\n \n \n def return_None():\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14311",
        "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex b6af5f5491..66ffb9fbbb 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -223,9 +223,10 @@ def get_child_arguments():\n     # __spec__ is set when the server was started with the `-m` option,\n     # see https://docs.python.org/3/reference/import.html#main-spec\n     # __spec__ may not exist, e.g. when running in a Conda env.\n-    if getattr(__main__, '__spec__', None) is not None and __main__.__spec__.parent:\n-        args += ['-m', __main__.__spec__.parent]\n+    if getattr(__main__, '__spec__', None) is not None and __main__.__spec__.name != '__main__':\n+        args += ['-m', __main__.__spec__.name]\n         args += sys.argv[1:]\n+\n     elif not py_script.exists():\n         # sys.argv[0] may not exist for several reasons on Windows.\n         # It may exist with a .exe extension or have a -script.py suffix.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14315",
        "model_patch": "diff --git a/django/db/backends/postgresql/client.py b/django/db/backends/postgresql/client.py\nindex 3effab65a8..199fa6ec31 100644\n--- a/django/db/backends/postgresql/client.py\n+++ b/django/db/backends/postgresql/client.py\n@@ -51,8 +51,11 @@ class DatabaseClient(BaseDatabaseClient):\n             env['PGSSLKEY'] = str(sslkey)\n         if passfile:\n             env['PGPASSFILE'] = str(passfile)\n+        if not env:\n+            env = None\n         return args, env\n \n+\n     def runshell(self, parameters):\n         sigint_handler = signal.getsignal(signal.SIGINT)\n         try:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14349",
        "model_patch": "diff --git a/django/core/validators.py b/django/core/validators.py\nindex a385819510..66b8a6370e 100644\n--- a/django/core/validators.py\n+++ b/django/core/validators.py\n@@ -101,6 +101,261 @@ class URLValidator(RegexValidator):\n     def __call__(self, value):\n         if not isinstance(value, str):\n             raise ValidationError(self.message, code=self.code, params={'value': value})\n+   # Reject URLs containing forbidden whitespace characters:\n+    # Line feed (\\n), carriage return (\\r), or tab (\\t)\n+    if any(char in value for char in \"\\n\\r\\t\"):\n+        raise ValidationError(self.message, code=self.code, params={'value': value})\n         # Check if the scheme is valid.\n         scheme = value.split('://')[0].lower()\n         if scheme not in self.schemes:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14351",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 6629a1fd51..a6249dc91f 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -132,16 +132,23 @@ class RawQuery:\n         else:\n             raise RuntimeError(\"Unexpected params type: %s\" % params_type)\n \n-        self.cursor = connection.cursor()\n-        self.cursor.execute(self.sql, params)\n+    def get_default_columns(self):\n+        \"\"\"\n+        Return the list of columns that are selected by default.\n+        In normal queries this is every concrete field on the model,\n+        but when this query is used as a subquery (for example when used\n+        in an __or__ condition) only the primary key column is returned\n+        so that the subquery returns a single column (avoiding a\n+        \"subquery must return only one column\" error).\n+        \"\"\"\n+        cols = [f.get_col(self.get_initial_alias())\n+                for f in self.get_meta().concrete_fields]\n+        if self.subquery and len(cols) > 1:\n+            pk_col = self.get_meta().pk.get_col(self.get_initial_alias())\n+            cols = [col for col in cols if col == pk_col]\n+        return cols\n \n \n-class Query(BaseExpression):\n-    \"\"\"A single SQL query.\"\"\"\n-\n-    alias_prefix = 'T'\n-    subq_aliases = frozenset([alias_prefix])\n-\n     compiler = 'SQLCompiler'\n \n     def __init__(self, model, where=WhereNode, alias_cols=True):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14373",
        "model_patch": "diff --git a/django/utils/dateformat.py b/django/utils/dateformat.py\nindex 38e89c47bb..3ac0bebb04 100644\n--- a/django/utils/dateformat.py\n+++ b/django/utils/dateformat.py\n@@ -312,9 +312,10 @@ class DateFormat(TimeFormat):\n         \"\"\"Year, 2 digits with leading zeros; e.g. '99'.\"\"\"\n         return '%02d' % (self.data.year % 100)\n \n-    def Y(self):\n-        \"Year, 4 digits; e.g. '1999'\"\n-        return self.data.year\n+def Y(self):\n+    \"Year, 4 digits; e.g. '1999'\"\n+    return '%04d' % self.data.year\n+\n \n     def z(self):\n         \"\"\"Day of the year, i.e. 1 to 366.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14376",
        "model_patch": "diff --git a/django/db/backends/mysql/base.py b/django/db/backends/mysql/base.py\nindex 2c62182d31..45e5b6bbcd 100644\n--- a/django/db/backends/mysql/base.py\n+++ b/django/db/backends/mysql/base.py\n@@ -199,10 +199,11 @@ class DatabaseWrapper(BaseDatabaseWrapper):\n         settings_dict = self.settings_dict\n         if settings_dict['USER']:\n             kwargs['user'] = settings_dict['USER']\n-        if settings_dict['NAME']:\n-            kwargs['db'] = settings_dict['NAME']\n-        if settings_dict['PASSWORD']:\n-            kwargs['passwd'] = settings_dict['PASSWORD']\n+if settings_dict['NAME']:\n+    kwargs['database'] = settings_dict['NAME']\n+if settings_dict['PASSWORD']:\n+    kwargs['password'] = settings_dict['PASSWORD']\n+\n         if settings_dict['HOST'].startswith('/'):\n             kwargs['unix_socket'] = settings_dict['HOST']\n         elif settings_dict['HOST']:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14404",
        "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 59a4a0364d..c59f3766b6 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -420,7 +420,8 @@ class AdminSite:\n     def catch_all_view(self, request, url):\n         if settings.APPEND_SLASH and not url.endswith('/'):\n             urlconf = getattr(request, 'urlconf', None)\n-            path = '%s/' % request.path_info\n+            path = '%s/' % request.path\n+\n             try:\n                 match = resolve(path, urlconf)\n             except Resolver404:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14434",
        "model_patch": "diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py\nindex ad2f5a7da1..84993ccc68 100644\n--- a/django/db/backends/base/schema.py\n+++ b/django/db/backends/base/schema.py\n@@ -1251,7 +1251,8 @@ class BaseDatabaseSchemaEditor:\n         else:\n             sql = self.sql_create_unique\n         if columns:\n-            columns = self._index_columns(table, columns, col_suffixes=(), opclasses=opclasses)\n+            columns = self._index_columns(model._meta.db_table, columns, col_suffixes=(), opclasses=opclasses)\n+\n         else:\n             columns = Expressions(model._meta.db_table, expressions, compiler, self.quote_value)\n         return Statement(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14493",
        "model_patch": "diff --git a/django/contrib/staticfiles/storage.py b/django/contrib/staticfiles/storage.py\nindex f957a667b2..d2202281f4 100644\n--- a/django/contrib/staticfiles/storage.py\n+++ b/django/contrib/staticfiles/storage.py\n@@ -261,15 +261,17 @@ class HashedFilesMixin:\n \n         paths = {path: paths[path] for path in adjustable_paths}\n \n-        for i in range(self.max_post_process_passes):\n-            substitutions = False\n-            for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n-                # Overwrite since hashed_name may be newer.\n-                processed_adjustable_paths[name] = (name, hashed_name, processed)\n-                substitutions = substitutions or subst\n+substitutions = False\n+for i in range(self.max_post_process_passes):\n+    substitutions = False\n+    for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n+        # Overwrite since hashed_name may be newer.\n+        processed_adjustable_paths[name] = (name, hashed_name, processed)\n+        substitutions = substitutions or subst\n+\n+    if not substitutions:\n+        break\n \n-            if not substitutions:\n-                break\n \n         if substitutions:\n             yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14500",
        "model_patch": "diff --git a/django/db/migrations/executor.py b/django/db/migrations/executor.py\nindex 57042a8690..ec8486191f 100644\n--- a/django/db/migrations/executor.py\n+++ b/django/db/migrations/executor.py\n@@ -192,9 +192,10 @@ class MigrationExecutor:\n         if self.progress_callback:\n             self.progress_callback(\"render_success\")\n \n-        for migration, _ in plan:\n             self.unapply_migration(states[migration], migration, fake=fake)\n-            applied_migrations.remove(migration)\n+            if not migration.replaces:\n+                applied_migrations.remove(migration)\n+\n \n         # Generate the post migration state by starting from the state before\n         # the last migration is unapplied and mutating it to include all the\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14534",
        "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 2ff8b0ee26..af4da848a8 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -275,9 +275,10 @@ class BoundWidget:\n             return self.data['template_name']\n         return self.parent_widget.template_name\n \n-    @property\n-    def id_for_label(self):\n-        return 'id_%s_%s' % (self.data['name'], self.data['index'])\n+@property\n+def id_for_label(self):\n+    return self.data.get('attrs', {}).get('id')\n+\n \n     @property\n     def choice_label(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14539",
        "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 1c844580c6..dcc9224a30 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -337,11 +337,12 @@ def urlencode(value, safe=None):\n     return quote(value, **kwargs)\n \n \n+@register.filter(is_safe=True, needs_autoescape=True)\n @register.filter(is_safe=True, needs_autoescape=True)\n @stringfilter\n def urlize(value, autoescape=True):\n-    \"\"\"Convert URLs in plain text into clickable links.\"\"\"\n-    return mark_safe(_urlize(value, nofollow=True, autoescape=autoescape))\n+    return mark_safe(_urlize(value, nofollow=True, autoescape=False))\n+\n \n \n @register.filter(is_safe=True, needs_autoescape=True)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14559",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 387deca527..ff1ba729e6 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -524,49 +524,53 @@ class QuerySet:\n \n         return objs\n \n-    def bulk_update(self, objs, fields, batch_size=None):\n-        \"\"\"\n-        Update the given fields in each of the given objects in the database.\n-        \"\"\"\n-        if batch_size is not None and batch_size < 0:\n-            raise ValueError('Batch size must be a positive integer.')\n-        if not fields:\n-            raise ValueError('Field names must be given to bulk_update().')\n-        objs = tuple(objs)\n-        if any(obj.pk is None for obj in objs):\n-            raise ValueError('All bulk_update() objects must have a primary key set.')\n-        fields = [self.model._meta.get_field(name) for name in fields]\n-        if any(not f.concrete or f.many_to_many for f in fields):\n-            raise ValueError('bulk_update() can only be used with concrete fields.')\n-        if any(f.primary_key for f in fields):\n-            raise ValueError('bulk_update() cannot be used with primary key fields.')\n-        if not objs:\n-            return\n-        # PK is used twice in the resulting update query, once in the filter\n-        # and once in the WHEN. Each field will also have one CAST.\n-        max_batch_size = connections[self.db].ops.bulk_batch_size(['pk', 'pk'] + fields, objs)\n-        batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n-        requires_casting = connections[self.db].features.requires_casted_case_in_updates\n-        batches = (objs[i:i + batch_size] for i in range(0, len(objs), batch_size))\n-        updates = []\n-        for batch_objs in batches:\n-            update_kwargs = {}\n-            for field in fields:\n-                when_statements = []\n-                for obj in batch_objs:\n-                    attr = getattr(obj, field.attname)\n-                    if not isinstance(attr, Expression):\n-                        attr = Value(attr, output_field=field)\n-                    when_statements.append(When(pk=obj.pk, then=attr))\n-                case_statement = Case(*when_statements, output_field=field)\n-                if requires_casting:\n-                    case_statement = Cast(case_statement, output_field=field)\n-                update_kwargs[field.attname] = case_statement\n-            updates.append(([obj.pk for obj in batch_objs], update_kwargs))\n-        with transaction.atomic(using=self.db, savepoint=False):\n-            for pks, update_kwargs in updates:\n-                self.filter(pk__in=pks).update(**update_kwargs)\n+def bulk_update(self, objs, fields, batch_size=None):\n+    \"\"\"\n+    Update the given fields in each of the given objects in the database.\n+    Returns the total number of rows matched (updated).\n+    \"\"\"\n+    if batch_size is not None and batch_size < 0:\n+        raise ValueError('Batch size must be a positive integer.')\n+    if not fields:\n+        raise ValueError('Field names must be given to bulk_update().')\n+    objs = tuple(objs)\n+    if any(obj.pk is None for obj in objs):\n+        raise ValueError('All bulk_update() objects must have a primary key set.')\n+    fields = [self.model._meta.get_field(name) for name in fields]\n+    if any(not f.concrete or f.many_to_many for f in fields):\n+        raise ValueError('bulk_update() can only be used with concrete fields.')\n+    if any(f.primary_key for f in fields):\n+        raise ValueError('bulk_update() cannot be used with primary key fields.')\n+    if not objs:\n+        return 0\n+    # PK is used twice in the resulting update query, once in the filter\n+    # and once in the WHEN. Each field will also have one CAST.\n+    max_batch_size = connections[self.db].ops.bulk_batch_size(['pk', 'pk'] + fields, objs)\n+    batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n+    requires_casting = connections[self.db].features.requires_casted_case_in_updates\n+    batches = (objs[i:i + batch_size] for i in range(0, len(objs), batch_size))\n+    updates = []\n+    for batch_objs in batches:\n+        update_kwargs = {}\n+        for field in fields:\n+            when_statements = []\n+            for obj in batch_objs:\n+                attr = getattr(obj, field.attname)\n+                if not isinstance(attr, Expression):\n+                    attr = Value(attr, output_field=field)\n+                when_statements.append(When(pk=obj.pk, then=attr))\n+            case_statement = Case(*when_statements, output_field=field)\n+            if requires_casting:\n+                case_statement = Cast(case_statement, output_field=field)\n+            update_kwargs[field.attname] = case_statement\n+        updates.append(([obj.pk for obj in batch_objs], update_kwargs))\n+    rows_updated = 0\n+    with transaction.atomic(using=self.db, savepoint=False):\n+        for pks, update_kwargs in updates:\n+            rows_updated += self.filter(pk__in=pks).update(**update_kwargs)\n     bulk_update.alters_data = True\n+    return rows_updated\n+\n \n     def get_or_create(self, defaults=None, **kwargs):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14580",
        "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex 4918261fb0..5265df27c2 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -162,10 +162,8 @@ class MigrationWriter:\n                 imports.remove(line)\n                 self.needs_manual_porting = True\n \n-        # django.db.migrations is always used, but models import may not be.\n-        # If models import exists, merge it with migrations import.\n-        if \"from django.db import models\" in imports:\n-            imports.discard(\"from django.db import models\")\n+        # django.db.migrations is always used. Ensure that models is imported if referenced in operations.\n+        if \"models.Model\" in \"\".join(operations):\n             imports.add(\"from django.db import migrations, models\")\n         else:\n             imports.add(\"from django.db import migrations\")\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14608",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 7a5551f650..83b170b18b 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -785,19 +785,34 @@ class ModelAdmin(BaseModelAdmin):\n \n         return modelform_factory(self.model, **defaults)\n \n-    def get_changelist_formset(self, request, **kwargs):\n-        \"\"\"\n-        Return a FormSet class for use on the changelist page if list_editable\n-        is used.\n-        \"\"\"\n-        defaults = {\n-            'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n-            **kwargs,\n-        }\n-        return modelformset_factory(\n-            self.model, self.get_changelist_form(request), extra=0,\n-            fields=self.list_editable, **defaults\n-        )\n+def get_changelist_formset(self, request, **kwargs):\n+    \"\"\"\n+    Return a FormSet class for use on the changelist page if list_editable\n+    is used.\n+\n+    We override the default formset error_class so that non form errors\n+    will be rendered with the 'nonform' CSS class, allowing developers\n+    to distinguish them from non field errors.\n+    \"\"\"\n+    from django.forms.utils import NonFormErrorList\n+    from django.forms.models import BaseModelFormSet\n+\n+    class CustomFormSet(BaseModelFormSet):\n+        error_class = NonFormErrorList\n+\n+    defaults = {\n+        'formfield_callback': partial(self.formfield_for_dbfield, request=request),\n+        **kwargs,\n+    }\n+    return modelformset_factory(\n+        self.model,\n+        self.get_changelist_form(request),\n+        extra=0,\n+        fields=self.list_editable,\n+        formset=CustomFormSet,\n+        **defaults\n+    )\n     def get_formsets_with_inlines(self, request, obj=None):\n         \"\"\"\ndiff --git a/django/forms/utils.py b/django/forms/utils.py\nindex 50412f414b..25fc4bba0a 100644\n--- a/django/forms/utils.py\n+++ b/django/forms/utils.py\n@@ -127,6 +127,512 @@ class ErrorList(UserList, list):\n         return self.as_ul()\n \n     def __repr__(self):\n+html_safe\n+class NonFormErrorList(ErrorList):\n+    \"\"\"\n+    A collection of errors for FormSets non form errors.\n+    This error list always applies the 'nonform' CSS class, resulting in the\n+    rendered <ul> having the classes \"errorlist nonform\".\n+    \"\"\"\n+    def __init__(self, initlist=None, error_class=None):\n+        # Force the usage of 'nonform' so that the final CSS class is\n+        # \"errorlist nonform\" (see ErrorList.__init__).\n+        super().__init__(initlist, error_class='nonform')\n         return repr(list(self))\n \n     def __contains__(self, item):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14631",
        "model_patch": "diff --git a/django/forms/boundfield.py b/django/forms/boundfield.py\nindex 88adadb37d..2b4dba21ba 100644\n--- a/django/forms/boundfield.py\n+++ b/django/forms/boundfield.py\n@@ -120,15 +120,642 @@ class BoundField:\n         \"\"\"\n         return self.form._field_data_value(self.field, self.html_name)\n \n-    def value(self):\n-        \"\"\"\n-        Return the value for this BoundField, using the initial value if\n-        the form is not bound or the data otherwise.\n-        \"\"\"\n-        data = self.initial\n-        if self.form.is_bound:\n-            data = self.field.bound_data(self.data, data)\n-        return self.field.prepare_value(data)\n+def value(self):\n+    \"\"\"\n+    Return the value for this BoundField. If the field is disabled, always\n+    return the initial value; otherwise, if the form is bound, use the submitted data.\n+    \"\"\"\n+    if self.field.disabled:\n+        return self.initial\n+    data = self.data\n+    if self.form.is_bound:\n+        data = self.field.bound_data(self.data, self.initial)\n+    return self.field.prepare_value(data)\n+def did_change(self):\n+    \"\"\"\n+    Determine if the value for this BoundField has changed from its initial value.\n+    \"\"\"\n+    if self.field.show_hidden_initial:\n+        initial_prefixed_name = self.form.add_initial_prefix(self.name)\n+        hidden_widget = self.field.hidden_widget()\n+        try:\n+            initial_value = self.field.to_python(\n+                self.form._widget_data_value(hidden_widget, initial_prefixed_name)\n+            )\n+        except ValidationError:\n+            return True\n+    else:\n+        initial_value = self.initial\n+    return self.field.has_changed(initial_value, self.value())\n     def label_tag(self, contents=None, attrs=None, label_suffix=None):\n         \"\"\"\ndiff --git a/django/forms/forms.py b/django/forms/forms.py\nindex d14037bfe9..ff746f308d 100644\n--- a/django/forms/forms.py\n+++ b/django/forms/forms.py\n@@ -387,17 +387,13 @@ class BaseForm:\n         self._post_clean()\n \n     def _clean_fields(self):\n-        for name, field in self.fields.items():\n-            if field.disabled:\n-                value = self.get_initial_for_field(field, name)\n-            else:\n-                value = self._field_data_value(field, self.add_prefix(name))\n+        for name in self.fields:\n+            bf = self[name]\n             try:\n-                if isinstance(field, FileField):\n-                    initial = self.get_initial_for_field(field, name)\n-                    value = field.clean(value, initial)\n+                if isinstance(bf.field, FileField):\n+                    value = bf.field.clean(bf.value(), bf.initial)\n                 else:\n-                    value = field.clean(value)\n+                    value = bf.field.clean(bf.value())\n                 self.cleaned_data[name] = value\n                 if hasattr(self, 'clean_%s' % name):\n                     value = getattr(self, 'clean_%s' % name)()\n@@ -434,29 +430,11 @@ class BaseForm:\n         \"\"\"Return True if data differs from initial.\"\"\"\n         return bool(self.changed_data)\n \n+    @cached_property\n     @cached_property\n     def changed_data(self):\n-        data = []\n-        for name, field in self.fields.items():\n-            data_value = self._field_data_value(field, self.add_prefix(name))\n-            if not field.show_hidden_initial:\n-                # Use the BoundField's initial as this is the value passed to\n-                # the widget.\n-                initial_value = self[name].initial\n-            else:\n-                initial_prefixed_name = self.add_initial_prefix(name)\n-                hidden_widget = field.hidden_widget()\n-                try:\n-                    initial_value = field.to_python(\n-                        self._widget_data_value(hidden_widget, initial_prefixed_name)\n-                    )\n-                except ValidationError:\n-                    # Always assume data has changed if validation fails.\n-                    data.append(name)\n-                    continue\n-            if field.has_changed(initial_value, data_value):\n-                data.append(name)\n-        return data\n+        return [name for name in self.fields if self[name].did_change()]\n     @property\n     def media(self):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14672",
        "model_patch": "diff --git a/django/db/models/fields/reverse_related.py b/django/db/models/fields/reverse_related.py\nindex ccc2223a5f..3a954bd7b4 100644\n--- a/django/db/models/fields/reverse_related.py\n+++ b/django/db/models/fields/reverse_related.py\n@@ -306,13 +306,14 @@ class ManyToManyRel(ForeignObjectRel):\n         self.symmetrical = symmetrical\n         self.db_constraint = db_constraint\n \n-    @property\n-    def identity(self):\n-        return super().identity + (\n-            self.through,\n-            self.through_fields,\n-            self.db_constraint,\n-        )\n+@property\n+def identity(self):\n+    return super().identity + (\n+        self.through,\n+        make_hashable(self.through_fields) if self.through_fields is not None else None,\n+        self.db_constraint,\n+    )\n+\n \n     def get_related_field(self):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14725",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 7effb202e3..3fac7f880c 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -813,11 +813,13 @@ class BaseModelFormSet(BaseFormSet):\n \n     def save_new_objects(self, commit=True):\n         self.new_objects = []\n+        # If new object creation is disallowed, do not save any extra forms.\n+        if not getattr(self, 'can_create', True):\n+            return self.new_objects\n         for form in self.extra_forms:\n             if not form.has_changed():\n                 continue\n-            # If someone has marked an add form for deletion, don't save the\n-            # object.\n+            # If someone has marked an add form for deletion, don't save the object.\n             if self.can_delete and self._should_delete_form(form):\n                 continue\n             self.new_objects.append(self.save_new(form, commit=commit))\n@@ -825,6 +827,7 @@ class BaseModelFormSet(BaseFormSet):\n                 self.saved_forms.append(form)\n         return self.new_objects\n \n+\n     def add_fields(self, form, index):\n         \"\"\"Add a hidden field for the object's primary key.\"\"\"\n         from django.db.models import AutoField, ForeignKey, OneToOneField\n@@ -875,8 +878,9 @@ def modelformset_factory(model, form=ModelForm, formfield_callback=None,\n                          widgets=None, validate_max=False, localized_fields=None,\n                          labels=None, help_texts=None, error_messages=None,\n                          min_num=None, validate_min=False, field_classes=None,\n-                         absolute_max=None, can_delete_extra=True, renderer=None):\n-    \"\"\"Return a FormSet class for the given Django model class.\"\"\"\n+                         absolute_max=None, can_delete_extra=True, renderer=None,\n+                         can_create=True):\n+\n     meta = getattr(form, 'Meta', None)\n     if (getattr(meta, 'fields', fields) is None and\n             getattr(meta, 'exclude', exclude) is None):\n@@ -896,9 +900,11 @@ def modelformset_factory(model, form=ModelForm, formfield_callback=None,\n                               absolute_max=absolute_max, can_delete_extra=can_delete_extra,\n                               renderer=renderer)\n     FormSet.model = model\n+    FormSet.can_create = can_create\n     return FormSet\n \n \n+\n # InlineFormSets #############################################################\n \n class BaseInlineFormSet(BaseModelFormSet):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14752",
        "model_patch": "diff --git a/django/contrib/admin/views/autocomplete.py b/django/contrib/admin/views/autocomplete.py\nindex 3903e4c98c..24a09c926f 100644\n--- a/django/contrib/admin/views/autocomplete.py\n+++ b/django/contrib/admin/views/autocomplete.py\n@@ -24,13 +24,14 @@ class AutocompleteJsonView(BaseListView):\n \n         self.object_list = self.get_queryset()\n         context = self.get_context_data()\n-        return JsonResponse({\n-            'results': [\n-                {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}\n-                for obj in context['object_list']\n-            ],\n-            'pagination': {'more': context['page_obj'].has_next()},\n-        })\n+return JsonResponse({\n+    'results': [\n+        self.serialize_result(obj, to_field_name)\n+        for obj in context['object_list']\n+    ],\n+    'pagination': {'more': context['page_obj'].has_next()},\n+})\n     def get_paginator(self, *args, **kwargs):\n         \"\"\"Use the ModelAdmin's paginator.\"\"\"\n@@ -100,3 +101,259 @@ class AutocompleteJsonView(BaseListView):\n     def has_perm(self, request, obj=None):\n         \"\"\"Check if user has permission to access the related model.\"\"\"\n         return self.model_admin.has_view_permission(request, obj=obj)\n+ef serialize_result(self, obj, to_field_name):\n+    \"\"\"\n+    Serialize a single result object.\n+    Override this method to add additional fields to the autocomplete result.\n+    \"\"\"\n+    return {'id': str(getattr(obj, to_field_name)), 'text': str(obj)}",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14765",
        "model_patch": "diff --git a/django/db/migrations/state.py b/django/db/migrations/state.py\nindex 088f5c41f0..f3bc293fe8 100644\n--- a/django/db/migrations/state.py\n+++ b/django/db/migrations/state.py\n@@ -91,10 +91,12 @@ class ProjectState:\n     def __init__(self, models=None, real_apps=None):\n         self.models = models or {}\n         # Apps to include from main registry, usually unmigrated ones\n-        if real_apps:\n-            self.real_apps = real_apps if isinstance(real_apps, set) else set(real_apps)\n+        if real_apps is not None:\n+            assert isinstance(real_apps, set), \"real_apps must be a set\"\n+            self.real_apps = real_apps\n         else:\n             self.real_apps = set()\n+\n         self.is_delayed = False\n         # {remote_model_key: {model_key: [(field_name, field)]}}\n         self.relations = None\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14771",
        "model_patch": "diff --git a/django/utils/autoreload.py b/django/utils/autoreload.py\nindex cc65c043ab..7cb3a01f42 100644\n--- a/django/utils/autoreload.py\n+++ b/django/utils/autoreload.py\n@@ -220,6 +220,208 @@ def get_child_arguments():\n     py_script = Path(sys.argv[0])\n \n     args = [sys.executable] + ['-W%s' % o for o in sys.warnoptions]\n+ Pass through -X options from current interpreter\n+for key, value in sys._xoptions.items():\n+    if value is True:\n+        args.append(f'-X{key}')\n+    else:\n+        args.append(f'-X{key}={value}')\n     # __spec__ is set when the server was started with the `-m` option,\n     # see https://docs.python.org/3/reference/import.html#main-spec\n     # __spec__ may not exist, e.g. when running in a Conda env.",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14787",
        "model_patch": "diff --git a/django/utils/decorators.py b/django/utils/decorators.py\nindex 5c9a5d01c7..430e4c5e69 100644\n--- a/django/utils/decorators.py\n+++ b/django/utils/decorators.py\n@@ -37,10 +37,12 @@ def _multi_decorate(decorators, method):\n         # 'self' argument, but it's a closure over self so it can call\n         # 'func'. Also, wrap method.__get__() in a function because new\n         # attributes can't be set on bound method objects, only on functions.\n-        bound_method = partial(method.__get__(self, type(self)))\n-        for dec in decorators:\n-            bound_method = dec(bound_method)\n-        return bound_method(*args, **kwargs)\n+    def bound_method(*a, **kw):\n+        return method.__get__(self, type(self))(*a, **kw)\n+    for dec in decorators:\n+        bound_method = dec(bound_method)\n+    return bound_method(*args, **kwargs)\n+\n \n     # Copy any attributes that a decorator adds to the function it decorates.\n     for dec in decorators:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14792",
        "model_patch": "diff --git a/django/utils/timezone.py b/django/utils/timezone.py\nindex bb2b6b9594..3d003a2732 100644\n--- a/django/utils/timezone.py\n+++ b/django/utils/timezone.py\n@@ -73,7 +73,20 @@ def get_current_timezone_name():\n \n def _get_timezone_name(timezone):\n     \"\"\"Return the name of ``timezone``.\"\"\"\n-    return str(timezone)\n+    tzname = str(timezone)\n+    # For GMT-based time zones, convert the full name to an abbreviated offset.\n+    # For example: \"Etc/GMT-10\" should become \"+10\" and \"Etc/GMT+10\" should become \"-10\"\n+    if tzname.startswith(\"Etc/GMT\") and len(tzname) > 7:\n+        try:\n+            offset = int(tzname[7:])\n+        except ValueError:\n+            return tzname\n+        if tzname[7] == '-':\n+            return \"+\" + str(abs(offset))\n+        elif tzname[7] == '+':\n+            return \"-\" + str(abs(offset))\n+    return tzname\n+\n \n # Timezone selection functions.\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14855",
        "model_patch": "diff --git a/django/contrib/admin/helpers.py b/django/contrib/admin/helpers.py\nindex dd154f72ee..3bf3381e23 100644\n--- a/django/contrib/admin/helpers.py\n+++ b/django/contrib/admin/helpers.py\n@@ -209,7 +209,8 @@ class AdminReadonlyField:\n             remote_field.model._meta.model_name,\n         )\n         try:\n-            url = reverse(url_name, args=[quote(remote_obj.pk)])\n+            url = reverse(url_name, args=[quote(remote_obj.pk)], current_app=self.model_admin.admin_site.name)\n+\n             return format_html('<a href=\"{}\">{}</a>', url, remote_obj)\n         except NoReverseMatch:\n             return str(remote_obj)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14915",
        "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 00c19e2c55..438e5693aa 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -677,18 +677,19 @@ class Select(ChoiceWidget):\n     checked_attribute = {'selected': True}\n     option_inherits_attrs = False\n \n-    def get_context(self, name, value, attrs):\n-        context = super().get_context(name, value, attrs)\n-        if self.allow_multiple_selected:\n-            context['widget']['attrs']['multiple'] = True\n+    def create_option(self, name, value, label, selected, index, subindex=None, attrs=None):\n+        context = super().create_option(name, value, label, selected, index, subindex, attrs)\n+        if not value:\n+            return context\n+        # Convert the value from ModelChoiceIteratorValue to an int key (if possible)\n+        try:\n+            key = int(value)\n+        except (TypeError, ValueError):\n+            key = value\n+        if key in self.show_fields:\n+            context['attrs']['data-fields'] = json.dumps(self.show_fields[key])\n         return context\n \n-    @staticmethod\n-    def _choice_has_empty_value(choice):\n-        \"\"\"Return True if the choice's value is empty string or None.\"\"\"\n-        value, _ = choice\n-        return value is None or value == ''\n-\n     def use_required_attribute(self, initial):\n         \"\"\"\n         Don't render 'required' if the first <option> has a value, as that's\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-14999",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 982816be3a..36c71648c5 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -320,12 +320,17 @@ class RenameModel(ModelOperation):\n         new_model = to_state.apps.get_model(app_label, self.new_name)\n         if self.allow_migrate_model(schema_editor.connection.alias, new_model):\n             old_model = from_state.apps.get_model(app_label, self.old_name)\n+            # If an explicit db_table is defined, the table names are identical.\n+            # Therefore, no alteration is needed.\n+            if old_model._meta.db_table == new_model._meta.db_table:\n+                return\n             # Move the main table\n             schema_editor.alter_db_table(\n                 new_model,\n                 old_model._meta.db_table,\n                 new_model._meta.db_table,\n             )\n+\n             # Alter the fields pointing to us\n             for related_object in old_model._meta.related_objects:\n                 if related_object.related_model == old_model:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15022",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 66f3396a6b..0780b5dbc0 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1031,14 +1031,18 @@ class ModelAdmin(BaseModelAdmin):\n         if search_fields and search_term:\n             orm_lookups = [construct_search(str(search_field))\n                            for search_field in search_fields]\n+            combined_q = None\n             for bit in smart_split(search_term):\n                 if bit.startswith(('\"', \"'\")) and bit[0] == bit[-1]:\n                     bit = unescape_string_literal(bit)\n-                or_queries = models.Q(\n-                    *((orm_lookup, bit) for orm_lookup in orm_lookups),\n-                    _connector=models.Q.OR,\n-                )\n-                queryset = queryset.filter(or_queries)\n+                q_bit = models.Q(*((orm_lookup, bit) for orm_lookup in orm_lookups), _connector=models.Q.OR)\n+                if combined_q is None:\n+                    combined_q = q_bit\n+                else:\n+                    combined_q &= q_bit\n+            if combined_q is not None:\n+                queryset = queryset.filter(combined_q)\n+\n             may_have_duplicates |= any(\n                 lookup_spawns_duplicates(self.opts, search_spec)\n                 for search_spec in orm_lookups\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15037",
        "model_patch": "diff --git a/django/core/management/commands/inspectdb.py b/django/core/management/commands/inspectdb.py\nindex f9b4bfb477..7aa46cc359 100644\n--- a/django/core/management/commands/inspectdb.py\n+++ b/django/core/management/commands/inspectdb.py\n@@ -120,14 +120,403 @@ class Command(BaseCommand):\n                             rel_type = 'OneToOneField'\n                         else:\n                             rel_type = 'ForeignKey'\n-                        rel_to = (\n-                            \"self\" if relations[column_name][1] == table_name\n-                            else table2model(relations[column_name][1])\n-                        )\n+                        rel_to = (\"self\" if relations[column_name][1] == table_name\n+                                  else table2model(relations[column_name][1]))\n                         if rel_to in known_models:\n                             field_type = '%s(%s' % (rel_type, rel_to)\n                         else:\n                             field_type = \"%s('%s'\" % (rel_type, rel_to)\n+                        # Handle foreign keys referencing non-primary fields:\n+                        remote_column, remote_table = relations[column_name]\n+                        target_pk = connection.introspection.get_primary_key_column(cursor, remote_table)\n+                        if remote_column != target_pk:\n+                            extra_params['to_field'] = remote_column\n                     else:\n                         # Calling `get_field_type` to get the field type string and any\n                         # additional parameters and notes.",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15098",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15103",
        "model_patch": "diff --git a/django/utils/html.py b/django/utils/html.py\nindex da1b5675ec..64ec4c45be 100644\n--- a/django/utils/html.py\n+++ b/django/utils/html.py\n@@ -61,7 +61,8 @@ _json_script_escapes = {\n }\n \n \n-def json_script(value, element_id):\n+def json_script(value, element_id=None):\n+\n     \"\"\"\n     Escape all the HTML/XML special characters with their unicode escapes, so\n     value is safe to be output anywhere except for inside a tag attribute. Wrap\n@@ -69,10 +70,17 @@ def json_script(value, element_id):\n     \"\"\"\n     from django.core.serializers.json import DjangoJSONEncoder\n     json_str = json.dumps(value, cls=DjangoJSONEncoder).translate(_json_script_escapes)\n-    return format_html(\n-        '<script id=\"{}\" type=\"application/json\">{}</script>',\n-        element_id, mark_safe(json_str)\n-    )\n+    if element_id:\n+        return format_html(\n+            '<script id=\"{}\" type=\"application/json\">{}</script>',\n+            element_id, mark_safe(json_str)\n+        )\n+    else:\n+        return format_html(\n+            '<script type=\"application/json\">{}</script>',\n+            mark_safe(json_str)\n+        )\n+\n \n \n def conditional_escape(text):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15104",
        "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex 97977d72ef..83e1c1342c 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -96,7 +96,8 @@ class MigrationAutodetector:\n         for name, field in sorted(fields.items()):\n             deconstruction = self.deep_deconstruct(field)\n             if field.remote_field and field.remote_field.model:\n-                del deconstruction[2]['to']\n+                deconstruction[2].pop('to', None)\n+\n             fields_def.append(deconstruction)\n         return fields_def\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15127",
        "model_patch": "diff --git a/django/contrib/messages/storage/base.py b/django/contrib/messages/storage/base.py\nindex 01422066a6..86c085f8d9 100644\n--- a/django/contrib/messages/storage/base.py\n+++ b/django/contrib/messages/storage/base.py\n@@ -36,9 +36,10 @@ class Message:\n     def tags(self):\n         return ' '.join(tag for tag in [self.extra_tags, self.level_tag] if tag)\n \n-    @property\n-    def level_tag(self):\n-        return LEVEL_TAGS.get(self.level, '')\n+@property\n+def level_tag(self):\n+    return utils.get_level_tags().get(self.level, '')\n+\n \n \n class BaseStorage:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15128",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex aaf35ee37c..7c27f20b8f 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -850,23 +850,30 @@ class Query(BaseExpression):\n \n         # 1. Update references in \"select\" (normal columns plus aliases),\n         # \"group by\" and \"where\".\n-        self.where.relabel_aliases(change_map)\n-        if isinstance(self.group_by, tuple):\n-            self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])\n-        self.select = tuple([col.relabeled_clone(change_map) for col in self.select])\n-        self.annotations = self.annotations and {\n-            key: col.relabeled_clone(change_map) for key, col in self.annotations.items()\n-        }\n-\n-        # 2. Rename the alias in the internal table/alias datastructures.\n-        for old_alias, new_alias in change_map.items():\n-            if old_alias not in self.alias_map:\n-                continue\n-            alias_data = self.alias_map[old_alias].relabeled_clone(change_map)\n-            self.alias_map[new_alias] = alias_data\n-            self.alias_refcount[new_alias] = self.alias_refcount[old_alias]\n-            del self.alias_refcount[old_alias]\n-            del self.alias_map[old_alias]\n+    # Ensure that no alias is re-used. If an alias in the mapping\u2019s values\n+    # already appears as a key or has been used earlier in the mapping,\n+    # generate a new alias by incrementing its numeric suffix.\n+    adjusted_map = {}\n+    for old_alias, new_alias in change_map.items():\n+        current_new = new_alias\n+        # Continue adjusting the alias until it is unique among change_map keys\n+        # (i.e. those that will be remapped) and already adjusted aliases.\n+        while current_new in change_map.keys() or current_new in adjusted_map.values():\n+            import re\n+            m = re.match(r\"([A-Za-z]+)(\\d+)$\", current_new)\n+            if m:\n+                prefix, num = m.groups()\n+                current_new = \"{}{}\".format(prefix, int(num) + 1)\n+            else:\n+                # Fallback in case alias does not match pattern\n+                current_new = current_new + \"_1\"\n+        adjusted_map[old_alias] = current_new\n+    change_map = adjusted_map\n+    assert not set(change_map.keys()) & set(change_map.values()), (\n+        \"Alias mapping collision remains after adjustment: %s\" % change_map\n+    )\n+\n+    # Existing implementation that applies the updated change_map.\n \n             table_aliases = self.table_map[alias_data.table_name]\n             for pos, alias in enumerate(table_aliases):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15161",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 8642e1f151..f7b5341891 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -442,8 +442,10 @@ def _resolve_combined_type(connector, lhs_type, rhs_type):\n             return combined_type\n \n \n+@deconstructible(path='django.db.models.CombinedExpression')\n class CombinedExpression(SQLiteNumericMixin, Expression):\n \n+\n     def __init__(self, lhs, connector, rhs, output_field=None):\n         super().__init__(output_field=output_field)\n         self.connector = connector\n@@ -651,7 +653,9 @@ class OuterRef(F):\n         return self\n \n \n+@deconstructible(path='django.db.models.Func')\n class Func(SQLiteNumericMixin, Expression):\n+\n     \"\"\"An SQL function call.\"\"\"\n     function = None\n     template = '%(function)s(%(expressions)s)'\n@@ -731,7 +735,9 @@ class Func(SQLiteNumericMixin, Expression):\n         return copy\n \n \n+@deconstructible(path='django.db.models.Value')\n class Value(SQLiteNumericMixin, Expression):\n+\n     \"\"\"Represent a wrapped value as a node within an expression.\"\"\"\n     # Provide a default value for `for_save` in order to allow unresolved\n     # instances to be compiled until a decision is taken in #25425.\n@@ -842,8 +848,10 @@ class Star(Expression):\n         return '*', []\n \n \n+@deconstructible(path='django.db.models.Col')\n class Col(Expression):\n \n+\n     contains_column_references = True\n     possibly_multivalued = False\n \n@@ -879,7 +887,9 @@ class Col(Expression):\n                 self.target.get_db_converters(connection))\n \n \n+@deconstructible(path='django.db.models.Ref')\n class Ref(Expression):\n+\n     \"\"\"\n     Reference to column alias of the query. For example, Ref('sum_cost') in\n     qs.annotate(sum_cost=Sum('cost')) query.\n@@ -953,7 +963,9 @@ class OrderByList(Func):\n         return super().as_sql(*args, **kwargs)\n \n \n+@deconstructible(path='django.db.models.ExpressionWrapper')\n class ExpressionWrapper(SQLiteNumericMixin, Expression):\n+\n     \"\"\"\n     An expression that can wrap another expression so that it can provide\n     extra context to the inner expression, such as the output_field.\n@@ -985,7 +997,9 @@ class ExpressionWrapper(SQLiteNumericMixin, Expression):\n         return \"{}({})\".format(self.__class__.__name__, self.expression)\n \n \n+@deconstructible(path='django.db.models.When')\n class When(Expression):\n+\n     template = 'WHEN %(condition)s THEN %(result)s'\n     # This isn't a complete conditional expression, must be used in Case().\n     conditional = False\n@@ -1052,7 +1066,9 @@ class When(Expression):\n         return cols\n \n \n+@deconstructible(path='django.db.models.Case')\n class Case(SQLiteNumericMixin, Expression):\n+\n     \"\"\"\n     An SQL searched CASE expression:\n \n@@ -1225,7 +1241,9 @@ class Exists(Subquery):\n         return sql, params\n \n \n+@deconstructible(path='django.db.models.OrderBy')\n class OrderBy(Expression):\n+\n     template = '%(expression)s %(ordering)s'\n     conditional = False\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15252",
        "model_patch": "diff --git a/django/db/migrations/recorder.py b/django/db/migrations/recorder.py\nindex 1a37c6b7d0..f87aff9ee4 100644\n--- a/django/db/migrations/recorder.py\n+++ b/django/db/migrations/recorder.py\n@@ -94,3 +94,17 @@ class MigrationRecorder:\n     def flush(self):\n         \"\"\"Delete all migration records. Useful for testing migrations.\"\"\"\n         self.migration_qs.all().delete()\n+\n+    def ensure_schema(self):\n+        \"Ensure the migration table exists, obeying allow_migrate rules.\"\n+        from django.db import router\n+\n+        # Only create migration table if allowed by the database router.\n+        if not router.allow_migrate(self.connection.alias, self.Migration):\n+            return\n+\n+        if self.Migration._meta.db_table in self.connection.introspection.table_names():\n+            return\n+\n+        with self.connection.schema_editor() as editor:\n+            editor.create_model(self.Migration)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15268",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex c120f5d32d..ef5644bcb1 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -150,16 +150,6 @@ class CreateModel(ModelOperation):\n                     managers=self.managers,\n                 ),\n             ]\n-        elif isinstance(operation, AlterTogetherOptionOperation) and self.name_lower == operation.name_lower:\n-            return [\n-                CreateModel(\n-                    self.name,\n-                    fields=self.fields,\n-                    options={**self.options, **{operation.option_name: operation.option_value}},\n-                    bases=self.bases,\n-                    managers=self.managers,\n-                ),\n-            ]\n         elif isinstance(operation, AlterOrderWithRespectTo) and self.name_lower == operation.name_lower:\n             return [\n                 CreateModel(\n@@ -524,6 +514,317 @@ class AlterTogetherOptionOperation(ModelOptionOperation):\n     def describe(self):\n         return \"Alter %s for %s (%s constraint(s))\" % (self.option_name, self.name, len(self.option_value or ''))\n \n+def reduce(self, operation, app_label):\n+    if isinstance(operation, self.__class__) and self.name_lower == operation.name_lower:\n+        # If multiple operations on the same model and same option occur,\n+        # use the later op.\n+        return operation\n+    return super().reduce(operation, app_label)\n     @property\n     def migration_name_fragment(self):\n         return 'alter_%s_%s' % (self.name_lower, self.option_name)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15277",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15278",
        "model_patch": "diff --git a/django/db/backends/sqlite3/schema.py b/django/db/backends/sqlite3/schema.py\nindex 6752a8e3c0..a7a4b418b0 100644\n--- a/django/db/backends/sqlite3/schema.py\n+++ b/django/db/backends/sqlite3/schema.py\n@@ -147,25 +147,33 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n         Shortcut to transform a model from old_model into new_model\n \n         This follows the correct procedure to perform non-rename or column\n-        addition operations based on SQLite's documentation\n-\n-        https://www.sqlite.org/lang_altertable.html#caution\n+def add_field(self, model, field):\n+    definition, params = self.column_sql(model, field)\n+    # For nullable unique fields (like a OneToOneField with null=True), remove\n+    # the UNIQUE keyword from the column definition because SQLite does not\n+    # allow adding a UNIQUE column.\n+    if field.unique and field.null:\n+        definition = definition.replace(\" UNIQUE\", \"\")\n+\n+    sql = self.sql_alter_table % {\n+        \"table\": self.quote_name(model._meta.db_table),\n+        \"column\": self.quote_name(field.column),\n+        \"definition\": definition,\n+    }\n+    self.execute(sql, params)\n+\n+    # If the field should be unique, add a unique index after adding the column.\n+    # SQLite\u2019s unique index on a nullable column will allow multiple NULLs,\n+    # which is Django\u2019s intended behavior.\n+    if field.unique and field.null:\n+        index_name = self._create_index_name(model._meta.db_table, [field.column], suffix=\"_uniq\")\n+        sql = self.sql_create_unique_index % {\n+            \"name\": self.quote_name(index_name),\n+            \"table\": self.quote_name(model._meta.db_table),\n+            \"columns\": self.quote_name(field.column),\n+        }\n+        self.execute(sql)\n \n-        The essential steps are:\n-          1. Create a table with the updated definition called \"new__app_model\"\n-          2. Copy the data from the existing \"app_model\" table to the new table\n-          3. Drop the \"app_model\" table\n-          4. Rename the \"new__app_model\" table to \"app_model\"\n-          5. Restore any index of the previous \"app_model\" table.\n-        \"\"\"\n-        # Self-referential fields must be recreated rather than copied from\n-        # the old model to ensure their remote_field.field_name doesn't refer\n-        # to an altered field.\n-        def is_self_referential(f):\n-            return f.is_relation and f.remote_field.model is model\n-        # Work out the new fields dict / mapping\n-        body = {\n-            f.name: f.clone() if is_self_referential(f) else f\n             for f in model._meta.local_concrete_fields\n         }\n         # Since mapping might mix column names and default values,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15280",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex fb6639793a..ee44473d2b 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1908,6 +1908,445 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n         rel_qs._prefetch_related_lookups = ()\n \n     all_related_objects = list(rel_qs)\n+   # FIX: Clear any deferred fields on the related objects so that attribute\n+    # access does not trigger an extra query. In the case of prefetching back\n+    # to the parent, the deferred fields remain set even though the field data\n+    # has been loaded, causing an unnecessary query on access.\n+    for rel_obj in all_related_objects:\n+        if hasattr(rel_obj, '_deferred_fields'):\n+            rel_obj._deferred_fields.clear()\n     rel_obj_cache = {}\n     for rel_obj in all_related_objects:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15315",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 7effb202e3..157c768366 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -1167,7 +1167,9 @@ class ModelChoiceIteratorValue:\n         return str(self.value)\n \n     def __hash__(self):\n-        return hash(self.value)\n+        # Use the object's identity to compute hash, ensuring immutability even if self.value changes.\n+        return id(self)\n+\n \n     def __eq__(self, other):\n         if isinstance(other, ModelChoiceIteratorValue):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15368",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15375",
        "model_patch": "diff --git a/django/db/models/aggregates.py b/django/db/models/aggregates.py\nindex 8c4eae7906..c95ed84d9a 100644\n--- a/django/db/models/aggregates.py\n+++ b/django/db/models/aggregates.py\n@@ -48,24 +48,20 @@ class Aggregate(Func):\n         return super().set_source_expressions(exprs)\n \n     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n-        # Aggregates are not allowed in UPDATE queries, so ignore for_save\n-        c = super().resolve_expression(query, allow_joins, reuse, summarize)\n-        c.filter = c.filter and c.filter.resolve_expression(query, allow_joins, reuse, summarize)\n-        if not summarize:\n-            # Call Aggregate.get_source_expressions() to avoid\n-            # returning self.filter and including that in this loop.\n-            expressions = super(Aggregate, c).get_source_expressions()\n-            for index, expr in enumerate(expressions):\n-                if expr.contains_aggregate:\n-                    before_resolved = self.get_source_expressions()[index]\n-                    name = before_resolved.name if hasattr(before_resolved, 'name') else repr(before_resolved)\n-                    raise FieldError(\"Cannot compute %s('%s'): '%s' is an aggregate\" % (c.name, name, name))\n-        if (default := c.default) is None:\n-            return c\n+        resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+        # If no default is provided the aggregate is unchanged.\n+        if resolved.default is None:\n+            return resolved\n+        # Work on a copy so that modifications (resetting .default) do not leak into\n+        # any annotations that have already been built.\n+        c = resolved.copy()\n+        default = c.default\n         if hasattr(default, 'resolve_expression'):\n-            default = default.resolve_expression(query, allow_joins, reuse, summarize)\n-        c.default = None  # Reset the default argument before wrapping.\n-        return Coalesce(c, default, output_field=c._output_field_or_none)\n+            default = default.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n+        c.default = None  # reset the default so that Coalesce wraps a clean aggregate\n+        output_field = c._output_field if getattr(c, '_output_field', None) is not None else c._output_field_or_none\n+        return Coalesce(c, default, output_field=output_field)\n+\n \n     @property\n     def default_alias(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15380",
        "model_patch": "diff --git a/django/db/migrations/autodetector.py b/django/db/migrations/autodetector.py\nindex bf9c2acd26..c90aed3a7a 100644\n--- a/django/db/migrations/autodetector.py\n+++ b/django/db/migrations/autodetector.py\n@@ -822,9 +822,10 @@ class MigrationAutodetector:\n         \"\"\"Work out renamed fields.\"\"\"\n         self.renamed_fields = {}\n         for app_label, model_name, field_name in sorted(self.new_field_keys - self.old_field_keys):\n-            old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n-            old_model_state = self.from_state.models[app_label, old_model_name]\n-            new_model_state = self.to_state.models[app_label, old_model_name]\n+old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n+old_model_state = self.from_state.models[app_label, old_model_name]\n+new_model_state = self.to_state.models[app_label, model_name]\n+\n             field = new_model_state.get_field(field_name)\n             # Scan to see if this is actually a rename!\n             field_dec = self.deep_deconstruct(field)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15382",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 81f8f79c71..549933854a 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -1209,18 +1209,28 @@ class Exists(Subquery):\n         clone.negated = not self.negated\n         return clone\n \n-    def as_sql(self, compiler, connection, template=None, **extra_context):\n-        query = self.query.exists(using=connection.alias)\n-        sql, params = super().as_sql(\n-            compiler,\n-            connection,\n-            template=template,\n-            query=query,\n-            **extra_context,\n-        )\n+def as_sql(self, compiler, connection, template=None, **extra_context):\n+    # If the underlying subquery is empty, then instead of removing the\n+    # WHERE clause altogether, return a constant condition.\n+    # For Exists(empty) the condition is always False, so for a non\u2011negated\n+    # exists we return \"0=1\". For a negated exists (i.e. ~Exists(empty)),\n+    # the condition is always True so we return \"1=1\".\n+    if self.query.is_empty():\n         if self.negated:\n-            sql = 'NOT {}'.format(sql)\n-        return sql, params\n+            return \"1=1\", []\n+        return \"0=1\", []\n+    query = self.query.exists(using=connection.alias)\n+    sql, params = super().as_sql(\n+        compiler,\n+        connection,\n+        template=template,\n+        query=query,\n+        **extra_context,\n+    )\n+    if self.negated:\n+        sql = 'NOT {}'.format(sql)\n+    return sql, params\n+\n \n     def select_format(self, compiler, sql, params):\n         # Wrap EXISTS() with a CASE WHEN expression if a database backend\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15467",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 64be087bf1..748d95f19b 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -269,7 +269,8 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n                         \"class\": get_ul_class(self.radio_fields[db_field.name]),\n                     }\n                 )\n-                kwargs[\"empty_label\"] = _(\"None\") if db_field.blank else None\n+                    kwargs[\"empty_label\"] = (kwargs.get(\"empty_label\") or _(\"None\")) if db_field.blank else None\n+\n \n         if \"queryset\" not in kwargs:\n             queryset = self.get_field_queryset(db, db_field, request)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15499",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 90fc31bee5..0f374ac92a 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -202,6 +202,334 @@ class CreateModel(ModelOperation):\n                     managers=self.managers,\n                 ),\n             ]\n+lif (\n+    isinstance(operation, AlterModelManagers)\n+    and self.name_lower == operation.name_lower\n+):\n+    return [\n+        CreateModel(\n+            self.name,\n+            fields=self.fields,\n+            options=self.options,\n+            bases=self.bases,\n+            managers=operation.managers,\n+        ),\n+    ]\n         elif (\n             isinstance(operation, FieldOperation)\n             and self.name_lower == operation.model_name_lower",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15503",
        "model_patch": "diff --git a/django/db/models/lookups.py b/django/db/models/lookups.py\nindex 5db549e6bf..bd22aa3da9 100644\n--- a/django/db/models/lookups.py\n+++ b/django/db/models/lookups.py\n@@ -77,15 +77,22 @@ class Lookup(Expression):\n         else:\n             self.lhs, self.rhs = new_exprs\n \n-    def get_prep_lookup(self):\n-        if not self.prepare_rhs or hasattr(self.rhs, \"resolve_expression\"):\n-            return self.rhs\n-        if hasattr(self.lhs, \"output_field\"):\n-            if hasattr(self.lhs.output_field, \"get_prep_value\"):\n-                return self.lhs.output_field.get_prep_value(self.rhs)\n-        elif self.rhs_is_direct_value():\n-            return Value(self.rhs)\n+def get_prep_lookup(self):\n+    # Fix for handling numeric keys in JSONField lookups.\n+    if self.lookup_name in (\"has_key\", \"has_keys\", \"has_any_keys\"):\n+        if isinstance(self.rhs, (int, float)):\n+            self.rhs = str(self.rhs)\n+        elif isinstance(self.rhs, (list, tuple)):\n+            self.rhs = type(self.rhs)(str(k) if isinstance(k, (int, float)) else k for k in self.rhs)\n+    if not self.prepare_rhs or hasattr(self.rhs, \"resolve_expression\"):\n         return self.rhs\n+    if hasattr(self.lhs, \"output_field\"):\n+        if hasattr(self.lhs.output_field, \"get_prep_value\"):\n+            return self.lhs.output_field.get_prep_value(self.rhs)\n+    elif self.rhs_is_direct_value():\n+        return Value(self.rhs)\n+    return self.rhs\n+\n \n     def get_prep_lhs(self):\n         if hasattr(self.lhs, \"resolve_expression\"):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15525",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15554",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 54f3258eac..67d130e531 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -1024,20 +1024,24 @@ class Query(BaseExpression):\n         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new\n         joins are created as LOUTER if the join is nullable.\n         \"\"\"\n+    # If the join comes from a FilteredRelation, we never want to reuse an existing one.\n+    if join.filtered_relation is not None:\n+        reuse_aliases = []\n+    else:\n         reuse_aliases = [\n             a\n             for a, j in self.alias_map.items()\n             if (reuse is None or a in reuse) and j.equals(join)\n         ]\n-        if reuse_aliases:\n-            if join.table_alias in reuse_aliases:\n-                reuse_alias = join.table_alias\n-            else:\n-                # Reuse the most recent alias of the joined table\n-                # (a many-to-many relation may be joined multiple times).\n-                reuse_alias = reuse_aliases[-1]\n-            self.ref_alias(reuse_alias)\n-            return reuse_alias\n+    if reuse_aliases:\n+        if join.table_alias in reuse_aliases:\n+            reuse_alias = join.table_alias\n+        else:\n+            # Reuse the most recent alias of the joined table\n+            # (a many-to-many relation may be joined multiple times).\n+            reuse_alias = reuse_aliases[-1]\n+        self.ref_alias(reuse_alias)\n+        return reuse_alias\n \n         # No reuse is possible, so we need a new alias.\n         alias, _ = self.table_alias(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15561",
        "model_patch": "diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py\nindex cd3aab43ad..c3bc055887 100644\n--- a/django/db/migrations/operations/fields.py\n+++ b/django/db/migrations/operations/fields.py\n@@ -230,12 +230,23 @@ class AlterField(FieldOperation):\n             from_model = from_state.apps.get_model(app_label, self.model_name)\n             from_field = from_model._meta.get_field(self.name)\n             to_field = to_model._meta.get_field(self.name)\n+            # On SQLite altering field choices should be a no-op.\n+            if schema_editor.connection.vendor == \"sqlite\":\n+                decon_from = from_field.deconstruct()\n+                decon_to = self.field.deconstruct()\n+                from_opts = dict(decon_from[2])\n+                to_opts = dict(decon_to[2])\n+                from_opts.pop(\"choices\", None)\n+                to_opts.pop(\"choices\", None)\n+                if from_opts == to_opts:\n+                    return\n             if not self.preserve_default:\n                 to_field.default = self.field.default\n             schema_editor.alter_field(from_model, from_field, to_field)\n             if not self.preserve_default:\n                 to_field.default = NOT_PROVIDED\n \n+\n     def database_backwards(self, app_label, schema_editor, from_state, to_state):\n         self.database_forwards(app_label, schema_editor, from_state, to_state)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15563",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex 5c78c6e315..5abfd79385 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -990,10 +990,13 @@ class QuerySet:\n         query = self.query.chain(sql.UpdateQuery)\n         query.add_update_values(kwargs)\n         # Clear any annotations so that they won't be present in subqueries.\n-        query.annotations = {}\n-        with transaction.mark_for_rollback_on_error(using=self.db):\n-            rows = query.get_compiler(self.db).execute_sql(CURSOR)\n-        self._result_cache = None\n+with transaction.mark_for_rollback_on_error(using=self.db):\n+    rows = query.get_compiler(self.db).execute_sql(CURSOR)\n+    for related_query in query.get_related_updates():\n+        rows += related_query.get_compiler(self.db).execute_sql(CURSOR)\n+self._result_cache = None\n+return rows\n+\n         return rows\n \n     update.alters_data = True\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15569",
        "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex 0caa165e15..6917820604 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -217,6 +217,7 @@ class RegisterLookupMixin:\n         if lookup_name is None:\n             lookup_name = lookup.lookup_name\n         del cls.class_lookups[lookup_name]\n+        cls._clear_cached_lookups()\n \n \n def select_related_descend(field, restricted, requested, load_fields, reverse=False):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15572",
        "model_patch": "diff --git a/django/template/autoreload.py b/django/template/autoreload.py\nindex 84c8554165..33c7b977cd 100644\n--- a/django/template/autoreload.py\n+++ b/django/template/autoreload.py\n@@ -17,7 +17,8 @@ def get_template_directories():\n         if not isinstance(backend, DjangoTemplates):\n             continue\n \n-        items.update(cwd / to_path(dir) for dir in backend.engine.dirs)\n+        items.update(cwd / to_path(dir) for dir in backend.engine.dirs if dir)\n+\n \n         for loader in backend.engine.template_loaders:\n             if not hasattr(loader, \"get_dirs\"):\n@@ -25,8 +26,9 @@ def get_template_directories():\n             items.update(\n                 cwd / to_path(directory)\n                 for directory in loader.get_dirs()\n-                if not is_django_path(directory)\n+                if directory and not is_django_path(directory)\n             )\n+\n     return items\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15629",
        "model_patch": "diff --git a/django/db/models/fields/related.py b/django/db/models/fields/related.py\nindex fad5560486..7971598a72 100644\n--- a/django/db/models/fields/related.py\n+++ b/django/db/models/fields/related.py\n@@ -1176,8 +1176,16 @@ class ForeignKey(ForeignObject):\n     def db_check(self, connection):\n         return None\n \n-    def db_type(self, connection):\n-        return self.target_field.rel_db_type(connection=connection)\n+def db_type(self, connection):\n+    db_type_str = self.target_field.rel_db_type(connection=connection)\n+    # Propagate db_collation information from the target (primary key) field.\n+    # MySQL requires that the fk column has the same collation as the pk.\n+    if connection.vendor == 'mysql' and hasattr(self.target_field, 'db_collation'):\n+        collation = self.target_field.db_collation\n+        if collation:\n+            db_type_str = f\"{db_type_str} COLLATE {collation}\"\n+    return db_type_str\n+\n \n     def db_parameters(self, connection):\n         return {\"type\": self.db_type(connection), \"check\": self.db_check(connection)}\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15695",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15731",
        "model_patch": "diff --git a/django/db/models/manager.py b/django/db/models/manager.py\nindex e37e56cd17..ae5e91025a 100644\n--- a/django/db/models/manager.py\n+++ b/django/db/models/manager.py\n@@ -1,6 +1,35 @@\n import copy\n import inspect\n from importlib import import_module\n+rom functools import wraps\n from django.db import router\n from django.db.models.query import QuerySet\n@@ -80,13 +109,12 @@ class BaseManager:\n \n     @classmethod\n     def _get_queryset_methods(cls, queryset_class):\n-        def create_method(name, method):\n-            def manager_method(self, *args, **kwargs):\n-                return getattr(self.get_queryset(), name)(*args, **kwargs)\n+    def create_method(name, method):\n+        @wraps(method)\n+        def manager_method(self, *args, **kwargs):\n+            return getattr(self.get_queryset(), name)(*args, **kwargs)\n+        return manager_method\n \n-            manager_method.__name__ = method.__name__\n-            manager_method.__doc__ = method.__doc__\n-            return manager_method\n \n         new_methods = {}\n         for name, method in inspect.getmembers(",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15732",
        "model_patch": "diff --git a/django/db/backends/postgresql/schema.py b/django/db/backends/postgresql/schema.py\nindex a22ae0094f..3c0378bf6a 100644\n--- a/django/db/backends/postgresql/schema.py\n+++ b/django/db/backends/postgresql/schema.py\n@@ -297,3 +297,1197 @@ class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n             include=include,\n             expressions=expressions,\n         )\n+   def _constraint_names(self, model, column_names, index=False):\n+        \"\"\"\n+        Return a list of constraint names on the given model for which the columns\n+        match the supplied list. If multiple unique constraints are found, filter out\n+        the primary key constraint (whose name ends with '_pkey') if it is the only extra.\n+        \"\"\"\n+        cursor = self.connection.cursor()\n+        constraints = self.connection.introspection.get_constraints(cursor, model._meta.db_table)\n+        matching = []\n+        for name, info in constraints.items():\n+            # Check if the set of columns match (order\u2010independent)\n+            if set(info[\"columns\"]) == set(column_names):\n+                if index and not info.get(\"index\", False):\n+                    continue\n+                matching.append(name)\n+        # If more than one constraint was found, and one looks like a primary key,\n+        # remove it so that only the extra (unique_together) constraint remains.\n+        if len(matching) > 1:\n+            non_pk = [name for name in matching if not name.endswith(\"_pkey\")]\n+            if len(non_pk) == 1:\n+                return non_pk\n+        return matching",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15741",
        "model_patch": "diff --git a/django/utils/formats.py b/django/utils/formats.py\nindex 3f38322d84..71f0b4c316 100644\n--- a/django/utils/formats.py\n+++ b/django/utils/formats.py\n@@ -106,6 +106,42 @@ def get_format(format_type, lang=None, use_l10n=None):\n     If use_l10n is provided and is not None, it forces the value to\n     be localized (or not), overriding the value of settings.USE_L10N.\n     \"\"\"\n+   format_type = str(format_type)\n     if use_l10n is None:\n         try:\n             use_l10n = settings._USE_L10N_INTERNAL",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15814",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 33cc636b22..e9fd326fff 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -2352,9 +2352,12 @@ class Query(BaseExpression):\n         \"\"\"\n         existing, defer = self.deferred_loading\n         field_names = set(field_names)\n-        if \"pk\" in field_names:\n-            field_names.remove(\"pk\")\n-            field_names.add(self.get_meta().pk.name)\n+    if \"pk\" in field_names:\n+        field_names.remove(\"pk\")\n+        meta = self.get_meta()\n+        concrete_meta = meta.concrete_model._meta\n+        field_names.add(concrete_meta.pk.name)\n+\n \n         if defer:\n             # Remove any existing deferred names from the current set before\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15851",
        "model_patch": "diff --git a/django/core/management/commands/dbshell.py b/django/core/management/commands/dbshell.py\nindex 30d2765afb..eab1b1440a 100644\n--- a/django/core/management/commands/dbshell.py\n+++ b/django/core/management/commands/dbshell.py\n@@ -24,25 +24,33 @@ class Command(BaseCommand):\n         parameters = parser.add_argument_group(\"parameters\", prefix_chars=\"--\")\n         parameters.add_argument(\"parameters\", nargs=\"*\")\n \n-    def handle(self, **options):\n-        connection = connections[options[\"database\"]]\n-        try:\n-            connection.client.runshell(options[\"parameters\"])\n-        except FileNotFoundError:\n-            # Note that we're assuming the FileNotFoundError relates to the\n-            # command missing. It could be raised for some other reason, in\n-            # which case this error message would be inaccurate. Still, this\n-            # message catches the common case.\n-            raise CommandError(\n-                \"You appear not to have the %r program installed or on your path.\"\n-                % connection.client.executable_name\n-            )\n-        except subprocess.CalledProcessError as e:\n-            raise CommandError(\n-                '\"%s\" returned non-zero exit status %s.'\n-                % (\n-                    \" \".join(e.cmd),\n-                    e.returncode,\n-                ),\n-                returncode=e.returncode,\n-            )\n+def handle(self, **options):\n+    connection = connections[options[\"database\"]]\n+    try:\n+        params = options[\"parameters\"]\n+        # If using psql, ensure extra parameters are inserted before the DB name.\n+        if getattr(connection.client, \"executable_name\", \"\") == \"psql\" and params:\n+            args = connection.client.settings_to_cmd_args()\n+            # Insert the extra parameters before the final argument (the database name).\n+            if args:\n+                args = args[:-1] + params + [args[-1]]\n+            else:\n+                args = params\n+            subprocess.check_call(args)\n+        else:\n+            connection.client.runshell(params)\n+    except FileNotFoundError:\n+        raise CommandError(\n+            \"You appear not to have the %r program installed or on your path.\"\n+            % connection.client.executable_name\n+        )\n+    except subprocess.CalledProcessError as e:\n+        raise CommandError(\n+            '\"%s\" returned non-zero exit status %s.'\n+            % (\n+                \" \".join(e.cmd),\n+                e.returncode,\n+            ),\n+            returncode=e.returncode,\n+        )\n+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15863",
        "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 7a5b28d159..5bb4ebc66b 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -151,13 +151,18 @@ def floatformat(text, arg=-1):\n             use_l10n = False\n             arg = arg[:-1] or -1\n     try:\n+try:\n+    if isinstance(text, Decimal):\n+        d = text\n+    else:\n         input_val = repr(text)\n         d = Decimal(input_val)\n-    except InvalidOperation:\n-        try:\n-            d = Decimal(str(float(text)))\n-        except (ValueError, InvalidOperation, TypeError):\n-            return \"\"\n+except InvalidOperation:\n+    try:\n+        d = Decimal(str(float(text)))\n+    except (ValueError, InvalidOperation, TypeError):\n+        return \"\"\n+\n     try:\n         p = int(arg)\n     except ValueError:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15916",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 192d9fad94..6b32642136 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -630,15 +630,16 @@ def modelform_factory(\n     # creating needs to inherit from the parent's inner meta.\n     bases = (form.Meta,) if hasattr(form, \"Meta\") else ()\n     Meta = type(\"Meta\", bases, attrs)\n-    if formfield_callback:\n+    if formfield_callback is not None:\n         Meta.formfield_callback = staticmethod(formfield_callback)\n     # Give this new form class a reasonable name.\n     class_name = model.__name__ + \"Form\"\n \n     # Class attributes for the new form class.\n-    form_class_attrs = {\"Meta\": Meta, \"formfield_callback\": formfield_callback}\n+    form_class_attrs = {\"Meta\": Meta}\n+    if formfield_callback is not None:\n+        form_class_attrs[\"formfield_callback\"] = formfield_callback\n \n-    if getattr(Meta, \"fields\", None) is None and getattr(Meta, \"exclude\", None) is None:\n         raise ImproperlyConfigured(\n             \"Calling modelform_factory without defining 'fields' or \"\n             \"'exclude' explicitly is prohibited.\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15930",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 14ed0c0a63..e6f5b177c8 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -986,7 +986,8 @@ class Query(BaseExpression):\n             if prefix not in self.subq_aliases:\n                 self.alias_prefix = prefix\n                 break\n-            if pos > local_recursion_limit:\n+                if pos >= local_recursion_limit:\n+\n                 raise RecursionError(\n                     \"Maximum recursion depth exceeded: too many subqueries.\"\n                 )\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15957",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex be0deb90b0..75763e07e8 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -2161,7 +2161,13 @@ class Prefetch:\n             )\n \n         self.queryset = queryset\n-        self.to_attr = to_attr\n+if queryset is not None and queryset.query.is_sliced:\n+    self.cache_slice = (queryset.query.low_mark, queryset.query.high_mark)\n+    queryset = queryset._clone()\n+    queryset.query.clear_limits()\n+else:\n+    self.cache_slice = None\n+\n \n     def __getstate__(self):\n         obj_dict = self.__dict__.copy()\n@@ -2498,7 +2504,10 @@ def prefetch_one_level(instances, prefetcher, lookup, level):\n \n     for obj in instances:\n         instance_attr_val = instance_attr(obj)\n-        vals = rel_obj_cache.get(instance_attr_val, [])\n+if hasattr(lookup, 'cache_slice') and lookup.cache_slice is not None:\n+    start, stop = lookup.cache_slice\n+    vals = vals[start:stop]\n+\n \n         if single:\n             val = vals[0] if vals else None\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15973",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-15987",
        "model_patch": "diff --git a/django/core/management/commands/loaddata.py b/django/core/management/commands/loaddata.py\nindex ac97f13161..108d045f2f 100644\n--- a/django/core/management/commands/loaddata.py\n+++ b/django/core/management/commands/loaddata.py\n@@ -360,27 +360,28 @@ class Command(BaseCommand):\n         application, if it exists, the directories in FIXTURE_DIRS, and the\n         current directory.\n         \"\"\"\n-        dirs = []\n-        fixture_dirs = settings.FIXTURE_DIRS\n-        if len(fixture_dirs) != len(set(fixture_dirs)):\n-            raise ImproperlyConfigured(\"settings.FIXTURE_DIRS contains duplicates.\")\n-        for app_config in apps.get_app_configs():\n-            app_label = app_config.label\n-            app_dir = os.path.join(app_config.path, \"fixtures\")\n-            if app_dir in fixture_dirs:\n-                raise ImproperlyConfigured(\n-                    \"'%s' is a default fixture directory for the '%s' app \"\n-                    \"and cannot be listed in settings.FIXTURE_DIRS.\"\n-                    % (app_dir, app_label)\n-                )\n-\n-            if self.app_label and app_label != self.app_label:\n-                continue\n-            if os.path.isdir(app_dir):\n-                dirs.append(app_dir)\n-        dirs.extend(fixture_dirs)\n-        dirs.append(\"\")\n-        return [os.path.realpath(d) for d in dirs]\n+dirs = []\n+fixture_dirs_raw = settings.FIXTURE_DIRS\n+# Normalize fixture directories to canonical real paths (as strings)\n+normalized_fixture_dirs = [os.path.realpath(str(d)) for d in fixture_dirs_raw]\n+if len(normalized_fixture_dirs) != len(set(normalized_fixture_dirs)):\n+    raise ImproperlyConfigured(\"settings.FIXTURE_DIRS contains duplicates.\")\n+for app_config in apps.get_app_configs():\n+    app_label = app_config.label\n+    app_dir = os.path.realpath(os.path.join(app_config.path, \"fixtures\"))\n+    if app_dir in normalized_fixture_dirs:\n+        raise ImproperlyConfigured(\n+            \"'%s' is a default fixture directory for the '%s' app \"\n+            \"and cannot be listed in settings.FIXTURE_DIRS.\"\n+            % (app_dir, app_label)\n+        )\n+    if self.app_label and app_label != self.app_label:\n+        continue\n+    if os.path.isdir(app_dir):\n+        dirs.append(app_dir)\n+dirs.extend(normalized_fixture_dirs)\n+dirs.append(\"\")\n+return [os.path.realpath(d) for d in dirs]\n \n     def parse_name(self, fixture_name):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16032",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex be0deb90b0..d8e72f6052 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -1609,6 +1609,48 @@ class QuerySet:\n         annotations.update(kwargs)\n \n         clone = self._chain()\n+f not select:\n+    clone._fields = None\n         names = self._fields\n         if names is None:\n             names = set(",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16082",
        "model_patch": "diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py\nindex 5e3c7cab82..1b0c88cc7a 100644\n--- a/django/db/models/expressions.py\n+++ b/django/db/models/expressions.py\n@@ -533,8 +533,10 @@ _connector_combinations = [\n             Combinable.SUB,\n             Combinable.MUL,\n             Combinable.DIV,\n+            Combinable.MOD,\n         )\n     },\n+\n     # Bitwise operators.\n     {\n         connector: [\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16100",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 5f07a4208a..8df5fd4d7e 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -1998,40 +1998,39 @@ class ModelAdmin(BaseModelAdmin):\n         # use the formset to validate/process POSTed data.\n         formset = cl.formset = None\n \n-        # Handle POSTed bulk-edit data.\n-        if request.method == \"POST\" and cl.list_editable and \"_save\" in request.POST:\n-            if not self.has_change_permission(request):\n-                raise PermissionDenied\n-            FormSet = self.get_changelist_formset(request)\n-            modified_objects = self._get_list_editable_queryset(\n-                request, FormSet.get_default_prefix()\n-            )\n-            formset = cl.formset = FormSet(\n-                request.POST, request.FILES, queryset=modified_objects\n-            )\n-            if formset.is_valid():\n-                changecount = 0\n-                for form in formset.forms:\n-                    if form.has_changed():\n-                        obj = self.save_form(request, form, change=True)\n-                        self.save_model(request, obj, form, change=True)\n-                        self.save_related(request, form, formsets=[], change=True)\n-                        change_msg = self.construct_change_message(request, form, None)\n-                        self.log_change(request, obj, change_msg)\n-                        changecount += 1\n-\n-                if changecount:\n-                    msg = ngettext(\n-                        \"%(count)s %(name)s was changed successfully.\",\n-                        \"%(count)s %(name)s were changed successfully.\",\n-                        changecount,\n-                    ) % {\n-                        \"count\": changecount,\n-                        \"name\": model_ngettext(self.opts, changecount),\n-                    }\n-                    self.message_user(request, msg, messages.SUCCESS)\n-\n-                return HttpResponseRedirect(request.get_full_path())\n+            # Handle POSTed bulk-edit data.\n+            if request.method == \"POST\" and cl.list_editable and \"_save\" in request.POST:\n+                if not self.has_change_permission(request):\n+                    raise PermissionDenied\n+                FormSet = self.get_changelist_formset(request)\n+                modified_objects = self._get_list_editable_queryset(\n+                    request, FormSet.get_default_prefix()\n+                )\n+                formset = cl.formset = FormSet(\n+                    request.POST, request.FILES, queryset=modified_objects\n+                )\n+                if formset.is_valid():\n+                    with transaction.atomic(using=router.db_for_write(self.model)):\n+                        changecount = 0\n+                        for form in formset.forms:\n+                            if form.has_changed():\n+                                obj = self.save_form(request, form, change=True)\n+                                self.save_model(request, obj, form, change=True)\n+                                self.save_related(request, form, formsets=[], change=True)\n+                                change_msg = self.construct_change_message(request, form, None)\n+                                self.log_change(request, obj, change_msg)\n+                                changecount += 1\n+                    if changecount:\n+                        msg = ngettext(\n+                            \"%(count)s %(name)s was changed successfully.\",\n+                            \"%(count)s %(name)s were changed successfully.\",\n+                            changecount,\n+                        ) % {\n+                            \"count\": changecount,\n+                            \"name\": model_ngettext(self.opts, changecount),\n+                        }\n+                        self.message_user(request, msg, messages.SUCCESS)\n+                    return HttpResponseRedirect(request.get_full_path())\n \n         # Handle GET -- construct a formset for display.\n         elif cl.list_editable and self.has_change_permission(request):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16116",
        "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 2e97d9064b..3f8455e3d6 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -247,13 +247,13 @@ class Command(BaseCommand):\n                         )\n                 else:\n                     self.log(\"No changes detected\")\n-        else:\n-            if self.update:\n-                self.write_to_last_migration_files(changes)\n             else:\n-                self.write_migration_files(changes)\n-            if check_changes:\n-                sys.exit(1)\n+                if check_changes:\n+                    sys.exit(1)\n+                if self.update:\n+                    self.write_to_last_migration_files(changes)\n+                else:\n+                    self.write_migration_files(changes)\n \n     def write_to_last_migration_files(self, changes):\n         loader = MigrationLoader(connections[DEFAULT_DB_ALIAS])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16136",
        "model_patch": "diff --git a/django/views/generic/base.py b/django/views/generic/base.py\nindex db1842e3e5..5be93b6473 100644\n--- a/django/views/generic/base.py\n+++ b/django/views/generic/base.py\n@@ -141,14 +141,20 @@ class View:\n             handler = self.http_method_not_allowed\n         return handler(request, *args, **kwargs)\n \n-    def http_method_not_allowed(self, request, *args, **kwargs):\n-        logger.warning(\n-            \"Method Not Allowed (%s): %s\",\n-            request.method,\n-            request.path,\n-            extra={\"status_code\": 405, \"request\": request},\n-        )\n-        return HttpResponseNotAllowed(self._allowed_methods())\n+def http_method_not_allowed(self, request, *args, **kwargs):\n+    logger.warning(\n+        \"Method Not Allowed (%s): %s\",\n+        request.method,\n+        request.path,\n+        extra={\"status_code\": 405, \"request\": request},\n+    )\n+    response = HttpResponseNotAllowed(self._allowed_methods())\n+    if self.view_is_async:\n+        async def wrapped_response():\n+            return response\n+        return wrapped_response()\n+    return response\n+\n \n     def options(self, request, *args, **kwargs):\n         \"\"\"Handle responding to requests for the OPTIONS HTTP verb.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16139",
        "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex b3cfc6723c..e3150359c7 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -163,7 +163,8 @@ class UserChangeForm(forms.ModelForm):\n         super().__init__(*args, **kwargs)\n         password = self.fields.get(\"password\")\n         if password:\n-            password.help_text = password.help_text.format(\"../password/\")\n+            password.help_text = password.help_text.format(f\"../../{self.instance.pk}/password/\")\n+\n         user_permissions = self.fields.get(\"user_permissions\")\n         if user_permissions:\n             user_permissions.queryset = user_permissions.queryset.select_related(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16145",
        "model_patch": "diff --git a/django/core/management/commands/runserver.py b/django/core/management/commands/runserver.py\nindex 3c39f57e4d..7273d913da 100644\n--- a/django/core/management/commands/runserver.py\n+++ b/django/core/management/commands/runserver.py\n@@ -96,6 +96,166 @@ class Command(BaseCommand):\n                     \"or address:port pair.\" % options[\"addrport\"]\n                 )\n             self.addr, _ipv4, _ipv6, _fqdn, self.port = m.groups()\n+           # Fix: Convert \"0\" to \"0.0.0.0\" to align with documentation expectations.\n+            if self.addr == \"0\":\n+                self.addr = \"0.0.0.0\"\n             if not self.port.isdigit():\n                 raise CommandError(\"%r is not a valid port number.\" % self.port)\n             if self.addr:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16255",
        "model_patch": "diff --git a/django/contrib/sitemaps/__init__.py b/django/contrib/sitemaps/__init__.py\nindex 27756d9d96..80b2e559e3 100644\n--- a/django/contrib/sitemaps/__init__.py\n+++ b/django/contrib/sitemaps/__init__.py\n@@ -163,12 +163,14 @@ class Sitemap:\n         return self._urls(page, protocol, domain)\n \n     def get_latest_lastmod(self):\n-        if not hasattr(self, \"lastmod\"):\n-            return None\n         if callable(self.lastmod):\n             try:\n                 return max([self.lastmod(item) for item in self.items()])\n-            except TypeError:\n+            except (TypeError, ValueError):\n+                return None\n+        else:\n+            return self.lastmod\n+\n                 return None\n         else:\n             return self.lastmod\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16256",
        "model_patch": "diff --git a/django/db/models/fields/related_descriptors.py b/django/db/models/fields/related_descriptors.py\nindex c5d87f647a..2fc15da42a 100644\n--- a/django/db/models/fields/related_descriptors.py\n+++ b/django/db/models/fields/related_descriptors.py\n@@ -807,7 +807,18 @@ def create_reverse_many_to_one_manager(superclass, rel):\n             db = router.db_for_write(self.model, instance=self.instance)\n             return super(RelatedManager, self.db_manager(db)).update_or_create(**kwargs)\n \n-        update_or_create.alters_data = True\n+            async def acreate(self, **kwargs):\n+                return await sync_to_async(self.create)(**kwargs)\n+            acreate.alters_data = True\n+\n+            async def aget_or_create(self, **kwargs):\n+                return await sync_to_async(self.get_or_create)(**kwargs)\n+            aget_or_create.alters_data = True\n+\n+            async def aupdate_or_create(self, **kwargs):\n+                return await sync_to_async(self.update_or_create)(**kwargs)\n+            aupdate_or_create.alters_data = True\n+\n \n         # remove() and clear() are only provided if the ForeignKey can have a\n         # value of null.\n@@ -1204,7 +1215,18 @@ def create_forward_many_to_many_manager(superclass, rel, reverse):\n \n         get_or_create.alters_data = True\n \n-        def update_or_create(self, *, through_defaults=None, **kwargs):\n+            async def acreate(self, *, through_defaults=None, **kwargs):\n+                return await sync_to_async(self.create)(through_defaults=through_defaults, **kwargs)\n+            acreate.alters_data = True\n+\n+            async def aget_or_create(self, *, through_defaults=None, **kwargs):\n+                return await sync_to_async(self.get_or_create)(through_defaults=through_defaults, **kwargs)\n+            aget_or_create.alters_data = True\n+\n+            async def aupdate_or_create(self, *, through_defaults=None, **kwargs):\n+                return await sync_to_async(self.update_or_create)(through_defaults=through_defaults, **kwargs)\n+            aupdate_or_create.alters_data = True\n+\n             db = router.db_for_write(self.instance.__class__, instance=self.instance)\n             obj, created = super(\n                 ManyRelatedManager, self.db_manager(db)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16263",
        "model_patch": "diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py\nindex 9735ce10c8..33d7294711 100644\n--- a/django/db/models/sql/query.py\n+++ b/django/db/models/sql/query.py\n@@ -549,15 +549,19 @@ class Query(BaseExpression):\n         \"\"\"\n         Perform a COUNT() query using the current filter constraints.\n         \"\"\"\n-        obj = self.clone()\n-        obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n-        return obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n-\n-    def has_filters(self):\n-        return self.where\n+    obj = self.clone()\n+    # Strip unused annotations and extra SELECT parts from the query,\n+    # since they have no effect on the simple COUNT(*) aggregate.\n+    obj.annotations = {}\n+    obj.extra = {}\n+    obj.select = ()\n+    obj.default_cols = False\n+    obj.order_by = ()\n+    obj.low_mark = 0\n+    obj.high_mark = None\n+    obj.add_annotation(Count(\"*\"), alias=\"__count\", is_summary=True)\n+    return obj.get_aggregation(using, [\"__count\"])[\"__count\"]\n \n-    def exists(self, limit=True):\n-        q = self.clone()\n         if not (q.distinct and q.is_sliced):\n             if q.group_by is True:\n                 q.add_fields(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16315",
        "model_patch": "diff --git a/django/db/models/query.py b/django/db/models/query.py\nindex be8580f2c4..5e5b1bca3c 100644\n--- a/django/db/models/query.py\n+++ b/django/db/models/query.py\n@@ -783,11 +783,12 @@ class QuerySet(AltersData):\n         if not objs:\n             return objs\n         opts = self.model._meta\n-        if unique_fields:\n-            # Primary key is allowed in unique_fields.\n-            unique_fields = [\n-                opts.pk.name if name == \"pk\" else name for name in unique_fields\n-            ]\n+if unique_fields:\n+    # Primary key is allowed in unique_fields.\n+    unique_fields = [\n+        opts.pk.name if name == \"pk\" else name for name in unique_fields\n+    ]\n+\n         on_conflict = self._check_bulk_create_options(\n             ignore_conflicts,\n             update_conflicts,\ndiff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py\nindex 0562a71dd1..b44e7d16c6 100644\n--- a/django/db/models/sql/compiler.py\n+++ b/django/db/models/sql/compiler.py\n@@ -1722,12 +1722,21 @@ class SQLInsertCompiler(SQLCompiler):\n \n         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)\n \n-        on_conflict_suffix_sql = self.connection.ops.on_conflict_suffix_sql(\n-            fields,\n-            self.query.on_conflict,\n-            self.query.update_fields,\n-            self.query.unique_fields,\n-        )\n+if self.query.update_fields:\n+    upd_fields = [self.model._meta.get_field(name).column for name in [f.name for f in self.query.update_fields]]\n+else:\n+    upd_fields = None\n+if self.query.unique_fields:\n+    uniq_fields = [self.model._meta.get_field(name).column for name in [f.name for f in self.query.unique_fields]]\n+else:\n+    uniq_fields = None\n+on_conflict_suffix_sql = self.connection.ops.on_conflict_suffix_sql(\n+    fields,\n+    self.query.on_conflict,\n+    upd_fields,\n+    uniq_fields,\n+)\n+\n         if (\n             self.returning_fields\n             and self.connection.features.can_return_columns_from_insert\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16333",
        "model_patch": "diff --git a/django/contrib/auth/forms.py b/django/contrib/auth/forms.py\nindex d73d1c8495..21ae055388 100644\n--- a/django/contrib/auth/forms.py\n+++ b/django/contrib/auth/forms.py\n@@ -136,12 +136,14 @@ class UserCreationForm(forms.ModelForm):\n             except ValidationError as error:\n                 self.add_error(\"password2\", error)\n \n-    def save(self, commit=True):\n-        user = super().save(commit=False)\n-        user.set_password(self.cleaned_data[\"password1\"])\n-        if commit:\n-            user.save()\n-        return user\n+def save(self, commit=True):\n+    user = super().save(commit=False)\n+    user.set_password(self.cleaned_data[\"password1\"])\n+    if commit:\n+        user.save()\n+        self.save_m2m()\n+    return user\n+\n \n \n class UserChangeForm(forms.ModelForm):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16429",
        "model_patch": "diff --git a/django/utils/timesince.py b/django/utils/timesince.py\nindex 701c49bab9..78f20aa6c5 100644\n--- a/django/utils/timesince.py\n+++ b/django/utils/timesince.py\n@@ -90,14 +90,16 @@ def timesince(d, now=None, reversed=False, time_strings=None, depth=2):\n         if pivot_month > 12:\n             pivot_month -= 12\n             pivot_year += 1\n-        pivot = datetime.datetime(\n-            pivot_year,\n-            pivot_month,\n-            min(MONTHS_DAYS[pivot_month - 1], d.day),\n-            d.hour,\n-            d.minute,\n-            d.second,\n-        )\n+pivot = datetime.datetime(\n+    pivot_year,\n+    pivot_month,\n+    min(MONTHS_DAYS[pivot_month - 1], d.day),\n+    d.hour,\n+    d.minute,\n+    d.second,\n+    tzinfo=d.tzinfo\n+)\n+\n     else:\n         pivot = d\n     remaining_time = (now - pivot).total_seconds()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16454",
        "model_patch": "diff --git a/django/core/management/base.py b/django/core/management/base.py\nindex abc6f79a15..7c9f0ee455 100644\n--- a/django/core/management/base.py\n+++ b/django/core/management/base.py\n@@ -70,6 +70,693 @@ class CommandParser(ArgumentParser):\n             super().error(message)\n         else:\n             raise CommandError(\"Error: %s\" % message)\n+   def add_subparsers(self, **kwargs):\n+        # Ensure that subparsers retain custom error formatting settings.\n+        kwargs.setdefault('parser_class', self.__class__)\n+        subparsers_action = super().add_subparsers(**kwargs)\n+        old_add_parser = subparsers_action.add_parser\n+        def custom_add_parser(name, **parser_kwargs):\n+            parser_kwargs.setdefault('missing_args_message', self.missing_args_message)\n+            parser_kwargs.setdefault('called_from_command_line', self.called_from_command_line)\n+            return old_add_parser(name, **parser_kwargs)\n+        subparsers_action.add_parser = custom_add_parser\n+        return subparsers_action\n def handle_default_options(options):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16485",
        "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 23c3a08c67..4ee4679140 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -192,7 +192,9 @@ def floatformat(text, arg=-1):\n     digits = [str(digit) for digit in reversed(digits)]\n     while len(digits) <= abs(exponent):\n         digits.append(\"0\")\n-    digits.insert(-exponent, \".\")\n+    if exponent < 0:\n+        digits.insert(-exponent, \".\")\n+\n     if sign and rounded_d:\n         digits.append(\"-\")\n     number = \"\".join(reversed(digits))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16493",
        "model_patch": "diff --git a/django/db/models/fields/files.py b/django/db/models/fields/files.py\nindex 7a99b12691..81e4b0d62e 100644\n--- a/django/db/models/fields/files.py\n+++ b/django/db/models/fields/files.py\n@@ -290,14 +290,17 @@ class FileField(Field):\n         else:\n             return []\n \n-    def deconstruct(self):\n-        name, path, args, kwargs = super().deconstruct()\n-        if kwargs.get(\"max_length\") == 100:\n-            del kwargs[\"max_length\"]\n-        kwargs[\"upload_to\"] = self.upload_to\n-        if self.storage is not default_storage:\n-            kwargs[\"storage\"] = getattr(self, \"_storage_callable\", self.storage)\n-        return name, path, args, kwargs\n+def deconstruct(self):\n+    name, path, args, kwargs = super().deconstruct()\n+    if kwargs.get(\"max_length\") == 100:\n+        del kwargs[\"max_length\"]\n+    kwargs[\"upload_to\"] = self.upload_to\n+    if hasattr(self, \"_storage_callable\"):\n+        kwargs[\"storage\"] = self._storage_callable\n+    elif self.storage is not default_storage:\n+        kwargs[\"storage\"] = self.storage\n+    return name, path, args, kwargs\n+\n \n     def get_internal_type(self):\n         return \"FileField\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16502",
        "model_patch": "diff --git a/django/core/servers/basehttp.py b/django/core/servers/basehttp.py\nindex fef5532e58..98e188e7e4 100644\n--- a/django/core/servers/basehttp.py\n+++ b/django/core/servers/basehttp.py\n@@ -143,11 +143,25 @@ class ServerHandler(simple_server.ServerHandler):\n         if self.headers.get(\"Connection\") == \"close\":\n             self.request_handler.close_connection = True\n \n+    def run(self, application):\n+        # Call the WSGI application to get the response iterable.\n+        self.result = application(self.environ, self.start_response)\n+        try:\n+            # Only write out the response body if the request method is not HEAD.\n+            if self.environ.get(\"REQUEST_METHOD\", \"\").upper() != \"HEAD\":\n+                for data in self.result:\n+                    self.write(data)\n+        finally:\n+            if hasattr(self.result, \"close\"):\n+                self.result.close()\n+        self.finish_response()\n+\n     def close(self):\n         self.get_stdin().read()\n         super().close()\n \n \n+\n class WSGIRequestHandler(simple_server.WSGIRequestHandler):\n     protocol_version = \"HTTP/1.1\"\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16527",
        "model_patch": "diff --git a/django/contrib/admin/templatetags/admin_modify.py b/django/contrib/admin/templatetags/admin_modify.py\nindex 9df4b7aadb..ce78c12786 100644\n--- a/django/contrib/admin/templatetags/admin_modify.py\n+++ b/django/contrib/admin/templatetags/admin_modify.py\n@@ -99,10 +99,14 @@ def submit_row(context):\n                 and change\n                 and context.get(\"show_delete\", True)\n             ),\n-            \"show_save_as_new\": not is_popup\n-            and has_change_permission\n-            and change\n-            and save_as,\n+\"show_save_as_new\": (\n+    not is_popup\n+    and has_add_permission\n+    and has_change_permission\n+    and change\n+    and save_as\n+),\n+\n             \"show_save_and_add_another\": can_save_and_add_another,\n             \"show_save_and_continue\": can_save_and_continue,\n             \"show_save\": show_save and can_save,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16560",
        "model_patch": "diff --git a/django/db/models/constraints.py b/django/db/models/constraints.py\nindex 075ecee1be..deb66214e1 100644\n--- a/django/db/models/constraints.py\n+++ b/django/db/models/constraints.py\n@@ -17,34 +17,40 @@ __all__ = [\"BaseConstraint\", \"CheckConstraint\", \"Deferrable\", \"UniqueConstraint\"\n \n \n class BaseConstraint:\n-    default_violation_error_message = _(\"Constraint \u201c%(name)s\u201d is violated.\")\n-    violation_error_message = None\n+default_violation_error_message = _(\"Constraint \u201c%(name)s\u201d is violated.\")\n+violation_error_message = None\n+default_violation_error_code = None\n     # RemovedInDjango60Warning: When the deprecation ends, replace with:\n     # def __init__(self, *, name, violation_error_message=None):\n-    def __init__(self, *args, name=None, violation_error_message=None):\n-        # RemovedInDjango60Warning.\n-        if name is None and not args:\n-            raise TypeError(\n-                f\"{self.__class__.__name__}.__init__() missing 1 required keyword-only \"\n-                f\"argument: 'name'\"\n-            )\n-        self.name = name\n-        if violation_error_message is not None:\n-            self.violation_error_message = violation_error_message\n-        else:\n-            self.violation_error_message = self.default_violation_error_message\n-        # RemovedInDjango60Warning.\n-        if args:\n-            warnings.warn(\n-                f\"Passing positional arguments to {self.__class__.__name__} is \"\n-                f\"deprecated.\",\n-                RemovedInDjango60Warning,\n-                stacklevel=2,\n-            )\n-            for arg, attr in zip(args, [\"name\", \"violation_error_message\"]):\n-                if arg:\n-                    setattr(self, attr, arg)\n+def __init__(self, *args, name=None, violation_error_message=None, violation_error_code=None):\n+    # RemovedInDjango60Warning: When the deprecation ends, replace with:\n+    # def __init__(self, *, name, violation_error_message=None, violation_error_code=None):\n+    if name is None and not args:\n+        raise TypeError(\n+            f\"{self.__class__.__name__}.__init__() missing 1 required keyword-only \"\n+            f\"argument: 'name'\"\n+        )\n+    self.name = name\n+    if violation_error_message is not None:\n+        self.violation_error_message = violation_error_message\n+    else:\n+        self.violation_error_message = self.default_violation_error_message\n+    self.violation_error_code = (\n+        violation_error_code if violation_error_code is not None else self.default_violation_error_code\n+    )\n+    if args:\n+        warnings.warn(\n+            f\"Passing positional arguments to {self.__class__.__name__} is \"\n+            f\"deprecated.\",\n+            RemovedInDjango60Warning,\n+            stacklevel=2,\n+        )\n+        for arg, attr in zip(args, [\"name\", \"violation_error_message\"]):\n+            if arg:\n+                setattr(self, attr, arg)\n     @property\n     def contains_expressions(self):\n@@ -63,18 +69,96 @@ class BaseConstraint:\n         raise NotImplementedError(\"This method must be implemented by a subclass.\")\n \n     def get_violation_error_message(self):\n+ef get_violation_error_code(self):\n+    return self.violation_error_code\n         return self.violation_error_message % {\"name\": self.name}\n \n-    def deconstruct(self):\n-        path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)\n-        path = path.replace(\"django.db.models.constraints\", \"django.db.models\")\n-        kwargs = {\"name\": self.name}\n-        if (\n-            self.violation_error_message is not None\n-            and self.violation_error_message != self.default_violation_error_message\n-        ):\n-            kwargs[\"violation_error_message\"] = self.violation_error_message\n-        return (path, (), kwargs)\n+def deconstruct(self):\n+    path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__name__)\n+    path = path.replace(\"django.db.models.constraints\", \"django.db.models\")\n+    kwargs = {\"name\": self.name}\n+    if (\n+        self.violation_error_message is not None\n+        and self.violation_error_message != self.default_violation_error_message\n+    ):\n+        kwargs[\"violation_error_message\"] = self.violation_error_message\n+    if self.violation_error_code is not None and self.violation_error_code != self.default_violation_error_code:\n+        kwargs[\"violation_error_code\"] = self.violation_error_code\n+    return (path, (), kwargs)\n     def clone(self):\n         _, args, kwargs = self.deconstruct()\n@@ -108,13 +192,16 @@ class CheckConstraint(BaseConstraint):\n     def remove_sql(self, model, schema_editor):\n         return schema_editor._delete_check_sql(model, self.name)\n \n-    def validate(self, model, instance, exclude=None, using=DEFAULT_DB_ALIAS):\n-        against = instance._get_field_value_map(meta=model._meta, exclude=exclude)\n-        try:\n-            if not Q(self.check).check(against, using=using):\n-                raise ValidationError(self.get_violation_error_message())\n-        except FieldError:\n-            pass\n+def validate(self, model, instance, exclude=None, using=DEFAULT_DB_ALIAS):\n+    against = instance._get_field_value_map(meta=model._meta, exclude=exclude)\n+    try:\n+        if not Q(self.check).check(against, using=using):\n+            raise ValidationError(\n+                self.get_violation_error_message(), code=self.get_violation_error_code()\n+            )\n+    except FieldError:\n+        pass\n     def __repr__(self):\n         return \"<%s: check=%s name=%s%s>\" % (\n@@ -338,68 +425,74 @@ class UniqueConstraint(BaseConstraint):\n             kwargs[\"opclasses\"] = self.opclasses\n         return path, self.expressions, kwargs\n \n-    def validate(self, model, instance, exclude=None, using=DEFAULT_DB_ALIAS):\n-        queryset = model._default_manager.using(using)\n-        if self.fields:\n-            lookup_kwargs = {}\n-            for field_name in self.fields:\n-                if exclude and field_name in exclude:\n-                    return\n-                field = model._meta.get_field(field_name)\n-                lookup_value = getattr(instance, field.attname)\n-                if lookup_value is None or (\n-                    lookup_value == \"\"\n-                    and connections[using].features.interprets_empty_strings_as_nulls\n-                ):\n-                    # A composite constraint containing NULL value cannot cause\n-                    # a violation since NULL != NULL in SQL.\n+def validate(self, model, instance, exclude=None, using=DEFAULT_DB_ALIAS):\n+    queryset = model._default_manager.using(using)\n+    if self.fields:\n+        lookup_kwargs = {}\n+        for field_name in self.fields:\n+            if exclude and field_name in exclude:\n+                return\n+            field = model._meta.get_field(field_name)\n+            lookup_value = getattr(instance, field.attname)\n+            if lookup_value is None or (\n+                lookup_value == \"\"\n+                and connections[using].features.interprets_empty_strings_as_nulls\n+            ):\n+                # A composite constraint containing NULL value cannot cause\n+                # a violation since NULL != NULL in SQL.\n+                return\n+            lookup_kwargs[field.name] = lookup_value\n+        queryset = queryset.filter(**lookup_kwargs)\n+    else:\n+        # Ignore constraints with excluded fields.\n+        if exclude:\n+            for expression in self.expressions:\n+                if hasattr(expression, \"flatten\"):\n+                    for expr in expression.flatten():\n+                        if isinstance(expr, F) and expr.name in exclude:\n+                            return\n+                elif isinstance(expression, F) and expression.name in exclude:\n                     return\n-                lookup_kwargs[field.name] = lookup_value\n-            queryset = queryset.filter(**lookup_kwargs)\n-        else:\n-            # Ignore constraints with excluded fields.\n-            if exclude:\n-                for expression in self.expressions:\n-                    if hasattr(expression, \"flatten\"):\n-                        for expr in expression.flatten():\n-                            if isinstance(expr, F) and expr.name in exclude:\n-                                return\n-                    elif isinstance(expression, F) and expression.name in exclude:\n-                        return\n-            replacements = {\n-                F(field): value\n-                for field, value in instance._get_field_value_map(\n-                    meta=model._meta, exclude=exclude\n-                ).items()\n-            }\n-            expressions = []\n-            for expr in self.expressions:\n-                # Ignore ordering.\n-                if isinstance(expr, OrderBy):\n-                    expr = expr.expression\n-                expressions.append(Exact(expr, expr.replace_expressions(replacements)))\n-            queryset = queryset.filter(*expressions)\n-        model_class_pk = instance._get_pk_val(model._meta)\n-        if not instance._state.adding and model_class_pk is not None:\n-            queryset = queryset.exclude(pk=model_class_pk)\n-        if not self.condition:\n-            if queryset.exists():\n-                if self.expressions:\n-                    raise ValidationError(self.get_violation_error_message())\n-                # When fields are defined, use the unique_error_message() for\n-                # backward compatibility.\n-                for model, constraints in instance.get_constraints():\n-                    for constraint in constraints:\n-                        if constraint is self:\n-                            raise ValidationError(\n-                                instance.unique_error_message(model, self.fields)\n-                            )\n-        else:\n-            against = instance._get_field_value_map(meta=model._meta, exclude=exclude)\n-            try:\n-                if (self.condition & Exists(queryset.filter(self.condition))).check(\n-                    against, using=using\n-                ):\n-                    raise ValidationError(self.get_violation_error_message())\n-            except FieldError:\n-                pass\n+        replacements = {\n+            F(field): value\n+            for field, value in instance._get_field_value_map(\n+                meta=model._meta, exclude=exclude\n+            ).items()\n+        }\n+        expressions = []\n+        for expr in self.expressions:\n+            # Ignore ordering.\n+            if isinstance(expr, OrderBy):\n+                expr = expr.expression\n+            expressions.append(Exact(expr, expr.replace_expressions(replacements)))\n+        queryset = queryset.filter(*expressions)\n+    model_class_pk = instance._get_pk_val(model._meta)\n+    if not instance._state.adding and model_class_pk is not None:\n+        queryset = queryset.exclude(pk=model_class_pk)\n+    if not self.condition:\n+        if queryset.exists():\n+            if self.expressions:\n+                raise ValidationError(\n+                    self.get_violation_error_message(), code=self.get_violation_error_code()\n+                )\n+            # When fields are defined, use the unique_error_message() for\n+            # backward compatibility.\n+            for model, constraints in instance.get_constraints():\n+                for constraint in constraints:\n+                    if constraint is self:\n+                        raise ValidationError(\n+                            instance.unique_error_message(model, self.fields),\n+                            code=self.get_violation_error_code(),\n+                        )\n+    else:\n+        against = instance._get_field_value_map(meta=model._meta, exclude=exclude)\n+        try:\n+            if (self.condition & Exists(queryset.filter(self.condition))).check(\n+                against, using=using\n+            ):\n+                raise ValidationError(\n+                    self.get_violation_error_message(), code=self.get_violation_error_code()\n+                )\n+        except FieldError:\n+            pass",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16569",
        "model_patch": "diff --git a/django/forms/formsets.py b/django/forms/formsets.py\nindex 235aaf844c..5deb7958d3 100644\n--- a/django/forms/formsets.py\n+++ b/django/forms/formsets.py\n@@ -490,12 +490,13 @@ class BaseFormSet(RenderableFormMixin):\n                     required=False,\n                     widget=self.get_ordering_widget(),\n                 )\n-        if self.can_delete and (self.can_delete_extra or index < initial_form_count):\n-            form.fields[DELETION_FIELD_NAME] = BooleanField(\n-                label=_(\"Delete\"),\n-                required=False,\n-                widget=self.get_deletion_widget(),\n-            )\n+if self.can_delete and (self.can_delete_extra or (index is not None and index < initial_form_count)):\n+    form.fields[DELETION_FIELD_NAME] = BooleanField(\n+        label=_(\"Delete\"),\n+        required=False,\n+        widget=self.get_deletion_widget(),\n+    )\n+\n \n     def add_prefix(self, index):\n         return \"%s-%s\" % (self.prefix, index)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16595",
        "model_patch": "diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py\nindex cd3aab43ad..22480de4ad 100644\n--- a/django/db/migrations/operations/fields.py\n+++ b/django/db/migrations/operations/fields.py\n@@ -247,9 +247,12 @@ class AlterField(FieldOperation):\n         return \"alter_%s_%s\" % (self.model_name_lower, self.name_lower)\n \n     def reduce(self, operation, app_label):\n-        if isinstance(operation, RemoveField) and self.is_same_field_operation(\n-            operation\n-        ):\n+        # if an AlterField for the same field is encountered,\n+        # simply reduce to the latter operation so that the most recent\n+        # change is preserved.\n+        if isinstance(operation, AlterField) and self.is_same_field_operation(operation):\n+            return [operation]\n+        if isinstance(operation, RemoveField) and self.is_same_field_operation(operation):\n             return [operation]\n         elif (\n             isinstance(operation, RenameField)\n@@ -267,6 +270,7 @@ class AlterField(FieldOperation):\n         return super().reduce(operation, app_label)\n \n \n+\n class RenameField(FieldOperation):\n     \"\"\"Rename a field on the model. Might affect db_column too.\"\"\"\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16612",
        "model_patch": "diff --git a/django/contrib/admin/sites.py b/django/contrib/admin/sites.py\nindex 61be31d890..0e1c6e592d 100644\n--- a/django/contrib/admin/sites.py\n+++ b/django/contrib/admin/sites.py\n@@ -453,7 +453,12 @@ class AdminSite:\n                 pass\n             else:\n                 if getattr(match.func, \"should_append_slash\", True):\n-                    return HttpResponsePermanentRedirect(\"%s/\" % request.path)\n+                    qs = request.META.get(\"QUERY_STRING\", \"\")\n+                    new_url = \"%s/\" % request.path\n+                    if qs:\n+                        new_url = \"%s?%s\" % (new_url, qs)\n+                    return HttpResponsePermanentRedirect(new_url)\n+\n         raise Http404\n \n     def _build_app_dict(self, request, label=None):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16631",
        "model_patch": "diff --git a/django/contrib/auth/base_user.py b/django/contrib/auth/base_user.py\nindex 5ee30bf59c..8bfed307b4 100644\n--- a/django/contrib/auth/base_user.py\n+++ b/django/contrib/auth/base_user.py\n@@ -133,15 +133,23 @@ class AbstractBaseUser(models.Model):\n \n     def get_session_auth_hash(self):\n         \"\"\"\n-        Return an HMAC of the password field.\n+        Return an HMAC of the password field using the fallback secret key if available.\n+\n+        When rotating the SECRET_KEY, set the new key in settings.SECRET_KEY and move the old key\n+        to the beginning of settings.SECRET_KEY_FALLBACKS. This allows sessions created with the old\n+        key to continue to be valid until the fallback is removed.\n         \"\"\"\n+        from django.conf import settings\n         key_salt = \"django.contrib.auth.models.AbstractBaseUser.get_session_auth_hash\"\n+        secret = settings.SECRET_KEY_FALLBACKS[0] if getattr(settings, \"SECRET_KEY_FALLBACKS\", []) else settings.SECRET_KEY\n         return salted_hmac(\n             key_salt,\n             self.password,\n+            secret=secret,\n             algorithm=\"sha256\",\n         ).hexdigest()\n \n+\n     @classmethod\n     def get_email_field_name(cls):\n         try:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16642",
        "model_patch": "diff --git a/django/http/response.py b/django/http/response.py\nindex f62dec8ce9..19f4173fc0 100644\n--- a/django/http/response.py\n+++ b/django/http/response.py\n@@ -607,12 +607,15 @@ class FileResponse(StreamingHttpResponse):\n             if filename:\n                 content_type, encoding = mimetypes.guess_type(filename)\n                 # Encoding isn't set to prevent browsers from automatically\n-                # uncompressing files.\n+                # uncompressing files. Map compression encodings to appropriate MIME types.\n                 content_type = {\n                     \"bzip2\": \"application/x-bzip\",\n                     \"gzip\": \"application/gzip\",\n                     \"xz\": \"application/x-xz\",\n+                    \"br\": \"application/brotli\",\n+                    \"Z\": \"application/x-compress\",\n                 }.get(encoding, content_type)\n+\n                 self.headers[\"Content-Type\"] = (\n                     content_type or \"application/octet-stream\"\n                 )\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16661",
        "model_patch": "diff --git a/django/contrib/admin/options.py b/django/contrib/admin/options.py\nindex 5240b07cd6..16d3685103 100644\n--- a/django/contrib/admin/options.py\n+++ b/django/contrib/admin/options.py\n@@ -461,10 +461,10 @@ class BaseModelAdmin(metaclass=forms.MediaDefiningClass):\n                 # Lookups on nonexistent fields are ok, since they're ignored\n                 # later.\n                 break\n-            # It is allowed to filter on values that would be found from local\n-            # model anyways. For example, if you filter on employee__department__id,\n-            # then the id value would be found already from employee__department_id.\n-            if not prev_field or (\n+    if not prev_field or (\n+        prev_field.is_relation and (field.primary_key or field not in prev_field.path_infos[-1].target_fields)\n+    ):\n+\n                 prev_field.is_relation\n                 and field not in prev_field.path_infos[-1].target_fields\n             ):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16662",
        "model_patch": "diff --git a/django/db/migrations/writer.py b/django/db/migrations/writer.py\nindex a59f0c8dcb..8f9e9de170 100644\n--- a/django/db/migrations/writer.py\n+++ b/django/db/migrations/writer.py\n@@ -173,8 +173,10 @@ class MigrationWriter:\n         else:\n             imports.add(\"from django.db import migrations\")\n \n-        # Sort imports by the package / module to be imported (the part after\n-        # \"from\" in \"from ... import ...\" or after \"import\" in \"import ...\").\n+        sorted_imports = sorted(imports, key=lambda i: (0 if i.startswith(\"import \") else 1, i.split()[1]))\n+\n+\t        sorted_imports = sorted(imports, key=lambda i: (0 if i.startswith(\"import \") else 1, i.split()[1]))\n+\n         sorted_imports = sorted(imports, key=lambda i: i.split()[1])\n         items[\"imports\"] = \"\\n\".join(sorted_imports) + \"\\n\" if imports else \"\"\n         if migration_imports:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16667",
        "model_patch": "diff --git a/django/forms/widgets.py b/django/forms/widgets.py\nindex 842b73e95c..dfafbea246 100644\n--- a/django/forms/widgets.py\n+++ b/django/forms/widgets.py\n@@ -1157,7 +1157,8 @@ class SelectDateWidget(Widget):\n             input_format = formats.sanitize_strftime_format(input_format)\n             try:\n                 date_value = datetime.date(int(y), int(m), int(d))\n-            except ValueError:\n+            except (ValueError, OverflowError):\n+\n                 # Return pseudo-ISO dates with zeros for any unselected values,\n                 # e.g. '2017-0-23'.\n                 return \"%s-%s-%s\" % (y or 0, m or 0, d or 0)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16801",
        "model_patch": "diff --git a/django/db/models/fields/files.py b/django/db/models/fields/files.py\nindex 7f8eb128e1..4ae4680814 100644\n--- a/django/db/models/fields/files.py\n+++ b/django/db/models/fields/files.py\n@@ -441,8 +441,9 @@ class ImageField(FileField):\n         # after their corresponding image field don't stay cleared by\n         # Model.__init__, see bug #11196.\n         # Only run post-initialization dimension update on non-abstract models\n-        if not cls._meta.abstract:\n-            signals.post_init.connect(self.update_dimension_fields, sender=cls)\n+if not cls._meta.abstract and (self.width_field or self.height_field):\n+    signals.post_init.connect(self.update_dimension_fields, sender=cls)\n+\n \n     def update_dimension_fields(self, instance, force=False, *args, **kwargs):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16819",
        "model_patch": "diff --git a/django/db/migrations/operations/models.py b/django/db/migrations/operations/models.py\nindex 967a91fdc8..e5236fe2ea 100644\n--- a/django/db/migrations/operations/models.py\n+++ b/django/db/migrations/operations/models.py\n@@ -856,6 +856,309 @@ class AddIndex(IndexOperation):\n             \", \".join(self.index.fields),\n             self.model_name,\n         )\n+ef reduce(self, operation, app_label):\n+    if (\n+        isinstance(operation, RemoveIndex)\n+        and self.model_name.lower() == operation.model_name.lower()\n+        and self.index.name.lower() == operation.name.lower()\n+    ):\n+        return []\n+    return super().reduce(operation, app_label)\n     @property\n     def migration_name_fragment(self):\n@@ -900,6 +1203,306 @@ class RemoveIndex(IndexOperation):\n     def describe(self):\n         return \"Remove index %s from %s\" % (self.name, self.model_name)\n \n+def reduce(self, operation, app_label):\n+    if (\n+        isinstance(operation, AddIndex)\n+        and self.model_name.lower() == operation.model_name.lower()\n+        and self.name.lower() == operation.index.name.lower()\n+    ):\n+        return []\n+    return super().reduce(operation, app_label)\n     @property\n     def migration_name_fragment(self):\n         return \"remove_%s_%s\" % (self.model_name_lower, self.name.lower())",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16877",
        "model_patch": "diff --git a/django/template/defaultfilters.py b/django/template/defaultfilters.py\nindex 5289ef34a0..7846942507 100644\n--- a/django/template/defaultfilters.py\n+++ b/django/template/defaultfilters.py\n@@ -447,6 +447,940 @@ def escape_filter(value):\n @register.filter(is_safe=True)\n @stringfilter\n def force_escape(value):\n+register.filter(needs_autoescape=True, is_safe=True)\n+def escapeseq(value, autoescape=True):\n+    \"\"\"\n+    Escapes each element in a sequence. If the value is not an iterable\n+    (or is a string), escape the value itself.\n+    Usage:\n+        {{ some_list|escapeseq|join:\",\" }}\n+    \"\"\"\n+    from django.utils.html import conditional_escape\n+    # If the value is a string, treat it as a scalar\n+    if isinstance(value, str):\n+        return conditional_escape(value) if autoescape else value\n+    try:\n+        # Attempt to get an iterator; this may succeed for strings as well.\n+        iter(value)\n+    except TypeError:\n+        # Not iterable, escape directly.\n+        return conditional_escape(value) if autoescape else value\n+    else:\n+        # Process each item in the iterable. If autoescape is off, return the item unchanged.\n+        return [conditional_escape(item) if autoescape else item for item in value]\n     \"\"\"\n     Escape a string's HTML. Return a new string containing the escaped\n     characters (as opposed to \"escape\", which marks the content for later",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16899",
        "model_patch": "diff --git a/django/contrib/admin/checks.py b/django/contrib/admin/checks.py\nindex c395b0bde2..a2ac177ff5 100644\n--- a/django/contrib/admin/checks.py\n+++ b/django/contrib/admin/checks.py\n@@ -771,13 +771,8 @@ class BaseModelAdminChecks:\n             except FieldDoesNotExist:\n                 return [\n                     checks.Error(\n-                        \"The value of '%s' is not a callable, an attribute of \"\n-                        \"'%s', or an attribute of '%s'.\"\n-                        % (\n-                            label,\n-                            obj.__class__.__name__,\n-                            obj.model._meta.label,\n-                        ),\n+                        \"The value of '%s' (i.e. '%s') is not a callable, an attribute of '%s', or an attribute of '%s'.\"\n+                        % (label, field_name, obj.__class__.__name__, obj.model._meta.label),\n                         obj=obj.__class__,\n                         id=\"admin.E035\",\n                     )\n@@ -785,6 +780,8 @@ class BaseModelAdminChecks:\n             else:\n                 return []\n \n+                return []\n+\n \n class ModelAdminChecks(BaseModelAdminChecks):\n     def check(self, admin_obj, **kwargs):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16901",
        "model_patch": "diff --git a/django/db/models/query_utils.py b/django/db/models/query_utils.py\nindex 78148f76b0..b844cc1c6c 100644\n--- a/django/db/models/query_utils.py\n+++ b/django/db/models/query_utils.py\n@@ -79,11 +79,39 @@ class Q(tree.Node):\n         obj.negate()\n         return obj\n \n-    def resolve_expression(\n-        self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n-    ):\n-        # We must promote any new joins to left outer joins so that when Q is\n-        # used as an expression, rows aren't filtered due to joins.\n+def resolve_expression(\n+    self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False\n+):\n+    # Fallback handling of XOR: if the connector is XOR, build an expression that\n+    # sums the boolean conditions (converted to 1/0) and check parity (= odd).\n+    if self.connector == self.XOR:\n+        # Import required classes for expression wrapping.\n+        from django.db.models import Case, When, IntegerField, Value, BooleanField\n+        # Flatten the Q tree to get all child conditions.\n+        conditions = []\n+        for child in self.flatten():\n+            # For any child that can resolve an expression, do so.\n+            if hasattr(child, \"resolve_expression\"):\n+                expr = child.resolve_expression(\n+                    query, allow_joins=allow_joins, reuse=reuse, summarize=summarize\n+                )\n+            else:\n+                expr = child\n+            conditions.append(\n+                Case(\n+                    When(expr, then=Value(1)),\n+                    default=Value(0),\n+                    output_field=IntegerField(),\n+                )\n+            )\n+        # Sum all converted integer conditions.\n+        from functools import reduce\n+        import operator\n+        total = reduce(operator.add, conditions)\n+        # Build an expression requiring that sum modulo 2 equals 1.\n+        xor_expr = (total % Value(2)) == Value(1)\n+        return xor_expr\n+    else:\n         clause, joins = query._add_q(\n             self,\n             reuse,\n@@ -95,6 +123,7 @@ class Q(tree.Node):\n         query.promote_joins(joins)\n         return clause\n \n+\n     def flatten(self):\n         \"\"\"\n         Recursively yield this Q object and all subexpressions, in depth-first\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16938",
        "model_patch": "diff --git a/django/core/serializers/python.py b/django/core/serializers/python.py\nindex 36048601af..753ca30176 100644\n--- a/django/core/serializers/python.py\n+++ b/django/core/serializers/python.py\n@@ -78,8 +78,10 @@ class Serializer(base.Serializer):\n                 def m2m_value(value):\n                     return self._value_from_field(value, value._meta.pk)\n \n-                def queryset_iterator(obj, field):\n-                    return getattr(obj, field.name).only(\"pk\").iterator()\n+def queryset_iterator(obj, field):\n+    # Remove the .only(\"pk\") to avoid conflict with select_related() used in custom managers.\n+    return getattr(obj, field.name).iterator()\n+\n \n             m2m_iter = getattr(obj, \"_prefetched_objects_cache\", {}).get(\n                 field.name,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-16950",
        "model_patch": "diff --git a/django/forms/models.py b/django/forms/models.py\nindex 3fa04b821f..ace2219b9f 100644\n--- a/django/forms/models.py\n+++ b/django/forms/models.py\n@@ -54,13 +54,17 @@ def construct_instance(form, instance, fields=None, exclude=None):\n \n     cleaned_data = form.cleaned_data\n     file_field_list = []\n-    for f in opts.fields:\n-        if (\n-            not f.editable\n-            or isinstance(f, models.AutoField)\n-            or f.name not in cleaned_data\n-        ):\n-            continue\n+for f in opts.fields:\n+    # If the field is not editable or is an AutoField, then set its default value\n+    # if it has one and the current instance value is empty.\n+    if not f.editable or isinstance(f, models.AutoField):\n+        if f.has_default() and getattr(instance, f.attname) in form.fields[f.name].empty_values:\n+            setattr(instance, f.attname, f.get_default())\n+        continue\n+\n+    if f.name not in cleaned_data:\n+        continue\n+\n         if fields is not None and f.name not in fields:\n             continue\n         if exclude and f.name in exclude:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-17029",
        "model_patch": "diff --git a/django/apps/registry.py b/django/apps/registry.py\nindex 0683f3ad3c..75f85dc5de 100644\n--- a/django/apps/registry.py\n+++ b/django/apps/registry.py\n@@ -376,6 +376,62 @@ class Apps:\n         # Call expire cache on each model. This will purge\n         # the relation tree and the fields cache.\n         self.get_models.cache_clear()\n+       self.get_swappable_settings_name.cache_clear()\n         if self.ready:\n             # Circumvent self.get_models() to prevent that the cache is refilled.\n             # This particularly prevents that an empty value is cached while cloning.",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-17084",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-17087",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-7530",
        "model_patch": "diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py\nindex 0b39536f5b..8ae4f347aa 100644\n--- a/django/core/management/commands/makemigrations.py\n+++ b/django/core/management/commands/makemigrations.py\n@@ -96,18 +96,23 @@ class Command(BaseCommand):\n         loader = MigrationLoader(None, ignore_no_migrations=True)\n \n         # Raise an error if any migrations are applied before their dependencies.\n-        consistency_check_labels = set(config.label for config in apps.get_app_configs())\n-        # Non-default databases are only checked if database routers used.\n-        aliases_to_check = connections if settings.DATABASE_ROUTERS else [DEFAULT_DB_ALIAS]\n-        for alias in sorted(aliases_to_check):\n-            connection = connections[alias]\n-            if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(\n-                    # At least one model must be migrated to the database.\n-                    router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n-                    for app_label in consistency_check_labels\n-                    for model in apps.get_models(app_label)\n-            )):\n-                loader.check_consistent_history(connection)\n+# Raise an error if any migrations are applied before their dependencies.\n+# Non-default databases are only checked if database routers are used.\n+aliases_to_check = connections if settings.DATABASE_ROUTERS else [DEFAULT_DB_ALIAS]\n+for alias in sorted(aliases_to_check):\n+    connection = connections[alias]\n+    if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(\n+            # At least one model must be migrated to the database.\n+            router.allow_migrate(\n+                connection.alias,\n+                app_config.label,\n+                model_name=model._meta.model_name\n+            )\n+            for app_config in apps.get_app_configs()\n+            for model in app_config.get_models()\n+    )):\n+        loader.check_consistent_history(connection)\n+\n \n         # Before anything else, see if there's conflicting apps and drop out\n         # hard if there are any and they don't want to merge\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "django__django-9296",
        "model_patch": "diff --git a/django/core/paginator.py b/django/core/paginator.py\nindex 1f92da5d4f..907886948e 100644\n--- a/django/core/paginator.py\n+++ b/django/core/paginator.py\n@@ -105,6 +105,252 @@ class Paginator:\n         a template for loop.\n         \"\"\"\n         return range(1, self.num_pages + 1)\n+   def __iter__(self):\n+        \"\"\"\n+        Allow iteration over all pages by yielding Page objects for each\n+        page number in the page_range.\n+        \"\"\"\n+        for page_num in self.page_range:\n+            yield self.page(page_num)\n     def _check_object_list_is_ordered(self):\n         \"\"\"",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-13989",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex 4b73d52293..d16c165ac1 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -6377,6 +6377,29 @@ optional.\n         documentation of the *weights* parameter to draw a histogram of\n         already-binned data.\n \n+    bin_range = range\n         Multiple data can be provided via *x* as a list of datasets\n         of potentially different length ([*x0*, *x1*, ...]), or as\n         a 2-D ndarray in which each column is a dataset.  Note that",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-14623",
        "model_patch": "diff --git a/lib/matplotlib/scale.py b/lib/matplotlib/scale.py\nindex b482a664b7..91da9341c3 100644\n--- a/lib/matplotlib/scale.py\n+++ b/lib/matplotlib/scale.py\n@@ -420,13 +420,23 @@ class LogScale(ScaleBase):\n     def limit_range_for_scale(self, vmin, vmax, minpos):\n         \"\"\"\n         Limit the domain to positive values.\n+        \n+        If the user has supplied inverted (i.e. reversed) limits (vmin > vmax)\n+        then preserve that order (after ensuring that both are positive) so that\n+        an axis can be inverted by passing reversed limits.\n         \"\"\"\n         if not np.isfinite(minpos):\n             minpos = 1e-300  # This value should rarely if ever\n                              # end up with a visible effect.\n-\n-        return (minpos if vmin <= 0 else vmin,\n-                minpos if vmax <= 0 else vmax)\n+        if vmin > vmax:\n+            if vmin <= 0:\n+                vmin = minpos\n+            if vmax <= 0:\n+                vmax = minpos\n+            return (vmin, vmax)\n+        else:\n+            return (minpos if vmin <= 0 else vmin,\n+                    minpos if vmax <= 0 else vmax)\n \n \n class FuncScaleLog(LogScale):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-20488",
        "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex e0c42c5b69..1781072c3e 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1547,9 +1547,11 @@ class LogNorm(Normalize):\n         # docstring inherited.\n         super().autoscale(np.ma.masked_less_equal(A, 0, copy=False))\n \n-    def autoscale_None(self, A):\n-        # docstring inherited.\n-        super().autoscale_None(np.ma.masked_less_equal(A, 0, copy=False))\n+def autoscale_None(self, A):\n+    # docstring inherited.\n+    super().autoscale_None(np.ma.masked_less_equal(A, 0, copy=False))\n+    if self.vmin <= 0:\n+        self.vmin = np.finfo(float).tiny\n \n \n @_make_norm_from_scale(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-20676",
        "model_patch": "diff --git a/lib/matplotlib/widgets.py b/lib/matplotlib/widgets.py\nindex a199e45d40..93ce1c074f 100644\n--- a/lib/matplotlib/widgets.py\n+++ b/lib/matplotlib/widgets.py\n@@ -2128,26 +2128,41 @@ class SpanSelector(_SelectorWidget):\n \n     prev = _api.deprecate_privatize_attribute(\"3.5\")\n \n-    def new_axes(self, ax):\n-        \"\"\"Set SpanSelector to operate on a new Axes.\"\"\"\n-        self.ax = ax\n-        if self.canvas is not ax.figure.canvas:\n-            if self.canvas is not None:\n-                self.disconnect_events()\n-\n-            self.canvas = ax.figure.canvas\n-            self.connect_default_events()\n-\n-        if self.direction == 'horizontal':\n+def new_axes(self, ax):\n+    \"\"\"Set SpanSelector to operate on a new Axes.\"\"\"\n+    self.ax = ax\n+    if self.canvas is not ax.figure.canvas:\n+        if self.canvas is not None:\n+            self.disconnect_events()\n+        self.canvas = ax.figure.canvas\n+        self.connect_default_events()\n+    if self.direction == 'horizontal':\n+        if self._interactive:\n+            trans = ax.transData\n+            clip_on = True\n+        else:\n             trans = ax.get_xaxis_transform()\n-            w, h = 0, 1\n+            clip_on = False\n+        w, h = 0, 1\n+    else:\n+        if self._interactive:\n+            trans = ax.transData\n+            clip_on = True\n         else:\n             trans = ax.get_yaxis_transform()\n-            w, h = 1, 0\n-        self._rect = Rectangle((0, 0), w, h,\n-                               transform=trans,\n-                               visible=False,\n-                               **self._rectprops)\n+            clip_on = False\n+        w, h = 1, 0\n+    self._rect = Rectangle((0, 0), w, h,\n+                           transform=trans,\n+                           visible=False,\n+                           clip_on=clip_on,\n+                           **self._rectprops)\n+    self.ax.add_patch(self._rect)\n+    if len(self.artists) > 0:\n+        self.artists[0] = self._rect\n+    else:\n+        self.artists.append(self._rect)\n+\n \n         self.ax.add_patch(self._rect)\n         if len(self.artists) > 0:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-20826",
        "model_patch": "diff --git a/lib/matplotlib/axes/_subplots.py b/lib/matplotlib/axes/_subplots.py\nindex f92d08440e..910fbd4063 100644\n--- a/lib/matplotlib/axes/_subplots.py\n+++ b/lib/matplotlib/axes/_subplots.py\n@@ -156,6 +156,328 @@ class SubplotBase:\n         twin.set_adjustable('datalim')\n         self._twinned_axes.join(self, twin)\n         return twin\n+   def clear(self):\n+        \"\"\"\n+        Clear the axes and reapply outer label settings for shared axes.\n+        This ensures that after clear() the tick visibility remains consistent\n+        with the shared subplot layout.\n+        \"\"\"\n+        ret = super().clear()\n+        self.label_outer()\n+        return ret\n subplot_class_factory = cbook._make_class_factory(",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-20859",
        "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex 44ab024698..a3ca1883e9 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -360,7 +360,8 @@ class Legend(Artist):\n         \"\"\"\n         # local import only to avoid circularity\n         from matplotlib.axes import Axes\n-        from matplotlib.figure import Figure\n+from matplotlib.figure import Figure, FigureBase\n+\n \n         super().__init__()\n \n@@ -434,11 +435,12 @@ class Legend(Artist):\n             self.isaxes = True\n             self.axes = parent\n             self.set_figure(parent.figure)\n-        elif isinstance(parent, Figure):\n+        elif isinstance(parent, FigureBase):\n             self.isaxes = False\n             self.set_figure(parent)\n         else:\n             raise TypeError(\"Legend needs either Axes or Figure as parent\")\n+\n         self.parent = parent\n \n         self._loc_used_default = loc is None\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-21568",
        "model_patch": "diff --git a/lib/matplotlib/dates.py b/lib/matplotlib/dates.py\nindex 0766156d64..30284951b3 100644\n--- a/lib/matplotlib/dates.py\n+++ b/lib/matplotlib/dates.py\n@@ -592,13 +592,9 @@ def drange(dstart, dend, delta):\n \n \n def _wrap_in_tex(text):\n-    p = r'([a-zA-Z]+)'\n-    ret_text = re.sub(p, r'}$\\1$\\\\mathdefault{', text)\n+    # Simply wrap the text in \\mathdefault as in 3.3 to maintain consistent spacing.\n+    return \"$\\\\mathdefault{\" + text + \"}$\"\n \n-    # Braces ensure dashes are not spaced like binary operators.\n-    ret_text = '$\\\\mathdefault{'+ret_text.replace('-', '{-}')+'}$'\n-    ret_text = ret_text.replace('$\\\\mathdefault{}$', '')\n-    return ret_text\n \n \n ## date tickers and formatters ###\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-22719",
        "model_patch": "diff --git a/lib/matplotlib/category.py b/lib/matplotlib/category.py\nindex c823b68fd9..249ae9fb3d 100644\n--- a/lib/matplotlib/category.py\n+++ b/lib/matplotlib/category.py\n@@ -52,15 +52,18 @@ class StrCategoryConverter(units.ConversionInterface):\n                 'numeric data')\n         StrCategoryConverter._validate_unit(unit)\n         # dtype = object preserves numerical pass throughs\n-        values = np.atleast_1d(np.array(value, dtype=object))\n-        # pass through sequence of non binary numbers\n-        with _api.suppress_matplotlib_deprecation_warning():\n-            is_numlike = all(units.ConversionInterface.is_numlike(v)\n-                             and not isinstance(v, (str, bytes))\n-                             for v in values)\n-        if is_numlike:\n-            _api.warn_deprecated(\n-                \"3.5\", message=\"Support for passing numbers through unit \"\n+    # If the data is empty, simply return it to avoid spurious deprecation warnings.\n+    try:\n+         if hasattr(value, '__len__') and len(value) == 0:\n+              return value\n+    except TypeError:\n+         pass\n+\n+    if is_numlike:\n+         _api.warn_deprecated(\n+             \"3.5\", message=\"Support for passing numbers through unit converters is deprecated since 3.5 and support will be removed two minor releases later; use Axis.convert_units instead.\"\n+         )\n+\n                 \"converters is deprecated since %(since)s and support will be \"\n                 \"removed %(removal)s; use Axis.convert_units instead.\")\n             return np.asarray(values, dtype=float)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-22865",
        "model_patch": "diff --git a/lib/matplotlib/colorbar.py b/lib/matplotlib/colorbar.py\nindex c59b0ac815..444510c22b 100644\n--- a/lib/matplotlib/colorbar.py\n+++ b/lib/matplotlib/colorbar.py\n@@ -720,21 +720,23 @@ class Colorbar:\n                 xy = np.array([[0, 0], [0.5, bot], [1, 0]])\n             else:\n                 # rectangle\n-                xy = np.array([[0, 0], [0, bot], [1., bot], [1, 0]])\n+                xy = np.array([[0, 0], [0, bot], [1.0, bot], [1, 0]])\n             if self.orientation == 'horizontal':\n                 xy = xy[:, ::-1]\n-            # add the patch\n+            # add the patch (with proper edge) if drawedges is True\n             val = -1 if self._long_axis().get_inverted() else 0\n             color = self.cmap(self.norm(self._values[val]))\n+            edgecolor = mpl.rcParams['axes.edgecolor'] if self.drawedges else None\n+            lw = mpl.rcParams['axes.linewidth'] * 0.5 if self.drawedges else 0\n             patch = mpatches.PathPatch(\n-                mpath.Path(xy), facecolor=color, linewidth=0,\n+                mpath.Path(xy), facecolor=color,\n+                edgecolor=edgecolor, linewidth=lw,\n                 antialiased=False, transform=self.ax.transAxes,\n                 hatch=hatches[0], clip_on=False,\n-                # Place it right behind the standard patches, which is\n-                # needed if we updated the extends\n                 zorder=np.nextafter(self.ax.patch.zorder, -np.inf))\n             self.ax.add_patch(patch)\n             self._extend_patches.append(patch)\n+\n         if self._extend_upper():\n             if not self.extendrect:\n                 # triangle\n@@ -744,18 +746,20 @@ class Colorbar:\n                 xy = np.array([[0, 1], [0, top], [1, top], [1, 1]])\n             if self.orientation == 'horizontal':\n                 xy = xy[:, ::-1]\n-            # add the patch\n+            # add the patch (with proper edge) if drawedges is True\n             val = 0 if self._long_axis().get_inverted() else -1\n             color = self.cmap(self.norm(self._values[val]))\n+            edgecolor = mpl.rcParams['axes.edgecolor'] if self.drawedges else None\n+            lw = mpl.rcParams['axes.linewidth'] * 0.5 if self.drawedges else 0\n             patch = mpatches.PathPatch(\n                 mpath.Path(xy), facecolor=color,\n-                linewidth=0, antialiased=False,\n-                transform=self.ax.transAxes, hatch=hatches[-1], clip_on=False,\n-                # Place it right behind the standard patches, which is\n-                # needed if we updated the extends\n+                edgecolor=edgecolor, linewidth=lw,\n+                antialiased=False, transform=self.ax.transAxes,\n+                hatch=hatches[-1], clip_on=False,\n                 zorder=np.nextafter(self.ax.patch.zorder, -np.inf))\n             self.ax.add_patch(patch)\n             self._extend_patches.append(patch)\n+\n         return\n \n     def add_lines(self, *args, **kwargs):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-22871",
        "model_patch": "diff --git a/lib/matplotlib/dates.py b/lib/matplotlib/dates.py\nindex 4d8ddf3ee5..d185d1840b 100644\n--- a/lib/matplotlib/dates.py\n+++ b/lib/matplotlib/dates.py\n@@ -770,9 +770,14 @@ class ConciseDateFormatter(ticker.Formatter):\n                         mpl.rcParams['text.usetex'])\n \n     def __call__(self, x, pos=None):\n-        formatter = DateFormatter(self.defaultfmt, self._tz,\n-                                  usetex=self._usetex)\n-        return formatter(x, pos=pos)\n+        # When a sequence of tick values is passed (pos is None),\n+        # use our custom format_ticks method so that the offset string is computed.\n+        # Otherwise, if only a single tick value is passed, return the formatted label.\n+        if pos is None:\n+            return self.format_ticks(x)\n+        else:\n+            return self.format_ticks([x])[0]\n+\n \n     def format_ticks(self, values):\n         tickdatetime = [num2date(value, tz=self._tz) for value in values]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-23299",
        "model_patch": "diff --git a/lib/matplotlib/pyplot.py b/lib/matplotlib/pyplot.py\nindex e3c66ea67c..bd50455bde 100644\n--- a/lib/matplotlib/pyplot.py\n+++ b/lib/matplotlib/pyplot.py\n@@ -198,11 +198,12 @@ def _get_backend_mod():\n \n     This is currently private, but may be made public in the future.\n     \"\"\"\n-    if _backend_mod is None:\n-        # Use __getitem__ here to avoid going through the fallback logic (which\n-        # will (re)import pyplot and then call switch_backend if we need to\n-        # resolve the auto sentinel)\n-        switch_backend(dict.__getitem__(rcParams, \"backend\"))\n+\tif _backend_mod is None:\n+\t    from matplotlib import _pylab_helpers\n+\t    figs_backup = _pylab_helpers.Gcf.figs.copy()\n+\t    switch_backend(dict.__getitem__(rcParams, \"backend\"))\n+\t    _pylab_helpers.Gcf.figs = figs_backup\n+\n     return _backend_mod\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-23314",
        "model_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/mpl_axes.py b/lib/mpl_toolkits/axes_grid1/mpl_axes.py\nindex 7eb289ec0e..90d3f62337 100644\n--- a/lib/mpl_toolkits/axes_grid1/mpl_axes.py\n+++ b/lib/mpl_toolkits/axes_grid1/mpl_axes.py\n@@ -92,7 +92,8 @@ class SimpleAxisArtist(Artist):\n     def set_visible(self, b):\n         self.toggle(all=b)\n         self.line.set_visible(b)\n-        self._axis.set_visible(True)\n+self._axis.set_visible(b)\n+\n         super().set_visible(b)\n \n     def set_label(self, txt):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-23412",
        "model_patch": "diff --git a/lib/matplotlib/patches.py b/lib/matplotlib/patches.py\nindex e062249589..8eaab4da83 100644\n--- a/lib/matplotlib/patches.py\n+++ b/lib/matplotlib/patches.py\n@@ -588,17 +588,12 @@ class Patch(artist.Artist):\n             return\n         # Patch has traditionally ignored the dashoffset.\n         with cbook._setattr_cm(\n-                 self, _dash_pattern=(0, self._dash_pattern[1])), \\\n-             self._bind_draw_path_function(renderer) as draw_path:\n-            path = self.get_path()\n-            transform = self.get_transform()\n-            tpath = transform.transform_path_non_affine(path)\n-            affine = transform.get_affine()\n-            draw_path(tpath, affine,\n-                      # Work around a bug in the PDF and SVG renderers, which\n-                      # do not draw the hatches if the facecolor is fully\n-                      # transparent, but do if it is None.\n-                      self._facecolor if self._facecolor[3] else None)\n+with self._bind_draw_path_function(renderer) as draw_path:\n+    path = self.get_path()\n+    transform = self.get_transform()\n+    tpath = transform.transform_path_non_affine(path)\n+    affine = transform.get_affine()\n+    draw_path(tpath, affine, self._facecolor if self._facecolor[3] else None)\n \n     def get_path(self):\n         \"\"\"Return the path of this patch.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-23476",
        "model_patch": "diff --git a/lib/matplotlib/backend_bases.py b/lib/matplotlib/backend_bases.py\nindex 9ae2982c62..07eb885f26 100644\n--- a/lib/matplotlib/backend_bases.py\n+++ b/lib/matplotlib/backend_bases.py\n@@ -1652,9 +1652,11 @@ class FigureCanvasBase:\n         self.mouse_grabber = None  # the Axes currently grabbing mouse\n         self.toolbar = None  # NavigationToolbar2 will set me\n         self._is_idle_drawing = False\n-        # We don't want to scale up the figure DPI more than once.\n-        figure._original_dpi = figure.dpi\n-        self._device_pixel_ratio = 1\n+# We don't want to scale up the figure DPI more than once.\n+if not hasattr(figure, \"_original_dpi\"):\n+    figure._original_dpi = figure.dpi\n+self._device_pixel_ratio = 1\n+\n         super().__init__()  # Typically the GUI widget init (if any).\n \n     callbacks = property(lambda self: self.figure._canvas_callbacks)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24026",
        "model_patch": "diff --git a/lib/matplotlib/stackplot.py b/lib/matplotlib/stackplot.py\nindex c580043eeb..eb7c8b9685 100644\n--- a/lib/matplotlib/stackplot.py\n+++ b/lib/matplotlib/stackplot.py\n@@ -68,9 +68,14 @@ def stackplot(axes, x, *args,\n \n     y = np.row_stack(args)\n \n-    labels = iter(labels)\n-    if colors is not None:\n-        axes.set_prop_cycle(color=colors)\n+labels = iter(labels)\n+if colors is not None:\n+    # Instead of setting the axes cycler (which corrupts later plots that use the axes\u2019 prop cycle),\n+    # create a local iterator that will be used only here.\n+    color_iter = iter(colors)\n+else:\n+    color_iter = None\n+\n \n     # Assume data passed has not been 'stacked', so stack it here.\n     # We'll need a float buffer for the upcoming calculations.\n@@ -108,7 +113,15 @@ def stackplot(axes, x, *args,\n         stack += first_line\n \n     # Color between x = 0 and the first array.\n+if color_iter is not None:\n+    try:\n+        color = next(color_iter)\n+    except StopIteration:\n+        color_iter = iter(colors)\n+        color = next(color_iter)\n+else:\n     color = axes._get_lines.get_next_color()\n+\n     coll = axes.fill_between(x, first_line, stack[0, :],\n                              facecolor=color, label=next(labels, None),\n                              **kwargs)\n@@ -117,7 +130,15 @@ def stackplot(axes, x, *args,\n \n     # Color between array i-1 and array i\n     for i in range(len(y) - 1):\n-        color = axes._get_lines.get_next_color()\n+if color_iter is not None:\n+    try:\n+        color = next(color_iter)\n+    except StopIteration:\n+        color_iter = iter(colors)\n+        color = next(color_iter)\n+else:\n+    color = axes._get_lines.get_next_color()\n+\n         r.append(axes.fill_between(x, stack[i, :], stack[i + 1, :],\n                                    facecolor=color, label=next(labels, None),\n                                    **kwargs))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24149",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex fdac0f3560..4a74a0aeb0 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -2168,14 +2168,18 @@ class Axes(_AxesBase):\n             return convert(dx)\n \n         try:\n-            # attempt to add the width to x0; this works for\n-            # datetime+timedelta, for instance\n+            try:\n+                x0 = cbook._safe_first_finite(x0)\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                pass\n \n             # only use the first element of x and x0.  This saves\n             # having to be sure addition works across the whole\n-            # vector.  This is particularly an issue if\n-            # x0 and dx are lists so x0 + dx just concatenates the lists.\n-            # We can't just cast x0 and dx to numpy arrays because that\n+            try:\n+                x = cbook._safe_first_finite(xconv)\n+            except (TypeError, IndexError, KeyError, StopIteration):\n+                x = xconv\n+\n             # removes the units from unit packages like `pint` that\n             # wrap numpy arrays.\n             try:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24177",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex 2412f815cd..6123cefc57 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -6883,16 +6883,21 @@ such objects\n                     edgecolor=None if fill else c,\n                     fill=fill if fill else None,\n                     zorder=None if fill else mlines.Line2D.zorder))\n+            for patch_list in patches:\n+                for patch in patch_list:\n+                    if orientation == 'vertical':\n+                        patch.sticky_edges.y.append(0)\n             for patch_list in patches:\n                 for patch in patch_list:\n                     if orientation == 'vertical':\n                         patch.sticky_edges.y.append(0)\n                     elif orientation == 'horizontal':\n                         patch.sticky_edges.x.append(0)\n-\n+            self._request_autoscale_view()\n             # we return patches, so put it back in the expected order\n             patches.reverse()\n \n+\n         # If None, make all labels None (via zip_longest below); otherwise,\n         # cast each element to str, but keep a single str as it.\n         labels = [] if label is None else np.atleast_1d(np.asarray(label, str))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24570",
        "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex 3a506543ac..40771ada9b 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -480,10 +480,19 @@ class HPacker(PackerBase):\n                                                           self.align)\n \n         pack_list = [w for w, h, xd, yd in whd_list]\n-        width, xoffsets_ = _get_packed_offsets(pack_list, self.width,\n-                                               sep, self.mode)\n+        hd_list = [(h, yd) for w, h, xd, yd in whd_list]\n+        effective_align = self.align\n+        # Remap the vertical align for HPacker:\n+        # \"bottom\" should align the bottom edges (like \"left\"),\n+        # and \"top\" should align top edges (like \"right\").\n+        if effective_align == \"bottom\":\n+            effective_align = \"left\"\n+        elif effective_align == \"top\":\n+            effective_align = \"right\"\n+        height, ydescent, yoffsets = _get_aligned_offsets(hd_list,\n+                                                          self.height,\n+                                                          effective_align)\n \n-        xoffsets = xoffsets_ + [xd for w, h, xd, yd in whd_list]\n \n         xdescent = whd_list[0][2]\n         xoffsets = xoffsets - xdescent\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24627",
        "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex 6c18ba1a64..1bceae06e9 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -918,6 +918,130 @@ default: %(va)s\n         self._axobservers.process(\"_axes_change_event\", self)\n         self.stale = True\n         self._localaxes.remove(ax)\n+or artist in ax.get_children():\n+    artist.axes = None\n+    if artist.figure is ax.figure:\n+        artist.figure = None\n         # Break link between any shared axes\n         for name in ax._axis_names:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24637",
        "model_patch": "diff --git a/lib/matplotlib/offsetbox.py b/lib/matplotlib/offsetbox.py\nindex efa34dd078..f50ac0b703 100644\n--- a/lib/matplotlib/offsetbox.py\n+++ b/lib/matplotlib/offsetbox.py\n@@ -1446,20 +1446,31 @@ or callable, default: value of *xycoords*\n             patchA = self.arrowprops.get(\"patchA\", self.patch)\n             self.arrow_patch.set_patchA(patchA)\n \n-    def draw(self, renderer):\n-        # docstring inherited\n-        if renderer is not None:\n-            self._renderer = renderer\n-        if not self.get_visible() or not self._check_xy(renderer):\n-            return\n-        self.update_positions(renderer)\n-        if self.arrow_patch is not None:\n-            if self.arrow_patch.figure is None and self.figure is not None:\n-                self.arrow_patch.figure = self.figure\n-            self.arrow_patch.draw(renderer)\n-        self.patch.draw(renderer)\n-        self.offsetbox.draw(renderer)\n-        self.stale = False\n+def draw(self, renderer):\n+    # docstring inherited\n+    if renderer is not None:\n+        self._renderer = renderer\n+    if not self.get_visible() or not self._check_xy(renderer):\n+        return\n+    self.update_positions(renderer)\n+\n+    # If a gid has been provided, wrap the drawing in a group\n+    gid = self.get_gid()\n+    if gid is not None and hasattr(renderer, \"open_group\"):\n+        renderer.open_group(\"annotationbbox\", gid=gid)\n+\n+    if self.arrow_patch is not None:\n+        if self.arrow_patch.figure is None and self.figure is not None:\n+            self.arrow_patch.figure = self.figure\n+        self.arrow_patch.draw(renderer)\n+    self.patch.draw(renderer)\n+    self.offsetbox.draw(renderer)\n+\n+    if gid is not None and hasattr(renderer, \"close_group\"):\n+        renderer.close_group(\"annotationbbox\")\n+\n+    self.stale = False\n+\n \n \n class DraggableBase:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24870",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex 58d9591266..d35d31104a 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -6456,7 +6456,16 @@ default: :rc:`scatter.edgecolors`\n         %(contour_doc)s\n         \"\"\"\n         kwargs['filled'] = False\n+        if 'levels' not in kwargs:\n+            z = None\n+            if len(args) == 1:\n+                z = np.asanyarray(args[0])\n+            elif len(args) >= 3:\n+                z = np.asanyarray(args[2])\n+            if z is not None and np.issubdtype(z.dtype, np.bool_):\n+                kwargs['levels'] = [0.5]\n         contours = mcontour.QuadContourSet(self, *args, **kwargs)\n+\n         self._request_autoscale_view()\n         return contours\n \n@@ -6472,7 +6481,16 @@ default: :rc:`scatter.edgecolors`\n         %(contour_doc)s\n         \"\"\"\n         kwargs['filled'] = True\n+        if 'levels' not in kwargs:\n+            z = None\n+            if len(args) == 1:\n+                z = np.asanyarray(args[0])\n+            elif len(args) >= 3:\n+                z = np.asanyarray(args[2])\n+            if z is not None and np.issubdtype(z.dtype, np.bool_):\n+                kwargs['levels'] = [0.5]\n         contours = mcontour.QuadContourSet(self, *args, **kwargs)\n+\n         self._request_autoscale_view()\n         return contours\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-24970",
        "model_patch": "diff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex 2d3072da04..e9f7951ea3 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -710,6 +710,115 @@ class Colormap:\n         # np.isnan() to after we have converted to an array.\n         mask_bad = X.mask if np.ma.is_masked(X) else None\n         xa = np.array(X, copy=True)\n+f np.issubdtype(xa.dtype, np.integer) and xa.dtype.itemsize < 8:\n+    xa = xa.astype(np.int64, copy=False)\n         if mask_bad is None:\n             mask_bad = np.isnan(xa)\n         if not xa.dtype.isnative:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25122",
        "model_patch": "diff --git a/lib/matplotlib/mlab.py b/lib/matplotlib/mlab.py\nindex 3552904c3d..f74d32d9c0 100644\n--- a/lib/matplotlib/mlab.py\n+++ b/lib/matplotlib/mlab.py\n@@ -424,10 +424,11 @@ def _spectral_helper(x, y=None, NFFT=None, Fs=None, detrend_func=None,\n             result /= Fs\n             # Scale the spectrum by the norm of the window to compensate for\n             # windowing loss; see Bendat & Piersol Sec 11.5.2.\n-            result /= (np.abs(window)**2).sum()\n+            result /= (window**2).sum()\n         else:\n             # In this case, preserve power in the segment, not amplitude\n-            result /= np.abs(window).sum()**2\n+            result /= (window.sum())**2\n+\n \n     t = np.arange(NFFT/2, len(x) - NFFT/2 + 1, NFFT - noverlap)/Fs\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25287",
        "model_patch": "diff --git a/lib/matplotlib/axis.py b/lib/matplotlib/axis.py\nindex c0e706e2b3..a347918a6d 100644\n--- a/lib/matplotlib/axis.py\n+++ b/lib/matplotlib/axis.py\n@@ -2251,7 +2251,8 @@ class XAxis(Axis):\n \n         self.offsetText.set(\n             x=1, y=0,\n-            verticalalignment='top', horizontalalignment='right',\n+            color=mpl.rcParams['xtick.color'] if mpl.rcParams['xtick.labelcolor'] == 'inherit' else mpl.rcParams['xtick.labelcolor'],\n+\n             transform=mtransforms.blended_transform_factory(\n                 self.axes.transAxes, mtransforms.IdentityTransform()),\n             fontsize=mpl.rcParams['xtick.labelsize'],\n@@ -2511,7 +2512,8 @@ class YAxis(Axis):\n         # x in axes coords, y in display coords(!).\n         self.offsetText.set(\n             x=0, y=0.5,\n-            verticalalignment='baseline', horizontalalignment='left',\n+            color=mpl.rcParams['ytick.color'] if mpl.rcParams['ytick.labelcolor'] == 'inherit' else mpl.rcParams['ytick.labelcolor'],\n+\n             transform=mtransforms.blended_transform_factory(\n                 self.axes.transAxes, mtransforms.IdentityTransform()),\n             fontsize=mpl.rcParams['ytick.labelsize'],\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25311",
        "model_patch": "diff --git a/lib/matplotlib/legend.py b/lib/matplotlib/legend.py\nindex ff6abdb958..f7e44e95e1 100644\n--- a/lib/matplotlib/legend.py\n+++ b/lib/matplotlib/legend.py\n@@ -1203,6 +1203,200 @@ class Legend(Artist):\n                 self._draggable.disconnect()\n             self._draggable = None\n         return self._draggable\n+   def __getstate__(self):\n+        state = self.__dict__.copy()\n+        # Remove the non-picklable draggable helper from the state.\n+        state['_draggable'] = None\n+        return state\n     def get_draggable(self):\n         \"\"\"Return ``True`` if the legend is draggable, ``False`` otherwise.\"\"\"",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25332",
        "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex b4c38368bf..f82503c5d8 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -201,6 +201,401 @@ class FigureBase(Artist):\n         self.suppressComposite = None\n         self.set(**kwargs)\n \n+    def __getstate__(self):\n+        state = self.__dict__.copy()\n+        state.pop('_align_label_groups', None)\n+        return state\n+    def __setstate__(self, state):\n+        self.__dict__.update(state)\n+        if '_align_label_groups' not in self.__dict__:\n+            from matplotlib import cbook\n+            self._align_label_groups = {\"x\": cbook.Grouper(), \"y\": cbook.Grouper()}\n     def _get_draw_artists(self, renderer):\n         \"\"\"Also runs apply_aspect\"\"\"\n         artists = self.get_children()",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25479",
        "model_patch": "diff --git a/lib/matplotlib/cm.py b/lib/matplotlib/cm.py\nindex 38158db956..316cb8267c 100644\n--- a/lib/matplotlib/cm.py\n+++ b/lib/matplotlib/cm.py\n@@ -248,13 +248,17 @@ def register_cmap(name=None, cmap=None, *, override_builtin=False):\n \n         Please do not use this unless you are sure you need it.\n     \"\"\"\n-    _api.check_isinstance((str, None), name=name)\n-    if name is None:\n-        try:\n-            name = cmap.name\n-        except AttributeError as err:\n-            raise ValueError(\"Arguments must include a name or a \"\n-                             \"Colormap\") from err\n+_api.check_isinstance((str, None), name=name)\n+if name is None:\n+    try:\n+        name = cmap.name\n+    except AttributeError as err:\n+        raise ValueError(\"Arguments must include a name or a Colormap\") from err\n+else:\n+    # If a registration name is provided, update the colormap's name attribute\n+    if cmap.name != name:\n+        cmap.name = name\n+\n     # override_builtin is allowed here for backward compatibility\n     # this is just a shim to enable that to work privately in\n     # the global ColormapRegistry\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25775",
        "model_patch": "diff --git a/lib/matplotlib/text.py b/lib/matplotlib/text.py\nindex 4591316cf9..a1ccb6fd1a 100644\n--- a/lib/matplotlib/text.py\n+++ b/lib/matplotlib/text.py\n@@ -187,6 +187,350 @@ class Text(Artist):\n             linespacing = 1.2  # Maybe use rcParam later.\n         self.set_linespacing(linespacing)\n         self.set_rotation_mode(rotation_mode)\n+       self.set_antialiased(mpl.rcParams[\"text.antialiased\"])\n+    def get_antialiased(self):\n+        \"\"\"Return the antialiased state of the text.\"\"\"\n+        return self._antialiased\n+    def set_antialiased(self, aa):\n+        \"\"\"Set the antialiased state of the text.\"\"\"\n+        self._antialiased = bool(aa)\n+        self.stale = True\n     def update(self, kwargs):\n         # docstring inherited\n@@ -733,6 +1077,62 @@ class Text(Artist):\n                 self.update_bbox_position_size(renderer)\n                 self._bbox_patch.draw(renderer)\n \n+            gc.set_antialiased(self.get_antialiased())\n             gc = renderer.new_gc()\n             gc.set_foreground(self.get_color())\n             gc.set_alpha(self.get_alpha())",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-25960",
        "model_patch": "diff --git a/lib/matplotlib/figure.py b/lib/matplotlib/figure.py\nindex dab2bc4a5a..61b1fbf091 100644\n--- a/lib/matplotlib/figure.py\n+++ b/lib/matplotlib/figure.py\n@@ -2264,27 +2264,14 @@ class SubFigure(FigureBase):\n \n         Parameters\n         ----------\n-        bbox : bbox or None\n-            If not None, then the bbox is used for relative bounding box.\n-            Otherwise, it is calculated from the subplotspec.\n+        bbox : Bbox or None\n+            If not None, then the bbox is used for the relative bounding box.\n+            Otherwise, the bounding box is obtained from the subplotspec position.\n         \"\"\"\n         if bbox is not None:\n-            self.bbox_relative.p0 = bbox.p0\n-            self.bbox_relative.p1 = bbox.p1\n+            self.bbox_relative = bbox\n             return\n-        # need to figure out *where* this subplotspec is.\n-        gs = self._subplotspec.get_gridspec()\n-        wr = np.asarray(gs.get_width_ratios())\n-        hr = np.asarray(gs.get_height_ratios())\n-        dx = wr[self._subplotspec.colspan].sum() / wr.sum()\n-        dy = hr[self._subplotspec.rowspan].sum() / hr.sum()\n-        x0 = wr[:self._subplotspec.colspan.start].sum() / wr.sum()\n-        y0 = 1 - hr[:self._subplotspec.rowspan.stop].sum() / hr.sum()\n-        if self.bbox_relative is None:\n-            self.bbox_relative = Bbox.from_bounds(x0, y0, dx, dy)\n-        else:\n-            self.bbox_relative.p0 = (x0, y0)\n-            self.bbox_relative.p1 = (x0 + dx, y0 + dy)\n+        self.bbox_relative = self._subplotspec.get_position(self._parent)\n \n     def get_constrained_layout(self):\n         \"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26113",
        "model_patch": "diff --git a/lib/matplotlib/axes/_axes.py b/lib/matplotlib/axes/_axes.py\nindex 5369eadbde..9d8dce71fb 100644\n--- a/lib/matplotlib/axes/_axes.py\n+++ b/lib/matplotlib/axes/_axes.py\n@@ -5013,11 +5013,12 @@ default: :rc:`scatter.edgecolors`\n                     Cs_at_i2[i2[i]].append(C[i])\n             if mincnt is None:\n                 mincnt = 0\n-            accum = np.array(\n-                [reduce_C_function(acc) if len(acc) > mincnt else np.nan\n-                 for Cs_at_i in [Cs_at_i1, Cs_at_i2]\n-                 for acc in Cs_at_i[1:]],  # [1:] drops out-of-range points.\n-                float)\n+    accum = np.array(\n+        [reduce_C_function(acc) if len(acc) >= mincnt else np.nan\n+         for Cs_at_i in [Cs_at_i1, Cs_at_i2]\n+         for acc in Cs_at_i[1:]],  # [1:] drops out-of-range points.\n+        float)\n+\n \n         good_idxs = ~np.isnan(accum)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26208",
        "model_patch": "diff --git a/lib/matplotlib/stackplot.py b/lib/matplotlib/stackplot.py\nindex c97a21e029..ef2665f58f 100644\n--- a/lib/matplotlib/stackplot.py\n+++ b/lib/matplotlib/stackplot.py\n@@ -115,13 +115,15 @@ def stackplot(axes, x, *args,\n     coll = axes.fill_between(x, first_line, stack[0, :],\n                              facecolor=next(colors), label=next(labels, None),\n                              **kwargs)\n-    coll.sticky_edges.y[:] = [0]\n+# (Removed sticky_edges assignment to allow autoscaling to work correctly)\n+\n     r = [coll]\n \n     # Color between array i-1 and array i\n-    for i in range(len(y) - 1):\n-        r.append(axes.fill_between(x, stack[i, :], stack[i + 1, :],\n-                                   facecolor=next(colors),\n-                                   label=next(labels, None),\n-                                   **kwargs))\n+for i in range(len(y) - 1):\n+    r.append(axes.fill_between(x, stack[i, :], stack[i + 1, :],\n+                               facecolor=next(colors),\n+                               label=next(labels, None),\n+                               **kwargs))\n+\n     return r\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26291",
        "model_patch": "diff --git a/lib/mpl_toolkits/axes_grid1/inset_locator.py b/lib/mpl_toolkits/axes_grid1/inset_locator.py\nindex 9d35051074..459d998ea6 100644\n--- a/lib/mpl_toolkits/axes_grid1/inset_locator.py\n+++ b/lib/mpl_toolkits/axes_grid1/inset_locator.py\n@@ -70,13 +70,14 @@ class AnchoredLocatorBase(AnchoredOffsetbox):\n \n     def __call__(self, ax, renderer):\n         self.axes = ax\n+        # Fix: assign the figure before computing the window extent\n+        self.set_figure(ax.figure)\n         bbox = self.get_window_extent(renderer)\n         px, py = self.get_offset(bbox.width, bbox.height, 0, 0, renderer)\n         bbox_canvas = Bbox.from_bounds(px, py, bbox.width, bbox.height)\n         tr = ax.figure.transSubfigure.inverted()\n         return TransformedBbox(bbox_canvas, tr)\n \n-\n class AnchoredSizeLocator(AnchoredLocatorBase):\n     def __init__(self, bbox_to_anchor, x_size, y_size, loc,\n                  borderpad=0.5, bbox_transform=None):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26342",
        "model_patch": "diff --git a/lib/matplotlib/contour.py b/lib/matplotlib/contour.py\nindex 3f84250b64..befc66c137 100644\n--- a/lib/matplotlib/contour.py\n+++ b/lib/matplotlib/contour.py\n@@ -99,24 +99,29 @@ class ContourLabeler:\n \n             - If one string color, e.g., *colors* = 'r' or *colors* =\n               'red', all labels will be plotted in this color.\n+    def get_paths(self):\n+        # Return the paths from the first collection as a reference.\n+        return self.collections[0].get_paths()\n \n-            - If a tuple of colors (string, float, RGB, etc), different labels\n-              will be plotted in different colors in the order specified.\n-\n-        inline : bool, default: True\n-            If ``True`` the underlying contour is removed where the label is\n-            placed.\n+    def set_paths(self, transformed_paths):\n+        \"\"\"\n+        Replace the internal paths of the contour set with the given transformed paths.\n \n-        inline_spacing : float, default: 5\n-            Space in pixels to leave on each side of label when placing inline.\n+        This method updates all underlying collections that render the contours,\n+        marks the contour set as stale, and triggers a canvas update if possible.\n+        \"\"\"\n+        # Iterate over all collections and update their paths\n+        for coll in self.collections:\n+            coll.set_paths(transformed_paths)\n \n-            This spacing will be exact for labels at locations where the\n-            contour is straight, less so for labels on curved contours.\n+        # Mark the ContourSet as stale so that a redraw will occur.\n+        self.stale = True\n \n-        fmt : `.Formatter` or str or callable or dict, optional\n-            How the levels are formatted:\n+        # Trigger a lazy redraw of the canvas if it exists.\n+        if self.figure is not None:\n+            self.figure.canvas.draw_idle()\n+        return self\n \n-            - If a `.Formatter`, it is used to format all levels at once, using\n               its `.Formatter.format_ticks` method.\n             - If a str, it is interpreted as a %-style format string.\n             - If a callable, it is called with one level at a time and should\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "matplotlib__matplotlib-26466",
        "model_patch": "diff --git a/lib/matplotlib/text.py b/lib/matplotlib/text.py\nindex d4922fc517..8277bde51b 100644\n--- a/lib/matplotlib/text.py\n+++ b/lib/matplotlib/text.py\n@@ -1456,7 +1456,11 @@ class _AnnotationBase:\n                  xycoords='data',\n                  annotation_clip=None):\n \n-        self.xy = xy\n+        try:\n+            self.xy = np.array(xy, copy=True)\n+        except Exception:\n+            self.xy = xy\n+\n         self.xycoords = xycoords\n         self.set_annotation_clip(annotation_clip)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "mwaskom__seaborn-3069",
        "model_patch": "diff --git a/seaborn/_core/plot.py b/seaborn/_core/plot.py\nindex 4f0290a4..5102eb7e 100644\n--- a/seaborn/_core/plot.py\n+++ b/seaborn/_core/plot.py\n@@ -1641,7 +1641,14 @@ class Plotter:\n                     if isinstance(a, str):\n                         lo = cast(float, lo) - 0.5\n                     if isinstance(b, str):\n-                        hi = cast(float, hi) + 0.5\n+                    ax.set(**{f\"{axis}lim\": (lo, hi)})\n+                    # For categorical (string) limits, disable grid on that axis\n+                    if isinstance(a, str):\n+                        if axis == \"x\":\n+                            ax.xaxis.grid(False)\n+                        else:\n+                            ax.yaxis.grid(False)\n+\n                     ax.set(**{f\"{axis}lim\": (lo, hi)})\n \n         engine_default = None if p._target is not None else \"tight\"\ndiff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex bbd71ec1..bc8a3ead 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -184,13 +184,18 @@ class Nominal(Scale):\n                 # axis.set_major_formatter(major_formatter)\n \n         mpl_scale = CatScale(data.name)\n-        if axis is None:\n-            axis = PseudoAxis(mpl_scale)\n+if axis is None:\n+    axis = PseudoAxis(mpl_scale)\n+    axis.update_units(stringify(np.array(units_seed)))\n+else:\n+    axis.update_units(stringify(np.array(units_seed)))\n+# Set the view interval with the \u00b10.5 margin.\n+if hasattr(axis, \"axis_name\") and axis.axis_name == \"y\":\n+    axis.set_view_interval(len(units_seed) - 0.5, -0.5)\n+else:\n+    axis.set_view_interval(-0.5, len(units_seed) - 0.5)\n+new._matplotlib_scale = mpl_scale\n \n-            # TODO Currently just used in non-Coordinate contexts, but should\n-            # we use this to (A) set the padding we want for categorial plots\n-            # and (B) allow the values parameter for a Coordinate to set xlim/ylim\n-            axis.set_view_interval(0, len(units_seed) - 1)\n \n         new._matplotlib_scale = mpl_scale\n \n@@ -211,11 +216,11 @@ class Nominal(Scale):\n             out[keep] = axis.convert_units(stringify(x[keep]))\n             return out\n \n-        new._pipeline = [\n-            convert_units,\n-            prop.get_mapping(new, data),\n-            # TODO how to handle color representation consistency?\n-        ]\n+new._pipeline = [\n+    lambda x: self._convert_units(x, units_seed, axis, stringify),\n+    prop.get_mapping(new, data),\n         def spacer(x):\n             return 1\n@@ -226,6 +231,521 @@ class Nominal(Scale):\n             new._legend = units_seed, list(stringify(units_seed))\n \n         return new\n+   def _convert_units(self, x, units_seed, axis, stringify):\n+        # Convert non\u2013numeric (categorical) data into positions with the proper margins.\n+        # This mirrors the logic used in _finalize_figure.\n+        arr = np.array([str(val) for val in x])\n+        keep = np.array([v in units_seed for v in arr], dtype=bool)\n+        out = np.full(len(x), np.nan)\n+        if keep.any():\n+            converted = axis.convert_units(stringify(arr[keep]))\n+            out[keep] = converted\n+        return out\n     def tick(self, locator: Locator | None = None):\n         \"\"\"",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "mwaskom__seaborn-3187",
        "model_patch": "diff --git a/seaborn/_core/scales.py b/seaborn/_core/scales.py\nindex 55874bf2..bfe7436c 100644\n--- a/seaborn/_core/scales.py\n+++ b/seaborn/_core/scales.py\n@@ -374,12 +374,18 @@ class ContinuousBase(Scale):\n         # Could add a Scale parameter, or perhaps Scale.suppress()?\n         # Are there other useful parameters that would be in Scale.legend()\n         # besides allowing Scale.legend(False)?\n-        if prop.legend:\n-            axis.set_view_interval(vmin, vmax)\n-            locs = axis.major.locator()\n-            locs = locs[(vmin <= locs) & (locs <= vmax)]\n-            labels = axis.major.formatter.format_ticks(locs)\n-            new._legend = list(locs), list(labels)\n+            if prop.legend:\n+                axis.set_view_interval(vmin, vmax)\n+                locs = axis.major.locator()\n+                locs = locs[(vmin <= locs) & (locs <= vmax)]\n+                leg_formatter = axis.major.formatter\n+                labels = leg_formatter.format_ticks(locs)\n+                # If using ScalarFormatter, include its offset text in the legend labels.\n+                if isinstance(leg_formatter, mpl.ticker.ScalarFormatter):\n+                    offset_text = leg_formatter.get_offset()\n+                    if offset_text:\n+                        labels = [f\"{lab} {offset_text}\" for lab in labels]\n+                new._legend = list(locs), list(labels)\n \n         return new\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pallets__flask-5014",
        "model_patch": "diff --git a/src/flask/blueprints.py b/src/flask/blueprints.py\nindex eb50585d..fd3be0d7 100644\n--- a/src/flask/blueprints.py\n+++ b/src/flask/blueprints.py\n@@ -182,6 +182,84 @@ class Blueprint(Scaffold):\n         root_path: t.Optional[str] = None,\n         cli_group: t.Optional[str] = _sentinel,  # type: ignore\n     ):\n+f not name:\n+    raise ValueError(\"Blueprints must have a non-empty name.\")\n         super().__init__(\n             import_name=import_name,\n             static_folder=static_folder,",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-1142",
        "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex 99260453..b3957b53 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -385,14 +385,20 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n \n         self.body = body\n \n-    def prepare_content_length(self, body):\n-        self.headers['Content-Length'] = '0'\n-        if hasattr(body, 'seek') and hasattr(body, 'tell'):\n-            body.seek(0, 2)\n-            self.headers['Content-Length'] = str(body.tell())\n-            body.seek(0, 0)\n-        elif body is not None:\n-            self.headers['Content-Length'] = str(len(body))\n+def prepare_content_length(self, body):\n+    # Only set Content-Length if the method requires it (i.e. methods other than GET/HEAD)\n+    if self.method in ('GET', 'HEAD') and body is None:\n+        # Remove any existing Content-Length header for GET/HEAD requests with no body.\n+        self.headers.pop('Content-Length', None)\n+        return\n+\n+    self.headers['Content-Length'] = '0'\n+    if hasattr(body, 'seek') and hasattr(body, 'tell'):\n+        body.seek(0, 2)\n+        self.headers['Content-Length'] = str(body.tell())\n+        body.seek(0, 0)\n+    elif body is not None:\n+        self.headers['Content-Length'] = str(len(body))\n \n     def prepare_auth(self, auth):\n         \"\"\"Prepares the given HTTP auth data.\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-1724",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-1766",
        "model_patch": "diff --git a/requests/auth.py b/requests/auth.py\nindex a3de123d..32fe5615 100644\n--- a/requests/auth.py\n+++ b/requests/auth.py\n@@ -143,8 +143,9 @@ class HTTPDigestAuth(AuthBase):\n             base += ', algorithm=\"%s\"' % algorithm\n         if entdig:\n             base += ', digest=\"%s\"' % entdig\n-        if qop:\n-            base += ', qop=auth, nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n+            if qop:\n+                base += ', qop=\"auth\", nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n+\n \n         return 'Digest %s' % (base)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-1921",
        "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex a023e4ec..5814a14e 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -54,11 +54,12 @@ def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n     merged_setting = dict_class(to_key_val_list(session_setting))\n     merged_setting.update(to_key_val_list(request_setting))\n \n-    # Remove keys that are set to None.\n-    for (k, v) in request_setting.items():\n+    # Remove keys that are set to None in either merged settings.\n+    for (k, v) in list(merged_setting.items()):\n         if v is None:\n             del merged_setting[k]\n \n+\n     return merged_setting\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-2317",
        "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex d701ff2e..60fa9b06 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -425,7 +425,11 @@ class Session(SessionRedirectMixin):\n             If Tuple, ('cert', 'key') pair.\n         \"\"\"\n \n-        method = builtin_str(method)\n+        if isinstance(method, bytes):\n+            method = method.decode('utf-8')\n+        else:\n+            method = builtin_str(method)\n+\n \n         # Create the Request.\n         req = Request(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-2931",
        "model_patch": "diff --git a/requests/utils.py b/requests/utils.py\nindex 132cd2b5..a96c475f 100644\n--- a/requests/utils.py\n+++ b/requests/utils.py\n@@ -691,13 +691,17 @@ def to_native_string(string, encoding='ascii'):\n     \"\"\"\n     out = None\n \n-    if isinstance(string, builtin_str):\n-        out = string\n+if isinstance(string, builtin_str):\n+    out = string\n+# In Python3, bytes should be left untouched (binary payload).\n+elif isinstance(string, bytes):\n+    out = string\n+else:\n+    if is_py2:\n+        out = string.encode(encoding)\n     else:\n-        if is_py2:\n-            out = string.encode(encoding)\n-        else:\n-            out = string.decode(encoding)\n+        out = string.decode(encoding)\n+\n \n     return out\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-5414",
        "model_patch": "diff --git a/requests/models.py b/requests/models.py\nindex e7d292d5..fd686d70 100644\n--- a/requests/models.py\n+++ b/requests/models.py\n@@ -393,6 +393,214 @@ class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n \n         if not host:\n             raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n+           # Check for empty labels in hostname (e.g. a leading dot or consecutive dots)\n+            if host.startswith('.') or '..' in host:\n+                raise InvalidURL('URL has an invalid label.')\n         # In general, we want to try IDNA encoding the hostname if the string contains\n         # non-ASCII characters. This allows users to automatically get the correct IDNA",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "psf__requests-6028",
        "model_patch": "diff --git a/requests/sessions.py b/requests/sessions.py\nindex 3f59cab9..be60c0fb 100644\n--- a/requests/sessions.py\n+++ b/requests/sessions.py\n@@ -293,9 +293,11 @@ class SessionRedirectMixin(object):\n         except KeyError:\n             username, password = None, None\n \n-        if username and password:\n+        # Even if the password is an empty string, it is valid and should be sent.\n+        if username is not None and password is not None and (username != '' or password != ''):\n             headers['Proxy-Authorization'] = _basic_auth_str(username, password)\n \n+\n         return new_proxies\n \n     def rebuild_method(self, prepared_request, response):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-2905",
        "model_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 45553eb9..58aedc32 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -217,8 +217,10 @@ def as_compatible_data(data, fastpath=False):\n     if isinstance(data, timedelta):\n         data = np.timedelta64(getattr(data, \"value\", data), \"ns\")\n \n-    # we don't want nested self-described arrays\n-    data = getattr(data, \"values\", data)\n+# we don't want nested self-described arrays; only unwrap if the data is array-like\n+if hasattr(data, \"values\") and hasattr(data, \"__iter__\"):\n+    data = data.values\n+\n \n     if isinstance(data, np.ma.MaskedArray):\n         mask = np.ma.getmaskarray(data)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3095",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex b00dad96..33e417e0 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -955,9 +955,10 @@ class Dataset(Mapping, ImplementsDatasetReduce, DataWithCoords):\n             variables = OrderedDict((k, v.copy(deep=deep, data=data.get(k)))\n                                     for k, v in self._variables.items())\n \n-        attrs = copy.deepcopy(self._attrs) if deep else copy.copy(self._attrs)\n+attrs = copy.deepcopy(self._attrs) if deep else copy.copy(self._attrs)\n+indexes = copy.deepcopy(self._indexes) if deep else copy.copy(self._indexes)\n+return self._replace(variables, attrs=attrs, indexes=indexes)\n \n-        return self._replace(variables, attrs=attrs)\n \n     @property\n     def _level_coords(self) -> 'OrderedDict[str, Hashable]':\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3151",
        "model_patch": "diff --git a/xarray/core/combine.py b/xarray/core/combine.py\nindex 37ae903b..5bf8a5cb 100644\n--- a/xarray/core/combine.py\n+++ b/xarray/core/combine.py\n@@ -500,15 +500,15 @@ def combine_by_coords(datasets, compat='no_conflicts', data_vars='all',\n                                    data_vars=data_vars, coords=coords,\n                                    fill_value=fill_value)\n \n-        # Check the overall coordinates are monotonically increasing\n-        for dim in concatenated.dims:\n-            if dim in concatenated:\n-                indexes = concatenated.indexes.get(dim)\n-                if not (indexes.is_monotonic_increasing\n-                        or indexes.is_monotonic_decreasing):\n-                    raise ValueError(\"Resulting object does not have monotonic\"\n-                                     \" global indexes along dimension {}\"\n-                                     .format(dim))\n+    # Check the overall coordinates along concatenated dimensions are monotonically increasing.\n+    # Only dimensions used for concatenation (i.e., those in concat_dims) need to be monotonic.\n+    for dim in concat_dims:\n+        indexes = concatenated.indexes.get(dim)\n+        if indexes is not None and not (indexes.is_monotonic_increasing or indexes.is_monotonic_decreasing):\n+            raise ValueError(\"Resulting object does not have monotonic\"\n+                             \" global indexes along dimension {}\"\n+                             .format(dim))\n+\n         concatenated_grouped_by_data_vars.append(concatenated)\n \n     return merge(concatenated_grouped_by_data_vars, compat=compat,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3305",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 807badde..34f1f23c 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -2873,9 +2873,13 @@ class DataArray(AbstractArray, DataWithCoords):\n         \"\"\"\n \n         ds = self._to_temp_dataset().quantile(\n-            q, dim=dim, keep_attrs=keep_attrs, interpolation=interpolation\n-        )\n-        return self._from_temp_dataset(ds)\n+ds = self._to_temp_dataset().quantile(\n+    q, dim=dim, keep_attrs=keep_attrs, interpolation=interpolation\n+)\n+result = self._from_temp_dataset(ds)\n+if keep_attrs:\n+    result.attrs = self.attrs\n+return result\n \n     def rank(\n         self, dim: Hashable, pct: bool = False, keep_attrs: bool = None\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3677",
        "model_patch": "diff --git a/xarray/core/merge.py b/xarray/core/merge.py\nindex 10c7804d..631f23c6 100644\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -809,6 +809,138 @@ def dataset_merge_method(\n     # method due for backwards compatibility\n     # TODO: consider deprecating it?\n \n+# Convert inputs that can be coerced to Dataset (e.g. DataArray)\n+if hasattr(other, \"to_dataset\"):\n+    other = other.to_dataset()\n     if isinstance(overwrite_vars, Iterable) and not isinstance(overwrite_vars, str):\n         overwrite_vars = set(overwrite_vars)\n     else:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-3993",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 2fef3edb..470ddf82 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -3479,23 +3479,22 @@ class DataArray(AbstractArray, DataWithCoords):\n         \"\"\"\n         ds = self._to_temp_dataset().differentiate(coord, edge_order, datetime_unit)\n         return self._from_temp_dataset(ds)\n-\n     def integrate(\n-        self, dim: Union[Hashable, Sequence[Hashable]], datetime_unit: str = None\n+        self, coord: Union[Hashable, Sequence[Hashable]], datetime_unit: str = None\n     ) -> \"DataArray\":\n-        \"\"\" integrate the array with the trapezoidal rule.\n+        \"\"\"Integrate the array with the trapezoidal rule.\n \n         .. note::\n-            This feature is limited to simple cartesian geometry, i.e. dim\n+            This feature is limited to simple cartesian geometry, i.e. the coordinate\n             must be one dimensional.\n \n         Parameters\n         ----------\n-        dim : hashable, or sequence of hashable\n+        coord : hashable or sequence of hashable\n             Coordinate(s) used for the integration.\n-        datetime_unit : {\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\", \\\n+        datetime_unit : {\"Y\", \"M\", \"W\", \"D\", \"h\", \"m\", \"s\", \"ms\", \"us\", \"ns\",\n                          \"ps\", \"fs\", \"as\"}, optional\n-            Can be used to specify the unit if datetime coordinate is used.\n+            Can be used to specify the unit if a datetime coordinate is used.\n \n         Returns\n         -------\n@@ -3528,7 +3527,7 @@ class DataArray(AbstractArray, DataWithCoords):\n         array([5.4, 6.6, 7.8])\n         Dimensions without coordinates: y\n         \"\"\"\n-        ds = self._to_temp_dataset().integrate(dim, datetime_unit)\n+        ds = self._to_temp_dataset().integrate(coord, datetime_unit)\n         return self._from_temp_dataset(ds)\n \n     def unify_chunks(self) -> \"DataArray\":\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4075",
        "model_patch": "diff --git a/xarray/core/weighted.py b/xarray/core/weighted.py\nindex 996d2e4c..a1e4f8e4 100644\n--- a/xarray/core/weighted.py\n+++ b/xarray/core/weighted.py\n@@ -139,15 +139,19 @@ class Weighted:\n     ) -> \"DataArray\":\n         \"\"\" Calculate the sum of weights, accounting for missing values \"\"\"\n \n-        # we need to mask data values that are nan; else the weights are wrong\n-        mask = da.notnull()\n+# we need to mask data values that are nan; else the weights are wrong\n+mask = da.notnull()\n \n-        sum_of_weights = self._reduce(mask, self.weights, dim=dim, skipna=False)\n+# Convert boolean weights to a numeric type to ensure proper summation\n+weights_numeric = self.weights if self.weights.dtype.kind != \"b\" else self.weights * 1\n \n-        # 0-weights are not valid\n-        valid_weights = sum_of_weights != 0.0\n+sum_of_weights = self._reduce(mask, weights_numeric, dim=dim, skipna=False)\n+\n+# 0-weights are not valid\n+valid_weights = sum_of_weights != 0.0\n+\n+return sum_of_weights.where(valid_weights)\n \n-        return sum_of_weights.where(valid_weights)\n \n     def _weighted_sum(\n         self,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4094",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex b0df8749..48d0b2fc 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -1960,8 +1960,9 @@ class DataArray(AbstractArray, DataWithCoords):\n \n         # pull variables out of datarray\n         data_dict = {}\n-        for k in variables:\n-            data_dict[k] = self.sel({variable_dim: k}).squeeze(drop=True)\n+for k in variables:\n+    data_dict[k] = self.sel({variable_dim: k}).squeeze(dim=variable_dim, drop=True)\n+\n \n         # unstacked dataset\n         return Dataset(data_dict)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4356",
        "model_patch": "diff --git a/xarray/core/nanops.py b/xarray/core/nanops.py\nindex 41c8d258..394c21ab 100644\n--- a/xarray/core/nanops.py\n+++ b/xarray/core/nanops.py\n@@ -26,23 +26,27 @@ def _maybe_null_out(result, axis, mask, min_count=1):\n     \"\"\"\n     xarray version of pandas.core.nanops._maybe_null_out\n     \"\"\"\n-    if hasattr(axis, \"__len__\"):  # if tuple or list\n-        raise ValueError(\n-            \"min_count is not available for reduction with more than one dimensions.\"\n-        )\n+    # Support min_count for reductions over multiple dimensions.\n+\n \n     if axis is not None and getattr(result, \"ndim\", False):\n-        null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0\n-        if null_mask.any():\n+        if hasattr(axis, \"__len__\"):\n+            # For multiple axes, compute the total number of valid elements\n+            total_count = np.prod(np.take(mask.shape, axis))\n+            valid_count = total_count - mask.sum(axis=axis)\n+        else:\n+            valid_count = mask.shape[axis] - mask.sum(axis)\n+        null_mask = valid_count < min_count\n+        if np.any(null_mask):\n             dtype, fill_value = dtypes.maybe_promote(result.dtype)\n             result = result.astype(dtype)\n             result[null_mask] = fill_value\n \n     elif getattr(result, \"dtype\", None) not in dtypes.NAT_TYPES:\n-        null_mask = mask.size - mask.sum()\n-        if null_mask < min_count:\n+        if (mask.size - mask.sum()) < min_count:\n             result = np.nan\n \n+\n     return result\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4629",
        "model_patch": "diff --git a/xarray/core/merge.py b/xarray/core/merge.py\nindex ca4e29b6..75b5bbee 100644\n--- a/xarray/core/merge.py\n+++ b/xarray/core/merge.py\n@@ -501,7 +501,8 @@ def merge_attrs(variable_attrs, combine_attrs):\n     if combine_attrs == \"drop\":\n         return {}\n     elif combine_attrs == \"override\":\n-        return variable_attrs[0]\n+        return dict(variable_attrs[0])\n+\n     elif combine_attrs == \"no_conflicts\":\n         result = dict(variable_attrs[0])\n         for attrs in variable_attrs[1:]:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4687",
        "model_patch": "diff --git a/xarray/core/computation.py b/xarray/core/computation.py\nindex 9fe93c88..f122cfb7 100644\n--- a/xarray/core/computation.py\n+++ b/xarray/core/computation.py\n@@ -1817,6 +1817,7 @@ def where(cond, x, y):\n         join=\"exact\",\n         dataset_join=\"exact\",\n         dask=\"allowed\",\n+        keep_attrs=\"override\"\n     )\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4695",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 32b24ef1..74a69e70 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -209,12 +209,11 @@ class _LocIndexer:\n \n \n # Used as the key corresponding to a DataArray's variable when converting\n-# arbitrary DataArray objects to datasets\n-_THIS_ARRAY = ReprObject(\"<this-array>\")\n-\n-\n-class DataArray(AbstractArray, DataWithCoords):\n-    \"\"\"N-dimensional array with labeled coordinates and dimensions.\n+    def __getitem__(self, key) -> \"DataArray\":\n+        if not utils.is_dict_like(key):\n+            # expand the indexer so we can handle Ellipsis\n+            key = indexing.expanded_indexer(key, self.data_array.ndim)\n+        return self.data_array.sel(key)\n \n     DataArray provides a wrapper around numpy ndarrays that uses\n     labeled dimensions and coordinates to support metadata aware\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-4966",
        "model_patch": "diff --git a/xarray/coding/variables.py b/xarray/coding/variables.py\nindex b035ff82..66f4eba3 100644\n--- a/xarray/coding/variables.py\n+++ b/xarray/coding/variables.py\n@@ -306,22 +306,42 @@ class UnsignedIntegerCoder(VariableCoder):\n         dims, data, attrs, encoding = unpack_for_decoding(variable)\n \n         if \"_Unsigned\" in attrs:\n-            unsigned = pop_to(attrs, encoding, \"_Unsigned\")\n+            unsigned = pop_to(attrs, encoding, \"_Unsigned\").lower()\n \n-            if data.dtype.kind == \"i\":\n-                if unsigned == \"true\":\n+            if unsigned == \"true\":\n+                if data.dtype.kind == \"i\":\n                     unsigned_dtype = np.dtype(\"u%s\" % data.dtype.itemsize)\n                     transform = partial(np.asarray, dtype=unsigned_dtype)\n                     data = lazy_elemwise_func(data, transform, unsigned_dtype)\n                     if \"_FillValue\" in attrs:\n                         new_fill = unsigned_dtype.type(attrs[\"_FillValue\"])\n                         attrs[\"_FillValue\"] = new_fill\n+                else:\n+                    warnings.warn(\n+                        \"variable %r has _Unsigned attribute 'true' but is not of signed integer type. Ignoring attribute.\" % name,\n+                        SerializationWarning,\n+                        stacklevel=3,\n+                    )\n+            elif unsigned == \"false\":\n+                if data.dtype.kind == \"u\":\n+                    signed_dtype = np.dtype(\"i%s\" % data.dtype.itemsize)\n+                    transform = partial(np.asarray, dtype=signed_dtype)\n+                    data = lazy_elemwise_func(data, transform, signed_dtype)\n+                    if \"_FillValue\" in attrs:\n+                        new_fill = signed_dtype.type(attrs[\"_FillValue\"])\n+                        attrs[\"_FillValue\"] = new_fill\n+                else:\n+                    warnings.warn(\n+                        \"variable %r has _Unsigned attribute 'false' but is not of unsigned integer type. Ignoring attribute.\" % name,\n+                        SerializationWarning,\n+                        stacklevel=3,\n+                    )\n             else:\n                 warnings.warn(\n-                    \"variable %r has _Unsigned attribute but is not \"\n-                    \"of integer type. Ignoring attribute.\" % name,\n+                    \"variable %r has unrecognized _Unsigned attribute value %r. Ignoring attribute.\" % (name, unsigned),\n                     SerializationWarning,\n                     stacklevel=3,\n                 )\n \n         return Variable(dims, data, attrs, encoding)\n+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6461",
        "model_patch": "diff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex a21cf8c2..b4426b07 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1806,10 +1806,11 @@ class Variable(AbstractArray, NdimSizeLenMixin, VariableArithmetic):\n                 if getattr(data, \"shape\", None) is None:\n                     # Reduce has produced a scalar value, not an array-like\n                     data = np.asanyarray(data)[slices]\n-                else:\n-                    data = data[slices]\n-                dims = self.dims\n-            else:\n+if keep_attrs is True:\n+    # When keep_attrs is True we want to use the attributes from self.\n+    # If other is a scalar it won\u2019t have any attributes so using attrs[1] fails.\n+    keep_attrs = lambda attrs, context: attrs[0]\n+\n                 dims = [\n                     adim for n, adim in enumerate(self.dims) if n not in removed_axes\n                 ]\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6599",
        "model_patch": "diff --git a/xarray/core/computation.py b/xarray/core/computation.py\nindex 823cbe02..643fb77a 100644\n--- a/xarray/core/computation.py\n+++ b/xarray/core/computation.py\n@@ -1906,6 +1906,200 @@ def polyval(\n         {degree_dim: np.arange(max_deg + 1)}, fill_value=0, copy=False\n     )\n     coord = _ensure_numeric(coord)  # type: ignore # https://github.com/python/mypy/issues/1533 ?\n+   # If coordinates are timedelta64, convert them to float seconds\n+    if np.issubdtype(coord.dtype, np.timedelta64):\n+        coord = coord.astype(\"timedelta64[ns]\").astype(\"float64\") / 1e9\n     # using Horner's method\n     # https://en.wikipedia.org/wiki/Horner%27s_method",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6721",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 71646f50..afff0124 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -2121,21 +2121,37 @@ class Dataset(\n         buf.write(\"\\n\".join(lines))\n \n     @property\n-    def chunks(self) -> Mapping[Hashable, tuple[int, ...]]:\n-        \"\"\"\n-        Mapping from dimension names to block lengths for this dataset's data, or None if\n-        the underlying data is not a dask array.\n-        Cannot be modified directly, but can be modified by calling .chunk().\n+@property\n+def chunks(self) -> Mapping[Hashable, tuple[int, ...]]:\n+    \"\"\"\n+    Mapping from dimension names to block lengths for this dataset's data, or None if\n+    the underlying data is not a dask array.\n+    Cannot be modified directly, but can be modified by calling .chunk().\n \n-        Same as Dataset.chunksizes, but maintained for backwards compatibility.\n+    Same as Dataset.chunksizes, but maintained for backwards compatibility.\n \n-        See Also\n-        --------\n-        Dataset.chunk\n-        Dataset.chunksizes\n-        xarray.unify_chunks\n-        \"\"\"\n-        return get_chunksizes(self.variables.values())\n+    See Also\n+    --------\n+    Dataset.chunk\n+    Dataset.chunksizes\n+    xarray.unify_chunks\n+    \"\"\"\n+    chunks = {}\n+    for v in self.variables.values():\n+        if v.encoding is not None and \"chunks\" in v.encoding:\n+            var_chunks = v.encoding[\"chunks\"]\n+        elif hasattr(v.data, \"chunks\"):\n+            var_chunks = v.data.chunks\n+        else:\n+            var_chunks = None\n+        if var_chunks is not None:\n+            for dim, c in zip(v.dims, var_chunks):\n+                if dim in chunks:\n+                    if chunks[dim] != c:\n+                        raise ValueError(f\"Inconsistent chunks along dimension {dim}. Please call unify_chunks().\")\n+                else:\n+                    chunks[dim] = c\n+    return Frozen(chunks)\n \n     @property\n     def chunksizes(self) -> Mapping[Hashable, tuple[int, ...]]:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6744",
        "model_patch": "diff --git a/xarray/core/rolling.py b/xarray/core/rolling.py\nindex aef290f6..156f1cd4 100644\n--- a/xarray/core/rolling.py\n+++ b/xarray/core/rolling.py\n@@ -267,19 +267,26 @@ class DataArrayRolling(Rolling[\"DataArray\"]):\n         # TODO legacy attribute\n         self.window_labels = self.obj[self.dim[0]]\n \n-    def __iter__(self) -> Iterator[tuple[RollingKey, DataArray]]:\n-        if self.ndim > 1:\n-            raise ValueError(\"__iter__ is only supported for 1d-rolling\")\n-        stops = np.arange(1, len(self.window_labels) + 1)\n-        starts = stops - int(self.window[0])\n-        starts[: int(self.window[0])] = 0\n-        for (label, start, stop) in zip(self.window_labels, starts, stops):\n-            window = self.obj.isel({self.dim[0]: slice(start, stop)})\n-\n-            counts = window.count(dim=self.dim[0])\n-            window = window.where(counts >= self.min_periods)\n-\n-            yield (label, window)\n+def __iter__(self) -> Iterator[tuple[RollingKey, DataArray]]:\n+    if self.ndim > 1:\n+        raise ValueError(\"__iter__ is only supported for 1d-rolling\")\n+    stops = np.arange(1, len(self.window_labels) + 1)\n+    starts = stops - int(self.window[0])\n+    starts[: int(self.window[0])] = 0\n+    if self.center[0]:\n+        center_offset = (int(self.window[0]) - 1) // 2\n+    for (orig_label, start, stop) in zip(self.window_labels, starts, stops):\n+        window = self.obj.isel({self.dim[0]: slice(start, stop)})\n+        counts = window.count(dim=self.dim[0])\n+        window = window.where(counts >= self.min_periods)\n+        if self.center[0]:\n+            idx = start + center_offset\n+            if idx >= len(self.window_labels):\n+                idx = len(self.window_labels) - 1\n+            yield (self.window_labels[idx], window)\n+        else:\n+            yield (orig_label, window)\n+\n \n     def construct(\n         self,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6938",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 9dfdb660..983a8cdb 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -566,7 +566,8 @@ class DataArray(\n             )\n         # use private APIs for speed: this is called by _to_temp_dataset(),\n         # which is used in the guts of a lot of operations (e.g., reindex)\n-        variables = self._coords.copy()\n+    indexes = self._indexes.copy()\n+\n         variables[name] = self.variable\n         if shallow_copy:\n             for k in variables:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-6992",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex 620f32f8..a6d99910 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -365,7 +365,8 @@ class DataVariables(Mapping[Any, \"DataArray\"]):\n         )\n \n     def __len__(self) -> int:\n-        return len(self._dataset._variables) - len(self._dataset._coord_names)\n+        return len(set(self._dataset._variables) - set(self._dataset._coord_names))\n+\n \n     def __contains__(self, key: Hashable) -> bool:\n         return key in self._dataset._variables and key not in self._dataset._coord_names\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-7229",
        "model_patch": "diff --git a/xarray/core/dataarray.py b/xarray/core/dataarray.py\nindex 72b41fb7..a0ac9c52 100644\n--- a/xarray/core/dataarray.py\n+++ b/xarray/core/dataarray.py\n@@ -861,6 +861,438 @@ class DataArray(\n         \"\"\"Attribute for location based indexing like pandas.\"\"\"\n         return _LocIndexer(self)\n \n+def where(self, cond, other=dtypes.NA, keep_attrs: bool | None = None) -> DataArray:\n+    result = ops.where_method(self, cond, other, keep_attrs=keep_attrs)\n+    if keep_attrs:\n+        # If keep_attrs is True, copy coordinate attributes from self to result.\n+        for name, coord in self.coords.items():\n+            if name in result.coords:\n+                result.coords[name].attrs = coord.attrs.copy()\n+    return result\n     @property\n     def attrs(self) -> dict[Any, Any]:\n         \"\"\"Dictionary storing arbitrary metadata with this array.\"\"\"",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-7233",
        "model_patch": "diff --git a/xarray/core/dataset.py b/xarray/core/dataset.py\nindex dbf5e46b..cf729cf2 100644\n--- a/xarray/core/dataset.py\n+++ b/xarray/core/dataset.py\n@@ -9095,9 +9095,9 @@ class Dataset(\n         See Also\n         --------\n         core.rolling.DatasetCoarsen\n-        DataArray.coarsen\n-        \"\"\"\n-        from .rolling import DatasetCoarsen\n+        # Finalize the coarsened dataset by replacing the variables,\n+        # making sure to preserve non\u2010dimensional coordinate names.\n+        return self._ds._replace(variables, coord_names=self._ds._coord_names.copy())\n \n         dim = either_dict_or_kwargs(dim, window_kwargs, \"coarsen\")\n         return DatasetCoarsen(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pydata__xarray-7393",
        "model_patch": "diff --git a/xarray/core/indexes.py b/xarray/core/indexes.py\nindex f3f03c94..65028c23 100644\n--- a/xarray/core/indexes.py\n+++ b/xarray/core/indexes.py\n@@ -177,10 +177,15 @@ def safe_cast_to_index(array: Any) -> pd.Index:\n     elif isinstance(array, PandasIndexingAdapter):\n         index = array.array\n     else:\n-        kwargs = {}\n-        if hasattr(array, \"dtype\") and array.dtype.kind == \"O\":\n+    kwargs = {}\n+    if hasattr(array, \"dtype\"):\n+        if array.dtype.kind == \"O\":\n             kwargs[\"dtype\"] = object\n-        index = pd.Index(np.asarray(array), **kwargs)\n+        else:\n+            # explicitly pass the current dtype so that pandas preserves it\n+            kwargs[\"dtype\"] = array.dtype\n+    index = pd.Index(np.asarray(array, dtype=array.dtype if hasattr(array, \"dtype\") else None), **kwargs)\n+\n \n     return _maybe_cast_to_cftimeindex(index)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-4551",
        "model_patch": "diff --git a/pylint/pyreverse/writer.py b/pylint/pyreverse/writer.py\nindex 0d80bb9ca..66bacd951 100644\n--- a/pylint/pyreverse/writer.py\n+++ b/pylint/pyreverse/writer.py\n@@ -133,13 +133,22 @@ class DotWriter(DiagramWriter):\n             label = \"\u00abinterface\u00bb\\\\n%s\" % label\n         if not self.config.only_classnames:\n             label = r\"{}|{}\\l|\".format(label, r\"\\l\".join(obj.attrs))\n-            for func in obj.methods:\n-                if func.args.args:\n-                    args = [arg.name for arg in func.args.args if arg.name != \"self\"]\n-                else:\n-                    args = []\n-                label = r\"{}{}({})\\l\".format(label, func.name, \", \".join(args))\n-            label = \"{%s}\" % label\n+for func in obj.methods:\n+    args_list = []\n+    if func.args.args:\n+        for arg in func.args.args:\n+            if arg.name == \"self\":\n+                continue\n+            if hasattr(arg, \"annotation\") and arg.annotation is not None:\n+                try:\n+                    annotation = (arg.annotation.as_string() if hasattr(arg.annotation, \"as_string\") else str(arg.annotation))\n+                except Exception:\n+                    annotation = \"?\"\n+                args_list.append(f\"{arg.name} : {annotation}\")\n+            else:\n+                args_list.append(arg.name)\n+    label = r\"{}{}({})\\l\".format(label, func.name, \", \".join(args_list))\n+\n         if is_exception(obj.node):\n             return dict(fontcolor=\"red\", label=label, shape=\"record\")\n         return dict(label=label, shape=\"record\")\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-4604",
        "model_patch": "diff --git a/pylint/checkers/imports.py b/pylint/checkers/imports.py\nindex ceadaef90..c6c1b2091 100644\n--- a/pylint/checkers/imports.py\n+++ b/pylint/checkers/imports.py\n@@ -630,11 +630,1140 @@ class ImportsChecker(DeprecatedMixin, BaseChecker):\n             if all(valid_targets):\n                 return\n         self._first_non_import_node = node\n+   # Replace the default assign visitor in order to process type comments.\n+    def visit_assign(self, node):\n+        if getattr(node, 'type_comment', None):\n+            self._process_type_comment(node)\n+        self.compute_first_non_import_node(node)\n     visit_tryfinally = (\n         visit_tryexcept\n     ) = (\n         visit_assignattr\n+    ) = (\n+        visit_ifexp\n+    ) = visit_comprehension = visit_expr = visit_if = compute_first_non_import_node\n+ef _process_type_comment(self, node):\n+        \"\"\"Process the type comment on an assignment node.\n+        Extract names from the type comment and mark any imported module\n+        as used if one of its identifiers is referenced.\n+        \"\"\"\n+        try:\n+            type_expr = astroid.parse_expr(node.type_comment)\n+        except Exception:\n+            return\n+        for name_node in type_expr.nodes_of_class(astroid.Name):\n+            candidate = name_node.name\n+            for import_node, imp_mod in self._imports_stack:\n+                parts = imp_mod.split('.')\n+                # Check if the candidate matches the base of an import\n+                # (for \"import abc\") or the last part (for \"from abc import ABC\")\n+                if candidate == parts[0] or candidate == parts[-1]:\n+                    self._add_imported_module(node, imp_mod)\n     ) = (\n         visit_assign\n     ) = (",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-4661",
        "model_patch": "diff --git a/pylint/constants.py b/pylint/constants.py\nindex 628e2001d..4e773a491 100644\n--- a/pylint/constants.py\n+++ b/pylint/constants.py\n@@ -3,6 +3,17 @@\n import builtins\n import platform\n import sys\n+mport os\n import astroid\n \n@@ -51,3 +62,401 @@ class WarningScope:\n full_version = f\"\"\"pylint {__version__}\n astroid {astroid.__version__}\n Python {sys.version}\"\"\"\n+ XDG Base Directory compliance: define the data storage directory.\n+# According to the XDG Base Directory Specification, user data files should reside in\n+# $XDG_DATA_HOME/pylint, where XDG_DATA_HOME defaults to ~/.local/share if not set.\n+XDG_DATA_HOME = os.environ.get(\"XDG_DATA_HOME\", os.path.join(os.path.expanduser(\"~\"), \".local\", \"share\"))\n+DATA_DIR = os.path.join(XDG_DATA_HOME, \"pylint\")",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-4970",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-6386",
        "model_patch": "diff --git a/pylint/config/option.py b/pylint/config/option.py\nindex 255450977..10f6da880 100644\n--- a/pylint/config/option.py\n+++ b/pylint/config/option.py\n@@ -178,6 +178,394 @@ class Option(optparse.Option):\n             DeprecationWarning,\n         )\n         super().__init__(*opts, **attrs)\n+       # FIX: Ensure the verbose option works as a flag (no argument required)\n+        # when using the short option (-v). Without this change, the verbose option\n+        # were defined with a type (e.g. \"yn\") and thus optparse expected an argument.\n+        if self.dest == \"verbose\":\n+            self.action = \"store_true\"\n+            self.type = None\n+            self.nargs = 0\n         if hasattr(self, \"hide\") and self.hide:\n             self.help = optparse.SUPPRESS_HELP",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-6528",
        "model_patch": "diff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\nindex b20cd873c..26d0fb73a 100644\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -60,12 +60,15 @@ def expand_modules(\n     path = sys.path.copy()\n \n     for something in files_or_modules:\n-        basename = os.path.basename(something)\n-        if (\n-            basename in ignore_list\n-            or _is_in_ignore_list_re(os.path.basename(something), ignore_list_re)\n-            or _is_in_ignore_list_re(something, ignore_list_paths_re)\n-        ):\n+norm_something = os.path.normpath(something)\n+parts = norm_something.split(os.sep)\n+if (\n+    os.path.basename(something) in ignore_list\n+    or _is_in_ignore_list_re(os.path.basename(something), ignore_list_re)\n+    or any(_is_in_ignore_list_re(part, ignore_list_re) for part in parts)\n+    or _is_in_ignore_list_re(something, ignore_list_paths_re)\n+):\n+\n             continue\n         module_path = get_python_path(something)\n         additional_search_path = [\".\", module_path] + path\n@@ -128,10 +131,14 @@ def expand_modules(\n             ):\n                 if filepath == subfilepath:\n                     continue\n-                if _is_in_ignore_list_re(\n-                    os.path.basename(subfilepath), ignore_list_re\n-                ) or _is_in_ignore_list_re(subfilepath, ignore_list_paths_re):\n-                    continue\n+norm_subfile = os.path.normpath(subfilepath)\n+sub_parts = norm_subfile.split(os.sep)\n+if (\n+    _is_in_ignore_list_re(os.path.basename(subfilepath), ignore_list_re)\n+    or any(_is_in_ignore_list_re(part, ignore_list_re) for part in sub_parts)\n+    or _is_in_ignore_list_re(subfilepath, ignore_list_paths_re)\n+):\n+\n \n                 modpath = _modpath_from_file(\n                     subfilepath, is_namespace, path=additional_search_path\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-6903",
        "model_patch": "diff --git a/pylint/lint/run.py b/pylint/lint/run.py\nindex a7e5d5574..b690dec23 100644\n--- a/pylint/lint/run.py\n+++ b/pylint/lint/run.py\n@@ -52,12 +52,14 @@ def _query_cpu() -> int | None:\n         with open(\"/sys/fs/cgroup/cpu/cpu.cfs_period_us\", encoding=\"utf-8\") as file:\n             cpu_period = int(file.read().rstrip())\n         # Divide quota by period and you should get num of allotted CPU to the container, rounded down if fractional.\n-        avail_cpu = int(cpu_quota / cpu_period)\n+        avail_cpu = max(int(cpu_quota / cpu_period), 1)\n+\n     elif Path(\"/sys/fs/cgroup/cpu/cpu.shares\").is_file():\n         with open(\"/sys/fs/cgroup/cpu/cpu.shares\", encoding=\"utf-8\") as file:\n             cpu_shares = int(file.read().rstrip())\n         # For AWS, gives correct value * 1024.\n-        avail_cpu = int(cpu_shares / 1024)\n+        avail_cpu = max(int(cpu_shares / 1024), 1)\n+\n     return avail_cpu\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-7080",
        "model_patch": "diff --git a/pylint/lint/expand_modules.py b/pylint/lint/expand_modules.py\nindex 5cacc0371..f580aeefd 100644\n--- a/pylint/lint/expand_modules.py\n+++ b/pylint/lint/expand_modules.py\n@@ -43,7 +43,9 @@ def get_python_path(filepath: str) -> str:\n \n def _is_in_ignore_list_re(element: str, ignore_list_re: list[Pattern[str]]) -> bool:\n     \"\"\"Determines if the element is matched in a regex ignore-list.\"\"\"\n-    return any(file_pattern.match(element) for file_pattern in ignore_list_re)\n+    normalized = element.replace(os.sep, \"/\")\n+    return any(file_pattern.match(normalized) for file_pattern in ignore_list_re)\n+\n \n \n def _is_ignored_file(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-7277",
        "model_patch": "diff --git a/pylint/__init__.py b/pylint/__init__.py\nindex 9f3dd74e6..70eff2d1d 100644\n--- a/pylint/__init__.py\n+++ b/pylint/__init__.py\n@@ -96,10 +96,11 @@ def modify_sys_path() -> None:\n       if pylint is installed in an editable configuration (as the last item).\n       https://github.com/PyCQA/pylint/issues/4161\n     \"\"\"\n-    sys.path.pop(0)\n-    env_pythonpath = os.environ.get(\"PYTHONPATH\", \"\")\n-    cwd = os.getcwd()\n-    if env_pythonpath.startswith(\":\") and env_pythonpath not in (f\":{cwd}\", \":.\"):\n+    import os\n+    if sys.path and sys.path[0] in (\"\", \".\", os.getcwd()):\n+        # Only remove the first entry if it is one of the default values.\n+        sys.path.pop(0)\n+\n         sys.path.pop(0)\n     elif env_pythonpath.endswith(\":\") and env_pythonpath not in (f\"{cwd}:\", \".:\"):\n         sys.path.pop(1)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pylint-dev__pylint-8898",
        "model_patch": "diff --git a/pylint/config/argument.py b/pylint/config/argument.py\nindex 30a5fd175..52267bdfb 100644\n--- a/pylint/config/argument.py\n+++ b/pylint/config/argument.py\n@@ -112,13 +112,21 @@ def _regex_transformer(value: str) -> Pattern[str]:\n \n \n def _regexp_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n-    \"\"\"Transforms a comma separated list of regular expressions.\"\"\"\n+    \"\"\"Transforms a comma separated list of regular expressions,\n+    allowing commas to be escaped with a backslash.\n+    \"\"\"\n+    import re\n     patterns: list[Pattern[str]] = []\n-    for pattern in _csv_transformer(value):\n-        patterns.append(_regex_transformer(pattern))\n+    # Split on commas that are not escaped\n+    for part in re.split(r'(?<!\\\\),', value):\n+        # Replace the escape sequence for commas and strip whitespace.\n+        pattern = part.replace(r'\\,', ',').strip()\n+        if pattern:\n+            patterns.append(_regex_transformer(pattern))\n     return patterns\n \n \n+\n def _regexp_paths_csv_transfomer(value: str) -> Sequence[Pattern[str]]:\n     \"\"\"Transforms a comma separated list of regular expressions paths.\"\"\"\n     patterns: list[Pattern[str]] = []\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-10051",
        "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex a4f4214b1..df9fc5c07 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -438,9 +438,16 @@ class LogCaptureFixture:\n         \"\"\"\n         return [r.getMessage() for r in self.records]\n \n-    def clear(self) -> None:\n-        \"\"\"Reset the list of log records and the captured log text.\"\"\"\n-        self.handler.reset()\n+def clear(self) -> None:\n+    \"\"\"Reset the list of log records and the captured log text.\n+    \n+    Also update cached phase-specific records to point to the new, empty handler records.\n+    \"\"\"\n+    self.handler.reset()\n+    records_dict = self._item.stash.get(caplog_records_key)\n+    if records_dict and isinstance(records_dict, dict):\n+        for key in list(records_dict.keys()):\n+            records_dict[key] = self.handler.records\n \n     def set_level(self, level: Union[int, str], logger: Optional[str] = None) -> None:\n         \"\"\"Set the level of a logger for the duration of a test.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-10081",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 851e4943b..2358039d3 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -316,7 +316,8 @@ class TestCaseFunction(Function):\n             # Arguably we could always postpone tearDown(), but this changes the moment where the\n             # TestCase instance interacts with the results object, so better to only do it\n             # when absolutely needed.\n-            if self.config.getoption(\"usepdb\") and not _is_skipped(self.obj):\n+            if self.config.getoption(\"usepdb\") and not _is_skipped(self.parent.obj):\n+\n                 self._explicit_tearDown = self._testcase.tearDown\n                 setattr(self._testcase, \"tearDown\", lambda *args: None)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-10356",
        "model_patch": "diff --git a/src/_pytest/mark/structures.py b/src/_pytest/mark/structures.py\nindex 800a25c92..bd4d2baba 100644\n--- a/src/_pytest/mark/structures.py\n+++ b/src/_pytest/mark/structures.py\n@@ -356,11 +356,26 @@ class MarkDecorator:\n \n \n def get_unpacked_marks(obj: object) -> Iterable[Mark]:\n-    \"\"\"Obtain the unpacked marks that are stored on an object.\"\"\"\n-    mark_list = getattr(obj, \"pytestmark\", [])\n-    if not isinstance(mark_list, list):\n-        mark_list = [mark_list]\n-    return normalize_mark_list(mark_list)\n+    # If obj is a class, try to merge markers from all bases (MRO)\n+    try:\n+        mro = obj.__mro__\n+    except AttributeError:\n+        mro = None\n+\n+    if mro is None:\n+        mark_list = getattr(obj, \"pytestmark\", [])\n+        if not isinstance(mark_list, list):\n+            mark_list = [mark_list]\n+        return normalize_mark_list(mark_list)\n+    else:\n+        marks = []\n+        for cls in mro:\n+            mark_list = getattr(cls, \"pytestmark\", [])\n+            if not isinstance(mark_list, list):\n+                mark_list = [mark_list]\n+            marks.extend(list(normalize_mark_list(mark_list)))\n+        return marks\n+\n \n \n def normalize_mark_list(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5262",
        "model_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\nindex 25eab7fdf..524e7aac1 100644\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -442,10 +442,17 @@ class EncodedFile(object):\n         data = \"\".join(linelist)\n         self.write(data)\n \n-    @property\n-    def name(self):\n-        \"\"\"Ensure that file.name is a string.\"\"\"\n-        return repr(self.buffer)\n+@property\n+def name(self):\n+    \"\"\"Ensure that file.name is a string.\"\"\"\n+    return repr(self.buffer)\n+\n+@property\n+def mode(self):\n+    \"\"\"Override mode property to report text mode (without 'b') so that\n+    consumers like youtube-dl write str rather than bytes.\n+    \"\"\"\n+    return self.buffer.mode.replace(\"b\", \"\")\n \n     def __getattr__(self, name):\n         return getattr(object.__getattribute__(self, \"buffer\"), name)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5631",
        "model_patch": "diff --git a/src/_pytest/compat.py b/src/_pytest/compat.py\nindex d238061b4..77fccc3b8 100644\n--- a/src/_pytest/compat.py\n+++ b/src/_pytest/compat.py\n@@ -67,9 +67,10 @@ def num_mock_patch_args(function):\n     mock_modules = [sys.modules.get(\"mock\"), sys.modules.get(\"unittest.mock\")]\n     if any(mock_modules):\n         sentinels = [m.DEFAULT for m in mock_modules if m is not None]\n-        return len(\n-            [p for p in patchings if not p.attribute_name and p.new in sentinels]\n-        )\n+\t        return len(\n+\t            [p for p in patchings if not p.attribute_name and any(p.new is s for s in sentinels)]\n+\t        )\n+\n     return len(patchings)\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5787",
        "model_patch": "diff --git a/src/_pytest/reports.py b/src/_pytest/reports.py\nindex 4682d5b6e..6d0b41a95 100644\n--- a/src/_pytest/reports.py\n+++ b/src/_pytest/reports.py\n@@ -178,12 +178,39 @@ class BaseReport:\n \n             reprtraceback[\"reprentries\"] = new_entries\n \n-            return {\n+            ser = {\n                 \"reprcrash\": reprcrash,\n                 \"reprtraceback\": reprtraceback,\n                 \"sections\": rep.longrepr.sections,\n             }\n \n+            # If the longrepr has a chain (from chained exceptions) then serialize it.\n+            chain = None\n+            if hasattr(rep.longrepr, \"chain\") and rep.longrepr.chain:\n+                chain = []\n+                for cause in rep.longrepr.chain:\n+                    entry = {\"reprcrash\": cause.reprcrash.__dict__.copy()}\n+                    if hasattr(cause, \"reprtraceback\") and cause.reprtraceback:\n+                        rb = cause.reprtraceback.__dict__.copy()\n+                        new_entries = []\n+                        for entry_inner in rb.get(\"reprentries\", []):\n+                            edata = {\n+                                \"type\": type(entry_inner).__name__,\n+                                \"data\": entry_inner.__dict__.copy(),\n+                            }\n+                            for key, value in edata[\"data\"].items():\n+                                if hasattr(value, \"__dict__\"):\n+                                    edata[\"data\"][key] = value.__dict__.copy()\n+                            new_entries.append(edata)\n+                        rb[\"reprentries\"] = new_entries\n+                        entry[\"reprtraceback\"] = rb\n+                    chain.append(entry)\n+            if chain:\n+                ser[\"chain\"] = chain\n+\n+            return ser\n+\n+\n         d = self.__dict__.copy()\n         if hasattr(self.longrepr, \"toterminal\"):\n             if hasattr(self.longrepr, \"reprtraceback\") and hasattr(\n@@ -254,10 +281,29 @@ class BaseReport:\n                     reprtraceback=ReprTraceback(**reprtraceback),\n                     reprcrash=ReprFileLocation(**reprcrash),\n                 )\n+                    # If a chain was serialized, reconstruct it into exception_info.chain.\n+                    if \"chain\" in reportdict[\"longrepr\"]:\n+                        exception_info.chain = []\n+                        for ch in reportdict[\"longrepr\"][\"chain\"]:\n+                            try:\n+                                # Rebuild a chained exception info similar to the parent\n+                                if \"reprtraceback\" in ch:\n+                                    rep_tb = ReprTraceback(**ch[\"reprtraceback\"])\n+                                else:\n+                                    rep_tb = None\n+                                cause = ReprExceptionInfo(\n+                                    reprtraceback=rep_tb,\n+                                    reprcrash=ReprFileLocation(**ch[\"reprcrash\"])\n+                                )\n+                                exception_info.chain.append(cause)\n+                            except Exception:\n+                                # In case of failure, skip this entry.\n+                                continue\n+\n+                    for section in reportdict[\"longrepr\"][\"sections\"]:\n+                        exception_info.addsection(*section)\n+                    reportdict[\"longrepr\"] = exception_info\n \n-                for section in reportdict[\"longrepr\"][\"sections\"]:\n-                    exception_info.addsection(*section)\n-                reportdict[\"longrepr\"] = exception_info\n \n         return cls(**reportdict)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5809",
        "model_patch": "diff --git a/src/_pytest/pastebin.py b/src/_pytest/pastebin.py\nindex 41576a615..dfe8b02b9 100644\n--- a/src/_pytest/pastebin.py\n+++ b/src/_pytest/pastebin.py\n@@ -77,11 +77,12 @@ def create_new_paste(contents):\n         from urllib.request import urlopen\n         from urllib.parse import urlencode\n \n-    params = {\n-        \"code\": contents,\n-        \"lexer\": \"python3\" if sys.version_info[0] >= 3 else \"python\",\n-        \"expiry\": \"1week\",\n-    }\n+params = {\n+    \"code\": contents,\n+    \"lexer\": \"text\",\n+    \"expiry\": \"1week\",\n+}\n+\n     url = \"https://bpaste.net\"\n     response = urlopen(url, data=urlencode(params).encode(\"ascii\")).read()\n     m = re.search(r'href=\"/raw/(\\w+)\"', response.decode(\"utf-8\"))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-5840",
        "model_patch": "diff --git a/src/_pytest/nodes.py b/src/_pytest/nodes.py\nindex 9b78dca38..c713b4d60 100644\n--- a/src/_pytest/nodes.py\n+++ b/src/_pytest/nodes.py\n@@ -362,13 +362,18 @@ class FSCollector(Collector):\n         session = session or parent.session\n \n         if nodeid is None:\n-            nodeid = self.fspath.relto(session.config.rootdir)\n-\n+            try:\n+                rootdir = str(session.config.rootdir)\n+                fspath_str = str(self.fspath)\n+                nodeid = os.path.relpath(fspath_str, rootdir)\n+            except Exception:\n+                nodeid = self.fspath.relto(session.config.rootdir)\n             if not nodeid:\n                 nodeid = _check_initialpaths_for_relpath(session, fspath)\n             if nodeid and os.sep != SEP:\n                 nodeid = nodeid.replace(os.sep, SEP)\n \n+\n         super().__init__(name, parent, config, session, nodeid=nodeid, fspath=fspath)\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-6197",
        "model_patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\nindex 306e5f217..b6cd7ba6e 100644\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -97,13 +97,14 @@ def pytest_addoption(parser):\n         help=\"disable string escape non-ascii characters, might cause unwanted \"\n         \"side effects(use at your own risk)\",\n     )\n+    # Do not collect __init__.py files to avoid unintended importing of package initializers.\n+    if path.basename == \"__init__.py\":\n+        return None\n+\n+    if path.ext == \".py\":\n+        # existing logic to decide if file should be collected as a test module\n+        # ... (rest of collection logic)\n \n-    group.addoption(\n-        \"--import-mode\",\n-        default=\"prepend\",\n-        choices=[\"prepend\", \"append\"],\n-        dest=\"importmode\",\n-        help=\"prepend/append to sys.path when importing test modules, \"\n         \"default is to prepend.\",\n     )\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-6202",
        "model_patch": "diff --git a/src/_pytest/python.py b/src/_pytest/python.py\nindex b8b365ad3..e673f613f 100644\n--- a/src/_pytest/python.py\n+++ b/src/_pytest/python.py\n@@ -286,7 +286,8 @@ class PyobjMixin(PyobjContext):\n             parts.append(name)\n         parts.reverse()\n         s = \".\".join(parts)\n-        return s.replace(\".[\", \"[\")\n+        return s\n+\n \n     def reportinfo(self):\n         # XXX caching?\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7205",
        "model_patch": "diff --git a/src/_pytest/setuponly.py b/src/_pytest/setuponly.py\nindex c9cc589ff..ded9b3980 100644\n--- a/src/_pytest/setuponly.py\n+++ b/src/_pytest/setuponly.py\n@@ -1,4 +1,47 @@\n import pytest\n+rom _pytest._io.saferepr import saferepr\n def pytest_addoption(parser):\n@@ -66,7 +109,8 @@ def _show_fixture_action(fixturedef, msg):\n             tw.write(\" (fixtures used: {})\".format(\", \".join(deps)))\n \n     if hasattr(fixturedef, \"cached_param\"):\n-        tw.write(\"[{}]\".format(fixturedef.cached_param))\n+        tw.write(\"[{}]\".format(saferepr(fixturedef.cached_param)))\n     tw.flush()",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7236",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 773f545af..57169bdc5 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -220,7 +220,7 @@ class TestCaseFunction(Function):\n             # arguably we could always postpone tearDown(), but this changes the moment where the\n             # TestCase instance interacts with the results object, so better to only do it\n             # when absolutely needed\n-            if self.config.getoption(\"usepdb\"):\n+            if self.config.getoption(\"usepdb\") and not getattr(self._testcase, \"__unittest_skip__\", False):\n                 self._explicit_tearDown = self._testcase.tearDown\n                 setattr(self._testcase, \"tearDown\", lambda *args: None)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7324",
        "model_patch": "diff --git a/src/_pytest/assertion/rewrite.py b/src/_pytest/assertion/rewrite.py\nindex cec0c5501..45858006c 100644\n--- a/src/_pytest/assertion/rewrite.py\n+++ b/src/_pytest/assertion/rewrite.py\n@@ -672,8 +672,9 @@ class AssertionRewriter(ast.NodeVisitor):\n         # Insert some special imports at the top of the module but after any\n         # docstrings and __future__ imports.\n         aliases = [\n-            ast.alias(\"builtins\", \"@py_builtins\"),\n-            ast.alias(\"_pytest.assertion.rewrite\", \"@pytest_ar\"),\n+            ast.alias(\"builtins\", \"_py_builtins\"),\n+            ast.alias(\"_pytest.assertion.rewrite\", \"_pytest_ar\"),\n+\n         ]\n         doc = getattr(mod, \"docstring\", None)\n         expect_docstring = doc is None\n@@ -752,13 +753,15 @@ class AssertionRewriter(ast.NodeVisitor):\n \n     def helper(self, name: str, *args: ast.expr) -> ast.expr:\n         \"\"\"Call a helper in this module.\"\"\"\n-        py_name = ast.Name(\"@pytest_ar\", ast.Load())\n+        py_name = ast.Name(\"_pytest_ar\", ast.Load())\n+\n         attr = ast.Attribute(py_name, name, ast.Load())\n         return ast.Call(attr, list(args), [])\n \n     def builtin(self, name: str) -> ast.Attribute:\n         \"\"\"Return the builtin called *name*.\"\"\"\n-        builtin_name = ast.Name(\"@py_builtins\", ast.Load())\n+        builtin_name = ast.Name(\"_py_builtins\", ast.Load())\n+\n         return ast.Attribute(builtin_name, name, ast.Load())\n \n     def explanation_param(self, expr: ast.expr) -> str:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7432",
        "model_patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\nindex 7bd975e5a..d8ffba578 100644\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -270,8 +270,6 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n         else:\n             rep.longrepr = \"Unexpected success\"\n         rep.outcome = \"failed\"\n-    elif item.config.option.runxfail:\n-        pass  # don't interfere\n     elif call.excinfo and isinstance(call.excinfo.value, xfail.Exception):\n         assert call.excinfo.value.msg is not None\n         rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7490",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7521",
        "model_patch": "diff --git a/src/_pytest/capture.py b/src/_pytest/capture.py\nindex 3f9c60fb9..43e87a750 100644\n--- a/src/_pytest/capture.py\n+++ b/src/_pytest/capture.py\n@@ -388,8 +388,10 @@ class FDCaptureBinary:\n                 TemporaryFile(buffering=0),  # type: ignore[arg-type]\n                 encoding=\"utf-8\",\n                 errors=\"replace\",\n+                newline=\"\",\n                 write_through=True,\n             )\n+\n             if targetfd in patchsysdict:\n                 self.syscapture = SysCapture(targetfd, self.tmpfile)\n             else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7571",
        "model_patch": "diff --git a/src/_pytest/logging.py b/src/_pytest/logging.py\nindex 11031f2f2..ecfce6172 100644\n--- a/src/_pytest/logging.py\n+++ b/src/_pytest/logging.py\n@@ -357,6 +357,194 @@ class LogCaptureFixture:\n             logger = logging.getLogger(logger_name)\n             logger.setLevel(level)\n \n+        # Restore the log capture handler\u2019s level to the default,\n+        # ensuring that subsequent tests see the initial (NOTSET) level.\n+        self.handler.setLevel(logging.NOTSET)\n     @property\n     def handler(self) -> LogCaptureHandler:\n         \"\"\"",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-7982",
        "model_patch": "diff --git a/src/_pytest/pathlib.py b/src/_pytest/pathlib.py\nindex f0bdb1481..3f845caf0 100644\n--- a/src/_pytest/pathlib.py\n+++ b/src/_pytest/pathlib.py\n@@ -29,10 +29,10 @@ from typing import Union\n import py\n \n from _pytest.compat import assert_never\n-from _pytest.outcomes import skip\n-from _pytest.warning_types import PytestWarning\n-\n-LOCK_TIMEOUT = 60 * 60 * 24 * 3\n+    p = Path(path)\n+    # Always resolve symlinks so that symlinked directories\n+    # are treated as the real target, restoring pre-6.1.0 behavior.\n+    return p.resolve()\n \n \n _AnyPurePath = TypeVar(\"_AnyPurePath\", bound=PurePath)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "pytest-dev__pytest-8399",
        "model_patch": "diff --git a/src/_pytest/unittest.py b/src/_pytest/unittest.py\nindex 719eb4e88..9d7d03579 100644\n--- a/src/_pytest/unittest.py\n+++ b/src/_pytest/unittest.py\n@@ -140,12 +140,18 @@ def _make_xunit_fixture(\n         def cleanup(*args):\n             pass\n \n+    fixture_name = (\n+        f\"_unittest_{setup_name}_fixture_{obj.__qualname__}\"\n+        if setup_name == \"setUpClass\"\n+        else f\"unittest_{setup_name}_fixture_{obj.__qualname__}\"\n+    )\n     @pytest.fixture(\n         scope=scope,\n         autouse=True,\n         # Use a unique name to speed up lookup.\n-        name=f\"unittest_{setup_name}_fixture_{obj.__qualname__}\",\n+        name=fixture_name,\n     )\n+\n     def fixture(self, request: FixtureRequest) -> Generator[None, None, None]:\n         if _is_skipped(self):\n             reason = self.__unittest_skip_why__\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-10297",
        "model_patch": "diff --git a/sklearn/linear_model/ridge.py b/sklearn/linear_model/ridge.py\nindex 911c74ae3..68023a8f7 100644\n--- a/sklearn/linear_model/ridge.py\n+++ b/sklearn/linear_model/ridge.py\n@@ -1332,12 +1332,13 @@ class RidgeClassifierCV(LinearClassifierMixin, _BaseRidgeCV):\n     a one-versus-all approach. Concretely, this is implemented by taking\n     advantage of the multi-variate response support in Ridge.\n     \"\"\"\n-    def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n-                 normalize=False, scoring=None, cv=None, class_weight=None):\n-        super(RidgeClassifierCV, self).__init__(\n-            alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n-            scoring=scoring, cv=cv)\n-        self.class_weight = class_weight\n+def __init__(self, alphas=(0.1, 1.0, 10.0), fit_intercept=True,\n+             normalize=False, scoring=None, cv=None, class_weight=None,\n+             store_cv_values=False):\n+    super(RidgeClassifierCV, self).__init__(\n+             alphas=alphas, fit_intercept=fit_intercept, normalize=normalize,\n+             scoring=scoring, cv=cv, store_cv_values=store_cv_values)\n+    self.class_weight = class_weight\n \n     def fit(self, X, y, sample_weight=None):\n         \"\"\"Fit the ridge classifier.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-10844",
        "model_patch": "diff --git a/sklearn/metrics/cluster/supervised.py b/sklearn/metrics/cluster/supervised.py\nindex a987778ae..5b633592c 100644\n--- a/sklearn/metrics/cluster/supervised.py\n+++ b/sklearn/metrics/cluster/supervised.py\n@@ -856,7 +856,8 @@ def fowlkes_mallows_score(labels_true, labels_pred, sparse=False):\n     tk = np.dot(c.data, c.data) - n_samples\n     pk = np.sum(np.asarray(c.sum(axis=0)).ravel() ** 2) - n_samples\n     qk = np.sum(np.asarray(c.sum(axis=1)).ravel() ** 2) - n_samples\n-    return tk / np.sqrt(pk * qk) if tk != 0. else 0.\n+    return np.sqrt(tk / float(pk)) * np.sqrt(tk / float(qk)) if tk != 0. else 0.\n+\n \n \n def entropy(labels):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-10908",
        "model_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex 9b1ebd632..79cf2b820 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -993,10 +993,10 @@ class CountVectorizer(BaseEstimator, VectorizerMixin):\n \n     def get_feature_names(self):\n         \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n+        if self.vocabulary is not None and not hasattr(self, \"vocabulary_\"):\n+            self._validate_vocabulary()\n         self._check_vocabulary()\n-\n-        return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n-                                     key=itemgetter(1))]\n+        return [t for t, i in sorted(six.iteritems(self.vocabulary_), key=itemgetter(1))]\n \n \n def _make_int_array():\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-11310",
        "model_patch": "diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\nindex 99d6096af..490564696 100644\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -33,6 +33,19 @@ from ..externals import six\n from ..utils import check_random_state\n from ..utils.fixes import sp_version\n from ..utils.fixes import MaskedArray\n+mport time\n from ..utils.random import sample_without_replacement\n from ..utils.validation import indexable, check_is_fitted\n from ..utils.metaestimators import if_delegate_has_method\n@@ -763,13 +776,15 @@ class BaseSearchCV(six.with_metaclass(ABCMeta, BaseEstimator,\n             self.best_score_ = results[\"mean_test_%s\" % refit_metric][\n                 self.best_index_]\n \n-        if self.refit:\n-            self.best_estimator_ = clone(base_estimator).set_params(\n-                **self.best_params_)\n-            if y is not None:\n-                self.best_estimator_.fit(X, y, **fit_params)\n-            else:\n-                self.best_estimator_.fit(X, **fit_params)\n+if self.refit:\n+    t_start = time.time()\n+    self.best_estimator_ = clone(base_estimator).set_params(\n+        **self.best_params_)\n+    if y is not None:\n+        self.best_estimator_.fit(X, y, **fit_params)\n+    else:\n+        self.best_estimator_.fit(X, **fit_params)\n+    self.refit_time_ = time.time() - t_start\n \n         # Store the only scorer not as a dict for single metric evaluation\n         self.scorer_ = scorers if self.multimetric_ else scorers['score']",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-11578",
        "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex e4ea696ce..2a60105d2 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,8 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+log_reg = LogisticRegression(fit_intercept=fit_intercept, multi_class=multi_class)\n+\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-12585",
        "model_patch": "diff --git a/sklearn/base.py b/sklearn/base.py\nindex 56ffb18bf..ae116a729 100644\n--- a/sklearn/base.py\n+++ b/sklearn/base.py\n@@ -46,15 +46,20 @@ def clone(estimator, safe=True):\n     \"\"\"\n     estimator_type = type(estimator)\n     # XXX: not handling dictionaries\n-    if estimator_type in (list, tuple, set, frozenset):\n-        return estimator_type([clone(e, safe=safe) for e in estimator])\n-    elif not hasattr(estimator, 'get_params'):\n-        if not safe:\n-            return copy.deepcopy(estimator)\n-        else:\n-            raise TypeError(\"Cannot clone object '%s' (type %s): \"\n-                            \"it does not seem to be a scikit-learn estimator \"\n-                            \"as it does not implement a 'get_params' methods.\"\n+if estimator_type in (list, tuple, set, frozenset):\n+    return estimator_type([clone(e, safe=safe) for e in estimator])\n+# If the estimator is a class (i.e. a type), return it unchanged.\n+if isinstance(estimator, type):\n+    return estimator\n+elif not hasattr(estimator, 'get_params'):\n+    if not safe:\n+        return copy.deepcopy(estimator)\n+    else:\n+        raise TypeError(\"Cannot clone object '%s' (type %s): \"\n+                        \"it does not seem to be a scikit-learn estimator \"\n+                        \"as it does not implement a 'get_params' methods.\"\n+                        % (repr(estimator), type(estimator)))\n+\n                             % (repr(estimator), type(estimator)))\n     klass = estimator.__class__\n     new_object_params = estimator.get_params(deep=False)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-12682",
        "model_patch": "diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py\nindex a318c957f..110d72b8c 100644\n--- a/sklearn/decomposition/dict_learning.py\n+++ b/sklearn/decomposition/dict_learning.py\n@@ -989,15 +989,18 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n     \"\"\"\n     _required_parameters = [\"dictionary\"]\n \n-    def __init__(self, dictionary, transform_algorithm='omp',\n-                 transform_n_nonzero_coefs=None, transform_alpha=None,\n-                 split_sign=False, n_jobs=None, positive_code=False):\n-        self._set_sparse_coding_params(dictionary.shape[0],\n-                                       transform_algorithm,\n-                                       transform_n_nonzero_coefs,\n-                                       transform_alpha, split_sign, n_jobs,\n-                                       positive_code)\n-        self.components_ = dictionary\n+def __init__(self, dictionary, transform_algorithm='omp',\n+             transform_n_nonzero_coefs=None, transform_alpha=None,\n+             split_sign=False, n_jobs=None, positive_code=False, lasso_max_iter=None):\n+    self._set_sparse_coding_params(dictionary.shape[0],\n+                                   transform_algorithm,\n+                                   transform_n_nonzero_coefs,\n+                                   transform_alpha, split_sign, n_jobs,\n+                                   positive_code)\n+    # new parameter to allow specifying Lasso's max_iter when using \"lasso_cd\"\n+    self.lasso_max_iter = lasso_max_iter\n+    self.components_ = dictionary\n     def fit(self, X, y=None):\n         \"\"\"Do nothing and return the estimator unchanged\n@@ -1016,6 +1019,748 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):\n         self : object\n             Returns the object itself\n         \"\"\"\n+ef transform(self, X, y=None):\n+    # Import the default sparse encoder function. This function is used\n+    # to compute the sparse representation for the data X.\n+    from sklearn.decomposition.dict_learning import sparse_encode\n+    # Build common keyword arguments for sparse_encode\n+    kwargs = dict(algorithm=self.transform_algorithm,\n+                  alpha=self.transform_alpha,\n+                  n_nonzero_coefs=self.transform_n_nonzero_coefs,\n+                  positive=self.positive_code,\n+                  n_jobs=self.n_jobs)\n+    if self.transform_algorithm == 'lasso_cd' and self.lasso_max_iter is not None:\n+        kwargs['max_iter'] = self.lasso_max_iter\n+    return sparse_encode(X, self.components_, **kwargs)\n         return self",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-12973",
        "model_patch": "diff --git a/sklearn/linear_model/least_angle.py b/sklearn/linear_model/least_angle.py\nindex 03b34a0dc..872e27141 100644\n--- a/sklearn/linear_model/least_angle.py\n+++ b/sklearn/linear_model/least_angle.py\n@@ -1479,25 +1479,73 @@ class LassoLarsIC(LassoLars):\n         self.eps = eps\n         self.fit_path = True\n \n-    def fit(self, X, y, copy_X=True):\n-        \"\"\"Fit the model using X, y as training data.\n+def fit(self, X, y, copy_X=None):\n+    \"\"\"Fit the model using X, y as training data.\n \n-        Parameters\n-        ----------\n-        X : array-like, shape (n_samples, n_features)\n-            training data.\n+    Parameters\n+    ----------\n+    X : array-like, shape (n_samples, n_features)\n+        training data.\n \n-        y : array-like, shape (n_samples,)\n-            target values. Will be cast to X's dtype if necessary\n+    y : array-like, shape (n_samples,)\n+        target values. Will be cast to X's dtype if necessary\n+\n+    copy_X : boolean, optional, default None\n+        Controls whether X is copied. If None, the value set during initialization\n+        (self.copy_X) is used.\n+\n+    Returns\n+    -------\n+    self : object\n+        returns an instance of self.\n+    \"\"\"\n+if copy_X is None:\n+    copy_X = self.copy_X\n-        copy_X : boolean, optional, default True\n-            If ``True``, X will be copied; else, it may be overwritten.\n \n-        Returns\n-        -------\n-        self : object\n-            returns an instance of self.\n-        \"\"\"\n         X, y = check_X_y(X, y, y_numeric=True)\n \n         X, y, Xmean, ymean, Xstd = LinearModel._preprocess_data(",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13124",
        "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex 24394f869..b1eda64fe 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -619,8 +619,9 @@ class StratifiedKFold(_BaseKFold):\n             n_splits = 3\n         super().__init__(n_splits, shuffle, random_state)\n \n-    def _make_test_folds(self, X, y=None):\n-        rng = self.random_state\n+    # Convert the provided random_state into a RandomState instance.\n+    rng = check_random_state(self.random_state)\n+\n         y = np.asarray(y)\n         type_of_target_y = type_of_target(y)\n         allowed_target_types = ('binary', 'multiclass')\n@@ -652,10 +653,15 @@ class StratifiedKFold(_BaseKFold):\n         # will break when the data is not 100% stratifiable for all classes.\n         # So we pass np.zeroes(max(c, n_splits)) as data to the KFold\n         per_cls_cvs = [\n-            KFold(self.n_splits, shuffle=self.shuffle,\n-                  random_state=rng).split(np.zeros(max(count, self.n_splits)))\n+            KFold(\n+                self.n_splits,\n+                shuffle=self.shuffle,\n+                random_state=(rng.randint(0, np.iinfo(np.int32).max)\n+                              if self.shuffle else None)\n+            ).split(np.zeros(max(count, self.n_splits)))\n             for count in y_counts]\n \n+\n         test_folds = np.zeros(n_samples, dtype=np.int)\n         for test_fold_indices, per_cls_splits in enumerate(zip(*per_cls_cvs)):\n             for cls, (_, test_split) in zip(unique_y, per_cls_splits):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13135",
        "model_patch": "diff --git a/sklearn/preprocessing/_discretization.py b/sklearn/preprocessing/_discretization.py\nindex dd969c12b..974ac838f 100644\n--- a/sklearn/preprocessing/_discretization.py\n+++ b/sklearn/preprocessing/_discretization.py\n@@ -171,9 +171,11 @@ class KBinsDiscretizer(BaseEstimator, TransformerMixin):\n \n                 # 1D k-means procedure\n                 km = KMeans(n_clusters=n_bins[jj], init=init, n_init=1)\n-                centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n-                bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5\n-                bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]\n+centers = km.fit(column[:, None]).cluster_centers_[:, 0]\n+centers.sort()\n+bin_edges[jj] = (centers[1:] + centers[:-1]) * 0.5\n+bin_edges[jj] = np.r_[col_min, bin_edges[jj], col_max]\n+\n \n         self.bin_edges_ = bin_edges\n         self.n_bins_ = n_bins\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13142",
        "model_patch": "diff --git a/sklearn/mixture/gaussian_mixture.py b/sklearn/mixture/gaussian_mixture.py\nindex 9e3bf3cb4..25705c257 100644\n--- a/sklearn/mixture/gaussian_mixture.py\n+++ b/sklearn/mixture/gaussian_mixture.py\n@@ -753,3 +753,442 @@ class GaussianMixture(BaseMixture):\n             The lower the better.\n         \"\"\"\n         return -2 * self.score(X) * X.shape[0] + 2 * self._n_parameters()\n+   def fit_predict(self, X, y=None):\n+        \"\"\"Fit the model and predict cluster labels for X.\n+        Parameters\n+        ----------\n+        X : array-like, shape (n_samples, n_features)\n+            Input data.\n+        y : Ignored\n+        Returns\n+        -------\n+        labels : array, shape (n_samples,)\n+            Cluster labels for each data point.\n+        \"\"\"\n+        self.fit(X)\n+        return self.predict(X)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13328",
        "model_patch": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 65c686400..620356db6 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -252,6 +252,89 @@ class HuberRegressor(LinearModel, RegressorMixin, BaseEstimator):\n         \"\"\"\n         X, y = check_X_y(\n             X, y, copy=False, accept_sparse=['csr'], y_numeric=True)\n+       if X.dtype == np.bool_:\n+            X = X.astype(np.float64, copy=False)\n         if sample_weight is not None:\n             sample_weight = np.array(sample_weight)\n             check_consistent_length(y, sample_weight)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13439",
        "model_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 7eaf9a46f..8259a7990 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -219,6 +219,121 @@ class Pipeline(_BaseComposition):\n             return self.named_steps[ind]\n         return est\n \n+    def __len__(self):\n+        \"\"\"Return the number of steps in the pipeline.\"\"\"\n+        return len(self.steps)\n     @property\n     def _estimator_type(self):\n         return self.steps[-1][1]._estimator_type",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13496",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-13779",
        "model_patch": "diff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..fad949c42 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,10 +78,13 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n+                if step is None:\n+                    continue\n                 if not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n \n+\n         names, clfs = zip(*self.estimators)\n         self._validate_names(names)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14053",
        "model_patch": "diff --git a/sklearn/tree/export.py b/sklearn/tree/export.py\nindex 1fe11e596..fbd40236b 100644\n--- a/sklearn/tree/export.py\n+++ b/sklearn/tree/export.py\n@@ -890,9 +890,10 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n         value_fmt = \"{}{} value: {}\\n\"\n \n     if feature_names:\n-        feature_names_ = [feature_names[i] for i in tree_.feature]\n+        feature_names_ = [feature_names[i] if i != _tree.TREE_UNDEFINED else None for i in tree_.feature]\n     else:\n-        feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n+        feature_names_ = [\"feature_{}\".format(i) if i != _tree.TREE_UNDEFINED else None for i in tree_.feature]\n+\n \n     export_text.report = \"\"\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14087",
        "model_patch": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex 1999f1dae..3be78c8f7 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -2170,10 +2170,11 @@ class LogisticRegressionCV(LogisticRegression, BaseEstimator,\n                 # Take the best scores across every fold and the average of\n                 # all coefficients corresponding to the best scores.\n                 best_indices = np.argmax(scores, axis=1)\n-                if self.multi_class == 'ovr':\n-                    w = np.mean([coefs_paths[i, best_indices[i], :]\n-                                 for i in range(len(folds))], axis=0)\n-                else:\n+    if self.multi_class == 'ovr':\n+        w = np.mean([coefs_paths[i, best_indices[i], :] for i in range(len(folds))], axis=0)\n+    else:\n+        w = np.mean([coefs_paths[i, best_indices[i], :] for i in range(len(folds))], axis=0)\n+\n                     w = np.mean([coefs_paths[:, i, best_indices[i], :]\n                                  for i in range(len(folds))], axis=0)\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14141",
        "model_patch": "diff --git a/sklearn/utils/_show_versions.py b/sklearn/utils/_show_versions.py\nindex e5d3141bf..8419e6912 100644\n--- a/sklearn/utils/_show_versions.py\n+++ b/sklearn/utils/_show_versions.py\n@@ -49,6 +49,310 @@ def _get_deps_info():\n         \"pandas\",\n         \"matplotlib\",\n     ]\n+   # For scikit-learn > 0.20, joblib is an external dependency so add it.\n+    try:\n+        import sklearn\n+        from distutils.version import LooseVersion\n+        if LooseVersion(sklearn.__version__) > LooseVersion(\"0.20\"):\n+            deps.append(\"joblib\")\n+    except Exception:\n+        pass\n     def get_version(module):\n         return module.__version__",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14496",
        "model_patch": "diff --git a/sklearn/cluster/optics_.py b/sklearn/cluster/optics_.py\nindex 4f7eb11ab..7e31e04e1 100755\n--- a/sklearn/cluster/optics_.py\n+++ b/sklearn/cluster/optics_.py\n@@ -436,8 +436,9 @@ if metric=\u2019precomputed\u2019.\n     \"\"\"\n     n_samples = X.shape[0]\n     _validate_size(min_samples, n_samples, 'min_samples')\n-    if min_samples <= 1:\n-        min_samples = max(2, min_samples * n_samples)\n+if min_samples <= 1:\n+    min_samples = int(round(max(2, min_samples * n_samples)))\n+\n \n     # Start all points as 'unprocessed' ##\n     reachability_ = np.empty(n_samples)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14629",
        "model_patch": "diff --git a/sklearn/model_selection/_validation.py b/sklearn/model_selection/_validation.py\nindex 95669a212..dd99c102e 100644\n--- a/sklearn/model_selection/_validation.py\n+++ b/sklearn/model_selection/_validation.py\n@@ -855,16 +855,23 @@ def _fit_and_predict(estimator, X, y, train, test, verbose, fit_params,\n     predictions = func(X_test)\n     if method in ['decision_function', 'predict_proba', 'predict_log_proba']:\n         if isinstance(predictions, list):\n-            predictions = [_enforce_prediction_order(\n-                estimator.classes_[i_label], predictions[i_label],\n-                n_classes=len(set(y[:, i_label])), method=method)\n-                for i_label in range(len(predictions))]\n+            # If the estimator is a multioutput classifier, use the classes_\n+            # attribute from each individual estimator in estimator.estimators_\n+            if hasattr(estimator, 'estimators_'):\n+                predictions = [_enforce_prediction_order(\n+                    estimator.estimators_[i_label].classes_, predictions[i_label],\n+                    n_classes=len(np.unique(y[:, i_label])), method=method)\n+                    for i_label in range(len(predictions))]\n+            else:\n+                predictions = [_enforce_prediction_order(\n+                    estimator.classes_[i_label], predictions[i_label],\n+                    n_classes=len(np.unique(y[:, i_label])), method=method)\n+                    for i_label in range(len(predictions))]\n         else:\n-            # A 2D y array should be a binary label indicator matrix\n-            n_classes = len(set(y)) if y.ndim == 1 else y.shape[1]\n+            n_classes = len(np.unique(y)) if y.ndim == 1 else y.shape[1]\n             predictions = _enforce_prediction_order(\n                 estimator.classes_, predictions, n_classes, method)\n-    return predictions, test\n+\n \n \n def _enforce_prediction_order(classes, predictions, n_classes, method):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14710",
        "model_patch": "diff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex ad6a5a8ca..aa209decf 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -426,11 +426,16 @@ class BaseHistGradientBoosting(BaseEstimator, ABC):\n \n         Scores are computed on validation data or on training data.\n         \"\"\"\n+        if hasattr(self, 'classes_'):\n+            y_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n+\n         if self._use_validation_data:\n+            if hasattr(self, 'classes_'):\n+                y_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\n             )\n@@ -438,6 +443,9 @@ class BaseHistGradientBoosting(BaseEstimator, ABC):\n         else:\n             return self._should_stop(self.train_score_)\n \n+        else:\n+            return self._should_stop(self.train_score_)\n+\n     def _check_early_stopping_loss(self,\n                                    raw_predictions,\n                                    y_train,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14894",
        "model_patch": "diff --git a/sklearn/svm/base.py b/sklearn/svm/base.py\nindex 64cebe837..12bf0bafa 100644\n--- a/sklearn/svm/base.py\n+++ b/sklearn/svm/base.py\n@@ -284,14 +284,19 @@ class BaseLibSVM(BaseEstimator, metaclass=ABCMeta):\n             n_class = len(self.classes_) - 1\n         else:  # regression\n             n_class = 1\n-        n_SV = self.support_vectors_.shape[0]\n-\n-        dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n-        dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n-                                     dual_coef_indices.size / n_class)\n-        self.dual_coef_ = sp.csr_matrix(\n-            (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n-            (n_class, n_SV))\n+n_SV = self.support_vectors_.shape[0]\n+# If there are no support vectors, return an empty dual_coef_ matrix.\n+if n_SV == 0:\n+    self.dual_coef_ = sp.csr_matrix((n_class, 0))\n+    return\n+\n+dual_coef_indices = np.tile(np.arange(n_SV), n_class)\n+dual_coef_indptr = np.arange(0, dual_coef_indices.size + 1,\n+                             dual_coef_indices.size / n_class)\n+self.dual_coef_ = sp.csr_matrix(\n+    (dual_coef_data, dual_coef_indices, dual_coef_indptr),\n+    (n_class, n_SV))\n+\n \n     def predict(self, X):\n         \"\"\"Perform regression on samples in X.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-14983",
        "model_patch": "diff --git a/sklearn/model_selection/_split.py b/sklearn/model_selection/_split.py\nindex c49a3ce6a..2c6444b7d 100644\n--- a/sklearn/model_selection/_split.py\n+++ b/sklearn/model_selection/_split.py\n@@ -1162,6 +1162,65 @@ class _RepeatedSplits(metaclass=ABCMeta):\n         cv = self.cv(random_state=rng, shuffle=True,\n                      **self.cvargs)\n         return cv.get_n_splits(X, y, groups) * self.n_repeats\n+   def __repr__(self):\n+        return _build_repr(self)\n class RepeatedKFold(_RepeatedSplits):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-15100",
        "model_patch": "diff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex bb5a9d646..a84d4482a 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -129,11 +129,9 @@ def strip_accents_unicode(s):\n         Remove accentuated char for any unicode symbol that has a direct\n         ASCII equivalent.\n     \"\"\"\n-    normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n-        return s\n-    else:\n-        return ''.join([c for c in normalized if not unicodedata.combining(c)])\n+normalized = unicodedata.normalize('NFKD', s)\n+return ''.join(c for c in normalized if not unicodedata.combining(c))\n+\n \n \n def strip_accents_ascii(s):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25102",
        "model_patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..0d5b94ee2 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -12,7 +12,9 @@ def _wrap_in_pandas_container(\n     *,\n     columns,\n     index=None,\n+    dtypes=None,\n ):\n+\n     \"\"\"Create a Pandas DataFrame.\n \n     If `data_to_wrap` is a DataFrame, then the `columns` and `index` will be changed\n@@ -52,14 +54,22 @@ def _wrap_in_pandas_container(\n \n     pd = check_pandas_support(\"Setting output container to 'pandas'\")\n \n-    if isinstance(data_to_wrap, pd.DataFrame):\n-        if columns is not None:\n-            data_to_wrap.columns = columns\n-        if index is not None:\n-            data_to_wrap.index = index\n-        return data_to_wrap\n+if isinstance(data_to_wrap, pd.DataFrame):\n+    if columns is not None:\n+        data_to_wrap.columns = columns\n+    if index is not None:\n+        data_to_wrap.index = index\n+    df = data_to_wrap\n+    if dtypes is not None:\n+        df = df.astype(dtypes)\n+    return df\n+\n+\n+df = pd.DataFrame(data_to_wrap, index=index, columns=columns)\n+if dtypes is not None:\n+    df = df.astype(dtypes)\n+return df\n \n-    return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n \n \n def _get_output_config(method, estimator=None):\n@@ -126,12 +136,15 @@ def _wrap_data_with_container(method, data_to_wrap, original_input, estimator):\n     if output_config[\"dense\"] == \"default\" or not _auto_wrap_is_configured(estimator):\n         return data_to_wrap\n \n-    # dense_config == \"pandas\"\n-    return _wrap_in_pandas_container(\n-        data_to_wrap=data_to_wrap,\n-        index=getattr(original_input, \"index\", None),\n-        columns=estimator.get_feature_names_out,\n-    )\n+# dense_config == \"pandas\"\n+config = getattr(estimator, \"_sklearn_output_config\", {})\n+return _wrap_in_pandas_container(\n+    data_to_wrap=data_to_wrap,\n+    index=getattr(original_input, \"index\", None),\n+    columns=estimator.get_feature_names_out,\n+    dtypes=config.get(\"dtypes\", None),\n+)\n+\n \n \n def _wrap_method_output(f, method):\n@@ -208,7 +221,8 @@ class _SetOutputMixin:\n             setattr(cls, method, wrapped_method)\n \n     @available_if(_auto_wrap_is_configured)\n-    def set_output(self, *, transform=None):\n+def set_output(self, *, transform=None, dtypes=None):\n+\n         \"\"\"Set output container.\n \n         See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n@@ -228,14 +242,18 @@ class _SetOutputMixin:\n         self : estimator instance\n             Estimator instance.\n         \"\"\"\n-        if transform is None:\n-            return self\n+if transform is None and dtypes is None:\n+    return self\n+\n+if not hasattr(self, \"_sklearn_output_config\"):\n+    self._sklearn_output_config = {}\n \n-        if not hasattr(self, \"_sklearn_output_config\"):\n-            self._sklearn_output_config = {}\n+if transform is not None:\n+    self._sklearn_output_config[\"transform\"] = transform\n+if dtypes is not None:\n+    self._sklearn_output_config[\"dtypes\"] = dtypes\n+return self\n \n-        self._sklearn_output_config[\"transform\"] = transform\n-        return self\n \n \n def _safe_set_output(estimator, *, transform=None):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25232",
        "model_patch": "diff --git a/sklearn/impute/_iterative.py b/sklearn/impute/_iterative.py\nindex 1d918bc0c..40285ac3d 100644\n--- a/sklearn/impute/_iterative.py\n+++ b/sklearn/impute/_iterative.py\n@@ -278,12 +278,9 @@ class IterativeImputer(_BaseImputer):\n         \"max_iter\": [Interval(Integral, 0, None, closed=\"left\")],\n         \"tol\": [Interval(Real, 0, None, closed=\"left\")],\n         \"n_nearest_features\": [None, Interval(Integral, 1, None, closed=\"left\")],\n-        \"initial_strategy\": [\n-            StrOptions({\"mean\", \"median\", \"most_frequent\", \"constant\"})\n-        ],\n-        \"imputation_order\": [\n-            StrOptions({\"ascending\", \"descending\", \"roman\", \"arabic\", \"random\"})\n-        ],\n+        \"initial_strategy\": [StrOptions({\"mean\", \"median\", \"most_frequent\", \"constant\"})],\n+        \"fill_value\": \"no_validation\",\n+        \"imputation_order\": [StrOptions({\"ascending\", \"descending\", \"roman\", \"arabic\", \"random\"})],\n         \"skip_complete\": [\"boolean\"],\n         \"min_value\": [None, Interval(Real, None, None, closed=\"both\"), \"array-like\"],\n         \"max_value\": [None, Interval(Real, None, None, closed=\"both\"), \"array-like\"],\n@@ -291,6 +288,7 @@ class IterativeImputer(_BaseImputer):\n         \"random_state\": [\"random_state\"],\n     }\n \n+\n     def __init__(\n         self,\n         estimator=None,\n@@ -301,6 +299,7 @@ class IterativeImputer(_BaseImputer):\n         tol=1e-3,\n         n_nearest_features=None,\n         initial_strategy=\"mean\",\n+        fill_value=None,\n         imputation_order=\"ascending\",\n         skip_complete=False,\n         min_value=-np.inf,\n@@ -310,6 +309,25 @@ class IterativeImputer(_BaseImputer):\n         add_indicator=False,\n         keep_empty_features=False,\n     ):\n+        super().__init__(\n+            missing_values=missing_values,\n+            add_indicator=add_indicator,\n+            keep_empty_features=keep_empty_features,\n+        )\n+        self.estimator = estimator\n+        self.sample_posterior = sample_posterior\n+        self.max_iter = max_iter\n+        self.tol = tol\n+        self.n_nearest_features = n_nearest_features\n+        self.initial_strategy = initial_strategy\n+        self.fill_value = fill_value\n+        self.imputation_order = imputation_order\n+        self.skip_complete = skip_complete\n+        self.min_value = min_value\n+        self.max_value = max_value\n+        self.verbose = verbose\n+        self.random_state = random_state\n+\n         super().__init__(\n             missing_values=missing_values,\n             add_indicator=add_indicator,\n@@ -609,14 +627,17 @@ class IterativeImputer(_BaseImputer):\n \n         X_missing_mask = _get_mask(X, self.missing_values)\n         mask_missing_values = X_missing_mask.copy()\n-        if self.initial_imputer_ is None:\n-            self.initial_imputer_ = SimpleImputer(\n-                missing_values=self.missing_values,\n-                strategy=self.initial_strategy,\n-                keep_empty_features=self.keep_empty_features,\n-            )\n-            X_filled = self.initial_imputer_.fit_transform(X)\n-        else:\n+            if self.initial_imputer_ is None:\n+                self.initial_imputer_ = SimpleImputer(\n+                    missing_values=self.missing_values,\n+                    strategy=self.initial_strategy,\n+                    fill_value=self.fill_value,\n+                    keep_empty_features=self.keep_empty_features,\n+                )\n+                X_filled = self.initial_imputer_.fit_transform(X)\n+            else:\n+                X_filled = self.initial_imputer_.transform(X)\n+\n             X_filled = self.initial_imputer_.transform(X)\n \n         valid_mask = np.flatnonzero(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25747",
        "model_patch": "diff --git a/sklearn/utils/_set_output.py b/sklearn/utils/_set_output.py\nindex 335773c6a..233dfc36a 100644\n--- a/sklearn/utils/_set_output.py\n+++ b/sklearn/utils/_set_output.py\n@@ -55,13 +55,17 @@ def _wrap_in_pandas_container(\n     if isinstance(data_to_wrap, pd.DataFrame):\n         if columns is not None:\n             data_to_wrap.columns = columns\n-        if index is not None:\n+        if index is not None and len(data_to_wrap) == len(index):\n             data_to_wrap.index = index\n         return data_to_wrap\n \n+\n+    if index is not None and len(data_to_wrap) != len(index):\n+        index = None\n     return pd.DataFrame(data_to_wrap, index=index, columns=columns)\n \n \n+\n def _get_output_config(method, estimator=None):\n     \"\"\"Get output config based on estimator and global configuration.\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25931",
        "model_patch": "diff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex 4d6c1c3f0..0583dcdc7 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -433,7 +433,8 @@ class IsolationForest(OutlierMixin, BaseBagging):\n         check_is_fitted(self)\n \n         # Check data\n-        X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False)\n+X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False,\n+                         preserve_feature_names=True)\n \n         # Take the opposite of the scores as bigger is better (here less\n         # abnormal)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-25973",
        "model_patch": "diff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py\nindex e983c55de..e6edeb2fa 100644\n--- a/sklearn/feature_selection/_sequential.py\n+++ b/sklearn/feature_selection/_sequential.py\n@@ -227,6 +227,206 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator\n             ensure_min_features=2,\n             force_all_finite=not tags.get(\"allow_nan\", True),\n         )\n+ If cv is provided as an iterator (e.g., from cv.split(...)),\n+# convert it to a list so that it can be reused at every scoring call.\n+if not hasattr(self.cv, \"split\"):\n+    self.cv = list(self.cv)\n         n_features = X.shape[1]\n \n         # FIXME: to be fixed in 1.3",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-26194",
        "model_patch": "diff --git a/sklearn/metrics/_ranking.py b/sklearn/metrics/_ranking.py\nindex 0cdead923..f218a7d76 100644\n--- a/sklearn/metrics/_ranking.py\n+++ b/sklearn/metrics/_ranking.py\n@@ -1081,9 +1081,11 @@ def roc_curve(\n \n     # Add an extra threshold position\n     # to make sure that the curve starts at (0, 0)\n-    tps = np.r_[0, tps]\n-    fps = np.r_[0, fps]\n-    thresholds = np.r_[thresholds[0] + 1, thresholds]\n+tps = np.r_[0, tps]\n+fps = np.r_[0, fps]\n+extra_threshold = 1.0 if (y_score.min() >= 0 and y_score.max() <= 1) else thresholds[0] + 1.0\n+thresholds = np.r_[extra_threshold, thresholds]\n+\n \n     if fps[-1] <= 0:\n         warnings.warn(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-26323",
        "model_patch": "diff --git a/sklearn/compose/_column_transformer.py b/sklearn/compose/_column_transformer.py\nindex 4eddd12b1..18ad78b6f 100644\n--- a/sklearn/compose/_column_transformer.py\n+++ b/sklearn/compose/_column_transformer.py\n@@ -275,8 +275,9 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n     def set_output(self, *, transform=None):\n         \"\"\"Set the output container when `\"transform\"` and `\"fit_transform\"` are called.\n \n-        Calling `set_output` will set the output of all estimators in `transformers`\n-        and `transformers_`.\n+        Calling `set_output` will set the output of all estimators in `transformers`,\n+        fitted transformers stored in `transformers_`, and also the estimator passed in\n+        via `remainder` (if it is an estimator).\n \n         Parameters\n         ----------\n@@ -293,18 +294,20 @@ class ColumnTransformer(TransformerMixin, _BaseComposition):\n             Estimator instance.\n         \"\"\"\n         super().set_output(transform=transform)\n-        transformers = (\n-            trans\n-            for _, trans, _ in chain(\n-                self.transformers, getattr(self, \"transformers_\", [])\n-            )\n-            if trans not in {\"passthrough\", \"drop\"}\n-        )\n-        for trans in transformers:\n-            _safe_set_output(trans, transform=transform)\n+        # Set output for all defined transformers (and fitted transformers)\n+        for name, trans, _ in chain(self.transformers, getattr(self, \"transformers_\", [])):\n+            if trans not in {\"passthrough\", \"drop\"}:\n+                _safe_set_output(trans, transform=transform)\n+\n+        # Additionally, if remainder is an estimator and it was not already processed,\n+        # then set its output as well.\n+        if not any(name == \"remainder\" for name, _, _ in chain(self.transformers, getattr(self, \"transformers_\", []))):\n+            if self.remainder not in {\"passthrough\", \"drop\"} and hasattr(self.remainder, \"fit\"):\n+                _safe_set_output(self.remainder, transform=transform)\n \n         return self\n \n+\n     def get_params(self, deep=True):\n         \"\"\"Get parameters for this estimator.\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "scikit-learn__scikit-learn-9288",
        "model_patch": "diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py\nindex b7fbdf7da..2547e962f 100644\n--- a/sklearn/cluster/k_means_.py\n+++ b/sklearn/cluster/k_means_.py\n@@ -434,12 +434,13 @@ def _kmeans_single_elkan(X, sample_weight, n_clusters, max_iter=300,\n     centers, labels, n_iter = k_means_elkan(X, checked_sample_weight,\n                                             n_clusters, centers, tol=tol,\n                                             max_iter=max_iter, verbose=verbose)\n+    diff = X - centers[labels]\n     if sample_weight is None:\n-        inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n+        inertia = np.dot(diff.ravel(), diff.ravel())\n     else:\n-        sq_distances = np.sum((X - centers[labels]) ** 2, axis=1,\n-                              dtype=np.float64) * checked_sample_weight\n-        inertia = np.sum(sq_distances, dtype=np.float64)\n+        sq_distances = np.sum(diff ** 2, axis=1, dtype=np.float64)\n+        inertia = np.dot(sq_distances, checked_sample_weight)\n+\n     return labels, inertia, centers, n_iter\n \n \n@@ -616,7 +617,8 @@ def _labels_inertia_precompute_dense(X, sample_weight, x_squared_norms,\n     if n_samples == distances.shape[0]:\n         # distances will be changed in-place\n         distances[:] = mindist\n-    inertia = (mindist * sample_weight).sum()\n+    inertia = np.dot(mindist, sample_weight)\n+\n     return labels, inertia\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10323",
        "model_patch": "diff --git a/sphinx/directives/code.py b/sphinx/directives/code.py\nindex dc44ed314..0ab2dbf47 100644\n--- a/sphinx/directives/code.py\n+++ b/sphinx/directives/code.py\n@@ -220,13 +220,14 @@ class LiteralIncludeReader:\n         if 'diff' in self.options:\n             lines = self.show_diff()\n         else:\n-            filters = [self.pyobject_filter,\n-                       self.start_filter,\n-                       self.end_filter,\n-                       self.lines_filter,\n-                       self.prepend_filter,\n-                       self.append_filter,\n-                       self.dedent_filter]\n+    filters = [self.pyobject_filter,\n+               self.start_filter,\n+               self.end_filter,\n+               self.lines_filter,\n+               self.dedent_filter,\n+               self.prepend_filter,\n+               self.append_filter]\n+\n             lines = self.read_file(self.filename, location=location)\n             for func in filters:\n                 lines = func(lines, location=location)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10435",
        "model_patch": "diff --git a/sphinx/writers/latex.py b/sphinx/writers/latex.py\nindex e0c7d56f8..998ad54b7 100644\n--- a/sphinx/writers/latex.py\n+++ b/sphinx/writers/latex.py\n@@ -1692,32 +1692,39 @@ class LaTeXTranslator(SphinxTranslator):\n     def depart_citation_reference(self, node: Element) -> None:\n         pass\n \n-    def visit_literal(self, node: Element) -> None:\n-        if self.in_title:\n-            self.body.append(r'\\sphinxstyleliteralintitle{\\sphinxupquote{')\n-            return\n-        elif 'kbd' in node['classes']:\n-            self.body.append(r'\\sphinxkeyboard{\\sphinxupquote{')\n-            return\n-        lang = node.get(\"language\", None)\n-        if 'code' not in node['classes'] or not lang:\n-            self.body.append(r'\\sphinxcode{\\sphinxupquote{')\n-            return\n-\n-        opts = self.config.highlight_options.get(lang, {})\n-        hlcode = self.highlighter.highlight_block(\n-            node.astext(), lang, opts=opts, location=node)\n-        # TODO: Use nowrap option once LaTeX formatter supports it\n-        # https://github.com/pygments/pygments/pull/1343\n-        hlcode = hlcode.replace(r'\\begin{Verbatim}[commandchars=\\\\\\{\\}]',\n-                                r'\\sphinxcode{\\sphinxupquote{')\n-        # get consistent trailer\n-        hlcode = hlcode.rstrip()[:-14]  # strip \\end{Verbatim}\n-        self.body.append(hlcode)\n-        self.body.append('}}')\n-        raise nodes.SkipNode\n-\n-    def depart_literal(self, node: Element) -> None:\n+def visit_literal(self, node: Element) -> None:\n+    if self.in_title:\n+        self.body.append(r'\\sphinxstyleliteralintitle{\\sphinxupquote{')\n+        return\n+    elif 'kbd' in node['classes']:\n+        self.body.append(r'\\sphinxkeyboard{\\sphinxupquote{')\n+        return\n+    lang = node.get(\"language\", None)\n+    # For inline code (i.e. the code role) we want to insert a \"%\" immediately\n+    # after the opening \\sphinxupquote{ and immediately before the closing \"}}\"\n+    if 'code' not in node['classes'] or not lang:\n+        self.body.append(r'\\sphinxcode{\\sphinxupquote{%')\n+        # Let depart_literal append the complementary ending\n+        return\n+\n+    opts = self.config.highlight_options.get(lang, {})\n+    hlcode = self.highlighter.highlight_block(\n+        node.astext(), lang, opts=opts, location=node)\n+    # Use the inline code wrapper with a % in it\n+    hlcode = hlcode.replace(r'\\begin{Verbatim}[commandchars=\\\\\\{\\}]',\n+                            r'\\sphinxcode{\\sphinxupquote{%',)\n+    # Strip the trailing \"\\end{Verbatim}\" (14 characters) from the highlighted code.\n+    hlcode = hlcode.rstrip()[:-14]\n+    self.body.append(hlcode)\n+    self.body.append('%}}')\n+    raise nodes.SkipNode\n+\n+\n+def depart_literal(self, node: Element) -> None:\n+    # For inline literal with the \"code\" role, append a \"%\" before closing\n+    if 'code' in node.get('classes', []) and node.get('language', None):\n+        self.body.append('%}}')\n+    else:\n         self.body.append('}}')\n \n     def visit_footnote_reference(self, node: Element) -> None:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10449",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex 06768168e..5e66034da 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -28,8 +28,9 @@ def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n             for param in sig.parameters.values():\n                 if param.annotation is not param.empty:\n                     annotation[param.name] = typing.stringify(param.annotation, mode)\n-            if sig.return_annotation is not sig.empty:\n+            if sig.return_annotation is not sig.empty and getattr(obj, '__name__', None) != '__init__':\n                 annotation['return'] = typing.stringify(sig.return_annotation, mode)\n+\n     except (TypeError, ValueError):\n         pass\n \n@@ -126,7 +127,8 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str]) -> No\n     if 'return' in annotations and 'return' not in arguments:\n         field = nodes.field()\n         field += nodes.field_name('', 'rtype')\n-        field += nodes.field_body('', nodes.paragraph('', annotation))\n+\t        field += nodes.field_body('', nodes.paragraph('', annotations['return']))\n+\n         node += field\n \n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10466",
        "model_patch": "diff --git a/sphinx/builders/gettext.py b/sphinx/builders/gettext.py\nindex e8bc547b7..b8e75efb6 100644\n--- a/sphinx/builders/gettext.py\n+++ b/sphinx/builders/gettext.py\n@@ -32,9 +32,301 @@ class Message:\n     \"\"\"An entry of translatable message.\"\"\"\n     def __init__(self, text: str, locations: List[Tuple[str, int]], uuids: List[str]):\n         self.text = text\n-        self.locations = locations\n+        # Deduplicate locations to avoid unnecessary duplicate entries in the .pot file.\n+        self.locations = self._unique_locations(locations)\n         self.uuids = uuids\n \n+    def _unique_locations(self, locations: List[Tuple[str, int]]) -> List[Tuple[str, int]]:\n+        seen = set()\n+        unique = []\n+        for loc in locations:\n+            if loc not in seen:\n+                unique.append(loc)\n+                seen.add(loc)\n+        return unique\n class Catalog:\n     \"\"\"Catalog of translatable messages.\"\"\"",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10614",
        "model_patch": "diff --git a/sphinx/ext/inheritance_diagram.py b/sphinx/ext/inheritance_diagram.py\nindex 6e3985512..ac244ea57 100644\n--- a/sphinx/ext/inheritance_diagram.py\n+++ b/sphinx/ext/inheritance_diagram.py\n@@ -413,15 +413,19 @@ def html_visit_inheritance_diagram(self: HTML5Translator, node: inheritance_diag\n     for child in pending_xrefs:\n         if child.get('refuri') is not None:\n             if graphviz_output_format == 'SVG':\n-                urls[child['reftitle']] = \"../\" + child.get('refuri')\n+                # If the current docname is in the root (no slash), then add '../'\n+                prefix = \"../\" if '/' not in self.builder.current_docname else \"\"\n+                urls[child['reftitle']] = prefix + child.get('refuri')\n             else:\n                 urls[child['reftitle']] = child.get('refuri')\n         elif child.get('refid') is not None:\n             if graphviz_output_format == 'SVG':\n-                urls[child['reftitle']] = '../' + current_filename + '#' + child.get('refid')\n+                prefix = \"../\" if '/' not in self.builder.current_docname else \"\"\n+                urls[child['reftitle']] = prefix + current_filename + '#' + child.get('refid')\n             else:\n                 urls[child['reftitle']] = '#' + child.get('refid')\n \n+\n     dotcode = graph.generate_dot(name, urls, env=self.builder.env)\n     render_dot_html(self, node, dotcode, {}, 'inheritance', 'inheritance',\n                     alt='Inheritance diagram of ' + node['content'])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-10673",
        "model_patch": "diff --git a/sphinx/environment/adapters/toctree.py b/sphinx/environment/adapters/toctree.py\nindex 9678e3c7c..d4576f62a 100644\n--- a/sphinx/environment/adapters/toctree.py\n+++ b/sphinx/environment/adapters/toctree.py\n@@ -141,23 +141,37 @@ class TocTree:\n                         toc = nodes.bullet_list('', item)\n                     else:\n                         if ref in parents:\n-                            logger.warning(__('circular toctree references '\n-                                              'detected, ignoring: %s <- %s'),\n+                            logger.warning(__('circular toctree references detected, ignoring: %s <- %s'),\n                                            ref, ' <- '.join(parents),\n                                            location=ref, type='toc', subtype='circular')\n                             continue\n-                        refdoc = ref\n-                        toc = self.env.tocs[ref].deepcopy()\n-                        maxdepth = self.env.metadata[ref].get('tocdepth', 0)\n-                        if ref not in toctree_ancestors or (prune and maxdepth > 0):\n-                            self._toctree_prune(toc, 2, maxdepth, collapse)\n-                        process_only_nodes(toc, builder.tags)\n-                        if title and toc.children and len(toc.children) == 1:\n-                            child = toc.children[0]\n-                            for refnode in child.findall(nodes.reference):\n-                                if refnode['refuri'] == ref and \\\n-                                   not refnode['anchorname']:\n-                                    refnode.children = [nodes.Text(title)]\n+                        if ref in ('genindex', 'modindex', 'search'):\n+                            if not title:\n+                                title = {\n+                                    'genindex': __('General Index'),\n+                                    'modindex': __('Module Index'),\n+                                    'search': __('Search')\n+                                }[ref]\n+                            reference = nodes.reference(\n+                                '', '', internal=True, refuri=ref, anchorname='',\n+                                *[nodes.Text(title)]\n+                            )\n+                            para = addnodes.compact_paragraph('', '', reference)\n+                            item = nodes.list_item('', para)\n+                            toc = nodes.bullet_list('', item)\n+                        else:\n+                            refdoc = ref\n+                            toc = self.env.tocs[ref].deepcopy()\n+                            maxdepth = self.env.metadata[ref].get('tocdepth', 0)\n+                            if ref not in toctree_ancestors or (prune and maxdepth > 0):\n+                                self._toctree_prune(toc, 2, maxdepth, collapse)\n+                            process_only_nodes(toc, builder.tags)\n+                            if title and toc.children and len(toc.children) == 1:\n+                                child = toc.children[0]\n+                                for refnode in child.findall(nodes.reference):\n+                                    if refnode['refuri'] == ref and not refnode['anchorname']:\n+                                        refnode.children = [nodes.Text(title)]\n+\n                     if not toc.children:\n                         # empty toc means: no titles will show up in the toctree\n                         logger.warning(__('toctree contains reference to document %r that '\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-11445",
        "model_patch": "diff --git a/sphinx/parsers.py b/sphinx/parsers.py\nindex 3bcd69f52..191f2c66a 100644\n--- a/sphinx/parsers.py\n+++ b/sphinx/parsers.py\n@@ -82,8 +82,13 @@ class RSTParser(docutils.parsers.rst.Parser, Parser):\n \n     def decorate(self, content: StringList) -> None:\n         \"\"\"Preprocess reST content before parsing.\"\"\"\n-        prepend_prolog(content, self.config.rst_prolog)\n-        append_epilog(content, self.config.rst_epilog)\n+        if self.config.rst_prolog:\n+            prolog = self.config.rst_prolog\n+            if not prolog.endswith('\\n'):\n+                prolog += '\\n'\n+            prepend_prolog(content, prolog)\n+        if self.config.rst_epilog:\n+            append_epilog(content, self.config.rst_epilog)\n \n \n def setup(app: Sphinx) -> dict[str, Any]:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-11510",
        "model_patch": "diff --git a/sphinx/io.py b/sphinx/io.py\nindex 4874fdf39..6b40bf963 100644\n--- a/sphinx/io.py\n+++ b/sphinx/io.py\n@@ -155,6 +155,781 @@ class SphinxFileInput(FileInput):\n     def __init__(self, *args: Any, **kwargs: Any) -> None:\n         kwargs['error_handler'] = 'sphinx'\n         super().__init__(*args, **kwargs)\n+   def read(self) -> str:\n+        # first, read the file content normally\n+        content = super().read()\n+        # if settings.env with an app is available, emit the \"source-read\" event\n+        env = getattr(self.settings, 'env', None)\n+        if env is not None and hasattr(env, 'app'):\n+            app = env.app\n+            try:\n+                import os\n+                # compute docname relative to the app source directory\n+                rel = os.path.relpath(self.source_path, app.srcdir)\n+                docname, _ = os.path.splitext(rel)\n+            except Exception:\n+                docname = self.source_path\n+            arg = [content]\n+            app.events.emit('source-read', docname, arg)\n+            return arg[0]\n+        return content\n def create_publisher(app: Sphinx, filetype: str) -> Publisher:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7440",
        "model_patch": "diff --git a/sphinx/domains/std.py b/sphinx/domains/std.py\nindex d820cfe5c..c3026d357 100644\n--- a/sphinx/domains/std.py\n+++ b/sphinx/domains/std.py\n@@ -305,7 +305,8 @@ def make_glossary_term(env: \"BuildEnvironment\", textnodes: Iterable[Node], index\n         term['ids'].append(node_id)\n \n     std = cast(StandardDomain, env.get_domain('std'))\n-    std.note_object('term', termtext.lower(), node_id, location=term)\n+    std.note_object('term', termtext, node_id, location=term)\n+\n \n     # add an index entry too\n     indexnode = addnodes.index()\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7454",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex f917dbdf3..518526084 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -123,11 +123,12 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str]) -> No\n \n         node += field\n \n-    if 'return' in annotations and 'return' not in arguments:\n-        field = nodes.field()\n-        field += nodes.field_name('', 'rtype')\n-        field += nodes.field_body('', nodes.paragraph('', annotation))\n-        node += field\n+if 'return' in annotations and 'return' not in arguments:\n+    field = nodes.field()\n+    field += nodes.field_name('', 'rtype')\n+    field += nodes.field_body('', nodes.paragraph('', annotations['return']))\n+    node += field\n+\n \n \n def setup(app: Sphinx) -> Dict[str, Any]:\ndiff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 64c1568f6..6fcf9b0d7 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -677,9 +677,16 @@ class Signature:\n \n             return '(%s) -> %s' % (', '.join(args), annotation)\n \n-    def format_annotation(self, annotation: Any) -> str:\n-        \"\"\"Return formatted representation of a type annotation.\"\"\"\n-        return stringify_annotation(annotation)\n+def format_annotation(self, annotation: Any) -> str:\n+    \"\"\"Return formatted representation of a type annotation.\n+    For a None annotation, return the appropriate role markup so that it\n+    becomes a clickable link in the rendered signature.\n+    \"\"\"\n+    if annotation is None:\n+        # Use explicit markup for None so that intersphinx processing creates a link.\n+        return \":py:obj:`None`\"\n+    return stringify_annotation(annotation)\n+\n \n     def format_annotation_new(self, annotation: Any) -> str:\n         \"\"\"format_annotation() for py37+\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7462",
        "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex 3ca730e30..2b1022b27 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -118,8 +118,10 @@ def _parse_annotation(annotation: str) -> List[Node]:\n             for elem in node.elts:\n                 result.extend(unparse(elem))\n                 result.append(addnodes.desc_sig_punctuation('', ', '))\n-            result.pop()\n-            return result\n+    if result:\n+        result.pop()\n+    return result\n+\n         else:\n             raise SyntaxError  # unsupported syntax\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7590",
        "model_patch": "diff --git a/sphinx/domains/cpp.py b/sphinx/domains/cpp.py\nindex fe52d881d..535edbd11 100644\n--- a/sphinx/domains/cpp.py\n+++ b/sphinx/domains/cpp.py\n@@ -4663,6 +4663,9 @@ class DefinitionParser(BaseParser):\n             pos = self.pos\n             if self.match(regex):\n                 while self.current_char in 'uUlLfF':\n+                while self.current_char in 'uUlLfF':\n+                    self.pos += 1\n+                while not self.eof and (self.current_char.isalnum() or self.current_char == '_'):\n                     self.pos += 1\n                 return ASTNumberLiteral(self.definition[pos:self.pos])\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7748",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 15f0d66e2..623276f3e 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -459,12 +459,380 @@ def signature(subject: Callable, bound_method: bool = False, follow_wrapped: boo\n     return inspect.Signature(parameters, return_annotation=return_annotation)\n \n \n-def stringify_signature(sig: inspect.Signature, show_annotation: bool = True,\n+def stringify_signature(sig: any, show_annotation: bool = True,\n                         show_return_annotation: bool = True) -> str:\n-    \"\"\"Stringify a Signature object.\n+    \"\"\"Stringify a Signature object or a collection of Signature objects.\n \n     :param show_annotation: Show annotation in result\n     \"\"\"\n+    # New support: if sig is a list or tuple (as for overloaded methods),\n+    # process each signature individually and join them by newlines.\n+    if isinstance(sig, (list, tuple)):\n+        signatures = []\n+        for s in sig:\n+            signatures.append(stringify_signature(s, show_annotation, show_return_annotation))\n+        return \"\\n\".join(signatures)\n     args = []\n     last_kind = None\n     for param in sig.parameters.values():",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7757",
        "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex fc1136ae2..af1a48bb2 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -178,9 +178,10 @@ def _parse_arglist(arglist: str) -> addnodes.desc_parameterlist:\n                 node += nodes.Text(' ')\n             else:\n                 node += addnodes.desc_sig_operator('', '=')\n-            node += nodes.inline('', param.default, classes=['default_value'],\n+            node += nodes.inline('', str(param.default), classes=['default_value'],\n                                  support_smartquotes=False)\n \n+\n         params += node\n         last_kind = param.kind\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7889",
        "model_patch": "diff --git a/sphinx/ext/autodoc/mock.py b/sphinx/ext/autodoc/mock.py\nindex 98a3a3a96..5edd1faed 100644\n--- a/sphinx/ext/autodoc/mock.py\n+++ b/sphinx/ext/autodoc/mock.py\n@@ -70,7 +70,8 @@ class _MockObject:\n \n def _make_subclass(name: str, module: str, superclass: Any = _MockObject,\n                    attributes: Any = None) -> Any:\n-    attrs = {'__module__': module, '__display_name__': module + '.' + name}\n+    attrs = {'__module__': str(module), '__display_name__': str(module) + '.' + name}\n+\n     attrs.update(attributes or {})\n \n     return type(name, (superclass,), attrs)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7910",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 441f850d1..1fba825e3 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -441,6 +441,139 @@ def signature(subject: Callable, bound_method: bool = False, follow_wrapped: boo\n     :param follow_wrapped: Same as ``inspect.signature()``.\n                            Defaults to ``False`` (get a signature of *subject*).\n     \"\"\"\n+   if getattr(subject, '__name__', None) == '__init__' and hasattr(subject, '__wrapped__'):\n+        subject = subject.__wrapped__\n     try:\n         try:\n             if _should_unwrap(subject):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-7985",
        "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex dd5317087..f7e208a91 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -212,8 +212,14 @@ class CheckExternalLinksBuilder(Builder):\n             # check for various conditions without bothering the network\n             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'ftp:')):\n                 return 'unchecked', '', 0\n-            elif not uri.startswith(('http:', 'https:')):\n-                return 'local', '', 0\n+elif not uri.startswith(('http:', 'https:')):\n+    # Check if the local (internal) link exists in the source directory.\n+    local_path = path.join(self.app.srcdir, unquote(uri))\n+    if path.exists(local_path):\n+        return 'working', '', 0\n+    else:\n+        return 'broken', __(\"Local file not found\"), 0\n+\n             elif uri in self.good:\n                 return 'working', 'old', 0\n             elif uri in self.broken:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8035",
        "model_patch": "diff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex 9a3428f5d..74449cf97 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -86,7 +86,19 @@ def process_documenter_options(documenter: \"Type[Documenter]\", config: Config, o\n             if name in config.autodoc_default_options and not negated:\n                 options[name] = config.autodoc_default_options[name]\n \n-    return Options(assemble_option_dict(options.items(), documenter.option_spec))\n+    opts = assemble_option_dict(options.items(), documenter.option_spec)\n+    # Add support for 'private-members' taking a comma separated list of members\n+    if 'private-members' in opts:\n+        val = opts['private-members']\n+        if isinstance(val, str):\n+            # if a value is provided, split by comma into a tuple of member names;\n+            # otherwise (empty string) use True which is the default to include all\n+            if val.strip():\n+                opts['private-members'] = tuple(x.strip() for x in val.split(','))\n+            else:\n+                opts['private-members'] = True\n+    return Options(opts)\n+\n \n \n def parse_generated_content(state: RSTState, content: StringList, documenter: Documenter\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8056",
        "model_patch": "diff --git a/sphinx/ext/napoleon/docstring.py b/sphinx/ext/napoleon/docstring.py\nindex b3daa06f1..a0634514e 100644\n--- a/sphinx/ext/napoleon/docstring.py\n+++ b/sphinx/ext/napoleon/docstring.py\n@@ -391,18 +391,24 @@ class GoogleDocstring:\n                                 ) -> List[str]:\n         lines = []\n         for _name, _type, _desc in fields:\n+            # When multiple parameter names are provided (e.g., \"x1, x2\"),\n+            # split them so that each one is rendered with its own field.\n+            param_names = [name.strip() for name in _name.split(',')]\n             _desc = self._strip_empty(_desc)\n             if any(_desc):\n                 _desc = self._fix_field_desc(_desc)\n-                field = ':%s %s: ' % (field_role, _name)\n-                lines.extend(self._format_block(field, _desc))\n+                for pname in param_names:\n+                    field = ':%s %s: ' % (field_role, pname)\n+                    lines.extend(self._format_block(field, _desc))\n             else:\n-                lines.append(':%s %s:' % (field_role, _name))\n-\n+                for pname in param_names:\n+                    lines.append(':%s %s:' % (field_role, pname))\n             if _type:\n-                lines.append(':%s %s: %s' % (type_role, _name, _type))\n+                for pname in param_names:\n+                    lines.append(':%s %s: %s' % (type_role, pname, _type))\n         return lines + ['']\n \n+\n     def _format_field(self, _name: str, _type: str, _desc: List[str]) -> List[str]:\n         _desc = self._strip_empty(_desc)\n         has_desc = any(_desc)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8120",
        "model_patch": "diff --git a/sphinx/application.py b/sphinx/application.py\nindex 385b74d8a..093970e2f 100644\n--- a/sphinx/application.py\n+++ b/sphinx/application.py\n@@ -293,8 +293,9 @@ class Sphinx:\n                 if catalog.domain == 'sphinx' and catalog.is_outdated():\n                     catalog.write_mo(self.config.language)\n \n-            locale_dirs = [None, path.join(package_dir, 'locale')] + list(repo.locale_dirs)\n-            self.translator, has_translation = locale.init(locale_dirs, self.config.language)\n+locale_dirs = list(repo.locale_dirs) + [path.join(package_dir, 'locale')]\n+self.translator, has_translation = locale.init(locale_dirs, self.config.language)\n+\n             if has_translation or self.config.language == 'en':\n                 # \"en\" never needs to be translated\n                 logger.info(__('done'))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8265",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 378174993..2311a5c26 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -580,7 +580,12 @@ def stringify_signature(sig: inspect.Signature, show_annotation: bool = True,\n                 arg.write(' = ')\n             else:\n                 arg.write('=')\n-            arg.write(object_description(param.default))\n+            # Fix: if default is a tuple, use repr() to ensure surrounding parenthesis remain.\n+            if isinstance(param.default, tuple):\n+                arg.write(repr(param.default))\n+            else:\n+                arg.write(object_description(param.default))\n+\n \n         args.append(arg.getvalue())\n         last_kind = param.kind\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8269",
        "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 9b54afc7c..4436746c4 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -162,14 +162,17 @@ class CheckExternalLinksBuilder(Builder):\n             kwargs['headers'] = get_request_headers()\n \n             try:\n-                if anchor and self.app.config.linkcheck_anchors:\n-                    # Read the whole document and see if #anchor exists\n-                    response = requests.get(req_url, stream=True, config=self.app.config,\n-                                            auth=auth_info, **kwargs)\n-                    found = check_anchor(response, unquote(anchor))\n-\n-                    if not found:\n-                        raise Exception(__(\"Anchor '%s' not found\") % anchor)\n+                    if anchor and self.app.config.linkcheck_anchors:\n+                        # Read the whole document and see if #anchor exists.\n+                        # First, check for HTTP errors.\n+                        response = requests.get(req_url, stream=True, config=self.app.config,\n+                                                auth=auth_info, **kwargs)\n+                        response.raise_for_status()\n+                        found = check_anchor(response, unquote(anchor))\n+\n+                        if not found:\n+                            raise Exception(__(\"Anchor '%s' not found\") % anchor)\n+\n                 else:\n                     try:\n                         # try a HEAD request first, which should be easier on\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8459",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex 70cbc3ba1..bced67479 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -28,11 +28,22 @@ def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n             annotations = app.env.temp_data.setdefault('annotations', {})\n             annotation = annotations.setdefault(name, OrderedDict())\n             sig = inspect.signature(obj)\n-            for param in sig.parameters.values():\n-                if param.annotation is not param.empty:\n-                    annotation[param.name] = typing.stringify(param.annotation)\n-            if sig.return_annotation is not sig.empty:\n-                annotation['return'] = typing.stringify(sig.return_annotation)\n+for param in sig.parameters.values():\n+    if param.annotation is not param.empty:\n+        ann = typing.stringify(param.annotation)\n+        aliases = app.config.autodoc_type_aliases\n+        if aliases:\n+            for alias, replacement in aliases.items():\n+                ann = re.sub(r'\\b%s\\b' % re.escape(alias), replacement, ann)\n+        annotation[param.name] = ann\n+if sig.return_annotation is not sig.empty:\n+    ann = typing.stringify(sig.return_annotation)\n+    aliases = app.config.autodoc_type_aliases\n+    if aliases:\n+        for alias, replacement in aliases.items():\n+            ann = re.sub(r'\\b%s\\b' % re.escape(alias), replacement, ann)\n+    annotation['return'] = ann\n+\n     except (TypeError, ValueError):\n         pass\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8475",
        "model_patch": "diff --git a/sphinx/builders/linkcheck.py b/sphinx/builders/linkcheck.py\nindex 1dc0337c3..e57a777c7 100644\n--- a/sphinx/builders/linkcheck.py\n+++ b/sphinx/builders/linkcheck.py\n@@ -20,7 +20,8 @@ from urllib.parse import unquote, urlparse\n \n from docutils import nodes\n from docutils.nodes import Node\n-from requests.exceptions import HTTPError\n+from requests.exceptions import HTTPError, TooManyRedirects\n+\n \n from sphinx.application import Sphinx\n from sphinx.builders import Builder\n@@ -173,11 +174,13 @@ class CheckExternalLinksBuilder(Builder):\n                                                  **kwargs)\n                         response.raise_for_status()\n                     except HTTPError:\n-                        # retry with GET request if that fails, some servers\n-                        # don't like HEAD requests.\n-                        response = requests.get(req_url, stream=True, config=self.app.config,\n-                                                auth=auth_info, **kwargs)\n-                        response.raise_for_status()\n+                        except (HTTPError, TooManyRedirects):\n+                            # retry with GET request if that fails due to an error or too many redirects,\n+                            # as some servers do not handle HEAD requests properly.\n+                            response = requests.get(req_url, stream=True, config=self.app.config,\n+                                                    auth=auth_info, **kwargs)\n+                            response.raise_for_status()\n+\n             except HTTPError as err:\n                 if err.response.status_code == 401:\n                     # We'll take \"Unauthorized\" as working.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8548",
        "model_patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex d6e73d36a..2e4a30816 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -41,21 +41,23 @@ def unmangle(subject: Any, name: str) -> Optional[str]:\n     \"\"\"unmangle the given name.\"\"\"\n     try:\n         if isclass(subject) and not name.endswith('__'):\n+            # Check if the attribute is defined in the current class.\n             prefix = \"_%s__\" % subject.__name__\n             if name.startswith(prefix):\n                 return name.replace(prefix, \"__\", 1)\n-            else:\n-                for cls in subject.__mro__:\n-                    prefix = \"_%s__\" % cls.__name__\n-                    if name.startswith(prefix):\n-                        # mangled attribute defined in parent class\n-                        return None\n+            # Otherwise, check whether the attribute came from a base class\n+            # and unmangle it from that base's namespace.\n+            for base in subject.__mro__[1:]:\n+                prefix = \"_%s__\" % base.__name__\n+                if name.startswith(prefix):\n+                    return name.replace(prefix, \"__\", 1)\n     except AttributeError:\n         pass\n \n     return name\n \n \n+\n def import_module(modname: str, warningiserror: bool = False) -> Any:\n     \"\"\"\n     Call importlib.import_module(modname), convert exceptions to ImportError\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8551",
        "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 404bb127f..20ffa6c38 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -65,17 +65,27 @@ class Field:\n         self.rolename = rolename\n         self.bodyrolename = bodyrolename\n \n-    def make_xref(self, rolename: str, domain: str, target: str,\n-                  innernode: \"Type[TextlikeNode]\" = addnodes.literal_emphasis,\n-                  contnode: Node = None, env: \"BuildEnvironment\" = None) -> Node:\n-        if not rolename:\n-            return contnode or innernode(target, target)\n-        refnode = addnodes.pending_xref('', refdomain=domain, refexplicit=False,\n-                                        reftype=rolename, reftarget=target)\n-        refnode += contnode or innernode(target, target)\n-        if env:\n-            env.get_domain(domain).process_field_xref(refnode)\n-        return refnode\n+def make_xref(self, rolename: str, domain: str, target: str,\n+              innernode: \"Type[TextlikeNode]\" = addnodes.literal_emphasis,\n+              contnode: Node = None, env: \"BuildEnvironment\" = None) -> Node:\n+    if not rolename:\n+        return contnode or innernode(target, target)\n+\n+    # FIX: if the domain is python and the target is unqualified (does not contain a dot),\n+    # then prepend the current module (set by py:currentmodule) so that the type\n+    # reference is resolved in the correct context.\n+    if env is not None and domain == 'py' and '.' not in target:\n+        current_module = env.ref_context.get('py:module')\n+        if current_module:\n+            target = current_module + '.' + target\n+\n+    refnode = addnodes.pending_xref('', refdomain=domain, refexplicit=False,\n+                                    reftype=rolename, reftarget=target)\n+    refnode += contnode or innernode(target, target)\n+    if env:\n+        env.get_domain(domain).process_field_xref(refnode)\n+    return refnode\n+\n \n     def make_xrefs(self, rolename: str, domain: str, target: str,\n                    innernode: \"Type[TextlikeNode]\" = addnodes.literal_emphasis,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8593",
        "model_patch": "diff --git a/sphinx/ext/autosummary/generate.py b/sphinx/ext/autosummary/generate.py\nindex 10f8ca913..fc3118b58 100644\n--- a/sphinx/ext/autosummary/generate.py\n+++ b/sphinx/ext/autosummary/generate.py\n@@ -229,15 +229,24 @@ def generate_autosummary_content(name: str, obj: Any, parent: Any,\n                                  modname: str = None, qualname: str = None) -> str:\n     doc = get_documenter(app, obj, parent)\n \n-    def skip_member(obj: Any, name: str, objtype: str) -> bool:\n-        try:\n-            return app.emit_firstresult('autodoc-skip-member', objtype, name,\n-                                        obj, False, {})\n-        except Exception as exc:\n-            logger.warning(__('autosummary: failed to determine %r to be documented, '\n-                              'the following exception was raised:\\n%s'),\n-                           name, exc, type='autosummary')\n-            return False\n+def skip_member(obj: Any, name: str, objtype: str) -> bool:\n+    # Check for meta information in the object's docstring.\n+    meta = {}\n+    doc = getattr(obj, '__doc__', '')\n+    if doc and ':meta public:' in doc:\n+        meta['public'] = True\n+\n+    try:\n+        result = app.emit_firstresult('autodoc-skip-member', objtype, name,\n+                                      obj, False, meta)\n+        # In case event handlers do not return any value, treat it as False.\n+        return result if result is not None else False\n+    except Exception as exc:\n+        logger.warning(__('autosummary: failed to determine %r to be documented, '\n+                          'the following exception was raised:\\n%s'),\n+                       name, exc, type='autosummary')\n+        return False\n+\n \n     def get_members(obj: Any, types: Set[str], include_public: List[str] = [],\n                     imported: bool = True) -> Tuple[List[str], List[str]]:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8595",
        "model_patch": "diff --git a/sphinx/ext/autodoc/importer.py b/sphinx/ext/autodoc/importer.py\nindex b6adb7ceb..fde53cab5 100644\n--- a/sphinx/ext/autodoc/importer.py\n+++ b/sphinx/ext/autodoc/importer.py\n@@ -145,6 +145,23 @@ def get_module_members(module: Any) -> List[Tuple[str, Any]]:\n     warnings.warn('sphinx.ext.autodoc.importer.get_module_members() is deprecated.',\n                   RemovedInSphinx50Warning)\n \n+    # If __all__ is defined, only use the names from __all__.\n+    if hasattr(module, '__all__'):\n+        all_attr = safe_getattr(module, '__all__', None)\n+        if isinstance(all_attr, list):\n+            # If __all__ is empty, return no members.\n+            if not all_attr:\n+                return []\n+            members = {}\n+            for name in all_attr:\n+                try:\n+                    value = safe_getattr(module, name, None)\n+                    members[name] = (name, value)\n+                except AttributeError:\n+                    continue\n+            return sorted(list(members.values()))\n+    \n+    # Fallback: if __all__ is not defined, include all members.\n     members = {}  # type: Dict[str, Tuple[str, Any]]\n     for name in dir(module):\n         try:\n@@ -152,7 +169,7 @@ def get_module_members(module: Any) -> List[Tuple[str, Any]]:\n             members[name] = (name, value)\n         except AttributeError:\n             continue\n-\n+    \n     # annotation only member (ex. attr: int)\n     try:\n         for name in getannotations(module):\n@@ -160,10 +177,11 @@ def get_module_members(module: Any) -> List[Tuple[str, Any]]:\n                 members[name] = (name, INSTANCEATTR)\n     except AttributeError:\n         pass\n-\n+    \n     return sorted(list(members.values()))\n \n \n+\n Attribute = NamedTuple('Attribute', [('name', str),\n                                      ('directly_defined', bool),\n                                      ('value', Any)])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8621",
        "model_patch": "diff --git a/sphinx/roles.py b/sphinx/roles.py\nindex 2d3042f8f..06cd1267e 100644\n--- a/sphinx/roles.py\n+++ b/sphinx/roles.py\n@@ -44,6 +44,1638 @@ generic_docroles = {\n     'program': addnodes.literal_strong,  # XXX should be an x-ref\n     'regexp': nodes.literal,\n \n+def kbd_role(typ: str, rawtext: str, text: str, lineno: int, inliner: Inliner,\n+             options: Dict = {}, content: List[str] = []) -> Tuple[List[Node], List[system_message]]:\n+    \"\"\"Custom kbd role to handle compound keystrokes with proper parsing.\n+    For keystrokes that are solely compound-key separators ('-', '+', '^'),\n+    the text is not split. For compound keystrokes, splits on unescaped\n+    separator characters and wraps each keystroke in its own <kbd> element.\n+    \"\"\"\n+    import re\n+    separators = ('-', '+', '^')\n+    # Handle standalone keystroke which is exactly one of the separators\n+    if text in separators:\n+        node = nodes.literal(rawtext, text, classes=['kbd'])\n+        return [node], []\n+    # If no separator is present, return as a single key\n+    if all(sep not in text for sep in separators):\n+        node = nodes.literal(rawtext, text, classes=['kbd'])\n+        return [node], []\n+    # Split text on unescaped compound-key separators\n+    pattern = re.compile(r'(?<!\\\\)([-+^])')\n+    tokens = pattern.split(text)\n+    def unescape(token):\n+        return token.replace('\\\\-', '-').replace('\\\\+', '+').replace('\\\\^', '^')\n+    container = nodes.literal(rawtext, '', classes=['kbd'])\n+    for i, token in enumerate(tokens):\n+        if i % 2 == 0:\n+            token = unescape(token)\n+            if token:\n+                key_node = nodes.literal(rawtext, token, classes=['kbd'])\n+                container += key_node\n+        else:\n+            # Insert the separator itself as plain text\n+            container += nodes.Text(token)\n+    return [container], []\n # -- generic cross-reference role ----------------------------------------------\n@@ -597,9 +2229,11 @@ class Index(ReferenceRole):\n \n \n specific_docroles = {\n+    # Override the default kbd role with our custom implementation.\n+    'kbd': kbd_role,\n+\n     # links to download references\n     'download': XRefRole(nodeclass=addnodes.download_reference),\n-    # links to anything\n     'any': AnyXRefRole(warn_dangling=True),\n \n     'pep': PEP(),\n@@ -612,6 +2246,7 @@ specific_docroles = {\n }  # type: Dict[str, RoleFunction]\n def setup(app: \"Sphinx\") -> Dict[str, Any]:\n     from docutils.parsers.rst import roles",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8638",
        "model_patch": "diff --git a/sphinx/ext/autodoc/directive.py b/sphinx/ext/autodoc/directive.py\nindex c134258d0..ed532e5a7 100644\n--- a/sphinx/ext/autodoc/directive.py\n+++ b/sphinx/ext/autodoc/directive.py\n@@ -130,6 +130,426 @@ class AutodocDirective(SphinxDirective):\n         documenter.generate(more_content=self.content)\n         if not params.result:\n             return []\n+       if getattr(documenter, 'objtype', '') in ('attribute', 'ivar'):\n+            text = params.result.astext()\n+            literal_node = nodes.literal_block(text, text)\n+            literal_node['language'] = 'none'\n+            # record dependencies as usual\n+            for fn in params.filename_set:\n+                self.state.document.settings.record_dependencies.add(fn)\n+            return [literal_node]\n         logger.debug('[autodoc] output:\\n%s', '\\n'.join(params.result))",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-8721",
        "model_patch": "diff --git a/sphinx/ext/viewcode.py b/sphinx/ext/viewcode.py\nindex a7d52a91c..1ff0c3e77 100644\n--- a/sphinx/ext/viewcode.py\n+++ b/sphinx/ext/viewcode.py\n@@ -182,6 +182,185 @@ def collect_pages(app: Sphinx) -> Generator[Tuple[str, Dict[str, Any], str], Non\n     env = app.builder.env\n     if not hasattr(env, '_viewcode_modules'):\n         return\n+ Do not generate viewcode pages for EPUB builds when viewcode_enable_epub is False.\n+if app.builder.name.startswith(\"epub\") and not app.config.viewcode_enable_epub:\n+    return\n     highlighter = app.builder.highlighter  # type: ignore\n     urito = app.builder.get_relative_uri",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9229",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex af4b47bb0..422c2633e 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -120,11 +120,12 @@ def modify_field_list(node: nodes.field_list, annotations: Dict[str, str]) -> No\n             field += nodes.field_body('', nodes.paragraph('', ''))\n             node += field\n \n-    if 'return' in annotations and 'return' not in arguments:\n-        field = nodes.field()\n-        field += nodes.field_name('', 'rtype')\n-        field += nodes.field_body('', nodes.paragraph('', annotation))\n-        node += field\n+if 'return' in annotations and 'return' not in arguments:\n+    field = nodes.field()\n+    field += nodes.field_name('', 'rtype')\n+    field += nodes.field_body('', nodes.paragraph('', annotations['return']))\n+    node += field\n+\n \n \n def augment_descriptions_with_types(\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9230",
        "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 3a3367ebe..47fefe6ee 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -297,21 +297,22 @@ class DocFieldTransformer:\n \n             # also support syntax like ``:param type name:``\n             if typedesc.is_typed:\n-                try:\n-                    argtype, argname = fieldarg.split(None, 1)\n-                except ValueError:\n-                    pass\n-                else:\n-                    types.setdefault(typename, {})[argname] = \\\n-                        [nodes.Text(argtype)]\n+                import re\n+                m = re.match(r'^(?P<argtype>.+\\))\\s+(?P<argname>\\S+)$', fieldarg)\n+                if m:\n+                    argtype = m.group('argtype')\n+                    argname = m.group('argname')\n+                    types.setdefault(typename, {})[argname] = [nodes.Text(argtype)]\n                     fieldarg = argname\n+                else:\n+                    try:\n+                        argtype, argname = fieldarg.split(None, 1)\n+                    except ValueError:\n+                        pass\n+                    else:\n+                        types.setdefault(typename, {})[argname] = [nodes.Text(argtype)]\n+                        fieldarg = argname\n \n-            translatable_content = nodes.inline(field_body.rawsource,\n-                                                translatable=True)\n-            translatable_content.document = field_body.parent.document\n-            translatable_content.source = field_body.parent.source\n-            translatable_content.line = field_body.parent.line\n-            translatable_content += content\n \n             # grouped entries need to be collected in one entry, while others\n             # get one entry per field\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9258",
        "model_patch": "diff --git a/sphinx/util/docfields.py b/sphinx/util/docfields.py\nindex 6d48e910c..26b1d9306 100644\n--- a/sphinx/util/docfields.py\n+++ b/sphinx/util/docfields.py\n@@ -182,10 +182,20 @@ class TypedField(GroupedField):\n                 # inconsistencies later when references are resolved\n                 fieldtype = types.pop(fieldarg)\n                 if len(fieldtype) == 1 and isinstance(fieldtype[0], nodes.Text):\n-                    typename = fieldtype[0].astext()\n-                    par.extend(self.make_xrefs(self.typerolename, domain, typename,\n-                                               addnodes.literal_emphasis, env=env))\n-                else:\n+                    typename_text = fieldtype[0].astext()\n+                    if '|' in typename_text:\n+                        parts = [part.strip() for part in typename_text.split('|')]\n+                        first = True\n+                        for part in parts:\n+                            if not first:\n+                                par += nodes.Text(\" | \")\n+                            par.extend(self.make_xrefs(self.typerolename, domain, part,\n+                                                       addnodes.literal_emphasis, env=env))\n+                            first = False\n+                    else:\n+                        par.extend(self.make_xrefs(self.typerolename, domain, typename_text,\n+                                                   addnodes.literal_emphasis, env=env))\n+\n                     par += fieldtype\n                 par += nodes.Text(')')\n             par += nodes.Text(' -- ')\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9281",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex a415a7074..b14395c3e 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -457,6 +457,10 @@ def object_description(object: Any) -> str:\n         else:\n             return \"frozenset({%s})\" % \", \".join(object_description(x)\n                                                  for x in sorted_values)\n+    # Special handling for Enum values (report as ClassName.MemberName)\n+    if isinstance(object, enum.Enum):\n+        return f\"{object.__class__.__name__}.{object.name}\"\n+\n     try:\n         s = repr(object)\n     except Exception as exc:\n@@ -467,6 +471,7 @@ def object_description(object: Any) -> str:\n     return s.replace('\\n', ' ')\n \n \n+\n def is_builtin_class_method(obj: Any, attr_name: str) -> bool:\n     \"\"\"If attr_name is implemented at builtin class, return True.\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9320",
        "model_patch": "diff --git a/sphinx/cmd/quickstart.py b/sphinx/cmd/quickstart.py\nindex a40a21073..97438e00c 100644\n--- a/sphinx/cmd/quickstart.py\n+++ b/sphinx/cmd/quickstart.py\n@@ -223,10 +223,11 @@ def ask_user(d: Dict) -> None:\n         print(__('sphinx-quickstart will not overwrite existing Sphinx projects.'))\n         print()\n         d['path'] = do_prompt(__('Please enter a new root path (or just Enter to exit)'),\n-                              '', is_path)\n+                              '', lambda x: x if x == \"\" else is_path(x))\n         if not d['path']:\n             sys.exit(1)\n \n+\n     if 'sep' not in d:\n         print()\n         print(__('You have two options for placing the build directory for Sphinx output.\\n'\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9367",
        "model_patch": "diff --git a/sphinx/pycode/ast.py b/sphinx/pycode/ast.py\nindex f541ec0a9..5ff9562f3 100644\n--- a/sphinx/pycode/ast.py\n+++ b/sphinx/pycode/ast.py\n@@ -212,11 +212,14 @@ class _UnparseVisitor(ast.NodeVisitor):\n     def visit_UnaryOp(self, node: ast.UnaryOp) -> str:\n         return \"%s %s\" % (self.visit(node.op), self.visit(node.operand))\n \n-    def visit_Tuple(self, node: ast.Tuple) -> str:\n-        if node.elts:\n-            return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n-        else:\n-            return \"()\"\n+def visit_Tuple(self, node: ast.Tuple) -> str:\n+    if not node.elts:\n+        return \"()\"\n+    elif len(node.elts) == 1:\n+        return \"(\" + self.visit(node.elts[0]) + \",)\"\n+    else:\n+        return \"(\" + \", \".join(self.visit(e) for e in node.elts) + \")\"\n+\n \n     if sys.version_info < (3, 8):\n         # these ast nodes were deprecated in python 3.8\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9461",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex 23dd9e930..7431b1007 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -837,7 +837,9 @@ def getdoc(obj: Any, attrgetter: Callable = safe_getattr,\n     * inherited docstring\n     * inherited decorated methods\n     \"\"\"\n-    doc = attrgetter(obj, '__doc__', None)\n+if doc is None and hasattr(obj, '__func__'):\n+    doc = attrgetter(obj.__func__, '__doc__', None)\n+\n     if ispartial(obj) and doc == obj.__class__.__doc__:\n         return getdoc(obj.func)\n     elif doc is None and allow_inherited:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9591",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex af4b47bb0..a4c078b79 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -24,6 +24,12 @@ def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n                      options: Dict, args: str, retann: str) -> None:\n     \"\"\"Record type hints to env object.\"\"\"\n     try:\n+        # If the object is a property, use its getter (fget) for retrieving type hints.\n+        if isinstance(obj, property):\n+            if obj.fget is None:\n+                return\n+            obj = obj.fget\n+\n         if callable(obj):\n             annotations = app.env.temp_data.setdefault('annotations', {})\n             annotation = annotations.setdefault(name, OrderedDict())\n@@ -37,6 +43,7 @@ def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,\n         pass\n \n \n+\n def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element) -> None:\n     if domain != 'py':\n         return\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9602",
        "model_patch": "diff --git a/sphinx/util/typing.py b/sphinx/util/typing.py\nindex cf4318cda..4f0c6df62 100644\n--- a/sphinx/util/typing.py\n+++ b/sphinx/util/typing.py\n@@ -177,10 +177,12 @@ def _restify_py37(cls: Optional[Type]) -> str:\n             args = ', '.join(restify(a) for a in cls.__args__[:-1])\n             text += r\"\\ [[%s], %s]\" % (args, restify(cls.__args__[-1]))\n         elif cls.__module__ == 'typing' and getattr(origin, '_name', None) == 'Literal':\n-            text += r\"\\ [%s]\" % ', '.join(repr(a) for a in cls.__args__)\n-        elif cls.__args__:\n+            # For Literal types, return a plain string to avoid treating literal values as py:class.\n+            return 'Literal[%s]' % ', '.join(repr(a) for a in cls.__args__)\n+        elif hasattr(cls, '__args__') and cls.__args__:\n             text += r\"\\ [%s]\" % \", \".join(restify(a) for a in cls.__args__)\n \n+\n         return text\n     elif isinstance(cls, typing._SpecialForm):\n         return ':obj:`~%s.%s`' % (cls.__module__, cls._name)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9658",
        "model_patch": "diff --git a/sphinx/util/inspect.py b/sphinx/util/inspect.py\nindex b767b8adc..728fa316f 100644\n--- a/sphinx/util/inspect.py\n+++ b/sphinx/util/inspect.py\n@@ -442,6 +442,11 @@ def safe_getattr(obj: Any, name: str, *defargs: Any) -> Any:\n \n def object_description(object: Any) -> str:\n     \"\"\"A repr() implementation that returns text safe to use in reST context.\"\"\"\n+    # If this is a mock object that has a proper _mock_name attribute,\n+    # use it as the description. This fixes issues with documenting bases that are mocks.\n+    if hasattr(object, '_mock_name') and object._mock_name:\n+        return object._mock_name\n+\n     if isinstance(object, dict):\n         try:\n             sorted_keys = sorted(object)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9673",
        "model_patch": "diff --git a/sphinx/ext/autodoc/typehints.py b/sphinx/ext/autodoc/typehints.py\nindex af4b47bb0..316d68d3e 100644\n--- a/sphinx/ext/autodoc/typehints.py\n+++ b/sphinx/ext/autodoc/typehints.py\n@@ -149,11 +149,12 @@ def augment_descriptions_with_types(\n         elif parts[0] == 'type':\n             name = ' '.join(parts[1:])\n             has_type.add(name)\n-        elif parts[0] == 'return':\n+        elif parts[0] in ('return', 'returns'):\n             has_description.add('return')\n         elif parts[0] == 'rtype':\n             has_type.add('return')\n \n+\n     # Add 'type' for parameters with a description but no declared type.\n     for name in annotations:\n         if name == 'return':\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9698",
        "model_patch": "diff --git a/sphinx/domains/python.py b/sphinx/domains/python.py\nindex cd02eaad5..80df49d75 100644\n--- a/sphinx/domains/python.py\n+++ b/sphinx/domains/python.py\n@@ -796,8 +796,9 @@ class PyMethod(PyObject):\n         if 'classmethod' in self.options:\n             return _('%s() (%s class method)') % (methname, clsname)\n         elif 'property' in self.options:\n-            return _('%s() (%s property)') % (methname, clsname)\n-        elif 'staticmethod' in self.options:\n+            # For properties, do not include parens in the index entry.\n+            return _('%s (%s property)') % (methname, clsname)\n+\n             return _('%s() (%s static method)') % (methname, clsname)\n         else:\n             return _('%s() (%s method)') % (methname, clsname)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sphinx-doc__sphinx-9711",
        "model_patch": "diff --git a/utils/checks.py b/utils/checks.py\nindex 093817409..f7832a433 100644\n--- a/utils/checks.py\n+++ b/utils/checks.py\n@@ -12,6 +12,60 @@ import os\n import re\n \n import sphinx\n+rom packaging.version import parse as parse_version\n name_mail_re = r'[\\w ]+(<.*?>)?'\n copyright_re = re.compile(r'^    :copyright: Copyright 200\\d(-20\\d\\d)? '\n@@ -24,7 +78,8 @@ license_re = re.compile(r'    :license: (.*?).\\n')\n def flake8ext(_func):\n     \"\"\"Decorate flake8_asserts functions\"\"\"\n     _func.name = _func.__name__\n-    _func.version = sphinx.__version__\n+    _func.version = parse_version(sphinx.__version__)\n+\n     _func.code = _func.__name__.upper()\n \n     return _func",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-11618",
        "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 593048464b..7047563cfe 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -236,38 +236,49 @@ def ambient_dimension(self):\n \n     def distance(self, p):\n         \"\"\"The Euclidean distance from self to point p.\n-\n+        \n         Parameters\n         ==========\n-\n+        \n         p : Point\n-\n+        \n         Returns\n         =======\n-\n+        \n         distance : number or symbolic expression.\n-\n+        \n         See Also\n         ========\n-\n+        \n         sympy.geometry.line.Segment.length\n-\n+        \n         Examples\n         ========\n-\n+        \n         >>> from sympy.geometry import Point\n         >>> p1, p2 = Point(1, 1), Point(4, 5)\n         >>> p1.distance(p2)\n         5\n-\n+        \n         >>> from sympy.abc import x, y\n         >>> p3 = Point(x, y)\n         >>> p3.distance(Point(0, 0))\n         sqrt(x**2 + y**2)\n-\n+        \n+        >>> # When points have different dimensions, missing coordinates are assumed to be 0.\n+        >>> from sympy import sqrt\n+        >>> Point(2, 0).distance(Point(1, 0, 2))\n+        sqrt(5)\n         \"\"\"\n-        return sqrt(sum([(a - b)**2 for a, b in zip(\n-            self.args, p.args if isinstance(p, Point) else p)]))\n+        self_coords = self.args\n+        other = p.args if isinstance(p, Point) else p\n+        # Determine maximum dimension between the two points\n+        max_dim = max(len(self_coords), len(other))\n+        # Pad the coordinates with zeros if dimensions are unequal\n+        self_extended = list(self_coords) + [S.Zero] * (max_dim - len(self_coords))\n+        other_extended = list(other) + [S.Zero] * (max_dim - len(other))\n+        return sqrt(sum((a - b)**2 for a, b in zip(self_extended, other_extended)))\n+\n \n     def taxicab_distance(self, p):\n         \"\"\"The Taxicab Distance from self to point p.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-12096",
        "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 1b8005e1d2..528a71aa62 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -507,7 +507,13 @@ def _eval_evalf(self, prec):\n             func = getattr(mpmath, fname)\n         except (AttributeError, KeyError):\n             try:\n-                return Float(self._imp_(*self.args), prec)\n+            try:\n+                result = self._imp_(*self.args)\n+                if hasattr(result, 'evalf'):\n+                    # recursively evalf the result if applicable\n+                    return result.evalf(prec)\n+                else:\n+                    return Float(result, prec)\n             except (AttributeError, TypeError, ValueError):\n                 return\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-12419",
        "model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex b6808b58d9..1b8895cb2d 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -1687,6 +1687,141 @@ class MatrixBase(MatrixArithmetic, MatrixOperations, MatrixProperties, MatrixSha\n     __hash__ = None  # Mutable\n \n     def __array__(self):\n+   def __iter__(self):\n+        for i in range(self.rows):\n+            for j in range(self.cols):\n+                yield self[i, j]\n         from .dense import matrix2numpy\n         return matrix2numpy(self)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-12481",
        "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 136ed5a478..c2b2ae5c99 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -891,19 +891,14 @@ def __new__(cls, *args, **kwargs):\n \n         # if there are n elements present, 0, 1, ..., n-1 should be present\n         # unless a cycle notation has been provided. A 0 will be added\n-        # for convenience in case one wants to enter permutations where\n-        # counting starts from 1.\n-\n-        temp = flatten(args)\n-        if has_dups(temp):\n-            if is_cycle:\n-                raise ValueError('there were repeated elements; to resolve '\n-                'cycles use Cycle%s.' % ''.join([str(tuple(c)) for c in args]))\n-            else:\n-                raise ValueError('there were repeated elements.')\n-        temp = set(temp)\n+if not is_cycle:\n+    temp = flatten(args)\n+    if has_dups(temp):\n+        raise ValueError('there were repeated elements.')\n+    temp = set(temp)\n+    if any(i not in temp for i in range(len(temp))):\n+        raise ValueError(\"Integers 0 through %s must be present.\" % max(temp))\n \n-        if not is_cycle and \\\n                 any(i not in temp for i in range(len(temp))):\n             raise ValueError(\"Integers 0 through %s must be present.\" %\n                              max(temp))\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-12489",
        "model_patch": "diff --git a/sympy/combinatorics/permutations.py b/sympy/combinatorics/permutations.py\nindex 4ac1c2ef3b..cc9215b649 100644\n--- a/sympy/combinatorics/permutations.py\n+++ b/sympy/combinatorics/permutations.py\n@@ -857,9 +857,11 @@ def __new__(cls, *args, **kwargs):\n         #g) (Permutation) = adjust size or return copy\n         ok = True\n         if not args:  # a\n-            return _af_new(list(range(size or 0)))\n+            return cls._af_new(list(range(size or 0)))\n+\n         elif len(args) > 1:  # c\n-            return _af_new(Cycle(*args).list(size))\n+            return cls._af_new(Cycle(*args).list(size))\n+\n         if len(args) == 1:\n             a = args[0]\n             if isinstance(a, Perm):  # g\n@@ -867,7 +869,8 @@ def __new__(cls, *args, **kwargs):\n                     return a\n                 return Perm(a.array_form, size=size)\n             if isinstance(a, Cycle):  # f\n-                return _af_new(a.list(size))\n+                    return cls._af_new(a.list(size))\n+\n             if not is_sequence(a):  # b\n                 return _af_new(list(range(a + 1)))\n             if has_variety(is_sequence(ai) for ai in a):\n@@ -924,17 +927,16 @@ def __new__(cls, *args, **kwargs):\n         obj._size = size\n         return obj\n \n-    @staticmethod\n-    def _af_new(perm):\n+    @classmethod\n+    def _af_new(cls, perm):\n         \"\"\"A method to produce a Permutation object from a list;\n         the list is bound to the _array_form attribute, so it must\n         not be modified; this method is meant for internal use only;\n         the list ``a`` is supposed to be generated as a temporary value\n         in a method, so p = Perm._af_new(a) is the only object\n         to hold a reference to ``a``::\n-\n+        \n         Examples\n-        ========\n \n         >>> from sympy.combinatorics.permutations import Perm\n         >>> Perm.print_cyclic = False\n@@ -944,7 +946,7 @@ def _af_new(perm):\n         Permutation([2, 1, 3, 0])\n \n         \"\"\"\n-        p = Basic.__new__(Perm, perm)\n+        p = Basic.__new__(cls, perm)\n         p._array_form = perm\n         p._size = len(perm)\n         return p\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13031",
        "model_patch": "diff --git a/sympy/matrices/matrices.py b/sympy/matrices/matrices.py\nindex da1d30716e..aadd307b90 100644\n--- a/sympy/matrices/matrices.py\n+++ b/sympy/matrices/matrices.py\n@@ -4046,11 +4046,13 @@ def _find_reasonable_pivot(col, iszerofunc=_iszero, simpfunc=_simplify):\n             isinstance(x, Float) for x in col):\n         col_abs = [abs(x) for x in col]\n         max_value = max(col_abs)\n-        if iszerofunc(max_value):\n-            # just because iszerofunc returned True, doesn't\n-            # mean the value is numerically zero.  Make sure\n-            # to replace all entries with numerical zeros\n-            if max_value != 0:\n+    if iszerofunc(max_value):\n+        if max_value == 0:\n+            newly_determined = [(i, 0) for i, x in enumerate(col) if x != 0]\n+        else:\n+            newly_determined = []\n+        return (None, None, False, newly_determined)\n+\n                 newly_determined = [(i, 0) for i, x in enumerate(col) if x != 0]\n             return (None, None, False, newly_determined)\n         index = col_abs.index(max_value)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13091",
        "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex db4e971848..10b0372d13 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -313,7 +313,8 @@ def __eq__(self, other):\n             try:\n                 other = _sympify(other)\n             except SympifyError:\n-                return False    # sympy != other\n+                return NotImplemented    # sympy != other\n+\n \n             if type(self) != type(other):\n                 return False\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13372",
        "model_patch": "diff --git a/sympy/core/evalf.py b/sympy/core/evalf.py\nindex 72a5fbae52..975287d8c6 100644\n--- a/sympy/core/evalf.py\n+++ b/sympy/core/evalf.py\n@@ -1301,12 +1301,18 @@ def evalf(x, prec, options):\n             elif re.is_number:\n                 re = re._to_mpmath(prec, allow_ints=False)._mpf_\n                 reprec = prec\n+            else:\n+                raise NotImplementedError(\"Cannot compute numerical value for %s\" % re)\n+\n             if im == 0:\n                 im = None\n                 imprec = None\n             elif im.is_number:\n                 im = im._to_mpmath(prec, allow_ints=False)._mpf_\n                 imprec = prec\n+            else:\n+                raise NotImplementedError(\"Cannot compute numerical value for %s\" % im)\n+\n             r = re, im, reprec, imprec\n         except AttributeError:\n             raise NotImplementedError\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13480",
        "model_patch": "diff --git a/sympy/functions/elementary/hyperbolic.py b/sympy/functions/elementary/hyperbolic.py\nindex 2a4555d919..732d2164e6 100644\n--- a/sympy/functions/elementary/hyperbolic.py\n+++ b/sympy/functions/elementary/hyperbolic.py\n@@ -587,7 +587,8 @@ def eval(cls, arg):\n                 x, m = _peeloff_ipi(arg)\n                 if m:\n                     cothm = coth(m)\n-                    if cotm is S.ComplexInfinity:\n+                    if cothm is S.ComplexInfinity:\n+\n                         return coth(x)\n                     else: # cothm == 0\n                         return tanh(x)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13551",
        "model_patch": "diff --git a/sympy/concrete/products.py b/sympy/concrete/products.py\nindex 66aafde2d6..dcc171837f 100644\n--- a/sympy/concrete/products.py\n+++ b/sympy/concrete/products.py\n@@ -1,25 +1,26 @@\n-from __future__ import print_function, division\n-\n-from sympy.tensor.indexed import Idx\n-from sympy.core.mul import Mul\n-from sympy.core.singleton import S\n-from sympy.core.symbol import symbols\n-from sympy.concrete.expr_with_intlimits import ExprWithIntLimits\n-from sympy.functions.elementary.exponential import exp, log\n-from sympy.polys import quo, roots\n-from sympy.simplify import powsimp\n+from sympy.concrete.expr_with_limits import ExprWithLimits, ExprWithIntLimits\n+\n+\n+class Product(ExprWithLimits, ExprWithIntLimits):\n+    def __new__(cls, function, *symbols, **assumptions):\n+        # Use ExprWithLimits.__new__ directly so that no additive\n+        # orientation factor is introduced.\n+        obj = ExprWithLimits.__new__(cls, function, *symbols, **assumptions)\n+        return obj\n+\n from sympy.core.compatibility import range\n \n \n class Product(ExprWithIntLimits):\n-    r\"\"\"Represents unevaluated products.\n-\n-    ``Product`` represents a finite or infinite product, with the first\n-    argument being the general form of terms in the series, and the second\n-    argument being ``(dummy_variable, start, end)``, with ``dummy_variable``\n-    taking all integer values from ``start`` through ``end``. In accordance\n-    with long-standing mathematical convention, the end term is included in\n-    the product.\n+    def doit(self, **hints):\n+        # Evaluate the product directly.\n+        from sympy import prod\n+        (i, a, b) = self.limits[0]\n+        if (b - a).is_integer and (b - a) < 50:\n+            result = prod(self.function.subs(i, a + j) for j in range(b - a + 1))\n+            return result\n+        return self\n+\n \n     Finite products\n     ===============\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13615",
        "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 917717bb74..92e3242728 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -999,11 +999,26 @@ def _complement(self, other):\n             return Union(a, b)\n \n         if isinstance(other, FiniteSet):\n-            nums = [m for m in other.args if m.is_number]\n-            if nums == []:\n-                return None\n+            num_part = []\n+            sym_part = []\n+            for el in other.args:\n+                c = self.contains(el)\n+                if c is S.true:\n+                    continue\n+                elif c is S.false:\n+                    num_part.append(el)\n+                else:\n+                    sym_part.append(el)\n+            if sym_part:\n+                if num_part:\n+                    return Union(FiniteSet(*num_part),\n+                                 Complement(FiniteSet(*sym_part), self, evaluate=False),\n+                                 evaluate=False)\n+                else:\n+                    return Complement(FiniteSet(*sym_part), self, evaluate=False)\n+            else:\n+                return FiniteSet(*num_part)\n \n-        return Set._complement(self, other)\n \n \n     def _union(self, other):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13647",
        "model_patch": "diff --git a/sympy/matrices/common.py b/sympy/matrices/common.py\nindex 056d9bc497..bc2c079dfb 100644\n--- a/sympy/matrices/common.py\n+++ b/sympy/matrices/common.py\n@@ -217,14 +217,19 @@ def col_insert(self, pos, other):\n \n         return self._eval_col_insert(pos, other)\n \n-    def col_join(self, other):\n-        \"\"\"Concatenates two matrices along self's last and other's first row.\n-\n-        Examples\n-        ========\n+        new_cols = self.cols + other.cols\n+        def entry(i, j):\n+            if j < pos:\n+                return self[i, j]\n+            elif j < pos + other.cols:\n+                # insert the new column block: use column offset j-pos\n+                return other[i, j - pos]\n+            else:\n+                # for columns right of the inserted block, take value from self.\n+                # note: j - other.cols gives the proper offset into self's original columns.\n+                return self[i, j - other.cols]\n+        return self._new(self.rows, new_cols, entry)\n \n-        >>> from sympy import zeros, ones\n-        >>> M = zeros(3)\n         >>> V = ones(1, 3)\n         >>> M.col_join(V)\n         Matrix([\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13757",
        "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex d5ac051f63..bbb58f3d14 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -27,7 +27,8 @@\n     _parallel_dict_from_expr,\n )\n \n-from sympy.polys.rationaltools import together\n+    _op_priority = 11.0\n+\n from sympy.polys.rootisolation import dup_isolate_real_roots_list\n from sympy.polys.groebnertools import groebner as _groebner\n from sympy.polys.fglmtools import matrix_fglm\n@@ -4157,6 +4158,31 @@ def eq(f, g, strict=False):\n             return f._strict_eq(sympify(g))\n \n     def ne(f, g, strict=False):\n+   _op_priority = 11.0\n         return not f.eq(g, strict=strict)\n \n     def _strict_eq(f, g):",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13798",
        "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex ad4d7d9613..aa76cedae5 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -156,11 +156,14 @@ def __init__(self, settings=None):\n             \"times\": r\" \\times \"\n         }\n \n-        self._settings['mul_symbol_latex'] = \\\n-            mul_symbol_table[self._settings['mul_symbol']]\n+        custom = self._settings.get('mul_symbol')\n+        if custom in mul_symbol_table:\n+            self._settings['mul_symbol_latex'] = mul_symbol_table[custom]\n+            self._settings['mul_symbol_latex_numbers'] = mul_symbol_table[custom]\n+        else:\n+            self._settings['mul_symbol_latex'] = custom\n+            self._settings['mul_symbol_latex_numbers'] = custom\n \n-        self._settings['mul_symbol_latex_numbers'] = \\\n-            mul_symbol_table[self._settings['mul_symbol'] or 'dot']\n \n         self._delim_dict = {'(': ')', '[': ']'}\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13852",
        "model_patch": "diff --git a/sympy/functions/special/zeta_functions.py b/sympy/functions/special/zeta_functions.py\nindex b8e2b66195..a3f3df0d93 100644\n--- a/sympy/functions/special/zeta_functions.py\n+++ b/sympy/functions/special/zeta_functions.py\n@@ -39,11 +39,13 @@ class lerchphi(Function):\n \n     Assume now `\\operatorname{Re}(a) > 0`. The integral representation\n \n-    .. math:: \\Phi_0(z, s, a) = \\int_0^\\infty \\frac{t^{s-1} e^{-at}}{1 - ze^{-t}}\n-                                \\frac{\\mathrm{d}t}{\\Gamma(s)}\n-\n-    provides an analytic continuation to :math:`\\mathbb{C} - [1, \\infty)`.\n-    Finally, for :math:`x \\in (1, \\infty)` we find\n+    @classmethod\n+    def eval(cls, s, z):\n+        from sympy import log, pi, S\n+        # Special evaluation: polylog(2, 1/2) = -log(2)**2/2 + pi**2/12\n+        if s == 2 and z == S(1)/2:\n+            return -log(2)**2/2 + pi**2/12\n+        return None\n \n     .. math:: \\lim_{\\epsilon \\to 0^+} \\Phi_0(x + i\\epsilon, s, a)\n              -\\lim_{\\epsilon \\to 0^+} \\Phi_0(x - i\\epsilon, s, a)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13877",
        "model_patch": "diff --git a/sympy/core/exprtools.py b/sympy/core/exprtools.py\nindex 4e0de9ec18..5b5cbf7751 100644\n--- a/sympy/core/exprtools.py\n+++ b/sympy/core/exprtools.py\n@@ -122,11 +122,12 @@ def _monotonic_sign(self):\n                     roots = []\n                 else:\n                     try:\n-                        roots = real_roots(d)\n-                    except (PolynomialError, NotImplementedError):\n-                        roots = [r for r in roots(d, x) if r.is_real]\n-                y = self.subs(x, x0)\n-                if x.is_nonnegative and all(r <= x0 for r in roots):\n+    for i, col_val in enumerate(col):\n+        # FIX: if an element equals S.NaN, treat it as zero so that pivot-search comparisons do not fail.\n+        if col_val == S.NaN:\n+            col_val = S.Zero\n+        col_val_is_zero = iszerofunc(col_val)\n+\n                     if y.is_nonnegative and d.is_positive:\n                         if y:\n                             return y if y.is_positive else Dummy('pos', positive=True)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13878",
        "model_patch": "diff --git a/sympy/stats/crv_types.py b/sympy/stats/crv_types.py\nindex fff7da80ae..64faa56ad4 100644\n--- a/sympy/stats/crv_types.py\n+++ b/sympy/stats/crv_types.py\n@@ -1384,6 +1384,161 @@ def check(a, b):\n     def pdf(self, x):\n         a, b = self.a, self.b\n         return a * b * x**(a-1) * (1-x**a)**(b-1)\n+   def _cdf(self, x):\n+        a, b = self.a, self.b\n+        # Precomputed CDF: F(x) = 1 - (1 - x**a)**b  for 0<=x<=1\n+        return 1 - (1 - x**a)**b\n def Kumaraswamy(name, a, b):\n     r\"\"\"\n@@ -1709,7 +1864,12 @@ class NakagamiDistribution(SingleContinuousDistribution):\n \n     def pdf(self, x):\n         mu, omega = self.mu, self.omega\n-        return 2*mu**mu/(gamma(mu)*omega**mu)*x**(2*mu - 1)*exp(-mu/omega*x**2)\n+        return 2 * mu**mu / (gamma(mu) * omega**mu) * x**(2*mu - 1) * exp(-mu*x**2/omega)\n+\n+    def _cdf(self, x):\n+        mu, omega = self.mu, self.omega\n+        # Precomputed CDF: F(x) = lowergamma(mu, (mu*x**2)/omega) / gamma(mu)\n+        return lowergamma(mu, mu*x**2/omega) / gamma(mu)\n \n \n def Nakagami(name, mu, omega):\n@@ -2551,8 +2711,309 @@ def set(self):\n     def pdf(self, x):\n         n = self.n\n         k = Dummy(\"k\")\n-        return 1/factorial(\n+        return 1/factorial(n - 1) * Sum((-1)**k * binomial(n, k) * (x - k)**(n - 1),\n+                                          (k, 0, floor(x)))\n+\n             n - 1)*Sum((-1)**k*binomial(n, k)*(x - k)**(n - 1), (k, 0, floor(x)))\n+   def _cdf(self, x):\n+        n = self.n\n+        k = Dummy(\"k\")\n+        # Precomputed Irwin-Hall CDF:\n+        #   F(x) = 1/factorial(n) * Sum[(-1)**k * binomial(n, k) * (x - k)**n, {k, 0, floor(x)}]\n+        return 1/factorial(n) * Sum((-1)**k * binomial(n, k) * (x - k)**n, (k, 0, floor(x)))",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-13974",
        "model_patch": "diff --git a/sympy/physics/quantum/tensorproduct.py b/sympy/physics/quantum/tensorproduct.py\nindex 9dd10d219e..de1d21df83 100644\n--- a/sympy/physics/quantum/tensorproduct.py\n+++ b/sympy/physics/quantum/tensorproduct.py\n@@ -147,6 +147,793 @@ def _eval_rewrite(self, pattern, rule, **hints):\n         sargs = self.args\n         terms = [t._eval_rewrite(pattern, rule, **hints) for t in sargs]\n         return TensorProduct(*terms).expand(tensorproduct=True)\n+   def _eval_power(self, exponent):\n+        \"\"\"\n+        Evaluate integer powers of a TensorProduct by repeated multiplication.\n+        This is needed so that expressions like (TensorProduct(A,B))**2\n+        can be simplified to TensorProduct(A**2, B**2) when applicable.\n+        \"\"\"\n+        from sympy import S, Pow\n+        # Only handle integer exponents.\n+        if not exponent.is_Integer:\n+            return Pow(self, exponent)\n+        n = int(exponent)\n+        if n == 0:\n+            return S.One\n+        if n < 0:\n+            return Pow(self, exponent)\n+        from sympy.physics.quantum.tensorproduct import tensor_product_simp\n+        result = self\n+        for _ in range(n - 1):\n+            result = tensor_product_simp(result * self)\n+        return result\n     def _sympystr(self, printer, *args):\n         from sympy.printing.str import sstr",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-14248",
        "model_patch": "diff --git a/sympy/printing/latex.py b/sympy/printing/latex.py\nindex 8253b2f682..6364d1ddcf 100644\n--- a/sympy/printing/latex.py\n+++ b/sympy/printing/latex.py\n@@ -389,6 +389,188 @@ def _print_Gradient(self, expr):\n     def _print_Mul(self, expr):\n         from sympy.core.power import Pow\n         from sympy.physics.units import Quantity\n+   c, rest = expr.as_coeff_Mul()\n+    from sympy.matrices.expressions.matexpr import MatrixSymbol\n+    if c == -1 and rest.is_MatrixSymbol:\n+        return \"-\" + self._print(rest)\n         include_parens = False\n         if _coeff_isneg(expr):\n             expr = -expr\ndiff --git a/sympy/printing/str.py b/sympy/printing/str.py\nindex 0baefe0f7f..efbc941091 100644\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -260,13 +260,18 @@ def _print_Mul(self, expr):\n \n         prec = precedence(expr)\n \n-        c, e = expr.as_coeff_Mul()\n+        c, rest = expr.as_coeff_Mul()\n+        # special case for MatrixSymbols: we want to print -X rather than \"(-1)*X\"\n+        from sympy.matrices.expressions.matexpr import MatrixSymbol\n+        if c == -1 and rest.is_MatrixSymbol:\n+            return \"-\" + self._print(rest)\n         if c < 0:\n-            expr = _keep_coeff(-c, e)\n+            expr = _keep_coeff(-c, rest)\n             sign = \"-\"\n         else:\n             sign = \"\"\n         a = []  # items in the numerator\n         b = []  # items that are in the denominator (if any)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-14531",
        "model_patch": "diff --git a/sympy/printing/str.py b/sympy/printing/str.py\nindex cc1d19fcce..9a88bb223f 100644\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -216,9 +216,10 @@ def _print_LatticeOp(self, expr):\n     def _print_Limit(self, expr):\n         e, z, z0, dir = expr.args\n         if str(dir) == \"+\":\n-            return \"Limit(%s, %s, %s)\" % (e, z, z0)\n+            return \"Limit(%s, %s, %s)\" % (self._print(e), self._print(z), self._print(z0))\n         else:\n-            return \"Limit(%s, %s, %s, dir='%s')\" % (e, z, z0, dir)\n+            return \"Limit(%s, %s, %s, dir='%s')\" % (self._print(e), self._print(z), self._print(z0), self._print(dir))\n+\n \n     def _print_list(self, expr):\n         return \"[%s]\" % self.stringify(expr, \", \")\n@@ -630,7 +631,8 @@ def _print_Relational(self, expr):\n         }\n \n         if expr.rel_op in charmap:\n-            return '%s(%s, %s)' % (charmap[expr.rel_op], expr.lhs, expr.rhs)\n+            return '%s(%s, %s)' % (charmap[expr.rel_op], self._print(expr.lhs), self._print(expr.rhs))\n+\n \n         return '%s %s %s' % (self.parenthesize(expr.lhs, precedence(expr)),\n                            self._relationals.get(expr.rel_op) or expr.rel_op,\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-14711",
        "model_patch": "diff --git a/sympy/physics/vector/vector.py b/sympy/physics/vector/vector.py\nindex a048ee57f1..20460269e7 100644\n--- a/sympy/physics/vector/vector.py\n+++ b/sympy/physics/vector/vector.py\n@@ -57,9 +57,12 @@ def __hash__(self):\n \n     def __add__(self, other):\n         \"\"\"The add operator for Vector. \"\"\"\n+        if other == 0:\n+            return self\n         other = _check_vector(other)\n         return Vector(self.args + other.args)\n \n+\n     def __and__(self, other):\n         \"\"\"Dot product of two vectors.\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-14976",
        "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex d06901425d..59ad6ca26f 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -117,10 +117,11 @@ def _module_format(self, fqn, register=True):\n \n         if self._settings['fully_qualified_modules']:\n             return fqn\n-        else:\n-            return fqn.split('(')[0].split('[')[0].split('.')[-1]\n+    def _print_Rational(self, expr):\n+        # When using mpmath the literal rational should be wrapped using mpf()\n+        # to ensure full multiprecision. This fixes issue #14971.\n+        return \"mpf('%s/%s')\" % (expr.p, expr.q)\n \n-    def _format_code(self, lines):\n         return lines\n \n     def _get_statement(self, codestring):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15017",
        "model_patch": "diff --git a/sympy/tensor/array/ndim_array.py b/sympy/tensor/array/ndim_array.py\nindex 099b291167..399c539bce 100644\n--- a/sympy/tensor/array/ndim_array.py\n+++ b/sympy/tensor/array/ndim_array.py\n@@ -163,18 +163,21 @@ def _handle_ndarray_creation_inputs(cls, iterable=None, shape=None, **kwargs):\n \n     def __len__(self):\n         \"\"\"Overload common function len(). Returns number of elements in array.\n-\n+        \n         Examples\n         ========\n-\n+        \n         >>> from sympy import MutableDenseNDimArray\n         >>> a = MutableDenseNDimArray.zeros(3, 3)\n         >>> a\n         [[0, 0, 0], [0, 0, 0], [0, 0, 0]]\n         >>> len(a)\n         9\n-\n+        \n+        For rank-0 arrays (scalars) return 1 as the correct number of elements.\n         \"\"\"\n+        if self.rank() == 0:\n+            return 1\n         return self._loop_size\n \n     @property\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15345",
        "model_patch": "diff --git a/sympy/printing/mathematica.py b/sympy/printing/mathematica.py\nindex ea7e3a2d94..73bd03940b 100644\n--- a/sympy/printing/mathematica.py\n+++ b/sympy/printing/mathematica.py\n@@ -100,6 +100,9 @@ def _print_Function(self, expr):\n                 if cond(*expr.args):\n                     return \"%s[%s]\" % (mfunc, self.stringify(expr.args, \", \"))\n         return expr.func.__name__ + \"[%s]\" % self.stringify(expr.args, \", \")\n+    def _print_Max(self, expr):\n+        # Override for correct Mathematica syntax: maintain order and use square brackets.\n+        return \"Max[%s]\" % self.stringify(expr.args, \", \")\n \n     def _print_Integral(self, expr):\n         if len(expr.variables) == 1 and not expr.limits[0][1:]:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15349",
        "model_patch": "diff --git a/sympy/algebras/quaternion.py b/sympy/algebras/quaternion.py\nindex b84e7cb95a..700e525b85 100644\n--- a/sympy/algebras/quaternion.py\n+++ b/sympy/algebras/quaternion.py\n@@ -529,7 +529,8 @@ def to_rotation_matrix(self, v=None):\n \n         m10 = 2*s*(q.b*q.c + q.d*q.a)\n         m11 = 1 - 2*s*(q.b**2 + q.d**2)\n-        m12 = 2*s*(q.c*q.d + q.b*q.a)\n+            m12 = 2*s*(q.c*q.d - q.b*q.a)\n+\n \n         m20 = 2*s*(q.b*q.d - q.c*q.a)\n         m21 = 2*s*(q.c*q.d + q.b*q.a)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15599",
        "model_patch": "diff --git a/sympy/core/mod.py b/sympy/core/mod.py\nindex eae25630cc..7939eec72a 100644\n--- a/sympy/core/mod.py\n+++ b/sympy/core/mod.py\n@@ -123,9 +123,12 @@ def doit(p, q):\n             for arg in p.args:\n                 both_l[isinstance(arg, cls)].append(arg)\n \n-            if mod_l and all(inner.args[1] == q for inner in mod_l):\n-                # finding distributive term\n-                non_mod_l = [cls(x, q) for x in non_mod_l]\n+was = non_mod_l[:]\n+non_mod_l = [cls(x, q) for x in non_mod_l]\n+changed = (was != non_mod_l)\n+if changed or (mod_l and all(inner.args[1] == q for inner in mod_l)):\n+    # finding distributive term\n+\n                 mod = []\n                 non_mod = []\n                 for j in non_mod_l:\ndiff --git a/sympy/core/tests/test_arit.py b/sympy/core/tests/test_arit.py\nindex 04d3b1ab9f..49b89999d8 100644\n--- a/sympy/core/tests/test_arit.py\n+++ b/sympy/core/tests/test_arit.py\n@@ -1625,6 +1625,43 @@ def test_Mod():\n     assert (3*i*x) % (2*i*y) == i*Mod(3*x, 2*y)\n     assert Mod(4*i, 4) == 0\n \n+    assert Mod(3*i, 2) == Mod(i, 2)\n     # issue 8677\n     n = Symbol('n', integer=True, positive=True)\n     assert factorial(n) % n == 0",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15809",
        "model_patch": "diff --git a/sympy/functions/elementary/miscellaneous.py b/sympy/functions/elementary/miscellaneous.py\nindex 5f9fe73c5c..a86d174cd0 100644\n--- a/sympy/functions/elementary/miscellaneous.py\n+++ b/sympy/functions/elementary/miscellaneous.py\n@@ -47,12 +47,11 @@ class IdentityFunction(with_metaclass(Singleton, Lambda)):\n     \"\"\"\n \n     def __new__(cls):\n-        from sympy.sets.sets import FiniteSet\n-        x = Dummy('x')\n-        #construct \"by hand\" to avoid infinite loop\n-        obj = Expr.__new__(cls, Tuple(x), x)\n-        obj.nargs = FiniteSet(1)\n-        return obj\n+    @classmethod\n+    def eval(cls, *args):\n+        if not args:\n+            return S.Infinity\n+        # \u2026 rest of the original evaluation logic \u2026\n \n Id = S.IdentityFunction\n \n@@ -67,13 +66,12 @@ def sqrt(arg, evaluate=None):\n     sqrt(x) -> Returns the principal square root of x.\n \n     The parameter evaluate determines if the expression should be evaluated.\n-    If None, its value is taken from global_evaluate\n-\n-    Examples\n-    ========\n+    @classmethod\n+    def eval(cls, *args):\n+        if not args:\n+            return S.NegativeInfinity\n+        # \u2026 rest of the original evaluation logic \u2026\n \n-    >>> from sympy import sqrt, Symbol\n-    >>> x = Symbol('x')\n \n     >>> sqrt(x)\n     sqrt(x)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15875",
        "model_patch": "diff --git a/sympy/core/add.py b/sympy/core/add.py\nindex 83a5f2aedc..cda34476fb 100644\n--- a/sympy/core/add.py\n+++ b/sympy/core/add.py\n@@ -529,6 +529,260 @@ def _eval_is_imaginary(self):\n         elif b.is_zero is False:\n             return False\n \n+    if self.is_number and self.is_complex:\n+        re, im = self.as_real_imag(deep=False)\n+        if re.is_zero is True and im.is_zero is True:\n+            return True\n+        if re.is_zero is False or im.is_zero is False:\n+            return False\n     def _eval_is_zero(self):\n         if self.is_commutative is False:\n             # issue 10528: there is no way to know if a nc symbol",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-15976",
        "model_patch": "diff --git a/sympy/printing/mathml.py b/sympy/printing/mathml.py\nindex 3f8b8d49e0..1d04ca9e58 100644\n--- a/sympy/printing/mathml.py\n+++ b/sympy/printing/mathml.py\n@@ -332,61 +332,71 @@ def _print_Sum(self, e):\n         # same internal representation.\n         return self._print_Integral(e)\n \n-    def _print_Symbol(self, sym):\n-        ci = self.dom.createElement(self.mathml_tag(sym))\n-\n-        def join(items):\n-            if len(items) > 1:\n-                mrow = self.dom.createElement('mml:mrow')\n-                for i, item in enumerate(items):\n-                    if i > 0:\n-                        mo = self.dom.createElement('mml:mo')\n-                        mo.appendChild(self.dom.createTextNode(\" \"))\n-                        mrow.appendChild(mo)\n-                    mi = self.dom.createElement('mml:mi')\n-                    mi.appendChild(self.dom.createTextNode(item))\n-                    mrow.appendChild(mi)\n-                return mrow\n-            else:\n-                mi = self.dom.createElement('mml:mi')\n-                mi.appendChild(self.dom.createTextNode(items[0]))\n-                return mi\n+def _print_Symbol(self, sym):\n+    from re import fullmatch\n+    # If the symbol\u2019s name is solely letters with a trailing number (e.g. \"x2\"),\n+    # do not split it into base and subscript to avoid rendering issues.\n+    if fullmatch(r'[a-zA-Z]+\\d+', sym.name):\n+        tag = self.mathml_tag(sym)\n+        ci = self.dom.createElement(tag)\n+        ci.appendChild(self.dom.createTextNode(sym.name))\n+        return ci\n \n-        # translate name, supers and subs to unicode characters\n-        def translate(s):\n-            if s in greek_unicode:\n-                return greek_unicode.get(s)\n-            else:\n-                return s\n-\n-        name, supers, subs = split_super_sub(sym.name)\n-        name = translate(name)\n-        supers = [translate(sup) for sup in supers]\n-        subs = [translate(sub) for sub in subs]\n-\n-        mname = self.dom.createElement('mml:mi')\n-        mname.appendChild(self.dom.createTextNode(name))\n-        if len(supers) == 0:\n-            if len(subs) == 0:\n-                ci.appendChild(self.dom.createTextNode(name))\n-            else:\n-                msub = self.dom.createElement('mml:msub')\n-                msub.appendChild(mname)\n-                msub.appendChild(join(subs))\n-                ci.appendChild(msub)\n+    ci = self.dom.createElement(self.mathml_tag(sym))\n+\n+    def join(items):\n+        if len(items) > 1:\n+            mrow = self.dom.createElement('mml:mrow')\n+            for i, item in enumerate(items):\n+                if i > 0:\n+                    mo = self.dom.createElement('mml:mo')\n+                    mo.appendChild(self.dom.createTextNode(\" \"))\n+                    mrow.appendChild(mo)\n+                mi = self.dom.createElement('mml:mi')\n+                mi.appendChild(self.dom.createTextNode(item))\n+                mrow.appendChild(mi)\n+            return mrow\n         else:\n-            if len(subs) == 0:\n-                msup = self.dom.createElement('mml:msup')\n-                msup.appendChild(mname)\n-                msup.appendChild(join(supers))\n-                ci.appendChild(msup)\n-            else:\n-                msubsup = self.dom.createElement('mml:msubsup')\n-                msubsup.appendChild(mname)\n-                msubsup.appendChild(join(subs))\n-                msubsup.appendChild(join(supers))\n-                ci.appendChild(msubsup)\n-        return ci\n+            mi = self.dom.createElement('mml:mi')\n+            mi.appendChild(self.dom.createTextNode(items[0]))\n+            return mi\n+\n+    # translate name, supers and subs to unicode characters\n+    def translate(s):\n+        if s in greek_unicode:\n+            return greek_unicode.get(s)\n+        else:\n+            return s\n+\n+    name, supers, subs = split_super_sub(sym.name)\n+    name = translate(name)\n+    supers = [translate(sup) for sup in supers]\n+    subs = [translate(sub) for sub in subs]\n+\n+    mname = self.dom.createElement('mml:mi')\n+    mname.appendChild(self.dom.createTextNode(name))\n+    if len(supers) == 0:\n+        if len(subs) == 0:\n+            ci.appendChild(self.dom.createTextNode(name))\n+        else:\n+            msub = self.dom.createElement('mml:msub')\n+            msub.appendChild(mname)\n+            msub.appendChild(join(subs))\n+            ci.appendChild(msub)\n+    else:\n+        if len(subs) == 0:\n+            msup = self.dom.createElement('mml:msup')\n+            msup.appendChild(mname)\n+            msup.appendChild(join(supers))\n+            ci.appendChild(msup)\n+        else:\n+            msubsup = self.dom.createElement('mml:msubsup')\n+            msubsup.appendChild(mname)\n+            msubsup.appendChild(join(subs))\n+            msubsup.appendChild(join(supers))\n+            ci.appendChild(msubsup)\n+    return ci\n+\n \n     _print_MatrixSymbol = _print_Symbol\n     _print_RandomSymbol = _print_Symbol\n@@ -742,64 +752,75 @@ def _print_Sum(self, e):\n \n         return mrow\n \n-    def _print_Symbol(self, sym, style='plain'):\n-        x = self.dom.createElement('mi')\n-\n+def _print_Symbol(self, sym, style='plain'):\n+    from re import fullmatch\n+    # If the symbol\u2019s name is solely letters with a trailing number (e.g. \"x2\"),\n+    # output it as one token rather than splitting into base and subscript.\n+    if fullmatch(r'[a-zA-Z]+\\d+', sym.name):\n+        mi = self.dom.createElement('mi')\n         if style == 'bold':\n-            x.setAttribute('mathvariant', 'bold')\n-\n-        def join(items):\n-            if len(items) > 1:\n-                mrow = self.dom.createElement('mrow')\n-                for i, item in enumerate(items):\n-                    if i > 0:\n-                        mo = self.dom.createElement('mo')\n-                        mo.appendChild(self.dom.createTextNode(\" \"))\n-                        mrow.appendChild(mo)\n-                    mi = self.dom.createElement('mi')\n-                    mi.appendChild(self.dom.createTextNode(item))\n-                    mrow.appendChild(mi)\n-                return mrow\n-            else:\n-                mi = self.dom.createElement('mi')\n-                mi.appendChild(self.dom.createTextNode(items[0]))\n-                return mi\n+            mi.setAttribute('mathvariant', 'bold')\n+        mi.appendChild(self.dom.createTextNode(sym.name))\n+        return mi\n \n-        # translate name, supers and subs to unicode characters\n-        def translate(s):\n-            if s in greek_unicode:\n-                return greek_unicode.get(s)\n-            else:\n-                return s\n-\n-        name, supers, subs = split_super_sub(sym.name)\n-        name = translate(name)\n-        supers = [translate(sup) for sup in supers]\n-        subs = [translate(sub) for sub in subs]\n-\n-        mname = self.dom.createElement('mi')\n-        mname.appendChild(self.dom.createTextNode(name))\n-        if len(supers) == 0:\n-            if len(subs) == 0:\n-                x.appendChild(self.dom.createTextNode(name))\n-            else:\n-                msub = self.dom.createElement('msub')\n-                msub.appendChild(mname)\n-                msub.appendChild(join(subs))\n-                x.appendChild(msub)\n+    x = self.dom.createElement('mi')\n+\n+    if style == 'bold':\n+        x.setAttribute('mathvariant', 'bold')\n+\n+    def join(items):\n+        if len(items) > 1:\n+            mrow = self.dom.createElement('mrow')\n+            for i, item in enumerate(items):\n+                if i > 0:\n+                    mo = self.dom.createElement('mo')\n+                    mo.appendChild(self.dom.createTextNode(\" \"))\n+                    mrow.appendChild(mo)\n+                mi = self.dom.createElement('mi')\n+                mi.appendChild(self.dom.createTextNode(item))\n+                mrow.appendChild(mi)\n+            return mrow\n         else:\n-            if len(subs) == 0:\n-                msup = self.dom.createElement('msup')\n-                msup.appendChild(mname)\n-                msup.appendChild(join(supers))\n-                x.appendChild(msup)\n-            else:\n-                msubsup = self.dom.createElement('msubsup')\n-                msubsup.appendChild(mname)\n-                msubsup.appendChild(join(subs))\n-                msubsup.appendChild(join(supers))\n-                x.appendChild(msubsup)\n-        return x\n+            mi = self.dom.createElement('mi')\n+            mi.appendChild(self.dom.createTextNode(items[0]))\n+            return mi\n+\n+    # translate name, supers and subs to unicode characters\n+    def translate(s):\n+        if s in greek_unicode:\n+            return greek_unicode.get(s)\n+        else:\n+            return s\n+\n+    name, supers, subs = split_super_sub(sym.name)\n+    name = translate(name)\n+    supers = [translate(sup) for sup in supers]\n+    subs = [translate(sub) for sub in subs]\n+\n+    mname = self.dom.createElement('mi')\n+    mname.appendChild(self.dom.createTextNode(name))\n+    if len(supers) == 0:\n+        if len(subs) == 0:\n+            x.appendChild(self.dom.createTextNode(name))\n+        else:\n+            msub = self.dom.createElement('msub')\n+            msub.appendChild(mname)\n+            msub.appendChild(join(subs))\n+            x.appendChild(msub)\n+    else:\n+        if len(subs) == 0:\n+            msup = self.dom.createElement('msup')\n+            msup.appendChild(mname)\n+            msup.appendChild(join(supers))\n+            x.appendChild(msup)\n+        else:\n+            msubsup = self.dom.createElement('msubsup')\n+            msubsup.appendChild(mname)\n+            msubsup.appendChild(join(subs))\n+            msubsup.appendChild(join(supers))\n+            x.appendChild(msubsup)\n+    return x\n+\n \n     def _print_MatrixSymbol(self, sym):\n         return self._print_Symbol(sym, style=self._settings['mat_symbol_style'])\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16450",
        "model_patch": "diff --git a/sympy/simplify/simplify.py b/sympy/simplify/simplify.py\nindex c6b511f206..77e6df9bf7 100644\n--- a/sympy/simplify/simplify.py\n+++ b/sympy/simplify/simplify.py\n@@ -251,8 +251,9 @@ def posify(eq):\n             eq[i] = e.subs(reps)\n         return f(eq), {r: s for s, r in reps.items()}\n \n-    reps = {s: Dummy(s.name, positive=True)\n+    reps = {s: Dummy(s.name, **dict(s.assumptions0, positive=True))\n                  for s in eq.free_symbols if s.is_positive is None}\n+\n     eq = eq.subs(reps)\n     return eq, {r: s for s, r in reps.items()}\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16597",
        "model_patch": "diff --git a/sympy/core/assumptions.py b/sympy/core/assumptions.py\nindex ce4dd30f2e..d34f0b5553 100644\n--- a/sympy/core/assumptions.py\n+++ b/sympy/core/assumptions.py\n@@ -174,6 +174,8 @@\n \n     'odd            ==  integer & !even',\n     'even           ==  integer & !odd',\n+'even           ->  finite',\n+'odd            ->  finite',\n \n     'real           ==  negative | zero | positive',\n     'transcendental ==  complex & !algebraic',\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16766",
        "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex a3f0310735..19f06fe4a5 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -356,6 +356,168 @@ def _print_sign(self, e):\n     def _print_Not(self, expr):\n         PREC = precedence(expr)\n         return self._operators['not'] + self.parenthesize(expr.args[0], PREC)\n+   def _print_Indexed(self, expr):\n+        base, *index = expr.args\n+        return \"{}[{}]\".format(str(base), \", \".join([self._print(ind) for ind in index]))\n for k in PythonCodePrinter._kf:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16792",
        "model_patch": "diff --git a/sympy/utilities/autowrap.py b/sympy/utilities/autowrap.py\nindex bd6afb12d1..94c907a14c 100644\n--- a/sympy/utilities/autowrap.py\n+++ b/sympy/utilities/autowrap.py\n@@ -612,6 +612,283 @@ def autowrap(expr, language=None, backend='f2py', tempdir=None, args=None,\n     else:\n         helpers = [helpers] if helpers else ()\n     args = list(args) if iterable(args, exclude=set) else args\n+ Force dependency on any argument that does not occur in expr.\n+# This ensures that array arguments retain their dimensional information\n+# (and are thus generated as pointer arguments in the C code).\n+for arg in args:\n+    if not expr.has(arg):\n+        expr = expr + 0*arg\n     if code_gen is None:\n         code_gen = get_code_generator(language, \"autowrap\")",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-16886",
        "model_patch": "diff --git a/sympy/crypto/crypto.py b/sympy/crypto/crypto.py\nindex ca552191c0..30a4bb2efe 100644\n--- a/sympy/crypto/crypto.py\n+++ b/sympy/crypto/crypto.py\n@@ -1520,7 +1520,8 @@ def decipher_kid_rsa(msg, key):\n     \"..-\": \"U\", \"...-\": \"V\",\n     \".--\": \"W\", \"-..-\": \"X\",\n     \"-.--\": \"Y\", \"--..\": \"Z\",\n-    \"-----\": \"0\", \"----\": \"1\",\n+\"-----\": \"0\", \".----\": \"1\",\n+\n     \"..---\": \"2\", \"...--\": \"3\",\n     \"....-\": \"4\", \".....\": \"5\",\n     \"-....\": \"6\", \"--...\": \"7\",\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-17139",
        "model_patch": "diff --git a/sympy/simplify/fu.py b/sympy/simplify/fu.py\nindex ad1130ef96..cd20e1a1ff 100644\n--- a/sympy/simplify/fu.py\n+++ b/sympy/simplify/fu.py\n@@ -501,6 +501,61 @@ def _f(rv):\n         if not (rv.is_Pow and rv.base.func == f):\n             return rv\n \n+        if not rv.exp.is_real:\n+            return rv\n         if (rv.exp < 0) == True:\n             return rv\n         if (rv.exp > max) == True:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-17318",
        "model_patch": "diff --git a/sympy/simplify/sqrtdenest.py b/sympy/simplify/sqrtdenest.py\nindex f0b7653ea8..be457bbe76 100644\n--- a/sympy/simplify/sqrtdenest.py\n+++ b/sympy/simplify/sqrtdenest.py\n@@ -156,10 +156,15 @@ def _sqrt_match(p):\n         res = (p, S.Zero, S.Zero)\n     elif p.is_Add:\n         pargs = sorted(p.args, key=default_sort_key)\n+        # If there are no square root terms then nothing can be denested;\n+        # so return an empty list to signal no match.\n+        if not any(arg.is_Pow and arg.exp == S.Half for arg in pargs):\n+            return []\n         if all((x**2).is_Rational for x in pargs):\n             r, b, a = split_surds(p)\n             res = a, b, r\n             return list(res)\n+\n         # to make the process canonical, the argument is included in the tuple\n         # so when the max is selected, it will be the largest arg having a\n         # given depth\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-17630",
        "model_patch": "diff --git a/sympy/matrices/expressions/blockmatrix.py b/sympy/matrices/expressions/blockmatrix.py\nindex 95302a05ca..01c5cce382 100644\n--- a/sympy/matrices/expressions/blockmatrix.py\n+++ b/sympy/matrices/expressions/blockmatrix.py\n@@ -125,8 +125,13 @@ def __new__(cls, *args, **kwargs):\n                     blocks fully filling a 2-D space then see\n                     Matrix.irregular.'''))\n         mat = ImmutableDenseMatrix(rows, evaluate=False)\n-        obj = Basic.__new__(cls, mat)\n-        return obj\n+obj = Basic.__new__(cls, mat)\n+# Store the block sizes from the original list \"rows\"\n+obj._rowblocksizes = [row[0].rows for row in rows]\n+obj._colblocksizes = [rows[0][i].cols for i in range(len(rows[0]))]\n+obj._blockshape = mat.shape\n+return obj\n+\n \n     @property\n     def shape(self):\n@@ -147,12 +152,16 @@ def blocks(self):\n         return self.args[0]\n \n     @property\n-    def rowblocksizes(self):\n-        return [self.blocks[i, 0].rows for i in range(self.blockshape[0])]\n+try:\n+    return [self.blocks[i, 0].rows for i in range(self.blockshape[0])]\n+except AttributeError:\n+    return self._rowblocksizes\n+\n+try:\n+    return [self.blocks[0, i].cols for i in range(self.blockshape[1])]\n+except AttributeError:\n+    return self._colblocksizes\n \n-    @property\n-    def colblocksizes(self):\n-        return [self.blocks[0, i].cols for i in range(self.blockshape[1])]\n \n     def structurally_equal(self, other):\n         return (isinstance(other, BlockMatrix)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-17655",
        "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 7c978c47be..c22af6c854 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -277,6 +277,137 @@ def __mul__(self, factor):\n         factor = sympify(factor)\n         coords = [simplify(x*factor) for x in self.args]\n         return Point(coords, evaluate=False)\n+   def __rmul__(self, factor):\n+        \"\"\"Right multiplication supports scalar * Point.\"\"\"\n+        return self.__mul__(factor)\n     def __neg__(self):\n         \"\"\"Negate the point.\"\"\"",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18189",
        "model_patch": "diff --git a/sympy/solvers/diophantine.py b/sympy/solvers/diophantine.py\nindex 6092e35dab..b4778d8bb1 100644\n--- a/sympy/solvers/diophantine.py\n+++ b/sympy/solvers/diophantine.py\n@@ -137,13 +137,14 @@ def diophantine(eq, param=symbols(\"t\", integer=True), syms=None,\n     >>> diophantine(eq)\n     {(2, 3)}\n     >>> diophantine(eq, permute=True)\n-    {(-3, -2), (-3, 2), (-2, -3), (-2, 3), (2, -3), (2, 3), (3, -2), (3, 2)}\n+    if syms:\n+        if not is_sequence(syms):\n+            raise TypeError(\"syms should be given as a sequence, e.g. a list\")\n+        syms = [s for s in syms if s in var]\n+        if syms != var:\n+            dict_sym_index = dict(zip(syms, range(len(syms))))\n+            return {tuple(sol[dict_sym_index[s]] for s in syms) for sol in diop_solve(eq, param)}\n \n-    Details\n-    =======\n-\n-    ``eq`` should be an expression which is assumed to be zero.\n-    ``t`` is the parameter to be used in the solution.\n \n     Examples\n     ========\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18199",
        "model_patch": "diff --git a/sympy/ntheory/residue_ntheory.py b/sympy/ntheory/residue_ntheory.py\nindex 9a3052d4c3..c93d23176e 100644\n--- a/sympy/ntheory/residue_ntheory.py\n+++ b/sympy/ntheory/residue_ntheory.py\n@@ -768,6 +768,136 @@ def nthroot_mod(a, n, p, all_roots=False):\n     \"\"\"\n     from sympy.core.numbers import igcdex\n     a, n, p = as_int(a), as_int(n), as_int(p)\n+   # fix: if a % p == 0 then 0 mod p is a valid (and only) solution\n+    if a % p == 0:\n+        return [0] if all_roots else 0\n     if n == 2:\n         return sqrt_mod(a, p, all_roots)\n     # see Hackman \"Elementary Number Theory\" (2009), page 76",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18211",
        "model_patch": "diff --git a/sympy/solvers/solveset.py b/sympy/solvers/solveset.py\nindex 445be3e0e8..06b0af6661 100644\n--- a/sympy/solvers/solveset.py\n+++ b/sympy/solvers/solveset.py\n@@ -567,11 +567,13 @@ def _solve_trig1(f, symbol, domain):\n \n     solns = solveset_complex(g, y) - solveset_complex(h, y)\n     if isinstance(solns, ConditionSet):\n-        raise NotImplementedError\n+        return ConditionSet(symbol, Eq(f_original, 0), domain)\n+\n \n     if isinstance(solns, FiniteSet):\n         if any(isinstance(s, RootOf) for s in solns):\n-            raise NotImplementedError\n+            return ConditionSet(symbol, Eq(f_original, 0), domain)\n+\n         result = Union(*[inverter(cov, s, symbol)[1] for s in solns])\n         # avoid spurious intersections with C in solution set\n         if domain is S.Complexes:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18698",
        "model_patch": "diff --git a/sympy/polys/sqfreetools.py b/sympy/polys/sqfreetools.py\nindex 1783a7744a..977488bdf2 100644\n--- a/sympy/polys/sqfreetools.py\n+++ b/sympy/polys/sqfreetools.py\n@@ -333,6 +333,18 @@ def dup_sqf_list(f, K, all=False):\n         i += 1\n \n     return coeff, result\n+    # Group factors with identical multiplicities so that factors like\n+    # (x - 2, 3) and (x - 3, 3) are combined into a single factor (x**2 - 5*x + 6, 3)\n+    grouped = {}\n+    order = []\n+    for fac, exp in result:\n+        if exp in grouped:\n+            grouped[exp] = dup_mul(grouped[exp], fac, K)\n+        else:\n+            grouped[exp] = fac\n+            order.append(exp)\n+    new_result = [(grouped[e], e) for e in order]\n+    return coeff, new_result\n \n \n def dup_sqf_list_include(f, K, all=False):\n@@ -419,8 +431,20 @@ def dmp_sqf_list(f, u, K, all=False):\n             result.append((g, i))\n \n         i += 1\n+    # Group factors with identical multiplicities.\n+    # Import dmp_mul (which multiplies two multivariate polynomials) if not already imported.\n+    from sympy.polys.densearith import dmp_mul\n+    grouped = {}\n+    order = []\n+    for fac, exp in result:\n+        if exp in grouped:\n+            grouped[exp] = dmp_mul(grouped[exp], fac, u, K)\n+        else:\n+            grouped[exp] = fac\n+            order.append(exp)\n+    new_result = [(grouped[e], e) for e in order]\n+    return coeff, new_result\n \n-    return coeff, result\n \n \n def dmp_sqf_list_include(f, u, K, all=False):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-18763",
        "model_patch": "",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19040",
        "model_patch": "diff --git a/sympy/core/expr.py b/sympy/core/expr.py\nindex a41a68c4dc..01ba55c7ca 100644\n--- a/sympy/core/expr.py\n+++ b/sympy/core/expr.py\n@@ -3583,10 +3583,17 @@ def gammasimp(self):\n         from sympy.simplify import gammasimp\n         return gammasimp(self)\n \n-    def factor(self, *gens, **args):\n-        \"\"\"See the factor() function in sympy.polys.polytools\"\"\"\n-        from sympy.polys import factor\n-        return factor(self, *gens, **args)\n+def factor(self, *gens, **args):\n+    \"\"\"See the factor() function in sympy.polys.polytools\n+\n+    When the 'extension' keyword is used and no generators are provided,\n+    all free symbols are used as generators so that factors which do not involve\n+    the algebraic extension (e.g., y-1) are preserved.\n+    \"\"\"\n+    if 'extension' in args and not gens:\n+        gens = tuple(self.free_symbols)\n+    from sympy.polys import factor\n+    return factor(self, *gens, **args)\n \n     def refine(self, assumption=True):\n         \"\"\"See the refine function in sympy.assumptions\"\"\"\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19346",
        "model_patch": "diff --git a/sympy/printing/repr.py b/sympy/printing/repr.py\nindex c936a692c0..2bdd428847 100644\n--- a/sympy/printing/repr.py\n+++ b/sympy/printing/repr.py\n@@ -338,8 +338,20 @@ def _print_BaseScalarField(self, bsf):\n         class_name = bsf.func.__name__\n         coords = self._print(bsf._coord_sys)\n         idx = self._print(bsf._index)\n-        return \"%s(%s, %s)\" % (class_name, coords, idx)\n+    def _print_set(self, expr):\n+        \"\"\"Return the string representation for a set in an evaluable format.\"\"\"\n+        if not expr:\n+            return \"set()\"\n+        # Use list conversion so that each element is processed by srepr\n+        return \"set([%s])\" % self.reprify(list(expr), \", \")\n+\n+    def _print_dict(self, expr):\n+        \"\"\"Return the string representation for a dictionary in an evaluable format.\"\"\"\n+        items = [\"%s: %s\" % (self._print(k), self._print(v)) for k, v in expr.items()]\n+        return \"{%s}\" % \", \".join(items)\n+\n \n def srepr(expr, **settings):\n-    \"\"\"return expr in repr form\"\"\"\n+    \"\"\"Return expr in an evaluable repr form.\"\"\"\n+\n     return ReprPrinter(settings).doprint(expr)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19495",
        "model_patch": "diff --git a/sympy/sets/conditionset.py b/sympy/sets/conditionset.py\nindex 118eda6f77..dca25d5d79 100644\n--- a/sympy/sets/conditionset.py\n+++ b/sympy/sets/conditionset.py\n@@ -32,13 +32,17 @@ class ConditionSet(Set):\n \n     >>> sin_sols = ConditionSet(x, Eq(sin(x), 0), Interval(0, 2*pi))\n     >>> 2*pi in sin_sols\n-    True\n-    >>> pi/2 in sin_sols\n-    False\n-    >>> 3*pi in sin_sols\n-    False\n-    >>> 5 in ConditionSet(x, x**2 > 4, S.Reals)\n-    True\n+def _subs(self, old, new, **hints):\n+    # Protect the bound variable. If the substitution target \u201cold\u201d is the bound\n+    # symbol (self.sym), do not change it.\n+    new_sym = self.sym if old == self.sym else self.sym._subs(old, new, **hints)\n+\n+    new_condition = self.condition._subs(old, new, **hints)\n+    new_base_set = self.base_set._subs(old, new, **hints)\n+\n+    if new_sym == self.sym and new_condition == self.condition and new_base_set == self.base_set:\n+        return self\n+    return ConditionSet(new_sym, new_condition, new_base_set)\n \n     If the value is not in the base set, the result is false:\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19637",
        "model_patch": "diff --git a/sympy/core/sympify.py b/sympy/core/sympify.py\nindex a3f1ce2851..a2650861e6 100644\n--- a/sympy/core/sympify.py\n+++ b/sympy/core/sympify.py\n@@ -469,6 +469,19 @@ def kernS(s):\n     from random import choice\n     from sympy.core.symbol import Symbol\n     hit = False\n+ern = None\n     quoted = '\"' in s or \"'\" in s\n     if '(' in s and not quoted:\n         if s.count('(') != s.count(\")\"):\n@@ -513,7 +526,8 @@ def kernS(s):\n             while kern in s:\n                 kern += choice(string.ascii_letters + string.digits)\n             s = s.replace(' ', kern)\n-        hit = kern in s\n+hit = True\n     for i in range(2):\n         try:",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19783",
        "model_patch": "diff --git a/sympy/physics/quantum/dagger.py b/sympy/physics/quantum/dagger.py\nindex 17da3cfd2c..123c54da66 100644\n--- a/sympy/physics/quantum/dagger.py\n+++ b/sympy/physics/quantum/dagger.py\n@@ -77,6 +77,7 @@ class Dagger(adjoint):\n     \"\"\"\n \n     def __new__(cls, arg):\n+        obj = None\n         if hasattr(arg, 'adjoint'):\n             obj = arg.adjoint()\n         elif hasattr(arg, 'conjugate') and hasattr(arg, 'transpose'):\n@@ -85,5 +86,484 @@ def __new__(cls, arg):\n             return obj\n         return Expr.__new__(cls, arg)\n \n+    def __mul__(self, other):\n+        from sympy.physics.quantum.operator import IdentityOperator\n+        from sympy import Mul\n+        if isinstance(other, IdentityOperator):\n+            return self\n+        return Mul(self, other)\n+    def __rmul__(self, other):\n+        from sympy.physics.quantum.operator import IdentityOperator\n+        from sympy import Mul\n+        if isinstance(other, IdentityOperator):\n+            return self\n+        return Mul(other, self)\n adjoint.__name__ = \"Dagger\"\n adjoint._sympyrepr = lambda a, b: \"Dagger(%s)\" % b._print(a.args[0])",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-19954",
        "model_patch": "diff --git a/sympy/combinatorics/perm_groups.py b/sympy/combinatorics/perm_groups.py\nindex de94ddabb4..5fbacb8b82 100644\n--- a/sympy/combinatorics/perm_groups.py\n+++ b/sympy/combinatorics/perm_groups.py\n@@ -2194,18 +2194,16 @@ def _number_blocks(blocks):\n                 # check if the system is minimal with\n                 # respect to the already discovere ones\n                 minimal = True\n-                to_remove = []\n-                for i, r in enumerate(rep_blocks):\n+                for i in reversed(range(len(rep_blocks))):\n+                    r = rep_blocks[i]\n                     if len(r) > len(rep) and rep.issubset(r):\n-                        # i-th block system is not minimal\n-                        del num_blocks[i], blocks[i]\n-                        to_remove.append(rep_blocks[i])\n+                        del rep_blocks[i]\n+                        del num_blocks[i]\n+                        del blocks[i]\n                     elif len(r) < len(rep) and r.issubset(rep):\n-                        # the system being checked is not minimal\n                         minimal = False\n                         break\n-                # remove non-minimal representative blocks\n-                rep_blocks = [r for r in rep_blocks if r not in to_remove]\n+\n \n                 if minimal and num_block not in num_blocks:\n                     blocks.append(block)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20154",
        "model_patch": "diff --git a/sympy/utilities/iterables.py b/sympy/utilities/iterables.py\nindex dd36dea304..4a01f52eab 100644\n--- a/sympy/utilities/iterables.py\n+++ b/sympy/utilities/iterables.py\n@@ -1802,9 +1802,10 @@ def partitions(n, m=None, k=None, size=False):\n         keys.append(r)\n     room = m - q - bool(r)\n     if size:\n-        yield sum(ms.values()), ms\n+        yield sum(ms.values()), ms.copy()\n     else:\n-        yield ms\n+        yield ms.copy()\n+\n \n     while keys != [1]:\n         # Reuse any 1's.\n@@ -1842,9 +1843,10 @@ def partitions(n, m=None, k=None, size=False):\n             break\n         room -= need\n         if size:\n-            yield sum(ms.values()), ms\n-        else:\n-            yield ms\n+    if size:\n+        yield sum(ms.values()), ms.copy()\n+    else:\n+        yield ms.copy()\n \n \n def ordered_partitions(n, m=None, sort=True):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20428",
        "model_patch": "diff --git a/sympy/polys/polytools.py b/sympy/polys/polytools.py\nindex 70112de3b6..5b4a8ef541 100644\n--- a/sympy/polys/polytools.py\n+++ b/sympy/polys/polytools.py\n@@ -2249,12 +2249,15 @@ def clear_denoms(self, convert=False):\n             raise OperationNotSupported(f, 'clear_denoms')\n \n         coeff, f = dom.to_sympy(coeff), f.per(result)\n-\n+        from sympy.polys.densebasic import dmp_strip\n+        f_rep_stripped = dmp_strip(f.rep.rep, f.rep.lev)\n+        f = f.__class__.new(DMP(f_rep_stripped, f.rep.dom, f.rep.lev), *f.gens)\n         if not convert or not dom.has_assoc_Ring:\n             return coeff, f\n         else:\n             return coeff, f.to_ring()\n \n+\n     def rat_clear_denoms(self, g):\n         \"\"\"\n         Clear denominators in a rational function ``f/g``.\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20438",
        "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 3c4aa86e36..a35cee340e 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -347,55 +347,16 @@ def _contains(self, other):\n             by the ``contains`` method.''' % (self, other)))\n \n     def is_subset(self, other):\n-        \"\"\"\n-        Returns True if ``self`` is a subset of ``other``.\n-\n-        Examples\n-        ========\n-\n-        >>> from sympy import Interval\n-        >>> Interval(0, 0.5).is_subset(Interval(0, 1))\n-        True\n-        >>> Interval(0, 1).is_subset(Interval(0, 1, left_open=True))\n-        False\n-\n-        \"\"\"\n         if not isinstance(other, Set):\n-            raise ValueError(\"Unknown argument '%s'\" % other)\n-\n-        # Handle the trivial cases\n-        if self == other:\n-            return True\n-        is_empty = self.is_empty\n-        if is_empty is True:\n-            return True\n-        elif fuzzy_not(is_empty) and other.is_empty:\n-            return False\n-        if self.is_finite_set is False and other.is_finite_set:\n-            return False\n-\n-        # Dispatch on subclass rules\n+            raise ValueError(\"other must be a Set, got %s\" % type(other))\n         ret = self._eval_is_subset(other)\n         if ret is not None:\n             return ret\n         ret = other._eval_is_superset(self)\n         if ret is not None:\n             return ret\n+        return fuzzy_and(s.is_subset(other) for s in self.args)\n \n-        # Use pairwise rules from multiple dispatch\n-        from sympy.sets.handlers.issubset import is_subset_sets\n-        ret = is_subset_sets(self, other)\n-        if ret is not None:\n-            return ret\n-\n-        # Fall back on computing the intersection\n-        # XXX: We shouldn't do this. A query like this should be handled\n-        # without evaluating new Set objects. It should be the other way round\n-        # so that the intersect method uses is_subset for evaluation.\n-        if self.intersect(other) == self:\n-            return True\n-\n-    def _eval_is_subset(self, other):\n         '''Returns a fuzzy bool for whether self is a subset of other.'''\n         return None\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20590",
        "model_patch": "diff --git a/sympy/core/symbol.py b/sympy/core/symbol.py\nindex 70e6953559..6976e2b988 100644\n--- a/sympy/core/symbol.py\n+++ b/sympy/core/symbol.py\n@@ -202,6 +202,7 @@ class Symbol(AtomicExpr, Boolean):\n \n     __slots__ = ('name',)\n \n+\n     is_Symbol = True\n     is_symbol = True\n \ndiff --git a/sympy/logic/boolalg.py b/sympy/logic/boolalg.py\nindex c01628fe58..23eb955000 100644\n--- a/sympy/logic/boolalg.py\n+++ b/sympy/logic/boolalg.py\n@@ -7,9 +7,10 @@\n from sympy.core.add import Add\n from sympy.core.basic import Basic\n from sympy.core.cache import cacheit\n-from sympy.core.compatibility import ordered, as_int\n-from sympy.core.decorators import sympify_method_args, sympify_return\n-from sympy.core.function import Application, Derivative\n+class Boolean(Basic):\n+    __slots__ = ()\n+    # Existing implementation of Boolean...\n+\n from sympy.core.numbers import Number\n from sympy.core.operations import LatticeOp\n from sympy.core.singleton import Singleton, S\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20801",
        "model_patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\nindex 79f6a7d165..ac7e5ee1a9 100644\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -2234,10 +2234,17 @@ def __rmod__(self, other):\n         return Rational.__rmod__(self, other)\n \n     def __eq__(self, other):\n+        from sympy.logic.boolalg import Boolean\n+        try:\n+            other = _sympify(other)\n+        except Exception:\n+            return NotImplemented\n+        if isinstance(other, Boolean):\n+            return bool(self) == bool(other)\n         if isinstance(other, int):\n-            return (self.p == other)\n+            return self.p == other\n         elif isinstance(other, Integer):\n-            return (self.p == other.p)\n+            return self.p == other.p\n         return Rational.__eq__(self, other)\n \n     def __ne__(self, other):\ndiff --git a/sympy/core/singleton.py b/sympy/core/singleton.py\nindex afede5fc33..c256df54a5 100644\n--- a/sympy/core/singleton.py\n+++ b/sympy/core/singleton.py\n@@ -180,15 +180,14 @@ def __new__(cls, *args, **kwargs):\n         S.register(result)\n         return result\n \n-    def __call__(self, *args, **kwargs):\n-        # Called when application code says SomeClass(), where SomeClass is a\n-        # class of which Singleton is the metaclas.\n-        # __call__ is invoked first, before __new__() and __init__().\n-        if self not in Singleton._instances:\n-            Singleton._instances[self] = \\\n-                super().__call__(*args, **kwargs)\n-                # Invokes the standard constructor of SomeClass.\n-        return Singleton._instances[self]\n+def __call__(self, *args, **kwargs):\n+    # Called when application code says SomeClass(), where SomeClass is a\n+    # class of which Singleton is the metaclass.\n+    # __call__ is invoked first, before __new__() and __init__().\n+    if self not in Singleton._instances:\n+        Singleton._instances[self] = super().__call__(*args, **kwargs)\n+    return Singleton._instances[self]\n+\n \n         # Inject pickling support.\n         def __getnewargs__(self):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-20916",
        "model_patch": "diff --git a/sympy/printing/pretty/pretty_symbology.py b/sympy/printing/pretty/pretty_symbology.py\nindex 3f7c4a2dc7..a6ace433d1 100644\n--- a/sympy/printing/pretty/pretty_symbology.py\n+++ b/sympy/printing/pretty/pretty_symbology.py\n@@ -515,6 +515,205 @@ def pretty_symbol(symb_name, bold_name=False):\n     if not _use_unicode:\n         return symb_name\n \n+    # Fix: if the symbol name is \"omega\" (as sometimes used in a vector printing context)\n+    # then use the Latin \"w\" instead of the Greek \u03c9.\n+    if name.lower() == \"omega\":\n+         name = \"w\"\n     name, sups, subs = split_super_sub(symb_name)\n \n     def translate(s, bold_name) :",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21379",
        "model_patch": "diff --git a/sympy/core/basic.py b/sympy/core/basic.py\nindex 3894f4fd1c..734324b76a 100644\n--- a/sympy/core/basic.py\n+++ b/sympy/core/basic.py\n@@ -910,20 +910,25 @@ def subs(self, *args, **kwargs):\n             sequence[i] = None if _aresame(*s) else tuple(s)\n         sequence = list(filter(None, sequence))\n \n-        if unordered:\n+    if unordered:\n+        from sympy.core.numbers import Number\n+        # If all substitution keys are numbers, avoid ordering because the\n+        # default_sort_key often causes piecewise elements (present via symbol\n+        # assumptions) to be processed into polynomial form which yields a\n+        # PolynomialError.\n+        if all(isinstance(k, Number) for k, v in sequence):\n+            sequence = list(sequence)\n+        else:\n             sequence = dict(sequence)\n-            # order so more complex items are first and items\n-            # of identical complexity are ordered so\n-            # f(x) < f(y) < x < y\n-            # \\___ 2 __/    \\_1_/  <- number of nodes\n-            #\n-            # For more complex ordering use an unordered sequence.\n+            # order so more complex items are first and items of identical\n+            # complexity are ordered so that f(x) < f(y) < x < y.\n             k = list(ordered(sequence, default=False, keys=(\n                 lambda x: -_nodes(x),\n                 lambda x: default_sort_key(x),\n-                )))\n+            )))\n             sequence = [(k, sequence[k]) for k in k]\n \n+\n         if kwargs.pop('simultaneous', False):  # XXX should this be the default for dict subs?\n             reps = {}\n             rv = self\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21596",
        "model_patch": "diff --git a/sympy/sets/sets.py b/sympy/sets/sets.py\nindex 9f19ecf2ab..013dc21644 100644\n--- a/sympy/sets/sets.py\n+++ b/sympy/sets/sets.py\n@@ -1388,8 +1388,12 @@ def _inf(self):\n     def _sup(self):\n         raise NotImplementedError()\n \n-    def _contains(self, other):\n-        return And(*[set.contains(other) for set in self.args])\n+def _contains(self, other):\n+    for s in self.args:\n+        if fuzzy_bool(s.contains(other)) is False:\n+            return S.false\n+    return S.true\n+\n \n     def __iter__(self):\n         sets_sift = sift(self.args, lambda x: x.is_iterable)\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21612",
        "model_patch": "diff --git a/sympy/printing/str.py b/sympy/printing/str.py\nindex c3fdcdd435..71cfcdadfa 100644\n--- a/sympy/printing/str.py\n+++ b/sympy/printing/str.py\n@@ -147,11 +147,16 @@ def _print_EulerGamma(self, expr):\n     def _print_Exp1(self, expr):\n         return 'E'\n \n-    def _print_ExprCondPair(self, expr):\n-        return '(%s, %s)' % (self._print(expr.expr), self._print(expr.cond))\n-\n-    def _print_Function(self, expr):\n-        return expr.func.__name__ + \"(%s)\" % self.stringify(expr.args, \", \")\n+    a = []\n+    for arg in args:\n+        s = self.parenthesize(arg, PREC, strict=False)\n+        # if the argument is a power with exponent -1, then force grouping\n+        if arg.is_Pow and arg.exp == -1:\n+            # if not already enclosed in parentheses, add them.\n+            if not (s.startswith('(') and s.endswith(')')):\n+                s = \"(\" + s + \")\"\n+        a.append(s)\n+    return \"*\".join(a)\n \n     def _print_GoldenRatio(self, expr):\n         return 'GoldenRatio'\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21847",
        "model_patch": "diff --git a/sympy/polys/monomials.py b/sympy/polys/monomials.py\nindex 0e84403307..04d39d58cd 100644\n--- a/sympy/polys/monomials.py\n+++ b/sympy/polys/monomials.py\n@@ -127,7 +127,8 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(powers.values()) >= min_degree:\n+\n                     monomials_list_comm.append(Mul(*item))\n             yield from set(monomials_list_comm)\n         else:\n@@ -139,7 +140,8 @@ def itermonomials(variables, max_degrees, min_degrees=None):\n                 for variable in item:\n                     if variable != 1:\n                         powers[variable] += 1\n-                if max(powers.values()) >= min_degree:\n+                if sum(powers.values()) >= min_degree:\n+\n                     monomials_list_non_comm.append(Mul(*item))\n             yield from set(monomials_list_non_comm)\n     else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-21930",
        "model_patch": "diff --git a/sympy/physics/secondquant.py b/sympy/physics/secondquant.py\nindex d19ee2fc63..dec70a9c24 100644\n--- a/sympy/physics/secondquant.py\n+++ b/sympy/physics/secondquant.py\n@@ -466,8 +466,9 @@ def apply_operator(self, state):\n         y*CreateBoson(x)\n         >>> B(0).apply_operator(BKet((n,)))\n         sqrt(n)*FockStateBosonKet((n - 1,))\n-        \"\"\"\n-        if not self.is_symbolic and isinstance(state, FockStateKet):\n+    def _latex(self, printer):\n+        return \"{b^\\\\dagger_{%s}}\" % self.state.name\n+\n             element = self.state\n             amp = sqrt(state[element] + 1)\n             return amp*state.up(element)\n@@ -939,7 +940,8 @@ def __repr__(self):\n         return \"CreateFermion(%s)\" % self.state\n \n     def _latex(self, printer):\n-        return \"a^\\\\dagger_{%s}\" % self.state.name\n+        return \"{a^\\\\dagger_{%s}}\" % self.state.name\n+\n \n Fd = CreateFermion\n F = AnnihilateFermion\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-22080",
        "model_patch": "diff --git a/sympy/utilities/lambdify.py b/sympy/utilities/lambdify.py\nindex 0ed6ce2eb1..9f294552a9 100644\n--- a/sympy/utilities/lambdify.py\n+++ b/sympy/utilities/lambdify.py\n@@ -770,6 +770,416 @@ def _lambdifygenerated(x):\n         else:\n             modules = [\"numpy\", \"scipy\"]\n \n+    # Fix for Mod function lambdify bug:\n+    # When modules==[] (empty), the printer ends up using the Python '%' operator\n+    # (which returns a non-negative remainder) and merges a multiplier into Mod.\n+    # Instead, we want to use sympy's Mod function. So if modules is [], we set it\n+    # to \"sympy\" so that the proper printer and namespace are used.\n+    if modules == []:\n+        modules = \"sympy\"\n     # Get the needed namespaces.\n     namespaces = []\n     # First find any function implementations",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-22456",
        "model_patch": "diff --git a/sympy/codegen/ast.py b/sympy/codegen/ast.py\nindex a02714b174..766492b17e 100644\n--- a/sympy/codegen/ast.py\n+++ b/sympy/codegen/ast.py\n@@ -895,7 +895,8 @@ class String(Token):\n \n     \"\"\"\n     __slots__ = ('text',)\n-    not_in_args = ['text']\n+    not_in_args = []\n+\n     is_Atom = True\n \n     @classmethod\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-22714",
        "model_patch": "diff --git a/sympy/geometry/point.py b/sympy/geometry/point.py\nindex 73c20334d0..3d9687dbbd 100644\n--- a/sympy/geometry/point.py\n+++ b/sympy/geometry/point.py\n@@ -152,8 +152,15 @@ def __new__(cls, *args, **kwargs):\n                         'warn' or 'ignore'.'''))\n         if any(coords[dim:]):\n             raise ValueError('Nonzero coordinates cannot be removed.')\n-        if any(a.is_number and im(a) for a in coords):\n-            raise ValueError('Imaginary coordinates are not permitted.')\n+        if evaluate:\n+            if any(a.is_number and im(a) for a in coords):\n+                raise ValueError('Imaginary coordinates are not permitted.')\n+        else:\n+            # In non-evaluated mode, the im(...) call might not simplify.\n+            # Check explicitly for the presence of the imaginary unit.\n+            if any(a.has(S.ImaginaryUnit) for a in coords):\n+                raise ValueError('Imaginary coordinates are not permitted.')\n+\n         if not all(isinstance(a, Expr) for a in coords):\n             raise TypeError('Coordinates must be valid SymPy expressions.')\n \n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-22914",
        "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex 3a72ab606c..53cc4e88d4 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -439,6 +439,240 @@ def _print_Indexed(self, expr):\n \n     def _print_Pow(self, expr, rational=False):\n         return self._hprint_Pow(expr, rational=rational)\n+   def _print_Min(self, expr):\n+        return \"min({})\".format(\", \".join(self._print(arg) for arg in expr.args))\n+    def _print_Max(self, expr):\n+        return \"max({})\".format(\", \".join(self._print(arg) for arg in expr.args))\n     def _print_Rational(self, expr):\n         return '{}/{}'.format(expr.p, expr.q)",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23262",
        "model_patch": "diff --git a/sympy/printing/pycode.py b/sympy/printing/pycode.py\nindex 1877c3f92a..ec33c1b774 100644\n--- a/sympy/printing/pycode.py\n+++ b/sympy/printing/pycode.py\n@@ -75,6 +75,283 @@ def _print_known_const(self, expr):\n \n \n class AbstractPythonCodePrinter(CodePrinter):\n+   def _print_Tuple(self, expr):\n+        # When printing a one-element tuple, add the trailing comma\n+        if len(expr) == 1:\n+            return \"(\" + self._print(expr[0]) + \",)\"\n+        else:\n+            return \"(\" + \", \".join(self._print(arg) for arg in expr) + \")\"\n     printmethod = \"_pythoncode\"\n     language = \"Python\"\n     reserved_words = _kw",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23413",
        "model_patch": "diff --git a/sympy/matrices/normalforms.py b/sympy/matrices/normalforms.py\nindex 7bce95d230..c9a4c2252a 100644\n--- a/sympy/matrices/normalforms.py\n+++ b/sympy/matrices/normalforms.py\n@@ -124,4 +124,9 @@ def hermite_normal_form(A, *, D=None, check_rank=False):\n     # Accept any of Python int, SymPy Integer, and ZZ itself:\n     if D is not None and not ZZ.of_type(D):\n         D = ZZ(int(D))\n-    return _hnf(A._rep, D=D, check_rank=check_rank).to_Matrix()\n+    # Convert input matrix A to a DomainMatrix to ensure that it retains the full numeric\n+    # and structural information. Without this conversion, a user-transformed input (e.g. via flips or transposes)\n+    # might have an internal representation (_rep) inconsistent with its intended rank.\n+    dM = _to_domain(A)\n+    return _hnf(dM.rep, D=D, check_rank=check_rank).to_Matrix()\n+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23534",
        "model_patch": "diff --git a/sympy/core/function.py b/sympy/core/function.py\nindex 710c5cfc74..a743a262b1 100644\n--- a/sympy/core/function.py\n+++ b/sympy/core/function.py\n@@ -2375,13 +2375,17 @@ def _eval_subs(self, old, new):\n             # handled by replacements from here on\n             i = self.variables.index(old)\n             for j in range(i, len(self.variables)):\n-                pt[j] = pt[j]._subs(old, new)\n+                pt[j] = pt[j].subs(old, new)\n+\n             return self.func(self.expr, self.variables, pt)\n-        v = [i._subs(old, new) for i in self.variables]\n+       v = [i.subs(old, new) for i in self.variables]\n+\n         if v != list(self.variables):\n             return self.func(self.expr, self.variables + (old,), pt + [new])\n-        expr = self.expr._subs(old, new)\n-        pt = [i._subs(old, new) for i in self.point]\n+       expr = self.expr.subs(old, new)\n+\n+       pt = [i.subs(old, new) for i in self.point]\n+\n         return self.func(expr, v, pt)\n \n     def _eval_derivative(self, s):\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23824",
        "model_patch": "diff --git a/sympy/physics/hep/gamma_matrices.py b/sympy/physics/hep/gamma_matrices.py\nindex 23284e4a92..ca82e3963e 100644\n--- a/sympy/physics/hep/gamma_matrices.py\n+++ b/sympy/physics/hep/gamma_matrices.py\n@@ -694,8 +694,9 @@ def kahane_simplify(expression):\n \n     # If `first_dum_pos` is not zero, it means that there are trailing free gamma\n     # matrices in front of `expression`, so multiply by them:\n-    for i in range(0, first_dum_pos):\n-        [ri.insert(0, free_pos[i]) for ri in resulting_indices]\n+for i in reversed(range(0, first_dum_pos)):\n+    [ri.insert(0, free_pos[i]) for ri in resulting_indices]\n+\n \n     resulting_expr = S.Zero\n     for i in resulting_indices:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-23950",
        "model_patch": "diff --git a/sympy/sets/contains.py b/sympy/sets/contains.py\nindex b2d4268d12..7fd443e31a 100644\n--- a/sympy/sets/contains.py\n+++ b/sympy/sets/contains.py\n@@ -45,4 +45,5 @@ def binary_symbols(self):\n             isinstance(i, (Eq, Ne))])\n \n     def as_set(self):\n-        raise NotImplementedError()\n+        return self.args[1]\n+\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24066",
        "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex 3daf84c108..ca103a52f5 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -189,11 +189,18 @@ def _collect_factor_and_dimension(self, expr):\n                 factor /= ifactor**count\n                 dim /= idim**count\n             return factor, dim\n-        elif isinstance(expr, Function):\n-            fds = [self._collect_factor_and_dimension(\n-                arg) for arg in expr.args]\n-            return (expr.func(*(f[0] for f in fds)),\n-                    *(d[1] for d in fds))\n+elif isinstance(expr, Function):\n+    # For standard functions (such as exp, log, sin, etc.) the output is\n+    # defined to be dimensionless even if the input carries a (possibly\n+    # unit-derived) dimension. This ensures that expressions like\n+    # exp(expr) yield Dimension(1) as required.\n+    from sympy import exp, log, sin, cos, tan, asin, acos, atan, sinh, cosh, tanh\n+    fds = [self._collect_factor_and_dimension(arg) for arg in expr.args]\n+    if expr.func in {exp, log, sin, cos, tan, asin, acos, atan, sinh, cosh, tanh}:\n+        return expr.func(*(f[0] for f in fds)), Dimension(1)\n+    else:\n+        return expr.func(*(f[0] for f in fds)), *[d[1] for d in fds]\n+\n         elif isinstance(expr, Dimension):\n             return S.One, expr\n         else:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24213",
        "model_patch": "diff --git a/sympy/physics/units/unitsystem.py b/sympy/physics/units/unitsystem.py\nindex a436880c4b..e784947db7 100644\n--- a/sympy/physics/units/unitsystem.py\n+++ b/sympy/physics/units/unitsystem.py\n@@ -173,15 +173,16 @@ def _collect_factor_and_dimension(self, expr):\n         elif isinstance(expr, Add):\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n             for addend in expr.args[1:]:\n-                addend_factor, addend_dim = \\\n-                    self._collect_factor_and_dimension(addend)\n-                if dim != addend_dim:\n+                addend_factor, addend_dim = self._collect_factor_and_dimension(addend)\n+                # Use dimension equivalence instead of strict equality.\n+                if not dim.equals(addend_dim):\n                     raise ValueError(\n                         'Dimension of \"{}\" is {}, '\n                         'but it should be {}'.format(\n                             addend, addend_dim, dim))\n                 factor += addend_factor\n             return factor, dim\n+\n         elif isinstance(expr, Derivative):\n             factor, dim = self._collect_factor_and_dimension(expr.args[0])\n             for independent, count in expr.variable_count:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24443",
        "model_patch": "diff --git a/sympy/combinatorics/homomorphisms.py b/sympy/combinatorics/homomorphisms.py\nindex bb7bdf32ba..ce0dc5488b 100644\n--- a/sympy/combinatorics/homomorphisms.py\n+++ b/sympy/combinatorics/homomorphisms.py\n@@ -333,16 +333,26 @@ def _image(r):\n             # both indices\n             while i < len(r):\n                 power = r_arr[j][1]\n-                if isinstance(domain, PermutationGroup) and r[i] in gens:\n-                    s = domain.generators[gens.index(r[i])]\n+                if isinstance(domain, PermutationGroup):\n+                    if r[i] in gens:\n+                        s = domain.generators[gens.index(r[i])]\n+                    elif r[i]**-1 in gens:\n+                        s = domain.generators[gens.index(r[i]**-1)]\n+                        power = -power\n+                    else:\n+                        s = r[i]\n                 else:\n                     s = r[i]\n+\n                 if s in images:\n                     w = w*images[s]**power\n                 elif s**-1 in images:\n                     w = w*images[s**-1]**power\n                 i += abs(power)\n                 j += 1\n+\n+                i += abs(power)\n+                j += 1\n             return w\n \n     for r in rels:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24539",
        "model_patch": "diff --git a/sympy/polys/rings.py b/sympy/polys/rings.py\nindex 12bd2fc920..2fb29cd1d1 100644\n--- a/sympy/polys/rings.py\n+++ b/sympy/polys/rings.py\n@@ -616,13 +616,14 @@ def set_ring(self, new_ring):\n             return new_ring.from_dict(self, self.ring.domain)\n \n     def as_expr(self, *symbols):\n-        if symbols and len(symbols) != self.ring.ngens:\n-            raise ValueError(\"not enough symbols, expected %s got %s\" % (self.ring.ngens, len(symbols)))\n+        if symbols:\n+            if len(symbols) != self.ring.ngens:\n+                raise ValueError(\"expected %s symbols, got %s\" % (self.ring.ngens, len(symbols)))\n         else:\n             symbols = self.ring.symbols\n-\n         return expr_from_dict(self.as_expr_dict(), *symbols)\n \n+\n     def as_expr_dict(self):\n         to_sympy = self.ring.domain.to_sympy\n         return {monom: to_sympy(coeff) for monom, coeff in self.iterterms()}\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24562",
        "model_patch": "diff --git a/sympy/core/numbers.py b/sympy/core/numbers.py\nindex 52f7ea45ad..592778091c 100644\n--- a/sympy/core/numbers.py\n+++ b/sympy/core/numbers.py\n@@ -1625,19 +1625,18 @@ def __new__(cls, p, q=None, gcd=None):\n             q = 1\n             gcd = 1\n \n-        if not isinstance(p, SYMPY_INTS):\n-            p = Rational(p)\n-            q *= p.q\n-            p = p.p\n-        else:\n-            p = int(p)\n+if not isinstance(p, SYMPY_INTS):\n+    p = Rational(p)\n+else:\n+    p = Integer(p)\n+if not isinstance(q, SYMPY_INTS):\n+    q = Rational(q)\n+else:\n+    q = Integer(q)\n+new_p = p.p * q.q\n+new_q = p.q * q.p\n+p, q = new_p, new_q\n \n-        if not isinstance(q, SYMPY_INTS):\n-            q = Rational(q)\n-            p *= q.q\n-            q = q.p\n-        else:\n-            q = int(q)\n \n         # p and q are now ints\n         if q == 0:\n",
        "model_name_or_path": "o3-mini"
    },
    {
        "instance_id": "sympy__sympy-24661",
        "model_patch": "diff --git a/sympy/parsing/sympy_parser.py b/sympy/parsing/sympy_parser.py\nindex 52711d1324..c4b3e52018 100644\n--- a/sympy/parsing/sympy_parser.py\n+++ b/sympy/parsing/sympy_parser.py\n@@ -1191,6 +1191,1308 @@ def visit_Call(self, node):\n         if isinstance(node.func, ast.Name) and node.func.id in self.functions:\n             new_node.keywords.append(ast.keyword(arg='evaluate', value=ast.NameConstant(value=False, ctx=ast.Load())))\n         return new_node\n+   def visit_Compare(self, node):\n+        # Transform a comparison (e.g., \"1 < 2\") into an unevaluated call \n+        # to the appropriate Sympy relational class (e.g., Lt(1, 2, evaluate=False)).\n+        # Note: Only single comparisons are supported.\n+        if len(node.ops) != 1:\n+            # For chained comparisons, let the generic visit handle it.\n+            return self.generic_visit(node)\n+        op_node = node.ops[0]\n+        if isinstance(op_node, ast.Lt):\n+            func_id = \"Lt\"\n+        elif isinstance(op_node, ast.LtE):\n+            func_id = \"Le\"\n+        elif isinstance(op_node, ast.Gt):\n+            func_id = \"Gt\"\n+        elif isinstance(op_node, ast.GtE):\n+            func_id = \"Ge\"\n+        elif isinstance(op_node, ast.Eq):\n+            func_id = \"Eq\"\n+        elif isinstance(op_node, ast.NotEq):\n+            func_id = \"Ne\"\n+        else:\n+            return self.generic_visit(node)\n+        left = self.visit(node.left)\n+        right = self.visit(node.comparators[0])\n+        new_node = ast.Call(\n+            func=ast.Name(id=func_id, ctx=ast.Load()),\n+            args=[left, right],\n+            keywords=[ast.keyword(arg='evaluate', value=ast.NameConstant(value=False, ctx=ast.Load()))],\n+        )\n+        return ast.copy_location(new_node, node)\n _transformation = {  # items can be added but never re-ordered",
        "model_name_or_path": "o3-mini"
    }
]